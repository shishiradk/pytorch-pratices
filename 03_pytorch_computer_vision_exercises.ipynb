{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/shishiradk/pytorch-pratices/blob/main/03_pytorch_computer_vision_exercises.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 03. PyTorch Computer Vision Exercises\n",
        "\n",
        "The following is a collection of exercises based on computer vision fundamentals in PyTorch.\n",
        "\n",
        "They're a bunch of fun.\n",
        "\n",
        "You're going to get to write plenty of code!\n",
        "\n",
        "## Resources\n",
        "\n",
        "1. These exercises are based on [notebook 03 of the Learn PyTorch for Deep Learning course](https://www.learnpytorch.io/03_pytorch_computer_vision/).\n",
        "2. See a live [walkthrough of the solutions (errors and all) on YouTube](https://youtu.be/_PibmqpEyhA).\n",
        "  * **Note:** Going through these exercises took me just over 3 hours of solid coding, so you should expect around the same.\n",
        "3. See [other solutions on the course GitHub](https://github.com/mrdbourke/pytorch-deep-learning/tree/main/extras/solutions)."
      ],
      "metadata": {
        "id": "Vex99np2wFVt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Check for GPU\n",
        "!nvidia-smi"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GaeYzOTLwWh2",
        "outputId": "8f8a2ab8-c80c-4cb9-d43d-5b1dac3e33a1"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tue Jan  6 08:02:59 2026       \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 550.54.15              Driver Version: 550.54.15      CUDA Version: 12.4     |\n",
            "|-----------------------------------------+------------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                        |               MIG M. |\n",
            "|=========================================+========================+======================|\n",
            "|   0  Tesla T4                       Off |   00000000:00:04.0 Off |                    0 |\n",
            "| N/A   66C    P8             11W /   70W |       0MiB /  15360MiB |      0%      Default |\n",
            "|                                         |                        |                  N/A |\n",
            "+-----------------------------------------+------------------------+----------------------+\n",
            "                                                                                         \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                              |\n",
            "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
            "|        ID   ID                                                               Usage      |\n",
            "|=========================================================================================|\n",
            "|  No running processes found                                                             |\n",
            "+-----------------------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Import torch\n",
        "import torch\n",
        "\n",
        "# Exercises require PyTorch > 1.10.0\n",
        "print(torch.__version__)\n",
        "\n",
        "# TODO: Setup device agnostic code\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DNwZLMbCzJLk",
        "outputId": "ecc2e275-7bbf-4df9-9c6e-19933016a4b6"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.9.0+cu126\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. What are 3 areas in industry where computer vision is currently being used?"
      ],
      "metadata": {
        "id": "FSFX7tc1w-en"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Self driving car\n",
        "2. Security\n",
        "3. Health Care"
      ],
      "metadata": {
        "id": "9TAQaVOIDo1o"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. Search \"what is overfitting in machine learning\" and write down a sentence about what you find."
      ],
      "metadata": {
        "id": "oBK-WI6YxDYa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Overfitting is the condition where model learnins training data too well but cant answer the slightly different data."
      ],
      "metadata": {
        "id": "p9GueTYwCToG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. Search \"ways to prevent overfitting in machine learning\", write down 3 of the things you find and a sentence about each.\n",
        "> **Note:** there are lots of these, so don't worry too much about all of them, just pick 3 and start with those."
      ],
      "metadata": {
        "id": "XeYFEqw8xK26"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. training data should be enough to learn the true pattern instead of meamorizing\n",
        "2. complex model overfit easily so simplify , for eg: using fewer feature (only necessarey one),\n",
        "3. Cross validation"
      ],
      "metadata": {
        "id": "GNLoBXslEQ2i"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4. Spend 20-minutes reading and clicking through the [CNN Explainer website](https://poloclub.github.io/cnn-explainer/).\n",
        "\n",
        "* Upload your own example image using the \"upload\" button on the website and see what happens in each layer of a CNN as your image passes through it."
      ],
      "metadata": {
        "id": "DKdEEFEqxM-8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5. Load the [`torchvision.datasets.MNIST()`](https://pytorch.org/vision/stable/generated/torchvision.datasets.MNIST.html#torchvision.datasets.MNIST) train and test datasets."
      ],
      "metadata": {
        "id": "lvf-3pODxXYI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torchvision\n",
        "from torchvision import datasets\n",
        "from torchvision import transforms"
      ],
      "metadata": {
        "id": "SHjeuN81bHza"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get the Mnist train dataset\n",
        "train_data = datasets.MNIST(root=\".\",\n",
        "                            train=True,\n",
        "                            download=True,\n",
        "                            transform=transforms.ToTensor())\n",
        "\n",
        "# Get the MNIST test datset\n",
        "test_data = datasets.MNIST(root=\".\",\n",
        "                           train=False,\n",
        "                           download=True,\n",
        "                           transform=transforms.ToTensor())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hDAq6GNbIIBp",
        "outputId": "57111cbb-6e60-47dc-f47d-2ce595ade821"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 9.91M/9.91M [00:00<00:00, 15.1MB/s]\n",
            "100%|██████████| 28.9k/28.9k [00:00<00:00, 505kB/s]\n",
            "100%|██████████| 1.65M/1.65M [00:00<00:00, 4.72MB/s]\n",
            "100%|██████████| 4.54k/4.54k [00:00<00:00, 8.86MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_data, test_data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0uZwS88qI5wA",
        "outputId": "94a3ec4f-4a95-49da-babf-0289e3c91500"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(Dataset MNIST\n",
              "     Number of datapoints: 60000\n",
              "     Root location: .\n",
              "     Split: Train\n",
              "     StandardTransform\n",
              " Transform: ToTensor(),\n",
              " Dataset MNIST\n",
              "     Number of datapoints: 10000\n",
              "     Root location: .\n",
              "     Split: Test\n",
              "     StandardTransform\n",
              " Transform: ToTensor())"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(train_data),len(test_data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dcOko-mkI5qU",
        "outputId": "faa1d6fb-c559-47de-cc78-159442b8cb74"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(60000, 10000)"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Data is in tuple form (image, label)\n",
        "img = train_data[0][0]\n",
        "label = train_data[0][1]\n",
        "print(f\"Image:\\n {img}\")\n",
        "print(f\"label:\\n {label}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0XIb4b6zI5cC",
        "outputId": "7798070c-52dc-4b99-c618-982a944b2fd6"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image:\n",
            " tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000],\n",
            "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000],\n",
            "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000],\n",
            "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000],\n",
            "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000],\n",
            "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000, 0.0118, 0.0706, 0.0706, 0.0706,\n",
            "          0.4941, 0.5333, 0.6863, 0.1020, 0.6510, 1.0000, 0.9686, 0.4980,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000],\n",
            "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.1176, 0.1412, 0.3686, 0.6039, 0.6667, 0.9922, 0.9922, 0.9922,\n",
            "          0.9922, 0.9922, 0.8824, 0.6745, 0.9922, 0.9490, 0.7647, 0.2510,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000],\n",
            "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.1922,\n",
            "          0.9333, 0.9922, 0.9922, 0.9922, 0.9922, 0.9922, 0.9922, 0.9922,\n",
            "          0.9922, 0.9843, 0.3647, 0.3216, 0.3216, 0.2196, 0.1529, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000],\n",
            "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0706,\n",
            "          0.8588, 0.9922, 0.9922, 0.9922, 0.9922, 0.9922, 0.7765, 0.7137,\n",
            "          0.9686, 0.9451, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000],\n",
            "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.3137, 0.6118, 0.4196, 0.9922, 0.9922, 0.8039, 0.0431, 0.0000,\n",
            "          0.1686, 0.6039, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000],\n",
            "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0549, 0.0039, 0.6039, 0.9922, 0.3529, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000],\n",
            "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.5451, 0.9922, 0.7451, 0.0078, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000],\n",
            "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0431, 0.7451, 0.9922, 0.2745, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000],\n",
            "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000, 0.1373, 0.9451, 0.8824, 0.6275,\n",
            "          0.4235, 0.0039, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000],\n",
            "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.3176, 0.9412, 0.9922,\n",
            "          0.9922, 0.4667, 0.0980, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000],\n",
            "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.1765, 0.7294,\n",
            "          0.9922, 0.9922, 0.5882, 0.1059, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000],\n",
            "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0627,\n",
            "          0.3647, 0.9882, 0.9922, 0.7333, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000],\n",
            "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.9765, 0.9922, 0.9765, 0.2510, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000],\n",
            "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.1804, 0.5098,\n",
            "          0.7176, 0.9922, 0.9922, 0.8118, 0.0078, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000],\n",
            "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000, 0.1529, 0.5804, 0.8980, 0.9922,\n",
            "          0.9922, 0.9922, 0.9804, 0.7137, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000],\n",
            "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0941, 0.4471, 0.8667, 0.9922, 0.9922, 0.9922,\n",
            "          0.9922, 0.7882, 0.3059, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000],\n",
            "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0902, 0.2588, 0.8353, 0.9922, 0.9922, 0.9922, 0.9922, 0.7765,\n",
            "          0.3176, 0.0078, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000],\n",
            "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0706, 0.6706,\n",
            "          0.8588, 0.9922, 0.9922, 0.9922, 0.9922, 0.7647, 0.3137, 0.0353,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000],\n",
            "         [0.0000, 0.0000, 0.0000, 0.0000, 0.2157, 0.6745, 0.8863, 0.9922,\n",
            "          0.9922, 0.9922, 0.9922, 0.9569, 0.5216, 0.0431, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000],\n",
            "         [0.0000, 0.0000, 0.0000, 0.0000, 0.5333, 0.9922, 0.9922, 0.9922,\n",
            "          0.8314, 0.5294, 0.5176, 0.0627, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000],\n",
            "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000],\n",
            "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000],\n",
            "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000]]])\n",
            "label:\n",
            " 5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#checking shapes of our data\n",
        "print(f\"Image shape: {img.shape} -> [color_channels, height, width] (CHW)\")\n",
        "print(f\"label: {label} -> no shape, due to being integer\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oYoOFxUiJY80",
        "outputId": "28c5fb20-bac7-4aa3-b3e8-8aa685f85e73"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image shape: torch.Size([1, 28, 28]) -> [color_channels, height, width] (CHW)\n",
            "label: 5 -> no shape, due to being integer\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Get the classes names from the datset\n",
        "class_names = train_data.classes\n",
        "class_names"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0y7tMp0kJY5Y",
        "outputId": "cce9f6a9-648c-47dc-c933-1ec04d10dbc9"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['0 - zero',\n",
              " '1 - one',\n",
              " '2 - two',\n",
              " '3 - three',\n",
              " '4 - four',\n",
              " '5 - five',\n",
              " '6 - six',\n",
              " '7 - seven',\n",
              " '8 - eight',\n",
              " '9 - nine']"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 6. Visualize at least 5 different samples of the MNIST training dataset."
      ],
      "metadata": {
        "id": "qxZW-uAbxe_F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "for i in range(5):\n",
        "  img = train_data[i][0]\n",
        "  print(img.shape)\n",
        "  img_squeeze = img.squeeze()\n",
        "  print(img_squeeze.shape)\n",
        "  label = train_data[i][1]\n",
        "  plt.figure(figsize=(3,3))\n",
        "  plt.imshow(img_squeeze, cmap=\"gray\")\n",
        "  plt.title(label)\n",
        "  plt.axis(False)"
      ],
      "metadata": {
        "id": "QVFsYi1PbItE",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "82ddc33f-4abd-42eb-d94d-9042715a3d0c"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1, 28, 28])\n",
            "torch.Size([28, 28])\n",
            "torch.Size([1, 28, 28])\n",
            "torch.Size([28, 28])\n",
            "torch.Size([1, 28, 28])\n",
            "torch.Size([28, 28])\n",
            "torch.Size([1, 28, 28])\n",
            "torch.Size([28, 28])\n",
            "torch.Size([1, 28, 28])\n",
            "torch.Size([28, 28])\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 300x300 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 300x300 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 300x300 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 300x300 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 300x300 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 7. Turn the MNIST train and test datasets into dataloaders using `torch.utils.data.DataLoader`, set the `batch_size=32`."
      ],
      "metadata": {
        "id": "JAPDzW0wxhi3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create train dataloader\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "train_dataloader = DataLoader(dataset=train_data,\n",
        "                              batch_size=32,\n",
        "                              shuffle=True)\n",
        "\n",
        "test_dataloader = DataLoader(dataset=test_data,\n",
        "                             batch_size=32,\n",
        "                             shuffle= False)"
      ],
      "metadata": {
        "id": "ALA6MPcFbJXQ"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataloader, test_dataloader"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y-2KM5QlLg0z",
        "outputId": "82451ce0-5921-41c8-ecd6-2ce58cf3aeb4"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(<torch.utils.data.dataloader.DataLoader at 0x7c09593addc0>,\n",
              " <torch.utils.data.dataloader.DataLoader at 0x7c094c128770>)"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for sample in next(iter(train_dataloader)):\n",
        "  print(sample.shape)\n",
        ""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MGqP_Jo8Lp8k",
        "outputId": "e1d7e501-d39b-4677-8229-323a4c643d44"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([32, 1, 28, 28])\n",
            "torch.Size([32])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(train_dataloader), len(test_dataloader)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uF6A62ecLpeP",
        "outputId": "fa4c432d-b052-4a44-eef8-c2c66dd16f7d"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1875, 313)"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 8. Recreate `model_2` used in notebook 03 (the same model from the [CNN Explainer website](https://poloclub.github.io/cnn-explainer/), also known as TinyVGG) capable of fitting on the MNIST dataset."
      ],
      "metadata": {
        "id": "bCCVfXk5xjYS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch import nn\n",
        "class MNIST_model(torch.nn.Module):\n",
        "  \"\"\"Model capable of predicting on MNIST datset.\"\"\"\n",
        "  def __init__(self, input_shape: int, hidden_units: int, output_shape: int):\n",
        "    super().__init__()\n",
        "    self.conv_block_1 = nn.Sequential(\n",
        "        nn.Conv2d(in_channels=input_shape,\n",
        "                  out_channels=hidden_units,\n",
        "                  kernel_size=3,\n",
        "                  stride=1,\n",
        "                  padding=1),\n",
        "        nn.ReLU(),\n",
        "        nn.Conv2d(in_channels=hidden_units,\n",
        "                  out_channels=hidden_units,\n",
        "                  kernel_size=3,\n",
        "                  stride=1,\n",
        "                  padding=1),\n",
        "        nn.ReLU(),\n",
        "        nn.MaxPool2d(kernel_size=2)\n",
        "    )\n",
        "    self.conv_block_2 = nn.Sequential(\n",
        "        nn.Conv2d(in_channels=hidden_units,\n",
        "                  out_channels=hidden_units,\n",
        "                  kernel_size=3,\n",
        "                  stride=1,\n",
        "                  padding=1),\n",
        "        nn.ReLU(),\n",
        "        nn.Conv2d(in_channels=hidden_units,\n",
        "                  out_channels=hidden_units,\n",
        "                  kernel_size=3,\n",
        "                  stride=1,\n",
        "                  padding=1),\n",
        "        nn.ReLU(),\n",
        "        nn.MaxPool2d(kernel_size=2)\n",
        "    )\n",
        "    self.classifier = nn.Sequential(\n",
        "        nn.Flatten(),\n",
        "        nn.Linear(in_features=hidden_units*7*7,\n",
        "                  out_features=output_shape)\n",
        "    )\n",
        "\n",
        "  def forward(self, x ):\n",
        "    x= self.conv_block_1(x)\n",
        "    x = self.conv_block_2(x)\n",
        "    x = self.classifier(x)\n",
        "    return x"
      ],
      "metadata": {
        "id": "5IKNF22XbKYS"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "print(f\"Using device: {device}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GIEZ-kgSZnYb",
        "outputId": "c0ee8282-7691-4429-c9f0-585062d94426"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = MNIST_model(input_shape=1,\n",
        "                    hidden_units=10,\n",
        "                    output_shape=10).to(device)\n",
        "model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8HmKQr7TZcXW",
        "outputId": "21891ad2-1c21-45fa-f51b-1bf9beeab1de"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "MNIST_model(\n",
              "  (conv_block_1): Sequential(\n",
              "    (0): Conv2d(1, 10, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (1): ReLU()\n",
              "    (2): Conv2d(10, 10, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (3): ReLU()\n",
              "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  )\n",
              "  (conv_block_2): Sequential(\n",
              "    (0): Conv2d(10, 10, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (1): ReLU()\n",
              "    (2): Conv2d(10, 10, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (3): ReLU()\n",
              "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  )\n",
              "  (classifier): Sequential(\n",
              "    (0): Flatten(start_dim=1, end_dim=-1)\n",
              "    (1): Linear(in_features=490, out_features=10, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 9. Train the model you built in exercise 8. for 5 epochs on CPU and GPU and see how long it takes on each."
      ],
      "metadata": {
        "id": "sf_3zUr7xlhy"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "jSo6vVWFbNLD"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 10. Make predictions using your trained model and visualize at least 5 of them comparing the prediciton to the target label."
      ],
      "metadata": {
        "id": "w1CsHhPpxp1w"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "_YGgZvSobNxu"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 11. Plot a confusion matrix comparing your model's predictions to the truth labels."
      ],
      "metadata": {
        "id": "qQwzqlBWxrpG"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "vSrXiT_AbQ6e"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 12. Create a random tensor of shape `[1, 3, 64, 64]` and pass it through a `nn.Conv2d()` layer with various hyperparameter settings (these can be any settings you choose), what do you notice if the `kernel_size` parameter goes up and down?"
      ],
      "metadata": {
        "id": "lj6bDhoWxt2y"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "leCTsqtSbR5P"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 13. Use a model similar to the trained `model_2` from notebook 03 to make predictions on the test [`torchvision.datasets.FashionMNIST`](https://pytorch.org/vision/main/generated/torchvision.datasets.FashionMNIST.html) dataset.\n",
        "* Then plot some predictions where the model was wrong alongside what the label of the image should've been.\n",
        "* After visualing these predictions do you think it's more of a modelling error or a data error?\n",
        "* As in, could the model do better or are the labels of the data too close to each other (e.g. a \"Shirt\" label is too close to \"T-shirt/top\")?"
      ],
      "metadata": {
        "id": "VHS20cNTxwSi"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "78a8LjtdbSZj"
      },
      "execution_count": 15,
      "outputs": []
    }
  ]
}