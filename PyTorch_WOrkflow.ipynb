{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/shishiradk/pytorch-pratices/blob/main/PyTorch_WOrkflow.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 492,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "O3WI6humdalv",
        "outputId": "6eafa712-393a-456b-fd3e-eba325b35e59"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'2.8.0+cu126'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 492
        }
      ],
      "source": [
        "import torch\n",
        "from torch import nn # nn conntains all of Pytorch's buildinng blocks for neural networks\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# check Pythorch version\n",
        "torch.__version__"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Data preparing and loading"
      ],
      "metadata": {
        "id": "Mw9xmslNfZva"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data can e almost anything in machine learning\n",
        "\n",
        "\n",
        "* Excel spreadsheet\n",
        "\n",
        "* Image of any kind\n",
        "\n",
        "* Videos (YT has lots of data)\n",
        "\n",
        "* Audio like songs or podcasts\n",
        "\n",
        "* DNA\n",
        "\n",
        "* Text\n",
        "\n",
        "# Machine learning is a game of two parts:\\\n",
        "1. Get data into a numerical representation.\n",
        "\n",
        "2. Build a model to learn patterns in that numerical representation.\n",
        "\n",
        "using linear regression formula\n",
        "\n",
        "we'll use a linear regression formula to make a st line with known parameters"
      ],
      "metadata": {
        "id": "8aUbr40xfe2T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create *known* parameters\n",
        "weight = 0.7\n",
        "bias = 0.3\n",
        "\n",
        "#create\n",
        "start = 0\n",
        "end = 1\n",
        "step = 0.02\n",
        "X = torch.arange(start, end ,step). unsqueeze(dim=1)\n",
        "y = weight * X + bias\n",
        "\n",
        "X[:10], y[:10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MU-1TiOZfJU6",
        "outputId": "021545e0-dac4-4423-e3cd-71b321266da2"
      },
      "execution_count": 493,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([[0.0000],\n",
              "         [0.0200],\n",
              "         [0.0400],\n",
              "         [0.0600],\n",
              "         [0.0800],\n",
              "         [0.1000],\n",
              "         [0.1200],\n",
              "         [0.1400],\n",
              "         [0.1600],\n",
              "         [0.1800]]),\n",
              " tensor([[0.3000],\n",
              "         [0.3140],\n",
              "         [0.3280],\n",
              "         [0.3420],\n",
              "         [0.3560],\n",
              "         [0.3700],\n",
              "         [0.3840],\n",
              "         [0.3980],\n",
              "         [0.4120],\n",
              "         [0.4260]]))"
            ]
          },
          "metadata": {},
          "execution_count": 493
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(X), len(y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nXV01tdKiroA",
        "outputId": "5e16d349-a2b8-454b-ea80-a5d7bb55277f"
      },
      "execution_count": 494,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(50, 50)"
            ]
          },
          "metadata": {},
          "execution_count": 494
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### splitting data into training tests sets\n"
      ],
      "metadata": {
        "id": "CUSUR583j77J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## Create a train test split\n",
        "train_split = int(0.8 * len(X))\n",
        "X_train,y_train = X[:train_split], y[:train_split]\n",
        "X_test , y_test = X[train_split:],y[train_split:]\n",
        "\n",
        "len(X_train), len(y_train), len(X_test), len(y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rjqq4CEijBMr",
        "outputId": "c1273666-9627-48d0-f970-463a8d2190e3"
      },
      "execution_count": 495,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(40, 40, 10, 10)"
            ]
          },
          "metadata": {},
          "execution_count": 495
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data Visualization"
      ],
      "metadata": {
        "id": "nTOzEs6RTP-s"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_predictions(train_data=X_train,\n",
        "                    train_labels=y_train,\n",
        "                    test_data=X_test,\n",
        "                    test_labels=y_test,\n",
        "                    predictions=None):\n",
        "\n",
        "  \"\"\"\n",
        "  Plots training data ,test data and compares predictions.\n",
        "  \"\"\"\n",
        "\n",
        "  #Plots training data in blue\n",
        "  plt.scatter(train_data,train_labels, c=\"b\",s=4, label=\"Training data\")\n",
        "\n",
        "  # plot test data in green\n",
        "  plt.scatter(test_data,test_labels, c=\"g\" , s=4, label=\"Testing data\")\n",
        "\n",
        "  # Are there predictions?\n",
        "  if predictions is not None:\n",
        "    #Plot the predictions if they exist\n",
        "    # Check if predictions require grad and detach if necessary\n",
        "    if predictions.requires_grad:\n",
        "        predictions = predictions.detach()\n",
        "    plt.scatter(test_data,predictions, c=\"r\", s=4, label=\"Predictions\")\n",
        "\n",
        "  # show the ledgends\n",
        "  plt.legend(prop={\"size\":14});"
      ],
      "metadata": {
        "id": "vkcJXLr-lqMC"
      },
      "execution_count": 496,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_predictions();"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 430
        },
        "id": "plB7paBVVWL1",
        "outputId": "b6a9e010-80b7-44d3-a669-707fc1073aad"
      },
      "execution_count": 497,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##2. Build model\n",
        "\n",
        "Our first Pytorch model\n"
      ],
      "metadata": {
        "id": "jbcV48f_XHmn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a Linear Regression model class\n",
        "class LinearRegressionModel(nn.Module): # <- almost everything in PyTorch is a nn.Module (think of this as neural network lego blocks)\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.weights = nn.Parameter(torch.randn(1, # <- start with random weights (this will get adjusted as the model learns)\n",
        "                                                dtype=torch.float), # <- PyTorch loves float32 by default\n",
        "                                   requires_grad=True) # <- can we update this value with gradient descent?)\n",
        "\n",
        "        self.bias = nn.Parameter(torch.randn(1, # <- start with random bias (this will get adjusted as the model learns)\n",
        "                                            dtype=torch.float), # <- PyTorch loves float32 by default\n",
        "                                requires_grad=True) # <- can we update this value with gradient descent?))\n",
        "\n",
        "    # Forward defines the computation in the model\n",
        "    def forward(self, x: torch.Tensor) -> torch.Tensor: # <- \"x\" is the input data (e.g. training/testing features)\n",
        "        return self.weights * x + self.bias # <- this is the linear regression formula (y = m*x + b)"
      ],
      "metadata": {
        "id": "DBUfGpW-WaiD"
      },
      "execution_count": 498,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### PyTorch model building essentials\n",
        "\n",
        "PyTorch has four (give or take) essential modules you can use to create almost any kind of neural network you can imagine.\n",
        "\n",
        "They are [`torch.nn`](https://pytorch.org/docs/stable/nn.html), [`torch.optim`](https://pytorch.org/docs/stable/optim.html), [`torch.utils.data.Dataset`](https://pytorch.org/docs/stable/data.html#torch.utils.data.Dataset) and [`torch.utils.data.DataLoader`](https://pytorch.org/docs/stable/data.html). For now, we'll focus on the first two and get to the other two later (though you may be able to guess what they do).\n",
        "\n",
        "| PyTorch module | What does it do? |\n",
        "| ----- | ----- |\n",
        "| [`torch.nn`](https://pytorch.org/docs/stable/nn.html) | Contains all of the building blocks for computational graphs (essentially a series of computations executed in a particular way). |\n",
        "| [`torch.nn.Parameter`](https://pytorch.org/docs/stable/generated/torch.nn.parameter.Parameter.html#parameter) | Stores tensors that can be used with `nn.Module`. If `requires_grad=True` gradients (used for updating model parameters via [**gradient descent**](https://ml-cheatsheet.readthedocs.io/en/latest/gradient_descent.html))  are calculated automatically, this is often referred to as \"autograd\".  |\n",
        "| [`torch.nn.Module`](https://pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module) | The base class for all neural network modules, all the building blocks for neural networks are subclasses. If you're building a neural network in PyTorch, your models should subclass `nn.Module`. Requires a `forward()` method be implemented. |\n",
        "| [`torch.optim`](https://pytorch.org/docs/stable/optim.html) | Contains various optimization algorithms (these tell the model parameters stored in `nn.Parameter` how to best change to improve gradient descent and in turn reduce the loss). |\n",
        "| `def forward()` | All `nn.Module` subclasses require a `forward()` method, this defines the computation that will take place on the data passed to the particular `nn.Module` (e.g. the linear regression formula above). |\n",
        "\n",
        "If the above sounds complex, think of like this, almost everything in a PyTorch neural network comes from `torch.nn`,\n",
        "* `nn.Module` contains the larger building blocks (layers)\n",
        "* `nn.Parameter` contains the smaller parameters like weights and biases (put these together to make `nn.Module`(s))\n",
        "* `forward()` tells the larger blocks how to make calculations on inputs (tensors full of data) within  `nn.Module`(s)\n",
        "* `torch.optim` contains optimization methods on how to improve the parameters within `nn.Parameter` to better represent input data\n",
        "\n",
        "![a pytorch linear model with annotations](https://raw.githubusercontent.com/mrdbourke/pytorch-deep-learning/main/images/01-pytorch-linear-model-annotated.png)\n",
        "*Basic building blocks of creating a PyTorch model by subclassing `nn.Module`. For objects that subclass `nn.Module`, the `forward()` method must be defined.*\n",
        "\n",
        "> **Resource:** See more of these essential modules and their use cases in the [PyTorch Cheat Sheet](https://pytorch.org/tutorials/beginner/ptcheat.html).\n"
      ],
      "metadata": {
        "id": "f3PDD7G9U7GQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(42)\n",
        "torch.randn(1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "86PEwGA9yC4X",
        "outputId": "996a118f-3d62-4486-b5a0-68afc1514d20"
      },
      "execution_count": 499,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0.3367])"
            ]
          },
          "metadata": {},
          "execution_count": 499
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "### Checking the contents of a PyTorch model\n",
        "Now we've got these out of the way, let's create a model instance with the class we've made and check its parameters using [`.parameters()`](https://pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module.parameters)."
      ],
      "metadata": {
        "id": "-QIpbVAPwnTw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a random seed\n",
        "#torch.manual_seed(42)\n",
        "\n",
        "# Create an instance of the model\n",
        "model_0 = LinearRegressionModel()\n",
        "\n",
        "# Check out the parameters\n",
        "list(model_0.parameters())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ainBsEmVZjoW",
        "outputId": "e6e3144e-1e8a-4b10-b805-6cd2f2abc1ac"
      },
      "execution_count": 500,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Parameter containing:\n",
              " tensor([0.1288], requires_grad=True),\n",
              " Parameter containing:\n",
              " tensor([0.2345], requires_grad=True)]"
            ]
          },
          "metadata": {},
          "execution_count": 500
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# List named parameters\n",
        "model_0.state_dict()"
      ],
      "metadata": {
        "id": "VZ50ViQhyYiQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "55528ee5-405d-41cb-ac70-f8b0376405aa"
      },
      "execution_count": 501,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "OrderedDict([('weights', tensor([0.1288])), ('bias', tensor([0.2345]))])"
            ]
          },
          "metadata": {},
          "execution_count": 501
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Notice how the values for `weights` and `bias` from `model_0.state_dict()` come out as random float tensors?\n",
        "\n",
        "This is because we initialized them above using `torch.randn()`.\n",
        "\n",
        "Essentially we want to start from random parameters and get the model to update them towards parameters that fit our data best (the hardcoded `weight` and `bias` values we set when creating our straight line data).\n",
        "\n",
        "> **Exercise:** Try changing the `torch.manual_seed()` value two cells above, see what happens to the weights and bias values.\n",
        "\n",
        "Because our model starts with random values, right now it'll have poor predictive power.\n",
        "\n"
      ],
      "metadata": {
        "id": "UIa0OjYx2D22"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Hmm?\n",
        "\n",
        "You probably noticed we used [`torch.inference_mode()`](https://pytorch.org/docs/stable/generated/torch.inference_mode.html) as a [context manager](https://realpython.com/python-with-statement/) (that's what the `with torch.inference_mode():` is) to make the predictions.\n",
        "\n",
        "As the name suggests, `torch.inference_mode()` is used when using a model for inference (making predictions).\n",
        "\n",
        "`torch.inference_mode()` turns off a bunch of things (like gradient tracking, which is necessary for training but not for inference) to make **forward-passes** (data going through the `forward()` method) faster.\n",
        "\n",
        "> **Note:** In older PyTorch code, you may also see `torch.no_grad()` being used for inference. While `torch.inference_mode()` and `torch.no_grad()` do similar things,\n",
        "`torch.inference_mode()` is newer, potentially faster and preferred. See this [Tweet from PyTorch](https://twitter.com/PyTorch/status/1437838231505096708?s=20) for more.\n",
        "\n",
        "We've made some predictions, let's see what they look like."
      ],
      "metadata": {
        "id": "ZPW19T4y2bE1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_test,y_test"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HoT1FJ6L23QR",
        "outputId": "ade7076d-044c-4b5a-8cc9-28914006c06f"
      },
      "execution_count": 502,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([[0.8000],\n",
              "         [0.8200],\n",
              "         [0.8400],\n",
              "         [0.8600],\n",
              "         [0.8800],\n",
              "         [0.9000],\n",
              "         [0.9200],\n",
              "         [0.9400],\n",
              "         [0.9600],\n",
              "         [0.9800]]),\n",
              " tensor([[0.8600],\n",
              "         [0.8740],\n",
              "         [0.8880],\n",
              "         [0.9020],\n",
              "         [0.9160],\n",
              "         [0.9300],\n",
              "         [0.9440],\n",
              "         [0.9580],\n",
              "         [0.9720],\n",
              "         [0.9860]]))"
            ]
          },
          "metadata": {},
          "execution_count": 502
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Make prediction with model\n",
        "with torch.inference_mode():\n",
        "  y_preds= model_0(X_test)\n",
        "\n",
        "# you can do something with torch.no_grad(),however, torch.inference_model() is prefered\n",
        "# with torch.no_grad():\n",
        "#   y_preds = model_0(X_test)\n",
        "\n",
        "y_preds"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pp_x9qMG1yIN",
        "outputId": "b3029003-a590-4ae4-94ff-b1c2db88aa2d"
      },
      "execution_count": 503,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.3375],\n",
              "        [0.3401],\n",
              "        [0.3427],\n",
              "        [0.3452],\n",
              "        [0.3478],\n",
              "        [0.3504],\n",
              "        [0.3530],\n",
              "        [0.3555],\n",
              "        [0.3581],\n",
              "        [0.3607]])"
            ]
          },
          "metadata": {},
          "execution_count": 503
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_test"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C37dVqll19NX",
        "outputId": "f9794b4b-a080-4179-c585-06a7c17e5729"
      },
      "execution_count": 504,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.8600],\n",
              "        [0.8740],\n",
              "        [0.8880],\n",
              "        [0.9020],\n",
              "        [0.9160],\n",
              "        [0.9300],\n",
              "        [0.9440],\n",
              "        [0.9580],\n",
              "        [0.9720],\n",
              "        [0.9860]])"
            ]
          },
          "metadata": {},
          "execution_count": 504
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plot_predictions(predictions=y_preds)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 430
        },
        "id": "Dsf7C4gw3ktX",
        "outputId": "5f78dca4-6084-499f-c66e-e52ae6bb9d7e"
      },
      "execution_count": 505,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##3. Train Model\n",
        "\n",
        "The whole idea of training is for a model to move from some *unknown* parameters(these may be random) to some *known* parameters\n",
        "\n",
        "or in other  words from  a poor or how wrog models prdictions are is to use a loss funstion .\n",
        "\n",
        "* Note: Loss fuction may also be called cost function or criterion in different areas. For our case, we're going to refer to it as a loss function.\n",
        "\n",
        "Thimgs we need to train:\n",
        "\n",
        "**Loss function:** A function to measure how wrong your model's predictions are to the ideal outputs,lower is better.\n",
        "\n",
        "**Optimizer:** Takes into account the loss of a model and adjustss the model's parameters(weights and bias) to improve the loss function.\n",
        "\n",
        "And specifically for Pytorch,we need:\n",
        "* A training loop\n",
        "* A testing loop"
      ],
      "metadata": {
        "id": "O9sGvhCJ6z6Y"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "read torch.optimizer"
      ],
      "metadata": {
        "id": "XYj4-OTVArlX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "list(model_0.parameters())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kw96EqZC3sDK",
        "outputId": "90505aa7-ce6d-4bcc-c91b-c2b7850458e4"
      },
      "execution_count": 506,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Parameter containing:\n",
              " tensor([0.1288], requires_grad=True),\n",
              " Parameter containing:\n",
              " tensor([0.2345], requires_grad=True)]"
            ]
          },
          "metadata": {},
          "execution_count": 506
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Check out models parameter is a value that the model sets itself\n",
        "model_0.state_dict()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O8uXt4gc9JM0",
        "outputId": "668d0a05-00e3-4996-d247-edfc2d80492c"
      },
      "execution_count": 507,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "OrderedDict([('weights', tensor([0.1288])), ('bias', tensor([0.2345]))])"
            ]
          },
          "metadata": {},
          "execution_count": 507
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## Setuo a loss function\n",
        "loss_fn =nn.L1Loss()\n",
        "\n",
        "# Setup an optimizer\n",
        "optimizer = torch.optim.SGD(params=model_0.parameters(),\n",
        "                            lr=0.0001) # lr= learning rate"
      ],
      "metadata": {
        "id": "0jNAjYPr9_6Y"
      },
      "execution_count": 508,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Pytorch training loop\n",
        "\n",
        "A couple of things we need in a training loop:\n",
        "\n",
        "0. Loopp through the data\n",
        "1. Forward pass  (this involves data moving through our models forward() function) to make pred on data - aslso called forward propagation\n",
        "2. Calculate the loss(compare forward pass prediction to ground truth labels)\n",
        "3. Optimizer zero grad\n",
        "4. Loss backward - move backwards through the network to calculate the gradiets of each of the parameters of our model with respect to the loss\n",
        "5. Optimizer step- use the optimizer to adjust our models parameters to try and imporive loss"
      ],
      "metadata": {
        "id": "DopXs1wfOAMf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "| Number | Step name | What does it do? | Code example |\n",
        "| ----- | ----- | ----- | ----- |\n",
        "| 1 | Forward pass | The model goes through all of the training data once, performing its `forward()` function calculations. | `model(x_train)` |\n",
        "| 2 | Calculate the loss | The model's outputs (predictions) are compared to the ground truth and evaluated to see how wrong they are. | `loss = loss_fn(y_pred, y_train)` |\n",
        "| 3 | Zero gradients | The optimizers gradients are set to zero (they are accumulated by default) so they can be recalculated for the specific training step. | `optimizer.zero_grad()` |\n",
        "| 4 | Perform backpropagation on the loss | Computes the gradient of the loss with respect for every model parameter to be updated  (each parameter with `requires_grad=True`). This is known as **backpropagation**, hence \"backwards\".  | `loss.backward()` |\n",
        "| 5 | Update the optimizer (**gradient descent**) | Update the parameters with `requires_grad=True` with respect to the loss gradients in order to improve them. | `optimizer.step()` |"
      ],
      "metadata": {
        "id": "Fh2flD0UOLFj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(42)\n",
        "\n",
        "# Set the number of epochs (how many times the model will pass over the training data)\n",
        "epochs = 20000\n",
        "\n",
        "\n",
        "# Create empty loss lists to track values\n",
        "epoch_count = []\n",
        "loss_values = []\n",
        "test_loss_values = []\n",
        "epoch_count = []\n",
        "\n",
        "  ### Training\n",
        "  #0. Loop through the data\n",
        "for epoch in range(epochs):\n",
        "\n",
        "\n",
        "    # Put model in training mode (this is the default state of a model)\n",
        "    model_0.train()\n",
        "\n",
        "    # 1. Forward pass on train data using the forward() method inside\n",
        "    y_pred = model_0(X_train)\n",
        "    # print(y_pred)\n",
        "\n",
        "    # 2. Calculate the loss (how different are our models predictions to the ground truth)\n",
        "    loss = loss_fn(y_pred, y_train)\n",
        "\n",
        "    # 3. Zero grad of the optimizer\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    # 4. Loss backwards\n",
        "    loss.backward()\n",
        "\n",
        "    # 5. Progress the optimizer\n",
        "    optimizer.step()\n",
        "\n",
        "    ### Testing\n",
        "\n",
        "    # Put the model in evaluation mode\n",
        "    model_0.eval()\n",
        "\n",
        "    with torch.inference_mode():\n",
        "      # 1. Forward pass on test data\n",
        "      test_pred = model_0(X_test)\n",
        "\n",
        "      # 2. Caculate loss on test data\n",
        "      test_loss = loss_fn(test_pred, y_test) # predictions come in torch.float datatype, so comparisons need to be done with tensors of the same type\n",
        "\n",
        "      # Print out what's happening\n",
        "      if epoch % 10 == 0:\n",
        "            epoch_count.append(epoch)\n",
        "            loss_values.append(loss.detach().numpy())\n",
        "            test_loss_values.append(test_loss.detach().numpy())\n",
        "            print(f\"Epoch: {epoch} | MAE Train Loss: {loss} | MAE Test Loss: {test_loss} \")\n",
        "            #Print out model state_dict()\n",
        "            print(model_0.state_dict())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "3blnVuY2Dawg",
        "outputId": "e5911658-025e-4f92-9813-f68031aa1969"
      },
      "execution_count": 509,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 0 | MAE Train Loss: 0.288301944732666 | MAE Test Loss: 0.5737625360488892 \n",
            "OrderedDict({'weights': tensor([0.1288]), 'bias': tensor([0.2346])})\n",
            "Epoch: 10 | MAE Train Loss: 0.2871498763561249 | MAE Test Loss: 0.5724154710769653 \n",
            "OrderedDict({'weights': tensor([0.1292]), 'bias': tensor([0.2356])})\n",
            "Epoch: 20 | MAE Train Loss: 0.28599777817726135 | MAE Test Loss: 0.5710684061050415 \n",
            "OrderedDict({'weights': tensor([0.1296]), 'bias': tensor([0.2366])})\n",
            "Epoch: 30 | MAE Train Loss: 0.28484565019607544 | MAE Test Loss: 0.5697212815284729 \n",
            "OrderedDict({'weights': tensor([0.1300]), 'bias': tensor([0.2376])})\n",
            "Epoch: 40 | MAE Train Loss: 0.2836935520172119 | MAE Test Loss: 0.5683742165565491 \n",
            "OrderedDict({'weights': tensor([0.1304]), 'bias': tensor([0.2386])})\n",
            "Epoch: 50 | MAE Train Loss: 0.2825414538383484 | MAE Test Loss: 0.5670271515846252 \n",
            "OrderedDict({'weights': tensor([0.1308]), 'bias': tensor([0.2396])})\n",
            "Epoch: 60 | MAE Train Loss: 0.28138938546180725 | MAE Test Loss: 0.5656800866127014 \n",
            "OrderedDict({'weights': tensor([0.1312]), 'bias': tensor([0.2406])})\n",
            "Epoch: 70 | MAE Train Loss: 0.28023725748062134 | MAE Test Loss: 0.5643329620361328 \n",
            "OrderedDict({'weights': tensor([0.1316]), 'bias': tensor([0.2416])})\n",
            "Epoch: 80 | MAE Train Loss: 0.2790851294994354 | MAE Test Loss: 0.562985897064209 \n",
            "OrderedDict({'weights': tensor([0.1320]), 'bias': tensor([0.2426])})\n",
            "Epoch: 90 | MAE Train Loss: 0.2779330313205719 | MAE Test Loss: 0.5616388320922852 \n",
            "OrderedDict({'weights': tensor([0.1324]), 'bias': tensor([0.2436])})\n",
            "Epoch: 100 | MAE Train Loss: 0.27678096294403076 | MAE Test Loss: 0.5602916479110718 \n",
            "OrderedDict({'weights': tensor([0.1327]), 'bias': tensor([0.2446])})\n",
            "Epoch: 110 | MAE Train Loss: 0.27562883496284485 | MAE Test Loss: 0.5589446425437927 \n",
            "OrderedDict({'weights': tensor([0.1331]), 'bias': tensor([0.2456])})\n",
            "Epoch: 120 | MAE Train Loss: 0.2744767367839813 | MAE Test Loss: 0.5575975179672241 \n",
            "OrderedDict({'weights': tensor([0.1335]), 'bias': tensor([0.2466])})\n",
            "Epoch: 130 | MAE Train Loss: 0.2733246386051178 | MAE Test Loss: 0.5562504529953003 \n",
            "OrderedDict({'weights': tensor([0.1339]), 'bias': tensor([0.2476])})\n",
            "Epoch: 140 | MAE Train Loss: 0.2721725106239319 | MAE Test Loss: 0.5549033880233765 \n",
            "OrderedDict({'weights': tensor([0.1343]), 'bias': tensor([0.2486])})\n",
            "Epoch: 150 | MAE Train Loss: 0.27102041244506836 | MAE Test Loss: 0.5535563230514526 \n",
            "OrderedDict({'weights': tensor([0.1347]), 'bias': tensor([0.2496])})\n",
            "Epoch: 160 | MAE Train Loss: 0.2698683738708496 | MAE Test Loss: 0.5522092580795288 \n",
            "OrderedDict({'weights': tensor([0.1351]), 'bias': tensor([0.2506])})\n",
            "Epoch: 170 | MAE Train Loss: 0.2687164545059204 | MAE Test Loss: 0.5508624315261841 \n",
            "OrderedDict({'weights': tensor([0.1355]), 'bias': tensor([0.2516])})\n",
            "Epoch: 180 | MAE Train Loss: 0.26756447553634644 | MAE Test Loss: 0.5495153665542603 \n",
            "OrderedDict({'weights': tensor([0.1359]), 'bias': tensor([0.2526])})\n",
            "Epoch: 190 | MAE Train Loss: 0.26641255617141724 | MAE Test Loss: 0.5481684803962708 \n",
            "OrderedDict({'weights': tensor([0.1363]), 'bias': tensor([0.2536])})\n",
            "Epoch: 200 | MAE Train Loss: 0.26526057720184326 | MAE Test Loss: 0.5468215942382812 \n",
            "OrderedDict({'weights': tensor([0.1366]), 'bias': tensor([0.2546])})\n",
            "Epoch: 210 | MAE Train Loss: 0.2641085982322693 | MAE Test Loss: 0.545474648475647 \n",
            "OrderedDict({'weights': tensor([0.1370]), 'bias': tensor([0.2556])})\n",
            "Epoch: 220 | MAE Train Loss: 0.2629566788673401 | MAE Test Loss: 0.5441276431083679 \n",
            "OrderedDict({'weights': tensor([0.1374]), 'bias': tensor([0.2566])})\n",
            "Epoch: 230 | MAE Train Loss: 0.2618047297000885 | MAE Test Loss: 0.5427807569503784 \n",
            "OrderedDict({'weights': tensor([0.1378]), 'bias': tensor([0.2576])})\n",
            "Epoch: 240 | MAE Train Loss: 0.26065272092819214 | MAE Test Loss: 0.5414338111877441 \n",
            "OrderedDict({'weights': tensor([0.1382]), 'bias': tensor([0.2586])})\n",
            "Epoch: 250 | MAE Train Loss: 0.2595008313655853 | MAE Test Loss: 0.5400869250297546 \n",
            "OrderedDict({'weights': tensor([0.1386]), 'bias': tensor([0.2596])})\n",
            "Epoch: 260 | MAE Train Loss: 0.25834888219833374 | MAE Test Loss: 0.5387399196624756 \n",
            "OrderedDict({'weights': tensor([0.1390]), 'bias': tensor([0.2606])})\n",
            "Epoch: 270 | MAE Train Loss: 0.25719690322875977 | MAE Test Loss: 0.5373929738998413 \n",
            "OrderedDict({'weights': tensor([0.1394]), 'bias': tensor([0.2616])})\n",
            "Epoch: 280 | MAE Train Loss: 0.2560449242591858 | MAE Test Loss: 0.5360460877418518 \n",
            "OrderedDict({'weights': tensor([0.1398]), 'bias': tensor([0.2626])})\n",
            "Epoch: 290 | MAE Train Loss: 0.2548930048942566 | MAE Test Loss: 0.5346991419792175 \n",
            "OrderedDict({'weights': tensor([0.1402]), 'bias': tensor([0.2636])})\n",
            "Epoch: 300 | MAE Train Loss: 0.253741055727005 | MAE Test Loss: 0.5333521962165833 \n",
            "OrderedDict({'weights': tensor([0.1405]), 'bias': tensor([0.2646])})\n",
            "Epoch: 310 | MAE Train Loss: 0.25258907675743103 | MAE Test Loss: 0.532005250453949 \n",
            "OrderedDict({'weights': tensor([0.1409]), 'bias': tensor([0.2656])})\n",
            "Epoch: 320 | MAE Train Loss: 0.25143712759017944 | MAE Test Loss: 0.5306583642959595 \n",
            "OrderedDict({'weights': tensor([0.1413]), 'bias': tensor([0.2666])})\n",
            "Epoch: 330 | MAE Train Loss: 0.25028517842292786 | MAE Test Loss: 0.5293114185333252 \n",
            "OrderedDict({'weights': tensor([0.1417]), 'bias': tensor([0.2676])})\n",
            "Epoch: 340 | MAE Train Loss: 0.24913319945335388 | MAE Test Loss: 0.5279644727706909 \n",
            "OrderedDict({'weights': tensor([0.1421]), 'bias': tensor([0.2686])})\n",
            "Epoch: 350 | MAE Train Loss: 0.24798128008842468 | MAE Test Loss: 0.5266175270080566 \n",
            "OrderedDict({'weights': tensor([0.1425]), 'bias': tensor([0.2696])})\n",
            "Epoch: 360 | MAE Train Loss: 0.2468293160200119 | MAE Test Loss: 0.5252706408500671 \n",
            "OrderedDict({'weights': tensor([0.1429]), 'bias': tensor([0.2706])})\n",
            "Epoch: 370 | MAE Train Loss: 0.24567735195159912 | MAE Test Loss: 0.5239236950874329 \n",
            "OrderedDict({'weights': tensor([0.1433]), 'bias': tensor([0.2716])})\n",
            "Epoch: 380 | MAE Train Loss: 0.24452543258666992 | MAE Test Loss: 0.5225766897201538 \n",
            "OrderedDict({'weights': tensor([0.1437]), 'bias': tensor([0.2726])})\n",
            "Epoch: 390 | MAE Train Loss: 0.24337346851825714 | MAE Test Loss: 0.5212298035621643 \n",
            "OrderedDict({'weights': tensor([0.1441]), 'bias': tensor([0.2736])})\n",
            "Epoch: 400 | MAE Train Loss: 0.24222150444984436 | MAE Test Loss: 0.51988285779953 \n",
            "OrderedDict({'weights': tensor([0.1444]), 'bias': tensor([0.2746])})\n",
            "Epoch: 410 | MAE Train Loss: 0.24106955528259277 | MAE Test Loss: 0.5185359120368958 \n",
            "OrderedDict({'weights': tensor([0.1448]), 'bias': tensor([0.2756])})\n",
            "Epoch: 420 | MAE Train Loss: 0.2399176061153412 | MAE Test Loss: 0.5171889066696167 \n",
            "OrderedDict({'weights': tensor([0.1452]), 'bias': tensor([0.2766])})\n",
            "Epoch: 430 | MAE Train Loss: 0.2387656718492508 | MAE Test Loss: 0.515842080116272 \n",
            "OrderedDict({'weights': tensor([0.1456]), 'bias': tensor([0.2776])})\n",
            "Epoch: 440 | MAE Train Loss: 0.23761367797851562 | MAE Test Loss: 0.5144951343536377 \n",
            "OrderedDict({'weights': tensor([0.1460]), 'bias': tensor([0.2786])})\n",
            "Epoch: 450 | MAE Train Loss: 0.23646172881126404 | MAE Test Loss: 0.5131481885910034 \n",
            "OrderedDict({'weights': tensor([0.1464]), 'bias': tensor([0.2796])})\n",
            "Epoch: 460 | MAE Train Loss: 0.23530979454517365 | MAE Test Loss: 0.5118013024330139 \n",
            "OrderedDict({'weights': tensor([0.1468]), 'bias': tensor([0.2806])})\n",
            "Epoch: 470 | MAE Train Loss: 0.23415783047676086 | MAE Test Loss: 0.5104542970657349 \n",
            "OrderedDict({'weights': tensor([0.1472]), 'bias': tensor([0.2816])})\n",
            "Epoch: 480 | MAE Train Loss: 0.23300588130950928 | MAE Test Loss: 0.5091073513031006 \n",
            "OrderedDict({'weights': tensor([0.1476]), 'bias': tensor([0.2826])})\n",
            "Epoch: 490 | MAE Train Loss: 0.2318539321422577 | MAE Test Loss: 0.5077604055404663 \n",
            "OrderedDict({'weights': tensor([0.1480]), 'bias': tensor([0.2836])})\n",
            "Epoch: 500 | MAE Train Loss: 0.2307019680738449 | MAE Test Loss: 0.506413459777832 \n",
            "OrderedDict({'weights': tensor([0.1483]), 'bias': tensor([0.2846])})\n",
            "Epoch: 510 | MAE Train Loss: 0.22955003380775452 | MAE Test Loss: 0.5050665736198425 \n",
            "OrderedDict({'weights': tensor([0.1487]), 'bias': tensor([0.2856])})\n",
            "Epoch: 520 | MAE Train Loss: 0.22839805483818054 | MAE Test Loss: 0.503719687461853 \n",
            "OrderedDict({'weights': tensor([0.1491]), 'bias': tensor([0.2866])})\n",
            "Epoch: 530 | MAE Train Loss: 0.22724613547325134 | MAE Test Loss: 0.502372682094574 \n",
            "OrderedDict({'weights': tensor([0.1495]), 'bias': tensor([0.2876])})\n",
            "Epoch: 540 | MAE Train Loss: 0.22609417140483856 | MAE Test Loss: 0.5010257363319397 \n",
            "OrderedDict({'weights': tensor([0.1499]), 'bias': tensor([0.2886])})\n",
            "Epoch: 550 | MAE Train Loss: 0.2249421775341034 | MAE Test Loss: 0.4996787905693054 \n",
            "OrderedDict({'weights': tensor([0.1503]), 'bias': tensor([0.2896])})\n",
            "Epoch: 560 | MAE Train Loss: 0.2237902581691742 | MAE Test Loss: 0.49833187460899353 \n",
            "OrderedDict({'weights': tensor([0.1507]), 'bias': tensor([0.2906])})\n",
            "Epoch: 570 | MAE Train Loss: 0.2226382941007614 | MAE Test Loss: 0.49698495864868164 \n",
            "OrderedDict({'weights': tensor([0.1511]), 'bias': tensor([0.2916])})\n",
            "Epoch: 580 | MAE Train Loss: 0.22148635983467102 | MAE Test Loss: 0.495637983083725 \n",
            "OrderedDict({'weights': tensor([0.1515]), 'bias': tensor([0.2926])})\n",
            "Epoch: 590 | MAE Train Loss: 0.22033441066741943 | MAE Test Loss: 0.49429112672805786 \n",
            "OrderedDict({'weights': tensor([0.1519]), 'bias': tensor([0.2936])})\n",
            "Epoch: 600 | MAE Train Loss: 0.21918244659900665 | MAE Test Loss: 0.4929441511631012 \n",
            "OrderedDict({'weights': tensor([0.1522]), 'bias': tensor([0.2946])})\n",
            "Epoch: 610 | MAE Train Loss: 0.21803048253059387 | MAE Test Loss: 0.49159717559814453 \n",
            "OrderedDict({'weights': tensor([0.1526]), 'bias': tensor([0.2956])})\n",
            "Epoch: 620 | MAE Train Loss: 0.21687853336334229 | MAE Test Loss: 0.49025028944015503 \n",
            "OrderedDict({'weights': tensor([0.1530]), 'bias': tensor([0.2966])})\n",
            "Epoch: 630 | MAE Train Loss: 0.2157265692949295 | MAE Test Loss: 0.48890337347984314 \n",
            "OrderedDict({'weights': tensor([0.1534]), 'bias': tensor([0.2976])})\n",
            "Epoch: 640 | MAE Train Loss: 0.21457462012767792 | MAE Test Loss: 0.48755645751953125 \n",
            "OrderedDict({'weights': tensor([0.1538]), 'bias': tensor([0.2986])})\n",
            "Epoch: 650 | MAE Train Loss: 0.21342268586158752 | MAE Test Loss: 0.4862094819545746 \n",
            "OrderedDict({'weights': tensor([0.1542]), 'bias': tensor([0.2996])})\n",
            "Epoch: 660 | MAE Train Loss: 0.21231241524219513 | MAE Test Loss: 0.48488742113113403 \n",
            "OrderedDict({'weights': tensor([0.1546]), 'bias': tensor([0.3005])})\n",
            "Epoch: 670 | MAE Train Loss: 0.21125774085521698 | MAE Test Loss: 0.4835902154445648 \n",
            "OrderedDict({'weights': tensor([0.1550]), 'bias': tensor([0.3015])})\n",
            "Epoch: 680 | MAE Train Loss: 0.21020305156707764 | MAE Test Loss: 0.4822930693626404 \n",
            "OrderedDict({'weights': tensor([0.1554]), 'bias': tensor([0.3024])})\n",
            "Epoch: 690 | MAE Train Loss: 0.2091483771800995 | MAE Test Loss: 0.48099595308303833 \n",
            "OrderedDict({'weights': tensor([0.1558]), 'bias': tensor([0.3034])})\n",
            "Epoch: 700 | MAE Train Loss: 0.20809368789196014 | MAE Test Loss: 0.4796987473964691 \n",
            "OrderedDict({'weights': tensor([0.1561]), 'bias': tensor([0.3043])})\n",
            "Epoch: 710 | MAE Train Loss: 0.20703904330730438 | MAE Test Loss: 0.4784015715122223 \n",
            "OrderedDict({'weights': tensor([0.1565]), 'bias': tensor([0.3053])})\n",
            "Epoch: 720 | MAE Train Loss: 0.20598435401916504 | MAE Test Loss: 0.47710442543029785 \n",
            "OrderedDict({'weights': tensor([0.1569]), 'bias': tensor([0.3062])})\n",
            "Epoch: 730 | MAE Train Loss: 0.2049296796321869 | MAE Test Loss: 0.4758072793483734 \n",
            "OrderedDict({'weights': tensor([0.1573]), 'bias': tensor([0.3072])})\n",
            "Epoch: 740 | MAE Train Loss: 0.20387499034404755 | MAE Test Loss: 0.4745101034641266 \n",
            "OrderedDict({'weights': tensor([0.1577]), 'bias': tensor([0.3081])})\n",
            "Epoch: 750 | MAE Train Loss: 0.2028203308582306 | MAE Test Loss: 0.4732128977775574 \n",
            "OrderedDict({'weights': tensor([0.1581]), 'bias': tensor([0.3091])})\n",
            "Epoch: 760 | MAE Train Loss: 0.20176562666893005 | MAE Test Loss: 0.4719157814979553 \n",
            "OrderedDict({'weights': tensor([0.1585]), 'bias': tensor([0.3100])})\n",
            "Epoch: 770 | MAE Train Loss: 0.2007141411304474 | MAE Test Loss: 0.4706236720085144 \n",
            "OrderedDict({'weights': tensor([0.1589]), 'bias': tensor([0.3110])})\n",
            "Epoch: 780 | MAE Train Loss: 0.1997527778148651 | MAE Test Loss: 0.4693773686885834 \n",
            "OrderedDict({'weights': tensor([0.1593]), 'bias': tensor([0.3119])})\n",
            "Epoch: 790 | MAE Train Loss: 0.19879139959812164 | MAE Test Loss: 0.46813106536865234 \n",
            "OrderedDict({'weights': tensor([0.1597]), 'bias': tensor([0.3128])})\n",
            "Epoch: 800 | MAE Train Loss: 0.19783005118370056 | MAE Test Loss: 0.4668847620487213 \n",
            "OrderedDict({'weights': tensor([0.1600]), 'bias': tensor([0.3137])})\n",
            "Epoch: 810 | MAE Train Loss: 0.1968686282634735 | MAE Test Loss: 0.4656384587287903 \n",
            "OrderedDict({'weights': tensor([0.1604]), 'bias': tensor([0.3146])})\n",
            "Epoch: 820 | MAE Train Loss: 0.19590726494789124 | MAE Test Loss: 0.46439218521118164 \n",
            "OrderedDict({'weights': tensor([0.1608]), 'bias': tensor([0.3155])})\n",
            "Epoch: 830 | MAE Train Loss: 0.19494588673114777 | MAE Test Loss: 0.46314582228660583 \n",
            "OrderedDict({'weights': tensor([0.1612]), 'bias': tensor([0.3164])})\n",
            "Epoch: 840 | MAE Train Loss: 0.1939845234155655 | MAE Test Loss: 0.4618995785713196 \n",
            "OrderedDict({'weights': tensor([0.1616]), 'bias': tensor([0.3173])})\n",
            "Epoch: 850 | MAE Train Loss: 0.19302314519882202 | MAE Test Loss: 0.46065330505371094 \n",
            "OrderedDict({'weights': tensor([0.1620]), 'bias': tensor([0.3182])})\n",
            "Epoch: 860 | MAE Train Loss: 0.19206176698207855 | MAE Test Loss: 0.45940694212913513 \n",
            "OrderedDict({'weights': tensor([0.1624]), 'bias': tensor([0.3191])})\n",
            "Epoch: 870 | MAE Train Loss: 0.19110040366649628 | MAE Test Loss: 0.4581606984138489 \n",
            "OrderedDict({'weights': tensor([0.1628]), 'bias': tensor([0.3200])})\n",
            "Epoch: 880 | MAE Train Loss: 0.1901390254497528 | MAE Test Loss: 0.45691436529159546 \n",
            "OrderedDict({'weights': tensor([0.1632]), 'bias': tensor([0.3209])})\n",
            "Epoch: 890 | MAE Train Loss: 0.18919770419597626 | MAE Test Loss: 0.4556836187839508 \n",
            "OrderedDict({'weights': tensor([0.1635]), 'bias': tensor([0.3218])})\n",
            "Epoch: 900 | MAE Train Loss: 0.18832547962665558 | MAE Test Loss: 0.4544892907142639 \n",
            "OrderedDict({'weights': tensor([0.1639]), 'bias': tensor([0.3226])})\n",
            "Epoch: 910 | MAE Train Loss: 0.1874532401561737 | MAE Test Loss: 0.45329490303993225 \n",
            "OrderedDict({'weights': tensor([0.1643]), 'bias': tensor([0.3235])})\n",
            "Epoch: 920 | MAE Train Loss: 0.18658101558685303 | MAE Test Loss: 0.4521004557609558 \n",
            "OrderedDict({'weights': tensor([0.1647]), 'bias': tensor([0.3243])})\n",
            "Epoch: 930 | MAE Train Loss: 0.18570879101753235 | MAE Test Loss: 0.4509061276912689 \n",
            "OrderedDict({'weights': tensor([0.1651]), 'bias': tensor([0.3252])})\n",
            "Epoch: 940 | MAE Train Loss: 0.18483653664588928 | MAE Test Loss: 0.44971179962158203 \n",
            "OrderedDict({'weights': tensor([0.1655]), 'bias': tensor([0.3260])})\n",
            "Epoch: 950 | MAE Train Loss: 0.1839643269777298 | MAE Test Loss: 0.448517382144928 \n",
            "OrderedDict({'weights': tensor([0.1659]), 'bias': tensor([0.3269])})\n",
            "Epoch: 960 | MAE Train Loss: 0.18309208750724792 | MAE Test Loss: 0.4473230242729187 \n",
            "OrderedDict({'weights': tensor([0.1663]), 'bias': tensor([0.3277])})\n",
            "Epoch: 970 | MAE Train Loss: 0.18221986293792725 | MAE Test Loss: 0.44612860679626465 \n",
            "OrderedDict({'weights': tensor([0.1666]), 'bias': tensor([0.3286])})\n",
            "Epoch: 980 | MAE Train Loss: 0.18134763836860657 | MAE Test Loss: 0.44493427872657776 \n",
            "OrderedDict({'weights': tensor([0.1670]), 'bias': tensor([0.3294])})\n",
            "Epoch: 990 | MAE Train Loss: 0.1804753988981247 | MAE Test Loss: 0.4437398910522461 \n",
            "OrderedDict({'weights': tensor([0.1674]), 'bias': tensor([0.3303])})\n",
            "Epoch: 1000 | MAE Train Loss: 0.17960317432880402 | MAE Test Loss: 0.44254547357559204 \n",
            "OrderedDict({'weights': tensor([0.1678]), 'bias': tensor([0.3311])})\n",
            "Epoch: 1010 | MAE Train Loss: 0.17873093485832214 | MAE Test Loss: 0.4413510859012604 \n",
            "OrderedDict({'weights': tensor([0.1682]), 'bias': tensor([0.3320])})\n",
            "Epoch: 1020 | MAE Train Loss: 0.17793776094913483 | MAE Test Loss: 0.4402094781398773 \n",
            "OrderedDict({'weights': tensor([0.1686]), 'bias': tensor([0.3328])})\n",
            "Epoch: 1030 | MAE Train Loss: 0.17715036869049072 | MAE Test Loss: 0.4390678405761719 \n",
            "OrderedDict({'weights': tensor([0.1690]), 'bias': tensor([0.3336])})\n",
            "Epoch: 1040 | MAE Train Loss: 0.1763629913330078 | MAE Test Loss: 0.43792620301246643 \n",
            "OrderedDict({'weights': tensor([0.1693]), 'bias': tensor([0.3344])})\n",
            "Epoch: 1050 | MAE Train Loss: 0.1755756288766861 | MAE Test Loss: 0.43678444623947144 \n",
            "OrderedDict({'weights': tensor([0.1697]), 'bias': tensor([0.3352])})\n",
            "Epoch: 1060 | MAE Train Loss: 0.17478826642036438 | MAE Test Loss: 0.435642808675766 \n",
            "OrderedDict({'weights': tensor([0.1701]), 'bias': tensor([0.3360])})\n",
            "Epoch: 1070 | MAE Train Loss: 0.17400088906288147 | MAE Test Loss: 0.43450117111206055 \n",
            "OrderedDict({'weights': tensor([0.1705]), 'bias': tensor([0.3368])})\n",
            "Epoch: 1080 | MAE Train Loss: 0.17321351170539856 | MAE Test Loss: 0.4333595335483551 \n",
            "OrderedDict({'weights': tensor([0.1709]), 'bias': tensor([0.3376])})\n",
            "Epoch: 1090 | MAE Train Loss: 0.17242613434791565 | MAE Test Loss: 0.4322178363800049 \n",
            "OrderedDict({'weights': tensor([0.1713]), 'bias': tensor([0.3384])})\n",
            "Epoch: 1100 | MAE Train Loss: 0.17163875699043274 | MAE Test Loss: 0.43107619881629944 \n",
            "OrderedDict({'weights': tensor([0.1716]), 'bias': tensor([0.3392])})\n",
            "Epoch: 1110 | MAE Train Loss: 0.17085139453411102 | MAE Test Loss: 0.429934561252594 \n",
            "OrderedDict({'weights': tensor([0.1720]), 'bias': tensor([0.3400])})\n",
            "Epoch: 1120 | MAE Train Loss: 0.1700640171766281 | MAE Test Loss: 0.4287928640842438 \n",
            "OrderedDict({'weights': tensor([0.1724]), 'bias': tensor([0.3408])})\n",
            "Epoch: 1130 | MAE Train Loss: 0.1692766398191452 | MAE Test Loss: 0.4276512563228607 \n",
            "OrderedDict({'weights': tensor([0.1728]), 'bias': tensor([0.3416])})\n",
            "Epoch: 1140 | MAE Train Loss: 0.16849978268146515 | MAE Test Loss: 0.4265202581882477 \n",
            "OrderedDict({'weights': tensor([0.1732]), 'bias': tensor([0.3424])})\n",
            "Epoch: 1150 | MAE Train Loss: 0.16779276728630066 | MAE Test Loss: 0.42543190717697144 \n",
            "OrderedDict({'weights': tensor([0.1736]), 'bias': tensor([0.3431])})\n",
            "Epoch: 1160 | MAE Train Loss: 0.16708578169345856 | MAE Test Loss: 0.42434364557266235 \n",
            "OrderedDict({'weights': tensor([0.1739]), 'bias': tensor([0.3439])})\n",
            "Epoch: 1170 | MAE Train Loss: 0.16637879610061646 | MAE Test Loss: 0.4232552945613861 \n",
            "OrderedDict({'weights': tensor([0.1743]), 'bias': tensor([0.3446])})\n",
            "Epoch: 1180 | MAE Train Loss: 0.16567182540893555 | MAE Test Loss: 0.42216700315475464 \n",
            "OrderedDict({'weights': tensor([0.1747]), 'bias': tensor([0.3454])})\n",
            "Epoch: 1190 | MAE Train Loss: 0.16496482491493225 | MAE Test Loss: 0.42107874155044556 \n",
            "OrderedDict({'weights': tensor([0.1751]), 'bias': tensor([0.3461])})\n",
            "Epoch: 1200 | MAE Train Loss: 0.16425785422325134 | MAE Test Loss: 0.4199903905391693 \n",
            "OrderedDict({'weights': tensor([0.1755]), 'bias': tensor([0.3469])})\n",
            "Epoch: 1210 | MAE Train Loss: 0.16355086863040924 | MAE Test Loss: 0.41890209913253784 \n",
            "OrderedDict({'weights': tensor([0.1758]), 'bias': tensor([0.3476])})\n",
            "Epoch: 1220 | MAE Train Loss: 0.16284386813640594 | MAE Test Loss: 0.417813777923584 \n",
            "OrderedDict({'weights': tensor([0.1762]), 'bias': tensor([0.3484])})\n",
            "Epoch: 1230 | MAE Train Loss: 0.16213688254356384 | MAE Test Loss: 0.4167254567146301 \n",
            "OrderedDict({'weights': tensor([0.1766]), 'bias': tensor([0.3491])})\n",
            "Epoch: 1240 | MAE Train Loss: 0.16142991185188293 | MAE Test Loss: 0.41563716530799866 \n",
            "OrderedDict({'weights': tensor([0.1770]), 'bias': tensor([0.3499])})\n",
            "Epoch: 1250 | MAE Train Loss: 0.16072292625904083 | MAE Test Loss: 0.4145488739013672 \n",
            "OrderedDict({'weights': tensor([0.1774]), 'bias': tensor([0.3506])})\n",
            "Epoch: 1260 | MAE Train Loss: 0.16001592576503754 | MAE Test Loss: 0.41346055269241333 \n",
            "OrderedDict({'weights': tensor([0.1777]), 'bias': tensor([0.3514])})\n",
            "Epoch: 1270 | MAE Train Loss: 0.15930894017219543 | MAE Test Loss: 0.41237226128578186 \n",
            "OrderedDict({'weights': tensor([0.1781]), 'bias': tensor([0.3521])})\n",
            "Epoch: 1280 | MAE Train Loss: 0.1586589515209198 | MAE Test Loss: 0.4113275110721588 \n",
            "OrderedDict({'weights': tensor([0.1785]), 'bias': tensor([0.3528])})\n",
            "Epoch: 1290 | MAE Train Loss: 0.1580282747745514 | MAE Test Loss: 0.41029366850852966 \n",
            "OrderedDict({'weights': tensor([0.1789]), 'bias': tensor([0.3535])})\n",
            "Epoch: 1300 | MAE Train Loss: 0.1573975831270218 | MAE Test Loss: 0.4092597961425781 \n",
            "OrderedDict({'weights': tensor([0.1792]), 'bias': tensor([0.3542])})\n",
            "Epoch: 1310 | MAE Train Loss: 0.15676690638065338 | MAE Test Loss: 0.4082259237766266 \n",
            "OrderedDict({'weights': tensor([0.1796]), 'bias': tensor([0.3549])})\n",
            "Epoch: 1320 | MAE Train Loss: 0.15613619983196259 | MAE Test Loss: 0.40719205141067505 \n",
            "OrderedDict({'weights': tensor([0.1800]), 'bias': tensor([0.3556])})\n",
            "Epoch: 1330 | MAE Train Loss: 0.15550552308559418 | MAE Test Loss: 0.4061582088470459 \n",
            "OrderedDict({'weights': tensor([0.1804]), 'bias': tensor([0.3563])})\n",
            "Epoch: 1340 | MAE Train Loss: 0.15487483143806458 | MAE Test Loss: 0.40512433648109436 \n",
            "OrderedDict({'weights': tensor([0.1807]), 'bias': tensor([0.3570])})\n",
            "Epoch: 1350 | MAE Train Loss: 0.15424413979053497 | MAE Test Loss: 0.4040904939174652 \n",
            "OrderedDict({'weights': tensor([0.1811]), 'bias': tensor([0.3577])})\n",
            "Epoch: 1360 | MAE Train Loss: 0.15361346304416656 | MAE Test Loss: 0.40305662155151367 \n",
            "OrderedDict({'weights': tensor([0.1815]), 'bias': tensor([0.3584])})\n",
            "Epoch: 1370 | MAE Train Loss: 0.15298277139663696 | MAE Test Loss: 0.4020227789878845 \n",
            "OrderedDict({'weights': tensor([0.1819]), 'bias': tensor([0.3591])})\n",
            "Epoch: 1380 | MAE Train Loss: 0.15235206484794617 | MAE Test Loss: 0.4009888768196106 \n",
            "OrderedDict({'weights': tensor([0.1822]), 'bias': tensor([0.3598])})\n",
            "Epoch: 1390 | MAE Train Loss: 0.15172138810157776 | MAE Test Loss: 0.39995500445365906 \n",
            "OrderedDict({'weights': tensor([0.1826]), 'bias': tensor([0.3605])})\n",
            "Epoch: 1400 | MAE Train Loss: 0.15109071135520935 | MAE Test Loss: 0.3989211618900299 \n",
            "OrderedDict({'weights': tensor([0.1830]), 'bias': tensor([0.3612])})\n",
            "Epoch: 1410 | MAE Train Loss: 0.15046000480651855 | MAE Test Loss: 0.397887259721756 \n",
            "OrderedDict({'weights': tensor([0.1834]), 'bias': tensor([0.3619])})\n",
            "Epoch: 1420 | MAE Train Loss: 0.14988309144973755 | MAE Test Loss: 0.3968978822231293 \n",
            "OrderedDict({'weights': tensor([0.1837]), 'bias': tensor([0.3626])})\n",
            "Epoch: 1430 | MAE Train Loss: 0.1493244469165802 | MAE Test Loss: 0.3959195017814636 \n",
            "OrderedDict({'weights': tensor([0.1841]), 'bias': tensor([0.3632])})\n",
            "Epoch: 1440 | MAE Train Loss: 0.14876581728458405 | MAE Test Loss: 0.394941121339798 \n",
            "OrderedDict({'weights': tensor([0.1845]), 'bias': tensor([0.3639])})\n",
            "Epoch: 1450 | MAE Train Loss: 0.1482071876525879 | MAE Test Loss: 0.3939627408981323 \n",
            "OrderedDict({'weights': tensor([0.1848]), 'bias': tensor([0.3645])})\n",
            "Epoch: 1460 | MAE Train Loss: 0.14764854311943054 | MAE Test Loss: 0.39298442006111145 \n",
            "OrderedDict({'weights': tensor([0.1852]), 'bias': tensor([0.3652])})\n",
            "Epoch: 1470 | MAE Train Loss: 0.1470898985862732 | MAE Test Loss: 0.3920060992240906 \n",
            "OrderedDict({'weights': tensor([0.1856]), 'bias': tensor([0.3658])})\n",
            "Epoch: 1480 | MAE Train Loss: 0.14653126895427704 | MAE Test Loss: 0.3910277187824249 \n",
            "OrderedDict({'weights': tensor([0.1860]), 'bias': tensor([0.3665])})\n",
            "Epoch: 1490 | MAE Train Loss: 0.14597263932228088 | MAE Test Loss: 0.3900493383407593 \n",
            "OrderedDict({'weights': tensor([0.1863]), 'bias': tensor([0.3671])})\n",
            "Epoch: 1500 | MAE Train Loss: 0.14541399478912354 | MAE Test Loss: 0.389070987701416 \n",
            "OrderedDict({'weights': tensor([0.1867]), 'bias': tensor([0.3678])})\n",
            "Epoch: 1510 | MAE Train Loss: 0.14485536515712738 | MAE Test Loss: 0.38809260725975037 \n",
            "OrderedDict({'weights': tensor([0.1871]), 'bias': tensor([0.3684])})\n",
            "Epoch: 1520 | MAE Train Loss: 0.14429673552513123 | MAE Test Loss: 0.3871142864227295 \n",
            "OrderedDict({'weights': tensor([0.1874]), 'bias': tensor([0.3691])})\n",
            "Epoch: 1530 | MAE Train Loss: 0.14373810589313507 | MAE Test Loss: 0.38613593578338623 \n",
            "OrderedDict({'weights': tensor([0.1878]), 'bias': tensor([0.3697])})\n",
            "Epoch: 1540 | MAE Train Loss: 0.14317946135997772 | MAE Test Loss: 0.3851575553417206 \n",
            "OrderedDict({'weights': tensor([0.1882]), 'bias': tensor([0.3704])})\n",
            "Epoch: 1550 | MAE Train Loss: 0.14262081682682037 | MAE Test Loss: 0.3841792047023773 \n",
            "OrderedDict({'weights': tensor([0.1885]), 'bias': tensor([0.3710])})\n",
            "Epoch: 1560 | MAE Train Loss: 0.1420646607875824 | MAE Test Loss: 0.38320648670196533 \n",
            "OrderedDict({'weights': tensor([0.1889]), 'bias': tensor([0.3717])})\n",
            "Epoch: 1570 | MAE Train Loss: 0.1415736973285675 | MAE Test Loss: 0.38228440284729004 \n",
            "OrderedDict({'weights': tensor([0.1893]), 'bias': tensor([0.3723])})\n",
            "Epoch: 1580 | MAE Train Loss: 0.14108271896839142 | MAE Test Loss: 0.38136234879493713 \n",
            "OrderedDict({'weights': tensor([0.1896]), 'bias': tensor([0.3729])})\n",
            "Epoch: 1590 | MAE Train Loss: 0.14059174060821533 | MAE Test Loss: 0.38044029474258423 \n",
            "OrderedDict({'weights': tensor([0.1900]), 'bias': tensor([0.3735])})\n",
            "Epoch: 1600 | MAE Train Loss: 0.14010074734687805 | MAE Test Loss: 0.3795182704925537 \n",
            "OrderedDict({'weights': tensor([0.1904]), 'bias': tensor([0.3741])})\n",
            "Epoch: 1610 | MAE Train Loss: 0.13960976898670197 | MAE Test Loss: 0.3785962164402008 \n",
            "OrderedDict({'weights': tensor([0.1907]), 'bias': tensor([0.3747])})\n",
            "Epoch: 1620 | MAE Train Loss: 0.13911880552768707 | MAE Test Loss: 0.3776741623878479 \n",
            "OrderedDict({'weights': tensor([0.1911]), 'bias': tensor([0.3753])})\n",
            "Epoch: 1630 | MAE Train Loss: 0.1386277973651886 | MAE Test Loss: 0.3767520785331726 \n",
            "OrderedDict({'weights': tensor([0.1914]), 'bias': tensor([0.3759])})\n",
            "Epoch: 1640 | MAE Train Loss: 0.1381368339061737 | MAE Test Loss: 0.3758300244808197 \n",
            "OrderedDict({'weights': tensor([0.1918]), 'bias': tensor([0.3765])})\n",
            "Epoch: 1650 | MAE Train Loss: 0.1376458704471588 | MAE Test Loss: 0.3749080002307892 \n",
            "OrderedDict({'weights': tensor([0.1922]), 'bias': tensor([0.3771])})\n",
            "Epoch: 1660 | MAE Train Loss: 0.13715489208698273 | MAE Test Loss: 0.3739859461784363 \n",
            "OrderedDict({'weights': tensor([0.1925]), 'bias': tensor([0.3777])})\n",
            "Epoch: 1670 | MAE Train Loss: 0.13666388392448425 | MAE Test Loss: 0.373063862323761 \n",
            "OrderedDict({'weights': tensor([0.1929]), 'bias': tensor([0.3783])})\n",
            "Epoch: 1680 | MAE Train Loss: 0.13617292046546936 | MAE Test Loss: 0.3721418082714081 \n",
            "OrderedDict({'weights': tensor([0.1932]), 'bias': tensor([0.3789])})\n",
            "Epoch: 1690 | MAE Train Loss: 0.13568195700645447 | MAE Test Loss: 0.3712197542190552 \n",
            "OrderedDict({'weights': tensor([0.1936]), 'bias': tensor([0.3795])})\n",
            "Epoch: 1700 | MAE Train Loss: 0.13519097864627838 | MAE Test Loss: 0.37029772996902466 \n",
            "OrderedDict({'weights': tensor([0.1940]), 'bias': tensor([0.3801])})\n",
            "Epoch: 1710 | MAE Train Loss: 0.1347000002861023 | MAE Test Loss: 0.36937564611434937 \n",
            "OrderedDict({'weights': tensor([0.1943]), 'bias': tensor([0.3807])})\n",
            "Epoch: 1720 | MAE Train Loss: 0.13424178957939148 | MAE Test Loss: 0.36848780512809753 \n",
            "OrderedDict({'weights': tensor([0.1947]), 'bias': tensor([0.3812])})\n",
            "Epoch: 1730 | MAE Train Loss: 0.1338140368461609 | MAE Test Loss: 0.36762291193008423 \n",
            "OrderedDict({'weights': tensor([0.1950]), 'bias': tensor([0.3818])})\n",
            "Epoch: 1740 | MAE Train Loss: 0.1333862841129303 | MAE Test Loss: 0.36675795912742615 \n",
            "OrderedDict({'weights': tensor([0.1954]), 'bias': tensor([0.3823])})\n",
            "Epoch: 1750 | MAE Train Loss: 0.1329585313796997 | MAE Test Loss: 0.3658929765224457 \n",
            "OrderedDict({'weights': tensor([0.1958]), 'bias': tensor([0.3829])})\n",
            "Epoch: 1760 | MAE Train Loss: 0.13253077864646912 | MAE Test Loss: 0.3650280237197876 \n",
            "OrderedDict({'weights': tensor([0.1961]), 'bias': tensor([0.3834])})\n",
            "Epoch: 1770 | MAE Train Loss: 0.13210302591323853 | MAE Test Loss: 0.3641630709171295 \n",
            "OrderedDict({'weights': tensor([0.1965]), 'bias': tensor([0.3840])})\n",
            "Epoch: 1780 | MAE Train Loss: 0.13167527318000793 | MAE Test Loss: 0.36329811811447144 \n",
            "OrderedDict({'weights': tensor([0.1968]), 'bias': tensor([0.3845])})\n",
            "Epoch: 1790 | MAE Train Loss: 0.13124752044677734 | MAE Test Loss: 0.36243313550949097 \n",
            "OrderedDict({'weights': tensor([0.1972]), 'bias': tensor([0.3851])})\n",
            "Epoch: 1800 | MAE Train Loss: 0.13081976771354675 | MAE Test Loss: 0.3615681827068329 \n",
            "OrderedDict({'weights': tensor([0.1975]), 'bias': tensor([0.3856])})\n",
            "Epoch: 1810 | MAE Train Loss: 0.13039201498031616 | MAE Test Loss: 0.3607032299041748 \n",
            "OrderedDict({'weights': tensor([0.1979]), 'bias': tensor([0.3862])})\n",
            "Epoch: 1820 | MAE Train Loss: 0.12996426224708557 | MAE Test Loss: 0.35983824729919434 \n",
            "OrderedDict({'weights': tensor([0.1982]), 'bias': tensor([0.3867])})\n",
            "Epoch: 1830 | MAE Train Loss: 0.12953650951385498 | MAE Test Loss: 0.35897329449653625 \n",
            "OrderedDict({'weights': tensor([0.1986]), 'bias': tensor([0.3873])})\n",
            "Epoch: 1840 | MAE Train Loss: 0.1291087567806244 | MAE Test Loss: 0.3581083416938782 \n",
            "OrderedDict({'weights': tensor([0.1989]), 'bias': tensor([0.3878])})\n",
            "Epoch: 1850 | MAE Train Loss: 0.1286810040473938 | MAE Test Loss: 0.3572433888912201 \n",
            "OrderedDict({'weights': tensor([0.1993]), 'bias': tensor([0.3884])})\n",
            "Epoch: 1860 | MAE Train Loss: 0.1282532513141632 | MAE Test Loss: 0.356378436088562 \n",
            "OrderedDict({'weights': tensor([0.1996]), 'bias': tensor([0.3889])})\n",
            "Epoch: 1870 | MAE Train Loss: 0.12782549858093262 | MAE Test Loss: 0.35551348328590393 \n",
            "OrderedDict({'weights': tensor([0.2000]), 'bias': tensor([0.3895])})\n",
            "Epoch: 1880 | MAE Train Loss: 0.12739959359169006 | MAE Test Loss: 0.3546542823314667 \n",
            "OrderedDict({'weights': tensor([0.2004]), 'bias': tensor([0.3900])})\n",
            "Epoch: 1890 | MAE Train Loss: 0.12703055143356323 | MAE Test Loss: 0.3538472056388855 \n",
            "OrderedDict({'weights': tensor([0.2007]), 'bias': tensor([0.3905])})\n",
            "Epoch: 1900 | MAE Train Loss: 0.1266614943742752 | MAE Test Loss: 0.3530401289463043 \n",
            "OrderedDict({'weights': tensor([0.2010]), 'bias': tensor([0.3910])})\n",
            "Epoch: 1910 | MAE Train Loss: 0.12629243731498718 | MAE Test Loss: 0.35223299264907837 \n",
            "OrderedDict({'weights': tensor([0.2014]), 'bias': tensor([0.3915])})\n",
            "Epoch: 1920 | MAE Train Loss: 0.12592338025569916 | MAE Test Loss: 0.3514259457588196 \n",
            "OrderedDict({'weights': tensor([0.2017]), 'bias': tensor([0.3920])})\n",
            "Epoch: 1930 | MAE Train Loss: 0.12555433809757233 | MAE Test Loss: 0.35061877965927124 \n",
            "OrderedDict({'weights': tensor([0.2021]), 'bias': tensor([0.3925])})\n",
            "Epoch: 1940 | MAE Train Loss: 0.1251852810382843 | MAE Test Loss: 0.34981170296669006 \n",
            "OrderedDict({'weights': tensor([0.2024]), 'bias': tensor([0.3930])})\n",
            "Epoch: 1950 | MAE Train Loss: 0.12481622397899628 | MAE Test Loss: 0.3490045964717865 \n",
            "OrderedDict({'weights': tensor([0.2028]), 'bias': tensor([0.3935])})\n",
            "Epoch: 1960 | MAE Train Loss: 0.12444718182086945 | MAE Test Loss: 0.3481975197792053 \n",
            "OrderedDict({'weights': tensor([0.2031]), 'bias': tensor([0.3940])})\n",
            "Epoch: 1970 | MAE Train Loss: 0.12407810986042023 | MAE Test Loss: 0.34739041328430176 \n",
            "OrderedDict({'weights': tensor([0.2035]), 'bias': tensor([0.3945])})\n",
            "Epoch: 1980 | MAE Train Loss: 0.1237090677022934 | MAE Test Loss: 0.3465833067893982 \n",
            "OrderedDict({'weights': tensor([0.2038]), 'bias': tensor([0.3950])})\n",
            "Epoch: 1990 | MAE Train Loss: 0.12334002554416656 | MAE Test Loss: 0.34577620029449463 \n",
            "OrderedDict({'weights': tensor([0.2042]), 'bias': tensor([0.3955])})\n",
            "Epoch: 2000 | MAE Train Loss: 0.12297096103429794 | MAE Test Loss: 0.34496909379959106 \n",
            "OrderedDict({'weights': tensor([0.2045]), 'bias': tensor([0.3960])})\n",
            "Epoch: 2010 | MAE Train Loss: 0.12260190397500992 | MAE Test Loss: 0.3441620171070099 \n",
            "OrderedDict({'weights': tensor([0.2048]), 'bias': tensor([0.3965])})\n",
            "Epoch: 2020 | MAE Train Loss: 0.12223285436630249 | MAE Test Loss: 0.3433549106121063 \n",
            "OrderedDict({'weights': tensor([0.2052]), 'bias': tensor([0.3970])})\n",
            "Epoch: 2030 | MAE Train Loss: 0.12186380475759506 | MAE Test Loss: 0.34254783391952515 \n",
            "OrderedDict({'weights': tensor([0.2055]), 'bias': tensor([0.3975])})\n",
            "Epoch: 2040 | MAE Train Loss: 0.12149474769830704 | MAE Test Loss: 0.34174075722694397 \n",
            "OrderedDict({'weights': tensor([0.2059]), 'bias': tensor([0.3980])})\n",
            "Epoch: 2050 | MAE Train Loss: 0.12112569808959961 | MAE Test Loss: 0.340933620929718 \n",
            "OrderedDict({'weights': tensor([0.2062]), 'bias': tensor([0.3985])})\n",
            "Epoch: 2060 | MAE Train Loss: 0.12078391015529633 | MAE Test Loss: 0.34016188979148865 \n",
            "OrderedDict({'weights': tensor([0.2066]), 'bias': tensor([0.3990])})\n",
            "Epoch: 2070 | MAE Train Loss: 0.12046919018030167 | MAE Test Loss: 0.33941373229026794 \n",
            "OrderedDict({'weights': tensor([0.2069]), 'bias': tensor([0.3995])})\n",
            "Epoch: 2080 | MAE Train Loss: 0.1201544776558876 | MAE Test Loss: 0.338665634393692 \n",
            "OrderedDict({'weights': tensor([0.2072]), 'bias': tensor([0.3999])})\n",
            "Epoch: 2090 | MAE Train Loss: 0.11983975023031235 | MAE Test Loss: 0.3379174470901489 \n",
            "OrderedDict({'weights': tensor([0.2076]), 'bias': tensor([0.4004])})\n",
            "Epoch: 2100 | MAE Train Loss: 0.1195250153541565 | MAE Test Loss: 0.3371693193912506 \n",
            "OrderedDict({'weights': tensor([0.2079]), 'bias': tensor([0.4008])})\n",
            "Epoch: 2110 | MAE Train Loss: 0.11921030282974243 | MAE Test Loss: 0.3364211618900299 \n",
            "OrderedDict({'weights': tensor([0.2082]), 'bias': tensor([0.4013])})\n",
            "Epoch: 2120 | MAE Train Loss: 0.11889559030532837 | MAE Test Loss: 0.3356730341911316 \n",
            "OrderedDict({'weights': tensor([0.2086]), 'bias': tensor([0.4017])})\n",
            "Epoch: 2130 | MAE Train Loss: 0.11858084052801132 | MAE Test Loss: 0.3349248766899109 \n",
            "OrderedDict({'weights': tensor([0.2089]), 'bias': tensor([0.4022])})\n",
            "Epoch: 2140 | MAE Train Loss: 0.11826612055301666 | MAE Test Loss: 0.3341767191886902 \n",
            "OrderedDict({'weights': tensor([0.2092]), 'bias': tensor([0.4026])})\n",
            "Epoch: 2150 | MAE Train Loss: 0.1179514080286026 | MAE Test Loss: 0.33342859148979187 \n",
            "OrderedDict({'weights': tensor([0.2096]), 'bias': tensor([0.4031])})\n",
            "Epoch: 2160 | MAE Train Loss: 0.11763668060302734 | MAE Test Loss: 0.3326804041862488 \n",
            "OrderedDict({'weights': tensor([0.2099]), 'bias': tensor([0.4035])})\n",
            "Epoch: 2170 | MAE Train Loss: 0.11732195317745209 | MAE Test Loss: 0.33193230628967285 \n",
            "OrderedDict({'weights': tensor([0.2102]), 'bias': tensor([0.4040])})\n",
            "Epoch: 2180 | MAE Train Loss: 0.11700721830129623 | MAE Test Loss: 0.33118414878845215 \n",
            "OrderedDict({'weights': tensor([0.2106]), 'bias': tensor([0.4044])})\n",
            "Epoch: 2190 | MAE Train Loss: 0.11669250577688217 | MAE Test Loss: 0.33043599128723145 \n",
            "OrderedDict({'weights': tensor([0.2109]), 'bias': tensor([0.4049])})\n",
            "Epoch: 2200 | MAE Train Loss: 0.11637777090072632 | MAE Test Loss: 0.32968786358833313 \n",
            "OrderedDict({'weights': tensor([0.2112]), 'bias': tensor([0.4053])})\n",
            "Epoch: 2210 | MAE Train Loss: 0.11606305837631226 | MAE Test Loss: 0.32893967628479004 \n",
            "OrderedDict({'weights': tensor([0.2116]), 'bias': tensor([0.4058])})\n",
            "Epoch: 2220 | MAE Train Loss: 0.115748330950737 | MAE Test Loss: 0.3281915783882141 \n",
            "OrderedDict({'weights': tensor([0.2119]), 'bias': tensor([0.4062])})\n",
            "Epoch: 2230 | MAE Train Loss: 0.11543361842632294 | MAE Test Loss: 0.3274434208869934 \n",
            "OrderedDict({'weights': tensor([0.2123]), 'bias': tensor([0.4067])})\n",
            "Epoch: 2240 | MAE Train Loss: 0.11511888355016708 | MAE Test Loss: 0.3266952633857727 \n",
            "OrderedDict({'weights': tensor([0.2126]), 'bias': tensor([0.4071])})\n",
            "Epoch: 2250 | MAE Train Loss: 0.11483540385961533 | MAE Test Loss: 0.3259890675544739 \n",
            "OrderedDict({'weights': tensor([0.2129]), 'bias': tensor([0.4075])})\n",
            "Epoch: 2260 | MAE Train Loss: 0.11457047611474991 | MAE Test Loss: 0.32530078291893005 \n",
            "OrderedDict({'weights': tensor([0.2132]), 'bias': tensor([0.4079])})\n",
            "Epoch: 2270 | MAE Train Loss: 0.1143055334687233 | MAE Test Loss: 0.32461249828338623 \n",
            "OrderedDict({'weights': tensor([0.2136]), 'bias': tensor([0.4083])})\n",
            "Epoch: 2280 | MAE Train Loss: 0.11404059082269669 | MAE Test Loss: 0.3239242434501648 \n",
            "OrderedDict({'weights': tensor([0.2139]), 'bias': tensor([0.4087])})\n",
            "Epoch: 2290 | MAE Train Loss: 0.11377564817667007 | MAE Test Loss: 0.32323598861694336 \n",
            "OrderedDict({'weights': tensor([0.2142]), 'bias': tensor([0.4091])})\n",
            "Epoch: 2300 | MAE Train Loss: 0.11351070553064346 | MAE Test Loss: 0.3225477337837219 \n",
            "OrderedDict({'weights': tensor([0.2145]), 'bias': tensor([0.4095])})\n",
            "Epoch: 2310 | MAE Train Loss: 0.11324578523635864 | MAE Test Loss: 0.3218594491481781 \n",
            "OrderedDict({'weights': tensor([0.2149]), 'bias': tensor([0.4099])})\n",
            "Epoch: 2320 | MAE Train Loss: 0.11298084259033203 | MAE Test Loss: 0.32117122411727905 \n",
            "OrderedDict({'weights': tensor([0.2152]), 'bias': tensor([0.4103])})\n",
            "Epoch: 2330 | MAE Train Loss: 0.11271589994430542 | MAE Test Loss: 0.32048290967941284 \n",
            "OrderedDict({'weights': tensor([0.2155]), 'bias': tensor([0.4107])})\n",
            "Epoch: 2340 | MAE Train Loss: 0.11245095729827881 | MAE Test Loss: 0.3197946548461914 \n",
            "OrderedDict({'weights': tensor([0.2158]), 'bias': tensor([0.4111])})\n",
            "Epoch: 2350 | MAE Train Loss: 0.1121860146522522 | MAE Test Loss: 0.31910640001296997 \n",
            "OrderedDict({'weights': tensor([0.2162]), 'bias': tensor([0.4115])})\n",
            "Epoch: 2360 | MAE Train Loss: 0.11192108690738678 | MAE Test Loss: 0.31841811537742615 \n",
            "OrderedDict({'weights': tensor([0.2165]), 'bias': tensor([0.4119])})\n",
            "Epoch: 2370 | MAE Train Loss: 0.11165612936019897 | MAE Test Loss: 0.3177298903465271 \n",
            "OrderedDict({'weights': tensor([0.2168]), 'bias': tensor([0.4123])})\n",
            "Epoch: 2380 | MAE Train Loss: 0.11139120161533356 | MAE Test Loss: 0.3170416057109833 \n",
            "OrderedDict({'weights': tensor([0.2171]), 'bias': tensor([0.4127])})\n",
            "Epoch: 2390 | MAE Train Loss: 0.11112625896930695 | MAE Test Loss: 0.31635335087776184 \n",
            "OrderedDict({'weights': tensor([0.2175]), 'bias': tensor([0.4131])})\n",
            "Epoch: 2400 | MAE Train Loss: 0.11086131632328033 | MAE Test Loss: 0.315665066242218 \n",
            "OrderedDict({'weights': tensor([0.2178]), 'bias': tensor([0.4135])})\n",
            "Epoch: 2410 | MAE Train Loss: 0.11059638112783432 | MAE Test Loss: 0.31497684121131897 \n",
            "OrderedDict({'weights': tensor([0.2181]), 'bias': tensor([0.4139])})\n",
            "Epoch: 2420 | MAE Train Loss: 0.1103314533829689 | MAE Test Loss: 0.31428855657577515 \n",
            "OrderedDict({'weights': tensor([0.2184]), 'bias': tensor([0.4143])})\n",
            "Epoch: 2430 | MAE Train Loss: 0.11006651073694229 | MAE Test Loss: 0.3136002719402313 \n",
            "OrderedDict({'weights': tensor([0.2187]), 'bias': tensor([0.4147])})\n",
            "Epoch: 2440 | MAE Train Loss: 0.10980156809091568 | MAE Test Loss: 0.3129120171070099 \n",
            "OrderedDict({'weights': tensor([0.2191]), 'bias': tensor([0.4151])})\n",
            "Epoch: 2450 | MAE Train Loss: 0.1095469743013382 | MAE Test Loss: 0.31224197149276733 \n",
            "OrderedDict({'weights': tensor([0.2194]), 'bias': tensor([0.4155])})\n",
            "Epoch: 2460 | MAE Train Loss: 0.10932715237140656 | MAE Test Loss: 0.31161436438560486 \n",
            "OrderedDict({'weights': tensor([0.2197]), 'bias': tensor([0.4158])})\n",
            "Epoch: 2470 | MAE Train Loss: 0.1091073527932167 | MAE Test Loss: 0.31098678708076477 \n",
            "OrderedDict({'weights': tensor([0.2200]), 'bias': tensor([0.4162])})\n",
            "Epoch: 2480 | MAE Train Loss: 0.10888753086328506 | MAE Test Loss: 0.31035923957824707 \n",
            "OrderedDict({'weights': tensor([0.2203]), 'bias': tensor([0.4165])})\n",
            "Epoch: 2490 | MAE Train Loss: 0.10866771638393402 | MAE Test Loss: 0.3097316324710846 \n",
            "OrderedDict({'weights': tensor([0.2206]), 'bias': tensor([0.4169])})\n",
            "Epoch: 2500 | MAE Train Loss: 0.10844792425632477 | MAE Test Loss: 0.3091040253639221 \n",
            "OrderedDict({'weights': tensor([0.2210]), 'bias': tensor([0.4172])})\n",
            "Epoch: 2510 | MAE Train Loss: 0.10822810232639313 | MAE Test Loss: 0.30847644805908203 \n",
            "OrderedDict({'weights': tensor([0.2213]), 'bias': tensor([0.4176])})\n",
            "Epoch: 2520 | MAE Train Loss: 0.10800830274820328 | MAE Test Loss: 0.30784887075424194 \n",
            "OrderedDict({'weights': tensor([0.2216]), 'bias': tensor([0.4179])})\n",
            "Epoch: 2530 | MAE Train Loss: 0.10778848081827164 | MAE Test Loss: 0.30722129344940186 \n",
            "OrderedDict({'weights': tensor([0.2219]), 'bias': tensor([0.4183])})\n",
            "Epoch: 2540 | MAE Train Loss: 0.1075686663389206 | MAE Test Loss: 0.3065936863422394 \n",
            "OrderedDict({'weights': tensor([0.2222]), 'bias': tensor([0.4186])})\n",
            "Epoch: 2550 | MAE Train Loss: 0.10734887421131134 | MAE Test Loss: 0.3059660792350769 \n",
            "OrderedDict({'weights': tensor([0.2225]), 'bias': tensor([0.4190])})\n",
            "Epoch: 2560 | MAE Train Loss: 0.1071290373802185 | MAE Test Loss: 0.3053385317325592 \n",
            "OrderedDict({'weights': tensor([0.2228]), 'bias': tensor([0.4193])})\n",
            "Epoch: 2570 | MAE Train Loss: 0.10690923780202866 | MAE Test Loss: 0.30471092462539673 \n",
            "OrderedDict({'weights': tensor([0.2231]), 'bias': tensor([0.4197])})\n",
            "Epoch: 2580 | MAE Train Loss: 0.10668941587209702 | MAE Test Loss: 0.30408334732055664 \n",
            "OrderedDict({'weights': tensor([0.2234]), 'bias': tensor([0.4200])})\n",
            "Epoch: 2590 | MAE Train Loss: 0.10646961629390717 | MAE Test Loss: 0.30345577001571655 \n",
            "OrderedDict({'weights': tensor([0.2238]), 'bias': tensor([0.4204])})\n",
            "Epoch: 2600 | MAE Train Loss: 0.10624980926513672 | MAE Test Loss: 0.3028281331062317 \n",
            "OrderedDict({'weights': tensor([0.2241]), 'bias': tensor([0.4207])})\n",
            "Epoch: 2610 | MAE Train Loss: 0.10602998733520508 | MAE Test Loss: 0.3022006154060364 \n",
            "OrderedDict({'weights': tensor([0.2244]), 'bias': tensor([0.4211])})\n",
            "Epoch: 2620 | MAE Train Loss: 0.10581018030643463 | MAE Test Loss: 0.3015730082988739 \n",
            "OrderedDict({'weights': tensor([0.2247]), 'bias': tensor([0.4214])})\n",
            "Epoch: 2630 | MAE Train Loss: 0.10559036582708359 | MAE Test Loss: 0.3009454309940338 \n",
            "OrderedDict({'weights': tensor([0.2250]), 'bias': tensor([0.4218])})\n",
            "Epoch: 2640 | MAE Train Loss: 0.10537055879831314 | MAE Test Loss: 0.30031782388687134 \n",
            "OrderedDict({'weights': tensor([0.2253]), 'bias': tensor([0.4221])})\n",
            "Epoch: 2650 | MAE Train Loss: 0.1051507443189621 | MAE Test Loss: 0.29969021677970886 \n",
            "OrderedDict({'weights': tensor([0.2256]), 'bias': tensor([0.4225])})\n",
            "Epoch: 2660 | MAE Train Loss: 0.10493092238903046 | MAE Test Loss: 0.29906266927719116 \n",
            "OrderedDict({'weights': tensor([0.2259]), 'bias': tensor([0.4228])})\n",
            "Epoch: 2670 | MAE Train Loss: 0.10471111536026001 | MAE Test Loss: 0.2984350621700287 \n",
            "OrderedDict({'weights': tensor([0.2263]), 'bias': tensor([0.4232])})\n",
            "Epoch: 2680 | MAE Train Loss: 0.10452882945537567 | MAE Test Loss: 0.2978687882423401 \n",
            "OrderedDict({'weights': tensor([0.2266]), 'bias': tensor([0.4235])})\n",
            "Epoch: 2690 | MAE Train Loss: 0.10434935986995697 | MAE Test Loss: 0.2973025441169739 \n",
            "OrderedDict({'weights': tensor([0.2269]), 'bias': tensor([0.4238])})\n",
            "Epoch: 2700 | MAE Train Loss: 0.10416992008686066 | MAE Test Loss: 0.2967362105846405 \n",
            "OrderedDict({'weights': tensor([0.2272]), 'bias': tensor([0.4241])})\n",
            "Epoch: 2710 | MAE Train Loss: 0.10399045795202255 | MAE Test Loss: 0.2961699366569519 \n",
            "OrderedDict({'weights': tensor([0.2275]), 'bias': tensor([0.4244])})\n",
            "Epoch: 2720 | MAE Train Loss: 0.10381100326776505 | MAE Test Loss: 0.2956036627292633 \n",
            "OrderedDict({'weights': tensor([0.2278]), 'bias': tensor([0.4247])})\n",
            "Epoch: 2730 | MAE Train Loss: 0.10363155603408813 | MAE Test Loss: 0.2950374186038971 \n",
            "OrderedDict({'weights': tensor([0.2281]), 'bias': tensor([0.4250])})\n",
            "Epoch: 2740 | MAE Train Loss: 0.10345210134983063 | MAE Test Loss: 0.2944711446762085 \n",
            "OrderedDict({'weights': tensor([0.2283]), 'bias': tensor([0.4253])})\n",
            "Epoch: 2750 | MAE Train Loss: 0.10327265411615372 | MAE Test Loss: 0.2939048409461975 \n",
            "OrderedDict({'weights': tensor([0.2286]), 'bias': tensor([0.4256])})\n",
            "Epoch: 2760 | MAE Train Loss: 0.10309319198131561 | MAE Test Loss: 0.2933385670185089 \n",
            "OrderedDict({'weights': tensor([0.2289]), 'bias': tensor([0.4259])})\n",
            "Epoch: 2770 | MAE Train Loss: 0.1029137372970581 | MAE Test Loss: 0.2927722930908203 \n",
            "OrderedDict({'weights': tensor([0.2292]), 'bias': tensor([0.4262])})\n",
            "Epoch: 2780 | MAE Train Loss: 0.1027342900633812 | MAE Test Loss: 0.2922060191631317 \n",
            "OrderedDict({'weights': tensor([0.2295]), 'bias': tensor([0.4265])})\n",
            "Epoch: 2790 | MAE Train Loss: 0.1025548204779625 | MAE Test Loss: 0.2916397452354431 \n",
            "OrderedDict({'weights': tensor([0.2298]), 'bias': tensor([0.4268])})\n",
            "Epoch: 2800 | MAE Train Loss: 0.10237538814544678 | MAE Test Loss: 0.2910734713077545 \n",
            "OrderedDict({'weights': tensor([0.2301]), 'bias': tensor([0.4271])})\n",
            "Epoch: 2810 | MAE Train Loss: 0.10219593346118927 | MAE Test Loss: 0.2905071973800659 \n",
            "OrderedDict({'weights': tensor([0.2304]), 'bias': tensor([0.4274])})\n",
            "Epoch: 2820 | MAE Train Loss: 0.10201647132635117 | MAE Test Loss: 0.28994089365005493 \n",
            "OrderedDict({'weights': tensor([0.2307]), 'bias': tensor([0.4277])})\n",
            "Epoch: 2830 | MAE Train Loss: 0.10183701664209366 | MAE Test Loss: 0.28937461972236633 \n",
            "OrderedDict({'weights': tensor([0.2310]), 'bias': tensor([0.4280])})\n",
            "Epoch: 2840 | MAE Train Loss: 0.10165756940841675 | MAE Test Loss: 0.28880834579467773 \n",
            "OrderedDict({'weights': tensor([0.2313]), 'bias': tensor([0.4283])})\n",
            "Epoch: 2850 | MAE Train Loss: 0.10147811472415924 | MAE Test Loss: 0.28824204206466675 \n",
            "OrderedDict({'weights': tensor([0.2316]), 'bias': tensor([0.4286])})\n",
            "Epoch: 2860 | MAE Train Loss: 0.10129865258932114 | MAE Test Loss: 0.28767579793930054 \n",
            "OrderedDict({'weights': tensor([0.2319]), 'bias': tensor([0.4289])})\n",
            "Epoch: 2870 | MAE Train Loss: 0.10111920535564423 | MAE Test Loss: 0.28710952401161194 \n",
            "OrderedDict({'weights': tensor([0.2322]), 'bias': tensor([0.4292])})\n",
            "Epoch: 2880 | MAE Train Loss: 0.10093975067138672 | MAE Test Loss: 0.28654325008392334 \n",
            "OrderedDict({'weights': tensor([0.2325]), 'bias': tensor([0.4295])})\n",
            "Epoch: 2890 | MAE Train Loss: 0.10076029598712921 | MAE Test Loss: 0.28597694635391235 \n",
            "OrderedDict({'weights': tensor([0.2328]), 'bias': tensor([0.4298])})\n",
            "Epoch: 2900 | MAE Train Loss: 0.1005808487534523 | MAE Test Loss: 0.28541070222854614 \n",
            "OrderedDict({'weights': tensor([0.2331]), 'bias': tensor([0.4301])})\n",
            "Epoch: 2910 | MAE Train Loss: 0.1004013791680336 | MAE Test Loss: 0.28484439849853516 \n",
            "OrderedDict({'weights': tensor([0.2334]), 'bias': tensor([0.4304])})\n",
            "Epoch: 2920 | MAE Train Loss: 0.10023055970668793 | MAE Test Loss: 0.2842968702316284 \n",
            "OrderedDict({'weights': tensor([0.2337]), 'bias': tensor([0.4307])})\n",
            "Epoch: 2930 | MAE Train Loss: 0.10008682310581207 | MAE Test Loss: 0.2837931215763092 \n",
            "OrderedDict({'weights': tensor([0.2340]), 'bias': tensor([0.4309])})\n",
            "Epoch: 2940 | MAE Train Loss: 0.09994306415319443 | MAE Test Loss: 0.28328937292099 \n",
            "OrderedDict({'weights': tensor([0.2343]), 'bias': tensor([0.4312])})\n",
            "Epoch: 2950 | MAE Train Loss: 0.09979931265115738 | MAE Test Loss: 0.2827856242656708 \n",
            "OrderedDict({'weights': tensor([0.2346]), 'bias': tensor([0.4314])})\n",
            "Epoch: 2960 | MAE Train Loss: 0.09965556114912033 | MAE Test Loss: 0.28228187561035156 \n",
            "OrderedDict({'weights': tensor([0.2349]), 'bias': tensor([0.4317])})\n",
            "Epoch: 2970 | MAE Train Loss: 0.09951181709766388 | MAE Test Loss: 0.28177815675735474 \n",
            "OrderedDict({'weights': tensor([0.2352]), 'bias': tensor([0.4319])})\n",
            "Epoch: 2980 | MAE Train Loss: 0.09936805814504623 | MAE Test Loss: 0.2812744081020355 \n",
            "OrderedDict({'weights': tensor([0.2354]), 'bias': tensor([0.4322])})\n",
            "Epoch: 2990 | MAE Train Loss: 0.09922430664300919 | MAE Test Loss: 0.2807706594467163 \n",
            "OrderedDict({'weights': tensor([0.2357]), 'bias': tensor([0.4324])})\n",
            "Epoch: 3000 | MAE Train Loss: 0.09908056259155273 | MAE Test Loss: 0.2802669107913971 \n",
            "OrderedDict({'weights': tensor([0.2360]), 'bias': tensor([0.4327])})\n",
            "Epoch: 3010 | MAE Train Loss: 0.09893680363893509 | MAE Test Loss: 0.2797631621360779 \n",
            "OrderedDict({'weights': tensor([0.2363]), 'bias': tensor([0.4329])})\n",
            "Epoch: 3020 | MAE Train Loss: 0.09879304468631744 | MAE Test Loss: 0.27925941348075867 \n",
            "OrderedDict({'weights': tensor([0.2366]), 'bias': tensor([0.4332])})\n",
            "Epoch: 3030 | MAE Train Loss: 0.09864930063486099 | MAE Test Loss: 0.27875566482543945 \n",
            "OrderedDict({'weights': tensor([0.2369]), 'bias': tensor([0.4334])})\n",
            "Epoch: 3040 | MAE Train Loss: 0.09850554168224335 | MAE Test Loss: 0.2782519459724426 \n",
            "OrderedDict({'weights': tensor([0.2371]), 'bias': tensor([0.4337])})\n",
            "Epoch: 3050 | MAE Train Loss: 0.0983617976307869 | MAE Test Loss: 0.2777481973171234 \n",
            "OrderedDict({'weights': tensor([0.2374]), 'bias': tensor([0.4339])})\n",
            "Epoch: 3060 | MAE Train Loss: 0.09821803867816925 | MAE Test Loss: 0.2772444486618042 \n",
            "OrderedDict({'weights': tensor([0.2377]), 'bias': tensor([0.4342])})\n",
            "Epoch: 3070 | MAE Train Loss: 0.0980742946267128 | MAE Test Loss: 0.276740700006485 \n",
            "OrderedDict({'weights': tensor([0.2380]), 'bias': tensor([0.4344])})\n",
            "Epoch: 3080 | MAE Train Loss: 0.09793053567409515 | MAE Test Loss: 0.27623695135116577 \n",
            "OrderedDict({'weights': tensor([0.2383]), 'bias': tensor([0.4347])})\n",
            "Epoch: 3090 | MAE Train Loss: 0.0977867841720581 | MAE Test Loss: 0.27573323249816895 \n",
            "OrderedDict({'weights': tensor([0.2386]), 'bias': tensor([0.4349])})\n",
            "Epoch: 3100 | MAE Train Loss: 0.09764303267002106 | MAE Test Loss: 0.27522945404052734 \n",
            "OrderedDict({'weights': tensor([0.2389]), 'bias': tensor([0.4352])})\n",
            "Epoch: 3110 | MAE Train Loss: 0.09749927371740341 | MAE Test Loss: 0.2747257351875305 \n",
            "OrderedDict({'weights': tensor([0.2391]), 'bias': tensor([0.4354])})\n",
            "Epoch: 3120 | MAE Train Loss: 0.09735552966594696 | MAE Test Loss: 0.2742219567298889 \n",
            "OrderedDict({'weights': tensor([0.2394]), 'bias': tensor([0.4357])})\n",
            "Epoch: 3130 | MAE Train Loss: 0.09721178561449051 | MAE Test Loss: 0.2737182378768921 \n",
            "OrderedDict({'weights': tensor([0.2397]), 'bias': tensor([0.4359])})\n",
            "Epoch: 3140 | MAE Train Loss: 0.09706802666187286 | MAE Test Loss: 0.27321451902389526 \n",
            "OrderedDict({'weights': tensor([0.2400]), 'bias': tensor([0.4362])})\n",
            "Epoch: 3150 | MAE Train Loss: 0.09692427515983582 | MAE Test Loss: 0.27271077036857605 \n",
            "OrderedDict({'weights': tensor([0.2403]), 'bias': tensor([0.4364])})\n",
            "Epoch: 3160 | MAE Train Loss: 0.09678052365779877 | MAE Test Loss: 0.27220702171325684 \n",
            "OrderedDict({'weights': tensor([0.2406]), 'bias': tensor([0.4367])})\n",
            "Epoch: 3170 | MAE Train Loss: 0.09663676470518112 | MAE Test Loss: 0.2717032730579376 \n",
            "OrderedDict({'weights': tensor([0.2409]), 'bias': tensor([0.4369])})\n",
            "Epoch: 3180 | MAE Train Loss: 0.09649301320314407 | MAE Test Loss: 0.271199494600296 \n",
            "OrderedDict({'weights': tensor([0.2411]), 'bias': tensor([0.4372])})\n",
            "Epoch: 3190 | MAE Train Loss: 0.09634925425052643 | MAE Test Loss: 0.2706957757472992 \n",
            "OrderedDict({'weights': tensor([0.2414]), 'bias': tensor([0.4374])})\n",
            "Epoch: 3200 | MAE Train Loss: 0.09621942043304443 | MAE Test Loss: 0.2702237665653229 \n",
            "OrderedDict({'weights': tensor([0.2417]), 'bias': tensor([0.4377])})\n",
            "Epoch: 3210 | MAE Train Loss: 0.09610652178525925 | MAE Test Loss: 0.26978346705436707 \n",
            "OrderedDict({'weights': tensor([0.2420]), 'bias': tensor([0.4379])})\n",
            "Epoch: 3220 | MAE Train Loss: 0.09599361568689346 | MAE Test Loss: 0.26934319734573364 \n",
            "OrderedDict({'weights': tensor([0.2422]), 'bias': tensor([0.4381])})\n",
            "Epoch: 3230 | MAE Train Loss: 0.09588073194026947 | MAE Test Loss: 0.2689029276371002 \n",
            "OrderedDict({'weights': tensor([0.2425]), 'bias': tensor([0.4383])})\n",
            "Epoch: 3240 | MAE Train Loss: 0.09576783329248428 | MAE Test Loss: 0.2684626281261444 \n",
            "OrderedDict({'weights': tensor([0.2428]), 'bias': tensor([0.4385])})\n",
            "Epoch: 3250 | MAE Train Loss: 0.0956549420952797 | MAE Test Loss: 0.268022358417511 \n",
            "OrderedDict({'weights': tensor([0.2431]), 'bias': tensor([0.4387])})\n",
            "Epoch: 3260 | MAE Train Loss: 0.09554203599691391 | MAE Test Loss: 0.2675820589065552 \n",
            "OrderedDict({'weights': tensor([0.2433]), 'bias': tensor([0.4389])})\n",
            "Epoch: 3270 | MAE Train Loss: 0.09542913734912872 | MAE Test Loss: 0.26714175939559937 \n",
            "OrderedDict({'weights': tensor([0.2436]), 'bias': tensor([0.4391])})\n",
            "Epoch: 3280 | MAE Train Loss: 0.09531624615192413 | MAE Test Loss: 0.26670151948928833 \n",
            "OrderedDict({'weights': tensor([0.2439]), 'bias': tensor([0.4393])})\n",
            "Epoch: 3290 | MAE Train Loss: 0.09520334750413895 | MAE Test Loss: 0.2662612199783325 \n",
            "OrderedDict({'weights': tensor([0.2441]), 'bias': tensor([0.4395])})\n",
            "Epoch: 3300 | MAE Train Loss: 0.09509044885635376 | MAE Test Loss: 0.2658209204673767 \n",
            "OrderedDict({'weights': tensor([0.2444]), 'bias': tensor([0.4397])})\n",
            "Epoch: 3310 | MAE Train Loss: 0.09497755765914917 | MAE Test Loss: 0.2653806805610657 \n",
            "OrderedDict({'weights': tensor([0.2447]), 'bias': tensor([0.4399])})\n",
            "Epoch: 3320 | MAE Train Loss: 0.09486464411020279 | MAE Test Loss: 0.26494038105010986 \n",
            "OrderedDict({'weights': tensor([0.2449]), 'bias': tensor([0.4401])})\n",
            "Epoch: 3330 | MAE Train Loss: 0.0947517529129982 | MAE Test Loss: 0.26450008153915405 \n",
            "OrderedDict({'weights': tensor([0.2452]), 'bias': tensor([0.4403])})\n",
            "Epoch: 3340 | MAE Train Loss: 0.09463886171579361 | MAE Test Loss: 0.26405981183052063 \n",
            "OrderedDict({'weights': tensor([0.2455]), 'bias': tensor([0.4405])})\n",
            "Epoch: 3350 | MAE Train Loss: 0.09452597051858902 | MAE Test Loss: 0.2636195421218872 \n",
            "OrderedDict({'weights': tensor([0.2458]), 'bias': tensor([0.4407])})\n",
            "Epoch: 3360 | MAE Train Loss: 0.09441306442022324 | MAE Test Loss: 0.2631792426109314 \n",
            "OrderedDict({'weights': tensor([0.2460]), 'bias': tensor([0.4409])})\n",
            "Epoch: 3370 | MAE Train Loss: 0.09430016577243805 | MAE Test Loss: 0.26273900270462036 \n",
            "OrderedDict({'weights': tensor([0.2463]), 'bias': tensor([0.4411])})\n",
            "Epoch: 3380 | MAE Train Loss: 0.09418727457523346 | MAE Test Loss: 0.26229870319366455 \n",
            "OrderedDict({'weights': tensor([0.2466]), 'bias': tensor([0.4413])})\n",
            "Epoch: 3390 | MAE Train Loss: 0.09407438337802887 | MAE Test Loss: 0.26185840368270874 \n",
            "OrderedDict({'weights': tensor([0.2468]), 'bias': tensor([0.4415])})\n",
            "Epoch: 3400 | MAE Train Loss: 0.09396146982908249 | MAE Test Loss: 0.2614181637763977 \n",
            "OrderedDict({'weights': tensor([0.2471]), 'bias': tensor([0.4417])})\n",
            "Epoch: 3410 | MAE Train Loss: 0.0938485786318779 | MAE Test Loss: 0.2609778344631195 \n",
            "OrderedDict({'weights': tensor([0.2474]), 'bias': tensor([0.4419])})\n",
            "Epoch: 3420 | MAE Train Loss: 0.09373567998409271 | MAE Test Loss: 0.2605375647544861 \n",
            "OrderedDict({'weights': tensor([0.2476]), 'bias': tensor([0.4421])})\n",
            "Epoch: 3430 | MAE Train Loss: 0.09362278878688812 | MAE Test Loss: 0.26009729504585266 \n",
            "OrderedDict({'weights': tensor([0.2479]), 'bias': tensor([0.4423])})\n",
            "Epoch: 3440 | MAE Train Loss: 0.09350989013910294 | MAE Test Loss: 0.25965699553489685 \n",
            "OrderedDict({'weights': tensor([0.2482]), 'bias': tensor([0.4425])})\n",
            "Epoch: 3450 | MAE Train Loss: 0.09339698404073715 | MAE Test Loss: 0.2592167258262634 \n",
            "OrderedDict({'weights': tensor([0.2485]), 'bias': tensor([0.4427])})\n",
            "Epoch: 3460 | MAE Train Loss: 0.09328410029411316 | MAE Test Loss: 0.2587764263153076 \n",
            "OrderedDict({'weights': tensor([0.2487]), 'bias': tensor([0.4429])})\n",
            "Epoch: 3470 | MAE Train Loss: 0.09317119419574738 | MAE Test Loss: 0.2583361566066742 \n",
            "OrderedDict({'weights': tensor([0.2490]), 'bias': tensor([0.4431])})\n",
            "Epoch: 3480 | MAE Train Loss: 0.09305830299854279 | MAE Test Loss: 0.25789588689804077 \n",
            "OrderedDict({'weights': tensor([0.2493]), 'bias': tensor([0.4433])})\n",
            "Epoch: 3490 | MAE Train Loss: 0.0929454043507576 | MAE Test Loss: 0.25745558738708496 \n",
            "OrderedDict({'weights': tensor([0.2495]), 'bias': tensor([0.4435])})\n",
            "Epoch: 3500 | MAE Train Loss: 0.09283250570297241 | MAE Test Loss: 0.25701531767845154 \n",
            "OrderedDict({'weights': tensor([0.2498]), 'bias': tensor([0.4437])})\n",
            "Epoch: 3510 | MAE Train Loss: 0.09271961450576782 | MAE Test Loss: 0.2565750479698181 \n",
            "OrderedDict({'weights': tensor([0.2501]), 'bias': tensor([0.4439])})\n",
            "Epoch: 3520 | MAE Train Loss: 0.0926184207201004 | MAE Test Loss: 0.2561669647693634 \n",
            "OrderedDict({'weights': tensor([0.2503]), 'bias': tensor([0.4440])})\n",
            "Epoch: 3530 | MAE Train Loss: 0.09253142774105072 | MAE Test Loss: 0.2557910978794098 \n",
            "OrderedDict({'weights': tensor([0.2506]), 'bias': tensor([0.4442])})\n",
            "Epoch: 3540 | MAE Train Loss: 0.09244445711374283 | MAE Test Loss: 0.2554151713848114 \n",
            "OrderedDict({'weights': tensor([0.2508]), 'bias': tensor([0.4443])})\n",
            "Epoch: 3550 | MAE Train Loss: 0.09235747903585434 | MAE Test Loss: 0.2550393044948578 \n",
            "OrderedDict({'weights': tensor([0.2511]), 'bias': tensor([0.4445])})\n",
            "Epoch: 3560 | MAE Train Loss: 0.09227049350738525 | MAE Test Loss: 0.2546634078025818 \n",
            "OrderedDict({'weights': tensor([0.2514]), 'bias': tensor([0.4446])})\n",
            "Epoch: 3570 | MAE Train Loss: 0.09218351542949677 | MAE Test Loss: 0.2542874813079834 \n",
            "OrderedDict({'weights': tensor([0.2516]), 'bias': tensor([0.4448])})\n",
            "Epoch: 3580 | MAE Train Loss: 0.09209652990102768 | MAE Test Loss: 0.2539116144180298 \n",
            "OrderedDict({'weights': tensor([0.2519]), 'bias': tensor([0.4449])})\n",
            "Epoch: 3590 | MAE Train Loss: 0.09200955927371979 | MAE Test Loss: 0.2535357177257538 \n",
            "OrderedDict({'weights': tensor([0.2521]), 'bias': tensor([0.4451])})\n",
            "Epoch: 3600 | MAE Train Loss: 0.0919225737452507 | MAE Test Loss: 0.2531598210334778 \n",
            "OrderedDict({'weights': tensor([0.2524]), 'bias': tensor([0.4452])})\n",
            "Epoch: 3610 | MAE Train Loss: 0.09183558821678162 | MAE Test Loss: 0.2527839243412018 \n",
            "OrderedDict({'weights': tensor([0.2526]), 'bias': tensor([0.4454])})\n",
            "Epoch: 3620 | MAE Train Loss: 0.09174861013889313 | MAE Test Loss: 0.25240805745124817 \n",
            "OrderedDict({'weights': tensor([0.2529]), 'bias': tensor([0.4455])})\n",
            "Epoch: 3630 | MAE Train Loss: 0.09166163206100464 | MAE Test Loss: 0.25203219056129456 \n",
            "OrderedDict({'weights': tensor([0.2531]), 'bias': tensor([0.4457])})\n",
            "Epoch: 3640 | MAE Train Loss: 0.09157465398311615 | MAE Test Loss: 0.25165629386901855 \n",
            "OrderedDict({'weights': tensor([0.2534]), 'bias': tensor([0.4458])})\n",
            "Epoch: 3650 | MAE Train Loss: 0.09148766845464706 | MAE Test Loss: 0.25128039717674255 \n",
            "OrderedDict({'weights': tensor([0.2536]), 'bias': tensor([0.4460])})\n",
            "Epoch: 3660 | MAE Train Loss: 0.09140069782733917 | MAE Test Loss: 0.25090450048446655 \n",
            "OrderedDict({'weights': tensor([0.2539]), 'bias': tensor([0.4461])})\n",
            "Epoch: 3670 | MAE Train Loss: 0.09131371229887009 | MAE Test Loss: 0.25052860379219055 \n",
            "OrderedDict({'weights': tensor([0.2541]), 'bias': tensor([0.4463])})\n",
            "Epoch: 3680 | MAE Train Loss: 0.0912267342209816 | MAE Test Loss: 0.25015270709991455 \n",
            "OrderedDict({'weights': tensor([0.2544]), 'bias': tensor([0.4464])})\n",
            "Epoch: 3690 | MAE Train Loss: 0.09113974869251251 | MAE Test Loss: 0.24977681040763855 \n",
            "OrderedDict({'weights': tensor([0.2547]), 'bias': tensor([0.4466])})\n",
            "Epoch: 3700 | MAE Train Loss: 0.09105277806520462 | MAE Test Loss: 0.24940089881420135 \n",
            "OrderedDict({'weights': tensor([0.2549]), 'bias': tensor([0.4467])})\n",
            "Epoch: 3710 | MAE Train Loss: 0.09096579253673553 | MAE Test Loss: 0.24902503192424774 \n",
            "OrderedDict({'weights': tensor([0.2552]), 'bias': tensor([0.4469])})\n",
            "Epoch: 3720 | MAE Train Loss: 0.09087880700826645 | MAE Test Loss: 0.24864915013313293 \n",
            "OrderedDict({'weights': tensor([0.2554]), 'bias': tensor([0.4470])})\n",
            "Epoch: 3730 | MAE Train Loss: 0.09079182147979736 | MAE Test Loss: 0.24827325344085693 \n",
            "OrderedDict({'weights': tensor([0.2557]), 'bias': tensor([0.4472])})\n",
            "Epoch: 3740 | MAE Train Loss: 0.09070484340190887 | MAE Test Loss: 0.24789735674858093 \n",
            "OrderedDict({'weights': tensor([0.2559]), 'bias': tensor([0.4473])})\n",
            "Epoch: 3750 | MAE Train Loss: 0.09061786532402039 | MAE Test Loss: 0.24752147495746613 \n",
            "OrderedDict({'weights': tensor([0.2562]), 'bias': tensor([0.4475])})\n",
            "Epoch: 3760 | MAE Train Loss: 0.0905308872461319 | MAE Test Loss: 0.24714557826519012 \n",
            "OrderedDict({'weights': tensor([0.2564]), 'bias': tensor([0.4476])})\n",
            "Epoch: 3770 | MAE Train Loss: 0.09044390171766281 | MAE Test Loss: 0.24676966667175293 \n",
            "OrderedDict({'weights': tensor([0.2567]), 'bias': tensor([0.4478])})\n",
            "Epoch: 3780 | MAE Train Loss: 0.09035692363977432 | MAE Test Loss: 0.24639379978179932 \n",
            "OrderedDict({'weights': tensor([0.2569]), 'bias': tensor([0.4479])})\n",
            "Epoch: 3790 | MAE Train Loss: 0.09026994556188583 | MAE Test Loss: 0.24601790308952332 \n",
            "OrderedDict({'weights': tensor([0.2572]), 'bias': tensor([0.4481])})\n",
            "Epoch: 3800 | MAE Train Loss: 0.09018296003341675 | MAE Test Loss: 0.2456420212984085 \n",
            "OrderedDict({'weights': tensor([0.2574]), 'bias': tensor([0.4482])})\n",
            "Epoch: 3810 | MAE Train Loss: 0.09009598195552826 | MAE Test Loss: 0.2452661097049713 \n",
            "OrderedDict({'weights': tensor([0.2577]), 'bias': tensor([0.4484])})\n",
            "Epoch: 3820 | MAE Train Loss: 0.09000900387763977 | MAE Test Loss: 0.2448902130126953 \n",
            "OrderedDict({'weights': tensor([0.2580]), 'bias': tensor([0.4485])})\n",
            "Epoch: 3830 | MAE Train Loss: 0.08992202579975128 | MAE Test Loss: 0.2445143759250641 \n",
            "OrderedDict({'weights': tensor([0.2582]), 'bias': tensor([0.4487])})\n",
            "Epoch: 3840 | MAE Train Loss: 0.08983504772186279 | MAE Test Loss: 0.2441384345293045 \n",
            "OrderedDict({'weights': tensor([0.2585]), 'bias': tensor([0.4488])})\n",
            "Epoch: 3850 | MAE Train Loss: 0.0897480696439743 | MAE Test Loss: 0.24376258254051208 \n",
            "OrderedDict({'weights': tensor([0.2587]), 'bias': tensor([0.4490])})\n",
            "Epoch: 3860 | MAE Train Loss: 0.08966108411550522 | MAE Test Loss: 0.2433866709470749 \n",
            "OrderedDict({'weights': tensor([0.2590]), 'bias': tensor([0.4491])})\n",
            "Epoch: 3870 | MAE Train Loss: 0.08957410603761673 | MAE Test Loss: 0.24301078915596008 \n",
            "OrderedDict({'weights': tensor([0.2592]), 'bias': tensor([0.4493])})\n",
            "Epoch: 3880 | MAE Train Loss: 0.08948712050914764 | MAE Test Loss: 0.2426348626613617 \n",
            "OrderedDict({'weights': tensor([0.2595]), 'bias': tensor([0.4494])})\n",
            "Epoch: 3890 | MAE Train Loss: 0.08940013498067856 | MAE Test Loss: 0.24225899577140808 \n",
            "OrderedDict({'weights': tensor([0.2597]), 'bias': tensor([0.4496])})\n",
            "Epoch: 3900 | MAE Train Loss: 0.08932188898324966 | MAE Test Loss: 0.2419155389070511 \n",
            "OrderedDict({'weights': tensor([0.2600]), 'bias': tensor([0.4497])})\n",
            "Epoch: 3910 | MAE Train Loss: 0.08925572037696838 | MAE Test Loss: 0.2416045367717743 \n",
            "OrderedDict({'weights': tensor([0.2602]), 'bias': tensor([0.4498])})\n",
            "Epoch: 3920 | MAE Train Loss: 0.0891895517706871 | MAE Test Loss: 0.2412935495376587 \n",
            "OrderedDict({'weights': tensor([0.2604]), 'bias': tensor([0.4499])})\n",
            "Epoch: 3930 | MAE Train Loss: 0.08912339061498642 | MAE Test Loss: 0.2409825623035431 \n",
            "OrderedDict({'weights': tensor([0.2607]), 'bias': tensor([0.4500])})\n",
            "Epoch: 3940 | MAE Train Loss: 0.08905721455812454 | MAE Test Loss: 0.2406715452671051 \n",
            "OrderedDict({'weights': tensor([0.2609]), 'bias': tensor([0.4501])})\n",
            "Epoch: 3950 | MAE Train Loss: 0.08899106085300446 | MAE Test Loss: 0.2403605729341507 \n",
            "OrderedDict({'weights': tensor([0.2612]), 'bias': tensor([0.4502])})\n",
            "Epoch: 3960 | MAE Train Loss: 0.08892489224672318 | MAE Test Loss: 0.2400495558977127 \n",
            "OrderedDict({'weights': tensor([0.2614]), 'bias': tensor([0.4503])})\n",
            "Epoch: 3970 | MAE Train Loss: 0.0888587236404419 | MAE Test Loss: 0.2397385537624359 \n",
            "OrderedDict({'weights': tensor([0.2616]), 'bias': tensor([0.4504])})\n",
            "Epoch: 3980 | MAE Train Loss: 0.08879256248474121 | MAE Test Loss: 0.23942752182483673 \n",
            "OrderedDict({'weights': tensor([0.2619]), 'bias': tensor([0.4505])})\n",
            "Epoch: 3990 | MAE Train Loss: 0.08872639387845993 | MAE Test Loss: 0.23911654949188232 \n",
            "OrderedDict({'weights': tensor([0.2621]), 'bias': tensor([0.4506])})\n",
            "Epoch: 4000 | MAE Train Loss: 0.08866022527217865 | MAE Test Loss: 0.23880553245544434 \n",
            "OrderedDict({'weights': tensor([0.2623]), 'bias': tensor([0.4507])})\n",
            "Epoch: 4010 | MAE Train Loss: 0.08859406411647797 | MAE Test Loss: 0.23849454522132874 \n",
            "OrderedDict({'weights': tensor([0.2626]), 'bias': tensor([0.4508])})\n",
            "Epoch: 4020 | MAE Train Loss: 0.08852788805961609 | MAE Test Loss: 0.23818352818489075 \n",
            "OrderedDict({'weights': tensor([0.2628]), 'bias': tensor([0.4509])})\n",
            "Epoch: 4030 | MAE Train Loss: 0.0884617418050766 | MAE Test Loss: 0.23787255585193634 \n",
            "OrderedDict({'weights': tensor([0.2631]), 'bias': tensor([0.4510])})\n",
            "Epoch: 4040 | MAE Train Loss: 0.08839556574821472 | MAE Test Loss: 0.23756155371665955 \n",
            "OrderedDict({'weights': tensor([0.2633]), 'bias': tensor([0.4511])})\n",
            "Epoch: 4050 | MAE Train Loss: 0.08832939714193344 | MAE Test Loss: 0.23725056648254395 \n",
            "OrderedDict({'weights': tensor([0.2635]), 'bias': tensor([0.4512])})\n",
            "Epoch: 4060 | MAE Train Loss: 0.08826323598623276 | MAE Test Loss: 0.23693950474262238 \n",
            "OrderedDict({'weights': tensor([0.2638]), 'bias': tensor([0.4513])})\n",
            "Epoch: 4070 | MAE Train Loss: 0.08819706737995148 | MAE Test Loss: 0.23662853240966797 \n",
            "OrderedDict({'weights': tensor([0.2640]), 'bias': tensor([0.4514])})\n",
            "Epoch: 4080 | MAE Train Loss: 0.0881309062242508 | MAE Test Loss: 0.23631751537322998 \n",
            "OrderedDict({'weights': tensor([0.2642]), 'bias': tensor([0.4515])})\n",
            "Epoch: 4090 | MAE Train Loss: 0.08806474506855011 | MAE Test Loss: 0.23600652813911438 \n",
            "OrderedDict({'weights': tensor([0.2645]), 'bias': tensor([0.4516])})\n",
            "Epoch: 4100 | MAE Train Loss: 0.08799856156110764 | MAE Test Loss: 0.2356955111026764 \n",
            "OrderedDict({'weights': tensor([0.2647]), 'bias': tensor([0.4517])})\n",
            "Epoch: 4110 | MAE Train Loss: 0.08793241530656815 | MAE Test Loss: 0.23538453876972198 \n",
            "OrderedDict({'weights': tensor([0.2650]), 'bias': tensor([0.4518])})\n",
            "Epoch: 4120 | MAE Train Loss: 0.08786623924970627 | MAE Test Loss: 0.235073521733284 \n",
            "OrderedDict({'weights': tensor([0.2652]), 'bias': tensor([0.4519])})\n",
            "Epoch: 4130 | MAE Train Loss: 0.08780007064342499 | MAE Test Loss: 0.2347625195980072 \n",
            "OrderedDict({'weights': tensor([0.2654]), 'bias': tensor([0.4520])})\n",
            "Epoch: 4140 | MAE Train Loss: 0.0877339094877243 | MAE Test Loss: 0.23445148766040802 \n",
            "OrderedDict({'weights': tensor([0.2657]), 'bias': tensor([0.4521])})\n",
            "Epoch: 4150 | MAE Train Loss: 0.08766774833202362 | MAE Test Loss: 0.2341405153274536 \n",
            "OrderedDict({'weights': tensor([0.2659]), 'bias': tensor([0.4522])})\n",
            "Epoch: 4160 | MAE Train Loss: 0.08760157972574234 | MAE Test Loss: 0.23382949829101562 \n",
            "OrderedDict({'weights': tensor([0.2661]), 'bias': tensor([0.4523])})\n",
            "Epoch: 4170 | MAE Train Loss: 0.08753541111946106 | MAE Test Loss: 0.23351851105690002 \n",
            "OrderedDict({'weights': tensor([0.2664]), 'bias': tensor([0.4524])})\n",
            "Epoch: 4180 | MAE Train Loss: 0.08746923506259918 | MAE Test Loss: 0.23320749402046204 \n",
            "OrderedDict({'weights': tensor([0.2666]), 'bias': tensor([0.4525])})\n",
            "Epoch: 4190 | MAE Train Loss: 0.08740308880805969 | MAE Test Loss: 0.23289652168750763 \n",
            "OrderedDict({'weights': tensor([0.2668]), 'bias': tensor([0.4526])})\n",
            "Epoch: 4200 | MAE Train Loss: 0.08733691275119781 | MAE Test Loss: 0.23258551955223083 \n",
            "OrderedDict({'weights': tensor([0.2671]), 'bias': tensor([0.4527])})\n",
            "Epoch: 4210 | MAE Train Loss: 0.08727075159549713 | MAE Test Loss: 0.23227453231811523 \n",
            "OrderedDict({'weights': tensor([0.2673]), 'bias': tensor([0.4528])})\n",
            "Epoch: 4220 | MAE Train Loss: 0.08720459043979645 | MAE Test Loss: 0.23196347057819366 \n",
            "OrderedDict({'weights': tensor([0.2676]), 'bias': tensor([0.4529])})\n",
            "Epoch: 4230 | MAE Train Loss: 0.08713842183351517 | MAE Test Loss: 0.23165249824523926 \n",
            "OrderedDict({'weights': tensor([0.2678]), 'bias': tensor([0.4530])})\n",
            "Epoch: 4240 | MAE Train Loss: 0.08707225322723389 | MAE Test Loss: 0.23134148120880127 \n",
            "OrderedDict({'weights': tensor([0.2680]), 'bias': tensor([0.4531])})\n",
            "Epoch: 4250 | MAE Train Loss: 0.0870060846209526 | MAE Test Loss: 0.23103049397468567 \n",
            "OrderedDict({'weights': tensor([0.2683]), 'bias': tensor([0.4532])})\n",
            "Epoch: 4260 | MAE Train Loss: 0.08693991601467133 | MAE Test Loss: 0.23071947693824768 \n",
            "OrderedDict({'weights': tensor([0.2685]), 'bias': tensor([0.4533])})\n",
            "Epoch: 4270 | MAE Train Loss: 0.08687376230955124 | MAE Test Loss: 0.23040850460529327 \n",
            "OrderedDict({'weights': tensor([0.2687]), 'bias': tensor([0.4534])})\n",
            "Epoch: 4280 | MAE Train Loss: 0.08680759370326996 | MAE Test Loss: 0.23009750247001648 \n",
            "OrderedDict({'weights': tensor([0.2690]), 'bias': tensor([0.4535])})\n",
            "Epoch: 4290 | MAE Train Loss: 0.08674142509698868 | MAE Test Loss: 0.2297864854335785 \n",
            "OrderedDict({'weights': tensor([0.2692]), 'bias': tensor([0.4536])})\n",
            "Epoch: 4300 | MAE Train Loss: 0.086675263941288 | MAE Test Loss: 0.2294754534959793 \n",
            "OrderedDict({'weights': tensor([0.2695]), 'bias': tensor([0.4537])})\n",
            "Epoch: 4310 | MAE Train Loss: 0.08660909533500671 | MAE Test Loss: 0.2291644811630249 \n",
            "OrderedDict({'weights': tensor([0.2697]), 'bias': tensor([0.4538])})\n",
            "Epoch: 4320 | MAE Train Loss: 0.08654292672872543 | MAE Test Loss: 0.22885346412658691 \n",
            "OrderedDict({'weights': tensor([0.2699]), 'bias': tensor([0.4539])})\n",
            "Epoch: 4330 | MAE Train Loss: 0.08647675812244415 | MAE Test Loss: 0.2285424768924713 \n",
            "OrderedDict({'weights': tensor([0.2702]), 'bias': tensor([0.4540])})\n",
            "Epoch: 4340 | MAE Train Loss: 0.08641058951616287 | MAE Test Loss: 0.22823145985603333 \n",
            "OrderedDict({'weights': tensor([0.2704]), 'bias': tensor([0.4541])})\n",
            "Epoch: 4350 | MAE Train Loss: 0.08634443581104279 | MAE Test Loss: 0.22792048752307892 \n",
            "OrderedDict({'weights': tensor([0.2706]), 'bias': tensor([0.4542])})\n",
            "Epoch: 4360 | MAE Train Loss: 0.0862782672047615 | MAE Test Loss: 0.22760948538780212 \n",
            "OrderedDict({'weights': tensor([0.2709]), 'bias': tensor([0.4543])})\n",
            "Epoch: 4370 | MAE Train Loss: 0.08621209859848022 | MAE Test Loss: 0.22729849815368652 \n",
            "OrderedDict({'weights': tensor([0.2711]), 'bias': tensor([0.4544])})\n",
            "Epoch: 4380 | MAE Train Loss: 0.08616070449352264 | MAE Test Loss: 0.2270534336566925 \n",
            "OrderedDict({'weights': tensor([0.2713]), 'bias': tensor([0.4545])})\n",
            "Epoch: 4390 | MAE Train Loss: 0.08611021935939789 | MAE Test Loss: 0.22680842876434326 \n",
            "OrderedDict({'weights': tensor([0.2715]), 'bias': tensor([0.4545])})\n",
            "Epoch: 4400 | MAE Train Loss: 0.08605974912643433 | MAE Test Loss: 0.22656342387199402 \n",
            "OrderedDict({'weights': tensor([0.2718]), 'bias': tensor([0.4546])})\n",
            "Epoch: 4410 | MAE Train Loss: 0.08600927144289017 | MAE Test Loss: 0.2263183891773224 \n",
            "OrderedDict({'weights': tensor([0.2720]), 'bias': tensor([0.4546])})\n",
            "Epoch: 4420 | MAE Train Loss: 0.0859588086605072 | MAE Test Loss: 0.22607333958148956 \n",
            "OrderedDict({'weights': tensor([0.2722]), 'bias': tensor([0.4547])})\n",
            "Epoch: 4430 | MAE Train Loss: 0.08590833097696304 | MAE Test Loss: 0.2258283644914627 \n",
            "OrderedDict({'weights': tensor([0.2724]), 'bias': tensor([0.4547])})\n",
            "Epoch: 4440 | MAE Train Loss: 0.08585785329341888 | MAE Test Loss: 0.22558331489562988 \n",
            "OrderedDict({'weights': tensor([0.2726]), 'bias': tensor([0.4548])})\n",
            "Epoch: 4450 | MAE Train Loss: 0.08580738306045532 | MAE Test Loss: 0.22533831000328064 \n",
            "OrderedDict({'weights': tensor([0.2729]), 'bias': tensor([0.4548])})\n",
            "Epoch: 4460 | MAE Train Loss: 0.08575691282749176 | MAE Test Loss: 0.2250932902097702 \n",
            "OrderedDict({'weights': tensor([0.2731]), 'bias': tensor([0.4549])})\n",
            "Epoch: 4470 | MAE Train Loss: 0.085706427693367 | MAE Test Loss: 0.22484827041625977 \n",
            "OrderedDict({'weights': tensor([0.2733]), 'bias': tensor([0.4549])})\n",
            "Epoch: 4480 | MAE Train Loss: 0.08565595000982285 | MAE Test Loss: 0.22460326552391052 \n",
            "OrderedDict({'weights': tensor([0.2735]), 'bias': tensor([0.4550])})\n",
            "Epoch: 4490 | MAE Train Loss: 0.08560547977685928 | MAE Test Loss: 0.2243582308292389 \n",
            "OrderedDict({'weights': tensor([0.2737]), 'bias': tensor([0.4550])})\n",
            "Epoch: 4500 | MAE Train Loss: 0.08555500954389572 | MAE Test Loss: 0.22411319613456726 \n",
            "OrderedDict({'weights': tensor([0.2740]), 'bias': tensor([0.4551])})\n",
            "Epoch: 4510 | MAE Train Loss: 0.08550453931093216 | MAE Test Loss: 0.22386817634105682 \n",
            "OrderedDict({'weights': tensor([0.2742]), 'bias': tensor([0.4551])})\n",
            "Epoch: 4520 | MAE Train Loss: 0.085454061627388 | MAE Test Loss: 0.2236231565475464 \n",
            "OrderedDict({'weights': tensor([0.2744]), 'bias': tensor([0.4552])})\n",
            "Epoch: 4530 | MAE Train Loss: 0.08540358394384384 | MAE Test Loss: 0.22337815165519714 \n",
            "OrderedDict({'weights': tensor([0.2746]), 'bias': tensor([0.4552])})\n",
            "Epoch: 4540 | MAE Train Loss: 0.08535311371088028 | MAE Test Loss: 0.2231331169605255 \n",
            "OrderedDict({'weights': tensor([0.2748]), 'bias': tensor([0.4553])})\n",
            "Epoch: 4550 | MAE Train Loss: 0.08530262857675552 | MAE Test Loss: 0.22288811206817627 \n",
            "OrderedDict({'weights': tensor([0.2751]), 'bias': tensor([0.4553])})\n",
            "Epoch: 4560 | MAE Train Loss: 0.08525215089321136 | MAE Test Loss: 0.22264310717582703 \n",
            "OrderedDict({'weights': tensor([0.2753]), 'bias': tensor([0.4554])})\n",
            "Epoch: 4570 | MAE Train Loss: 0.0852016732096672 | MAE Test Loss: 0.2223980873823166 \n",
            "OrderedDict({'weights': tensor([0.2755]), 'bias': tensor([0.4554])})\n",
            "Epoch: 4580 | MAE Train Loss: 0.08515121042728424 | MAE Test Loss: 0.22215303778648376 \n",
            "OrderedDict({'weights': tensor([0.2757]), 'bias': tensor([0.4555])})\n",
            "Epoch: 4590 | MAE Train Loss: 0.08510073274374008 | MAE Test Loss: 0.22190801799297333 \n",
            "OrderedDict({'weights': tensor([0.2759]), 'bias': tensor([0.4555])})\n",
            "Epoch: 4600 | MAE Train Loss: 0.08505026251077652 | MAE Test Loss: 0.2216629981994629 \n",
            "OrderedDict({'weights': tensor([0.2761]), 'bias': tensor([0.4556])})\n",
            "Epoch: 4610 | MAE Train Loss: 0.08499978482723236 | MAE Test Loss: 0.22141799330711365 \n",
            "OrderedDict({'weights': tensor([0.2764]), 'bias': tensor([0.4556])})\n",
            "Epoch: 4620 | MAE Train Loss: 0.0849493145942688 | MAE Test Loss: 0.22117295861244202 \n",
            "OrderedDict({'weights': tensor([0.2766]), 'bias': tensor([0.4557])})\n",
            "Epoch: 4630 | MAE Train Loss: 0.08489883691072464 | MAE Test Loss: 0.22092795372009277 \n",
            "OrderedDict({'weights': tensor([0.2768]), 'bias': tensor([0.4557])})\n",
            "Epoch: 4640 | MAE Train Loss: 0.08484835922718048 | MAE Test Loss: 0.22068294882774353 \n",
            "OrderedDict({'weights': tensor([0.2770]), 'bias': tensor([0.4558])})\n",
            "Epoch: 4650 | MAE Train Loss: 0.08479788154363632 | MAE Test Loss: 0.2204379141330719 \n",
            "OrderedDict({'weights': tensor([0.2772]), 'bias': tensor([0.4558])})\n",
            "Epoch: 4660 | MAE Train Loss: 0.08474741876125336 | MAE Test Loss: 0.22019287943840027 \n",
            "OrderedDict({'weights': tensor([0.2775]), 'bias': tensor([0.4559])})\n",
            "Epoch: 4670 | MAE Train Loss: 0.0846969410777092 | MAE Test Loss: 0.21994785964488983 \n",
            "OrderedDict({'weights': tensor([0.2777]), 'bias': tensor([0.4559])})\n",
            "Epoch: 4680 | MAE Train Loss: 0.08464646339416504 | MAE Test Loss: 0.2197028398513794 \n",
            "OrderedDict({'weights': tensor([0.2779]), 'bias': tensor([0.4560])})\n",
            "Epoch: 4690 | MAE Train Loss: 0.08459599316120148 | MAE Test Loss: 0.21945783495903015 \n",
            "OrderedDict({'weights': tensor([0.2781]), 'bias': tensor([0.4560])})\n",
            "Epoch: 4700 | MAE Train Loss: 0.08454551547765732 | MAE Test Loss: 0.21921280026435852 \n",
            "OrderedDict({'weights': tensor([0.2783]), 'bias': tensor([0.4561])})\n",
            "Epoch: 4710 | MAE Train Loss: 0.08449503034353256 | MAE Test Loss: 0.21896779537200928 \n",
            "OrderedDict({'weights': tensor([0.2786]), 'bias': tensor([0.4561])})\n",
            "Epoch: 4720 | MAE Train Loss: 0.084444560110569 | MAE Test Loss: 0.21872279047966003 \n",
            "OrderedDict({'weights': tensor([0.2788]), 'bias': tensor([0.4562])})\n",
            "Epoch: 4730 | MAE Train Loss: 0.08439408242702484 | MAE Test Loss: 0.2184777706861496 \n",
            "OrderedDict({'weights': tensor([0.2790]), 'bias': tensor([0.4562])})\n",
            "Epoch: 4740 | MAE Train Loss: 0.08434361964464188 | MAE Test Loss: 0.21823272109031677 \n",
            "OrderedDict({'weights': tensor([0.2792]), 'bias': tensor([0.4563])})\n",
            "Epoch: 4750 | MAE Train Loss: 0.08429314941167831 | MAE Test Loss: 0.21798770129680634 \n",
            "OrderedDict({'weights': tensor([0.2794]), 'bias': tensor([0.4563])})\n",
            "Epoch: 4760 | MAE Train Loss: 0.08424266427755356 | MAE Test Loss: 0.2177426815032959 \n",
            "OrderedDict({'weights': tensor([0.2797]), 'bias': tensor([0.4564])})\n",
            "Epoch: 4770 | MAE Train Loss: 0.08419219404459 | MAE Test Loss: 0.21749767661094666 \n",
            "OrderedDict({'weights': tensor([0.2799]), 'bias': tensor([0.4564])})\n",
            "Epoch: 4780 | MAE Train Loss: 0.08414171636104584 | MAE Test Loss: 0.21725264191627502 \n",
            "OrderedDict({'weights': tensor([0.2801]), 'bias': tensor([0.4565])})\n",
            "Epoch: 4790 | MAE Train Loss: 0.08409123867750168 | MAE Test Loss: 0.21700763702392578 \n",
            "OrderedDict({'weights': tensor([0.2803]), 'bias': tensor([0.4565])})\n",
            "Epoch: 4800 | MAE Train Loss: 0.08404076099395752 | MAE Test Loss: 0.21676263213157654 \n",
            "OrderedDict({'weights': tensor([0.2805]), 'bias': tensor([0.4566])})\n",
            "Epoch: 4810 | MAE Train Loss: 0.08399029076099396 | MAE Test Loss: 0.2165175974369049 \n",
            "OrderedDict({'weights': tensor([0.2807]), 'bias': tensor([0.4566])})\n",
            "Epoch: 4820 | MAE Train Loss: 0.0839398205280304 | MAE Test Loss: 0.21627256274223328 \n",
            "OrderedDict({'weights': tensor([0.2810]), 'bias': tensor([0.4567])})\n",
            "Epoch: 4830 | MAE Train Loss: 0.08388935029506683 | MAE Test Loss: 0.21602754294872284 \n",
            "OrderedDict({'weights': tensor([0.2812]), 'bias': tensor([0.4567])})\n",
            "Epoch: 4840 | MAE Train Loss: 0.08383886516094208 | MAE Test Loss: 0.2157825231552124 \n",
            "OrderedDict({'weights': tensor([0.2814]), 'bias': tensor([0.4568])})\n",
            "Epoch: 4850 | MAE Train Loss: 0.08378839492797852 | MAE Test Loss: 0.21553751826286316 \n",
            "OrderedDict({'weights': tensor([0.2816]), 'bias': tensor([0.4568])})\n",
            "Epoch: 4860 | MAE Train Loss: 0.08373792469501495 | MAE Test Loss: 0.21529248356819153 \n",
            "OrderedDict({'weights': tensor([0.2818]), 'bias': tensor([0.4569])})\n",
            "Epoch: 4870 | MAE Train Loss: 0.0836874395608902 | MAE Test Loss: 0.21504747867584229 \n",
            "OrderedDict({'weights': tensor([0.2821]), 'bias': tensor([0.4569])})\n",
            "Epoch: 4880 | MAE Train Loss: 0.08363696187734604 | MAE Test Loss: 0.21480247378349304 \n",
            "OrderedDict({'weights': tensor([0.2823]), 'bias': tensor([0.4570])})\n",
            "Epoch: 4890 | MAE Train Loss: 0.08358648419380188 | MAE Test Loss: 0.2145574539899826 \n",
            "OrderedDict({'weights': tensor([0.2825]), 'bias': tensor([0.4570])})\n",
            "Epoch: 4900 | MAE Train Loss: 0.08353602141141891 | MAE Test Loss: 0.21431240439414978 \n",
            "OrderedDict({'weights': tensor([0.2827]), 'bias': tensor([0.4571])})\n",
            "Epoch: 4910 | MAE Train Loss: 0.08348555862903595 | MAE Test Loss: 0.21406738460063934 \n",
            "OrderedDict({'weights': tensor([0.2829]), 'bias': tensor([0.4571])})\n",
            "Epoch: 4920 | MAE Train Loss: 0.0834350734949112 | MAE Test Loss: 0.2138223648071289 \n",
            "OrderedDict({'weights': tensor([0.2832]), 'bias': tensor([0.4572])})\n",
            "Epoch: 4930 | MAE Train Loss: 0.08338459581136703 | MAE Test Loss: 0.21357735991477966 \n",
            "OrderedDict({'weights': tensor([0.2834]), 'bias': tensor([0.4572])})\n",
            "Epoch: 4940 | MAE Train Loss: 0.08333412557840347 | MAE Test Loss: 0.21333232522010803 \n",
            "OrderedDict({'weights': tensor([0.2836]), 'bias': tensor([0.4573])})\n",
            "Epoch: 4950 | MAE Train Loss: 0.08328364789485931 | MAE Test Loss: 0.2130873203277588 \n",
            "OrderedDict({'weights': tensor([0.2838]), 'bias': tensor([0.4573])})\n",
            "Epoch: 4960 | MAE Train Loss: 0.08323316276073456 | MAE Test Loss: 0.21284231543540955 \n",
            "OrderedDict({'weights': tensor([0.2840]), 'bias': tensor([0.4574])})\n",
            "Epoch: 4970 | MAE Train Loss: 0.083182692527771 | MAE Test Loss: 0.21259728074073792 \n",
            "OrderedDict({'weights': tensor([0.2843]), 'bias': tensor([0.4574])})\n",
            "Epoch: 4980 | MAE Train Loss: 0.08313222229480743 | MAE Test Loss: 0.21235224604606628 \n",
            "OrderedDict({'weights': tensor([0.2845]), 'bias': tensor([0.4575])})\n",
            "Epoch: 4990 | MAE Train Loss: 0.08308175206184387 | MAE Test Loss: 0.21210722625255585 \n",
            "OrderedDict({'weights': tensor([0.2847]), 'bias': tensor([0.4575])})\n",
            "Epoch: 5000 | MAE Train Loss: 0.08303127437829971 | MAE Test Loss: 0.2118622064590454 \n",
            "OrderedDict({'weights': tensor([0.2849]), 'bias': tensor([0.4576])})\n",
            "Epoch: 5010 | MAE Train Loss: 0.08298079669475555 | MAE Test Loss: 0.21161720156669617 \n",
            "OrderedDict({'weights': tensor([0.2851]), 'bias': tensor([0.4576])})\n",
            "Epoch: 5020 | MAE Train Loss: 0.08293694257736206 | MAE Test Loss: 0.21141910552978516 \n",
            "OrderedDict({'weights': tensor([0.2853]), 'bias': tensor([0.4576])})\n",
            "Epoch: 5030 | MAE Train Loss: 0.08289696276187897 | MAE Test Loss: 0.21124112606048584 \n",
            "OrderedDict({'weights': tensor([0.2855]), 'bias': tensor([0.4576])})\n",
            "Epoch: 5040 | MAE Train Loss: 0.08285696059465408 | MAE Test Loss: 0.21106314659118652 \n",
            "OrderedDict({'weights': tensor([0.2857]), 'bias': tensor([0.4576])})\n",
            "Epoch: 5050 | MAE Train Loss: 0.0828169584274292 | MAE Test Loss: 0.2108851671218872 \n",
            "OrderedDict({'weights': tensor([0.2859]), 'bias': tensor([0.4576])})\n",
            "Epoch: 5060 | MAE Train Loss: 0.08277696371078491 | MAE Test Loss: 0.2107071876525879 \n",
            "OrderedDict({'weights': tensor([0.2861]), 'bias': tensor([0.4576])})\n",
            "Epoch: 5070 | MAE Train Loss: 0.08273696154356003 | MAE Test Loss: 0.21052923798561096 \n",
            "OrderedDict({'weights': tensor([0.2863]), 'bias': tensor([0.4576])})\n",
            "Epoch: 5080 | MAE Train Loss: 0.08269698172807693 | MAE Test Loss: 0.21035125851631165 \n",
            "OrderedDict({'weights': tensor([0.2865]), 'bias': tensor([0.4576])})\n",
            "Epoch: 5090 | MAE Train Loss: 0.08265697956085205 | MAE Test Loss: 0.21017327904701233 \n",
            "OrderedDict({'weights': tensor([0.2867]), 'bias': tensor([0.4576])})\n",
            "Epoch: 5100 | MAE Train Loss: 0.08261698484420776 | MAE Test Loss: 0.209995299577713 \n",
            "OrderedDict({'weights': tensor([0.2869]), 'bias': tensor([0.4576])})\n",
            "Epoch: 5110 | MAE Train Loss: 0.08257700502872467 | MAE Test Loss: 0.2098173201084137 \n",
            "OrderedDict({'weights': tensor([0.2871]), 'bias': tensor([0.4576])})\n",
            "Epoch: 5120 | MAE Train Loss: 0.08253699541091919 | MAE Test Loss: 0.20963934063911438 \n",
            "OrderedDict({'weights': tensor([0.2873]), 'bias': tensor([0.4576])})\n",
            "Epoch: 5130 | MAE Train Loss: 0.0824970081448555 | MAE Test Loss: 0.20946137607097626 \n",
            "OrderedDict({'weights': tensor([0.2875]), 'bias': tensor([0.4576])})\n",
            "Epoch: 5140 | MAE Train Loss: 0.08245700597763062 | MAE Test Loss: 0.20928338170051575 \n",
            "OrderedDict({'weights': tensor([0.2877]), 'bias': tensor([0.4576])})\n",
            "Epoch: 5150 | MAE Train Loss: 0.08241702616214752 | MAE Test Loss: 0.20910540223121643 \n",
            "OrderedDict({'weights': tensor([0.2879]), 'bias': tensor([0.4576])})\n",
            "Epoch: 5160 | MAE Train Loss: 0.08237701654434204 | MAE Test Loss: 0.2089274376630783 \n",
            "OrderedDict({'weights': tensor([0.2881]), 'bias': tensor([0.4576])})\n",
            "Epoch: 5170 | MAE Train Loss: 0.08233702182769775 | MAE Test Loss: 0.2087494432926178 \n",
            "OrderedDict({'weights': tensor([0.2883]), 'bias': tensor([0.4576])})\n",
            "Epoch: 5180 | MAE Train Loss: 0.08229703456163406 | MAE Test Loss: 0.20857146382331848 \n",
            "OrderedDict({'weights': tensor([0.2885]), 'bias': tensor([0.4576])})\n",
            "Epoch: 5190 | MAE Train Loss: 0.08225702494382858 | MAE Test Loss: 0.20839349925518036 \n",
            "OrderedDict({'weights': tensor([0.2887]), 'bias': tensor([0.4576])})\n",
            "Epoch: 5200 | MAE Train Loss: 0.08221703767776489 | MAE Test Loss: 0.20821551978588104 \n",
            "OrderedDict({'weights': tensor([0.2889]), 'bias': tensor([0.4576])})\n",
            "Epoch: 5210 | MAE Train Loss: 0.0821770429611206 | MAE Test Loss: 0.2080375701189041 \n",
            "OrderedDict({'weights': tensor([0.2891]), 'bias': tensor([0.4576])})\n",
            "Epoch: 5220 | MAE Train Loss: 0.08213705569505692 | MAE Test Loss: 0.2078595906496048 \n",
            "OrderedDict({'weights': tensor([0.2893]), 'bias': tensor([0.4576])})\n",
            "Epoch: 5230 | MAE Train Loss: 0.08209706097841263 | MAE Test Loss: 0.2076815664768219 \n",
            "OrderedDict({'weights': tensor([0.2895]), 'bias': tensor([0.4576])})\n",
            "Epoch: 5240 | MAE Train Loss: 0.08205706626176834 | MAE Test Loss: 0.20750363171100616 \n",
            "OrderedDict({'weights': tensor([0.2897]), 'bias': tensor([0.4576])})\n",
            "Epoch: 5250 | MAE Train Loss: 0.08201706409454346 | MAE Test Loss: 0.20732566714286804 \n",
            "OrderedDict({'weights': tensor([0.2899]), 'bias': tensor([0.4576])})\n",
            "Epoch: 5260 | MAE Train Loss: 0.08197706937789917 | MAE Test Loss: 0.20714762806892395 \n",
            "OrderedDict({'weights': tensor([0.2901]), 'bias': tensor([0.4576])})\n",
            "Epoch: 5270 | MAE Train Loss: 0.08193707466125488 | MAE Test Loss: 0.20696966350078583 \n",
            "OrderedDict({'weights': tensor([0.2903]), 'bias': tensor([0.4576])})\n",
            "Epoch: 5280 | MAE Train Loss: 0.08189708739519119 | MAE Test Loss: 0.2067917138338089 \n",
            "OrderedDict({'weights': tensor([0.2905]), 'bias': tensor([0.4576])})\n",
            "Epoch: 5290 | MAE Train Loss: 0.08185708522796631 | MAE Test Loss: 0.20661373436450958 \n",
            "OrderedDict({'weights': tensor([0.2907]), 'bias': tensor([0.4576])})\n",
            "Epoch: 5300 | MAE Train Loss: 0.08181709796190262 | MAE Test Loss: 0.20643575489521027 \n",
            "OrderedDict({'weights': tensor([0.2909]), 'bias': tensor([0.4576])})\n",
            "Epoch: 5310 | MAE Train Loss: 0.08177709579467773 | MAE Test Loss: 0.20625779032707214 \n",
            "OrderedDict({'weights': tensor([0.2911]), 'bias': tensor([0.4576])})\n",
            "Epoch: 5320 | MAE Train Loss: 0.08173710107803345 | MAE Test Loss: 0.20607979595661163 \n",
            "OrderedDict({'weights': tensor([0.2913]), 'bias': tensor([0.4576])})\n",
            "Epoch: 5330 | MAE Train Loss: 0.08169712126255035 | MAE Test Loss: 0.2059018313884735 \n",
            "OrderedDict({'weights': tensor([0.2915]), 'bias': tensor([0.4576])})\n",
            "Epoch: 5340 | MAE Train Loss: 0.08165711909532547 | MAE Test Loss: 0.2057238519191742 \n",
            "OrderedDict({'weights': tensor([0.2917]), 'bias': tensor([0.4576])})\n",
            "Epoch: 5350 | MAE Train Loss: 0.08161712437868118 | MAE Test Loss: 0.20554587244987488 \n",
            "OrderedDict({'weights': tensor([0.2919]), 'bias': tensor([0.4576])})\n",
            "Epoch: 5360 | MAE Train Loss: 0.0815771222114563 | MAE Test Loss: 0.20536787807941437 \n",
            "OrderedDict({'weights': tensor([0.2921]), 'bias': tensor([0.4576])})\n",
            "Epoch: 5370 | MAE Train Loss: 0.08153713494539261 | MAE Test Loss: 0.20518994331359863 \n",
            "OrderedDict({'weights': tensor([0.2923]), 'bias': tensor([0.4576])})\n",
            "Epoch: 5380 | MAE Train Loss: 0.08149713277816772 | MAE Test Loss: 0.20501196384429932 \n",
            "OrderedDict({'weights': tensor([0.2925]), 'bias': tensor([0.4576])})\n",
            "Epoch: 5390 | MAE Train Loss: 0.08145713806152344 | MAE Test Loss: 0.204833984375 \n",
            "OrderedDict({'weights': tensor([0.2927]), 'bias': tensor([0.4576])})\n",
            "Epoch: 5400 | MAE Train Loss: 0.08141714334487915 | MAE Test Loss: 0.2046559751033783 \n",
            "OrderedDict({'weights': tensor([0.2929]), 'bias': tensor([0.4576])})\n",
            "Epoch: 5410 | MAE Train Loss: 0.08137715607881546 | MAE Test Loss: 0.20447799563407898 \n",
            "OrderedDict({'weights': tensor([0.2931]), 'bias': tensor([0.4576])})\n",
            "Epoch: 5420 | MAE Train Loss: 0.08133715391159058 | MAE Test Loss: 0.20430007576942444 \n",
            "OrderedDict({'weights': tensor([0.2933]), 'bias': tensor([0.4576])})\n",
            "Epoch: 5430 | MAE Train Loss: 0.08129717409610748 | MAE Test Loss: 0.20412206649780273 \n",
            "OrderedDict({'weights': tensor([0.2935]), 'bias': tensor([0.4576])})\n",
            "Epoch: 5440 | MAE Train Loss: 0.0812571719288826 | MAE Test Loss: 0.20394408702850342 \n",
            "OrderedDict({'weights': tensor([0.2937]), 'bias': tensor([0.4576])})\n",
            "Epoch: 5450 | MAE Train Loss: 0.08121716976165771 | MAE Test Loss: 0.2037661075592041 \n",
            "OrderedDict({'weights': tensor([0.2939]), 'bias': tensor([0.4576])})\n",
            "Epoch: 5460 | MAE Train Loss: 0.08117717504501343 | MAE Test Loss: 0.20358812808990479 \n",
            "OrderedDict({'weights': tensor([0.2941]), 'bias': tensor([0.4576])})\n",
            "Epoch: 5470 | MAE Train Loss: 0.08113717287778854 | MAE Test Loss: 0.20341014862060547 \n",
            "OrderedDict({'weights': tensor([0.2943]), 'bias': tensor([0.4576])})\n",
            "Epoch: 5480 | MAE Train Loss: 0.08109718561172485 | MAE Test Loss: 0.20323219895362854 \n",
            "OrderedDict({'weights': tensor([0.2945]), 'bias': tensor([0.4576])})\n",
            "Epoch: 5490 | MAE Train Loss: 0.08105719089508057 | MAE Test Loss: 0.20305418968200684 \n",
            "OrderedDict({'weights': tensor([0.2947]), 'bias': tensor([0.4576])})\n",
            "Epoch: 5500 | MAE Train Loss: 0.08101719617843628 | MAE Test Loss: 0.2028762400150299 \n",
            "OrderedDict({'weights': tensor([0.2949]), 'bias': tensor([0.4576])})\n",
            "Epoch: 5510 | MAE Train Loss: 0.08097721636295319 | MAE Test Loss: 0.2026982605457306 \n",
            "OrderedDict({'weights': tensor([0.2951]), 'bias': tensor([0.4576])})\n",
            "Epoch: 5520 | MAE Train Loss: 0.0809372067451477 | MAE Test Loss: 0.20252028107643127 \n",
            "OrderedDict({'weights': tensor([0.2953]), 'bias': tensor([0.4576])})\n",
            "Epoch: 5530 | MAE Train Loss: 0.08089721947908401 | MAE Test Loss: 0.20234230160713196 \n",
            "OrderedDict({'weights': tensor([0.2955]), 'bias': tensor([0.4576])})\n",
            "Epoch: 5540 | MAE Train Loss: 0.08085722476243973 | MAE Test Loss: 0.20216432213783264 \n",
            "OrderedDict({'weights': tensor([0.2957]), 'bias': tensor([0.4576])})\n",
            "Epoch: 5550 | MAE Train Loss: 0.08081723749637604 | MAE Test Loss: 0.20198635756969452 \n",
            "OrderedDict({'weights': tensor([0.2959]), 'bias': tensor([0.4576])})\n",
            "Epoch: 5560 | MAE Train Loss: 0.08077722787857056 | MAE Test Loss: 0.201808363199234 \n",
            "OrderedDict({'weights': tensor([0.2961]), 'bias': tensor([0.4576])})\n",
            "Epoch: 5570 | MAE Train Loss: 0.08073723316192627 | MAE Test Loss: 0.2016303837299347 \n",
            "OrderedDict({'weights': tensor([0.2963]), 'bias': tensor([0.4576])})\n",
            "Epoch: 5580 | MAE Train Loss: 0.08069723844528198 | MAE Test Loss: 0.20145240426063538 \n",
            "OrderedDict({'weights': tensor([0.2965]), 'bias': tensor([0.4576])})\n",
            "Epoch: 5590 | MAE Train Loss: 0.0806572437286377 | MAE Test Loss: 0.20127442479133606 \n",
            "OrderedDict({'weights': tensor([0.2967]), 'bias': tensor([0.4576])})\n",
            "Epoch: 5600 | MAE Train Loss: 0.080617256462574 | MAE Test Loss: 0.20109646022319794 \n",
            "OrderedDict({'weights': tensor([0.2969]), 'bias': tensor([0.4576])})\n",
            "Epoch: 5610 | MAE Train Loss: 0.08057725429534912 | MAE Test Loss: 0.200918510556221 \n",
            "OrderedDict({'weights': tensor([0.2971]), 'bias': tensor([0.4576])})\n",
            "Epoch: 5620 | MAE Train Loss: 0.08053726702928543 | MAE Test Loss: 0.2007405310869217 \n",
            "OrderedDict({'weights': tensor([0.2973]), 'bias': tensor([0.4576])})\n",
            "Epoch: 5630 | MAE Train Loss: 0.08049727231264114 | MAE Test Loss: 0.2005625218153 \n",
            "OrderedDict({'weights': tensor([0.2975]), 'bias': tensor([0.4576])})\n",
            "Epoch: 5640 | MAE Train Loss: 0.08045727759599686 | MAE Test Loss: 0.20038454234600067 \n",
            "OrderedDict({'weights': tensor([0.2977]), 'bias': tensor([0.4576])})\n",
            "Epoch: 5650 | MAE Train Loss: 0.08041727542877197 | MAE Test Loss: 0.20020660758018494 \n",
            "OrderedDict({'weights': tensor([0.2979]), 'bias': tensor([0.4576])})\n",
            "Epoch: 5660 | MAE Train Loss: 0.08037728071212769 | MAE Test Loss: 0.20002858340740204 \n",
            "OrderedDict({'weights': tensor([0.2981]), 'bias': tensor([0.4576])})\n",
            "Epoch: 5670 | MAE Train Loss: 0.0803372859954834 | MAE Test Loss: 0.19985060393810272 \n",
            "OrderedDict({'weights': tensor([0.2983]), 'bias': tensor([0.4576])})\n",
            "Epoch: 5680 | MAE Train Loss: 0.08029729872941971 | MAE Test Loss: 0.1996726542711258 \n",
            "OrderedDict({'weights': tensor([0.2985]), 'bias': tensor([0.4576])})\n",
            "Epoch: 5690 | MAE Train Loss: 0.08025729656219482 | MAE Test Loss: 0.19949467480182648 \n",
            "OrderedDict({'weights': tensor([0.2987]), 'bias': tensor([0.4576])})\n",
            "Epoch: 5700 | MAE Train Loss: 0.08021730929613113 | MAE Test Loss: 0.19931669533252716 \n",
            "OrderedDict({'weights': tensor([0.2989]), 'bias': tensor([0.4576])})\n",
            "Epoch: 5710 | MAE Train Loss: 0.08017731457948685 | MAE Test Loss: 0.19913871586322784 \n",
            "OrderedDict({'weights': tensor([0.2991]), 'bias': tensor([0.4576])})\n",
            "Epoch: 5720 | MAE Train Loss: 0.08013731241226196 | MAE Test Loss: 0.19896073639392853 \n",
            "OrderedDict({'weights': tensor([0.2993]), 'bias': tensor([0.4576])})\n",
            "Epoch: 5730 | MAE Train Loss: 0.08009732514619827 | MAE Test Loss: 0.1987827718257904 \n",
            "OrderedDict({'weights': tensor([0.2995]), 'bias': tensor([0.4576])})\n",
            "Epoch: 5740 | MAE Train Loss: 0.08005733042955399 | MAE Test Loss: 0.1986047923564911 \n",
            "OrderedDict({'weights': tensor([0.2997]), 'bias': tensor([0.4576])})\n",
            "Epoch: 5750 | MAE Train Loss: 0.0800173357129097 | MAE Test Loss: 0.19842681288719177 \n",
            "OrderedDict({'weights': tensor([0.2999]), 'bias': tensor([0.4576])})\n",
            "Epoch: 5760 | MAE Train Loss: 0.07997734099626541 | MAE Test Loss: 0.19824881851673126 \n",
            "OrderedDict({'weights': tensor([0.3001]), 'bias': tensor([0.4576])})\n",
            "Epoch: 5770 | MAE Train Loss: 0.07993734627962112 | MAE Test Loss: 0.19807088375091553 \n",
            "OrderedDict({'weights': tensor([0.3003]), 'bias': tensor([0.4576])})\n",
            "Epoch: 5780 | MAE Train Loss: 0.07989734411239624 | MAE Test Loss: 0.19789287447929382 \n",
            "OrderedDict({'weights': tensor([0.3005]), 'bias': tensor([0.4576])})\n",
            "Epoch: 5790 | MAE Train Loss: 0.07985734939575195 | MAE Test Loss: 0.1977149248123169 \n",
            "OrderedDict({'weights': tensor([0.3007]), 'bias': tensor([0.4576])})\n",
            "Epoch: 5800 | MAE Train Loss: 0.07981736212968826 | MAE Test Loss: 0.1975369155406952 \n",
            "OrderedDict({'weights': tensor([0.3009]), 'bias': tensor([0.4576])})\n",
            "Epoch: 5810 | MAE Train Loss: 0.07977736741304398 | MAE Test Loss: 0.19735893607139587 \n",
            "OrderedDict({'weights': tensor([0.3011]), 'bias': tensor([0.4576])})\n",
            "Epoch: 5820 | MAE Train Loss: 0.07973736524581909 | MAE Test Loss: 0.19718100130558014 \n",
            "OrderedDict({'weights': tensor([0.3013]), 'bias': tensor([0.4576])})\n",
            "Epoch: 5830 | MAE Train Loss: 0.079697385430336 | MAE Test Loss: 0.19700300693511963 \n",
            "OrderedDict({'weights': tensor([0.3015]), 'bias': tensor([0.4576])})\n",
            "Epoch: 5840 | MAE Train Loss: 0.07965738326311111 | MAE Test Loss: 0.1968250274658203 \n",
            "OrderedDict({'weights': tensor([0.3017]), 'bias': tensor([0.4576])})\n",
            "Epoch: 5850 | MAE Train Loss: 0.07961738109588623 | MAE Test Loss: 0.19664707779884338 \n",
            "OrderedDict({'weights': tensor([0.3019]), 'bias': tensor([0.4576])})\n",
            "Epoch: 5860 | MAE Train Loss: 0.07957738637924194 | MAE Test Loss: 0.19646906852722168 \n",
            "OrderedDict({'weights': tensor([0.3021]), 'bias': tensor([0.4576])})\n",
            "Epoch: 5870 | MAE Train Loss: 0.07953738421201706 | MAE Test Loss: 0.19629108905792236 \n",
            "OrderedDict({'weights': tensor([0.3023]), 'bias': tensor([0.4576])})\n",
            "Epoch: 5880 | MAE Train Loss: 0.07949739694595337 | MAE Test Loss: 0.19611310958862305 \n",
            "OrderedDict({'weights': tensor([0.3025]), 'bias': tensor([0.4576])})\n",
            "Epoch: 5890 | MAE Train Loss: 0.07945740222930908 | MAE Test Loss: 0.19593514502048492 \n",
            "OrderedDict({'weights': tensor([0.3027]), 'bias': tensor([0.4576])})\n",
            "Epoch: 5900 | MAE Train Loss: 0.0794174075126648 | MAE Test Loss: 0.1957571804523468 \n",
            "OrderedDict({'weights': tensor([0.3029]), 'bias': tensor([0.4576])})\n",
            "Epoch: 5910 | MAE Train Loss: 0.07937741279602051 | MAE Test Loss: 0.19557920098304749 \n",
            "OrderedDict({'weights': tensor([0.3031]), 'bias': tensor([0.4576])})\n",
            "Epoch: 5920 | MAE Train Loss: 0.07933741807937622 | MAE Test Loss: 0.19540122151374817 \n",
            "OrderedDict({'weights': tensor([0.3033]), 'bias': tensor([0.4576])})\n",
            "Epoch: 5930 | MAE Train Loss: 0.07929743826389313 | MAE Test Loss: 0.19522324204444885 \n",
            "OrderedDict({'weights': tensor([0.3035]), 'bias': tensor([0.4576])})\n",
            "Epoch: 5940 | MAE Train Loss: 0.07925742864608765 | MAE Test Loss: 0.19504526257514954 \n",
            "OrderedDict({'weights': tensor([0.3037]), 'bias': tensor([0.4576])})\n",
            "Epoch: 5950 | MAE Train Loss: 0.07921743392944336 | MAE Test Loss: 0.19486728310585022 \n",
            "OrderedDict({'weights': tensor([0.3039]), 'bias': tensor([0.4576])})\n",
            "Epoch: 5960 | MAE Train Loss: 0.07917743921279907 | MAE Test Loss: 0.1946893036365509 \n",
            "OrderedDict({'weights': tensor([0.3041]), 'bias': tensor([0.4576])})\n",
            "Epoch: 5970 | MAE Train Loss: 0.07913744449615479 | MAE Test Loss: 0.1945113241672516 \n",
            "OrderedDict({'weights': tensor([0.3043]), 'bias': tensor([0.4576])})\n",
            "Epoch: 5980 | MAE Train Loss: 0.0790974572300911 | MAE Test Loss: 0.19433334469795227 \n",
            "OrderedDict({'weights': tensor([0.3045]), 'bias': tensor([0.4576])})\n",
            "Epoch: 5990 | MAE Train Loss: 0.07905744761228561 | MAE Test Loss: 0.19415536522865295 \n",
            "OrderedDict({'weights': tensor([0.3047]), 'bias': tensor([0.4576])})\n",
            "Epoch: 6000 | MAE Train Loss: 0.07901746034622192 | MAE Test Loss: 0.19397740066051483 \n",
            "OrderedDict({'weights': tensor([0.3049]), 'bias': tensor([0.4576])})\n",
            "Epoch: 6010 | MAE Train Loss: 0.07897746562957764 | MAE Test Loss: 0.1937994509935379 \n",
            "OrderedDict({'weights': tensor([0.3051]), 'bias': tensor([0.4576])})\n",
            "Epoch: 6020 | MAE Train Loss: 0.07893747836351395 | MAE Test Loss: 0.1936214715242386 \n",
            "OrderedDict({'weights': tensor([0.3053]), 'bias': tensor([0.4576])})\n",
            "Epoch: 6030 | MAE Train Loss: 0.07889748364686966 | MAE Test Loss: 0.19344347715377808 \n",
            "OrderedDict({'weights': tensor([0.3055]), 'bias': tensor([0.4576])})\n",
            "Epoch: 6040 | MAE Train Loss: 0.07885748893022537 | MAE Test Loss: 0.19326548278331757 \n",
            "OrderedDict({'weights': tensor([0.3057]), 'bias': tensor([0.4576])})\n",
            "Epoch: 6050 | MAE Train Loss: 0.07881748676300049 | MAE Test Loss: 0.19308754801750183 \n",
            "OrderedDict({'weights': tensor([0.3059]), 'bias': tensor([0.4576])})\n",
            "Epoch: 6060 | MAE Train Loss: 0.0787823423743248 | MAE Test Loss: 0.19297738373279572 \n",
            "OrderedDict({'weights': tensor([0.3061]), 'bias': tensor([0.4576])})\n",
            "Epoch: 6070 | MAE Train Loss: 0.07874744385480881 | MAE Test Loss: 0.192867249250412 \n",
            "OrderedDict({'weights': tensor([0.3063]), 'bias': tensor([0.4575])})\n",
            "Epoch: 6080 | MAE Train Loss: 0.07871253788471222 | MAE Test Loss: 0.19275712966918945 \n",
            "OrderedDict({'weights': tensor([0.3065]), 'bias': tensor([0.4575])})\n",
            "Epoch: 6090 | MAE Train Loss: 0.07867763191461563 | MAE Test Loss: 0.19264695048332214 \n",
            "OrderedDict({'weights': tensor([0.3067]), 'bias': tensor([0.4574])})\n",
            "Epoch: 6100 | MAE Train Loss: 0.07864274084568024 | MAE Test Loss: 0.192536860704422 \n",
            "OrderedDict({'weights': tensor([0.3068]), 'bias': tensor([0.4574])})\n",
            "Epoch: 6110 | MAE Train Loss: 0.07860783487558365 | MAE Test Loss: 0.19242669641971588 \n",
            "OrderedDict({'weights': tensor([0.3070]), 'bias': tensor([0.4573])})\n",
            "Epoch: 6120 | MAE Train Loss: 0.07857291400432587 | MAE Test Loss: 0.19231656193733215 \n",
            "OrderedDict({'weights': tensor([0.3072]), 'bias': tensor([0.4573])})\n",
            "Epoch: 6130 | MAE Train Loss: 0.07853801548480988 | MAE Test Loss: 0.19220641255378723 \n",
            "OrderedDict({'weights': tensor([0.3074]), 'bias': tensor([0.4572])})\n",
            "Epoch: 6140 | MAE Train Loss: 0.07850310951471329 | MAE Test Loss: 0.1920963078737259 \n",
            "OrderedDict({'weights': tensor([0.3076]), 'bias': tensor([0.4572])})\n",
            "Epoch: 6150 | MAE Train Loss: 0.0784682109951973 | MAE Test Loss: 0.19198617339134216 \n",
            "OrderedDict({'weights': tensor([0.3077]), 'bias': tensor([0.4571])})\n",
            "Epoch: 6160 | MAE Train Loss: 0.07843330502510071 | MAE Test Loss: 0.19187600910663605 \n",
            "OrderedDict({'weights': tensor([0.3079]), 'bias': tensor([0.4571])})\n",
            "Epoch: 6170 | MAE Train Loss: 0.07839839905500412 | MAE Test Loss: 0.19176587462425232 \n",
            "OrderedDict({'weights': tensor([0.3081]), 'bias': tensor([0.4570])})\n",
            "Epoch: 6180 | MAE Train Loss: 0.07836349308490753 | MAE Test Loss: 0.19165575504302979 \n",
            "OrderedDict({'weights': tensor([0.3083]), 'bias': tensor([0.4570])})\n",
            "Epoch: 6190 | MAE Train Loss: 0.07832858711481094 | MAE Test Loss: 0.19154557585716248 \n",
            "OrderedDict({'weights': tensor([0.3085]), 'bias': tensor([0.4569])})\n",
            "Epoch: 6200 | MAE Train Loss: 0.07829368859529495 | MAE Test Loss: 0.19143548607826233 \n",
            "OrderedDict({'weights': tensor([0.3086]), 'bias': tensor([0.4569])})\n",
            "Epoch: 6210 | MAE Train Loss: 0.07825878262519836 | MAE Test Loss: 0.1913253217935562 \n",
            "OrderedDict({'weights': tensor([0.3088]), 'bias': tensor([0.4568])})\n",
            "Epoch: 6220 | MAE Train Loss: 0.07822386920452118 | MAE Test Loss: 0.19121518731117249 \n",
            "OrderedDict({'weights': tensor([0.3090]), 'bias': tensor([0.4568])})\n",
            "Epoch: 6230 | MAE Train Loss: 0.07818897068500519 | MAE Test Loss: 0.19110503792762756 \n",
            "OrderedDict({'weights': tensor([0.3092]), 'bias': tensor([0.4567])})\n",
            "Epoch: 6240 | MAE Train Loss: 0.0781540647149086 | MAE Test Loss: 0.19099493324756622 \n",
            "OrderedDict({'weights': tensor([0.3094]), 'bias': tensor([0.4567])})\n",
            "Epoch: 6250 | MAE Train Loss: 0.0781191736459732 | MAE Test Loss: 0.1908847987651825 \n",
            "OrderedDict({'weights': tensor([0.3095]), 'bias': tensor([0.4566])})\n",
            "Epoch: 6260 | MAE Train Loss: 0.07808425277471542 | MAE Test Loss: 0.19077463448047638 \n",
            "OrderedDict({'weights': tensor([0.3097]), 'bias': tensor([0.4566])})\n",
            "Epoch: 6270 | MAE Train Loss: 0.07804935425519943 | MAE Test Loss: 0.19066449999809265 \n",
            "OrderedDict({'weights': tensor([0.3099]), 'bias': tensor([0.4565])})\n",
            "Epoch: 6280 | MAE Train Loss: 0.07801444828510284 | MAE Test Loss: 0.19055438041687012 \n",
            "OrderedDict({'weights': tensor([0.3101]), 'bias': tensor([0.4565])})\n",
            "Epoch: 6290 | MAE Train Loss: 0.07797954231500626 | MAE Test Loss: 0.1904442012310028 \n",
            "OrderedDict({'weights': tensor([0.3103]), 'bias': tensor([0.4564])})\n",
            "Epoch: 6300 | MAE Train Loss: 0.07794465124607086 | MAE Test Loss: 0.19033411145210266 \n",
            "OrderedDict({'weights': tensor([0.3104]), 'bias': tensor([0.4564])})\n",
            "Epoch: 6310 | MAE Train Loss: 0.07790974527597427 | MAE Test Loss: 0.19022394716739655 \n",
            "OrderedDict({'weights': tensor([0.3106]), 'bias': tensor([0.4563])})\n",
            "Epoch: 6320 | MAE Train Loss: 0.07787483185529709 | MAE Test Loss: 0.19011381268501282 \n",
            "OrderedDict({'weights': tensor([0.3108]), 'bias': tensor([0.4563])})\n",
            "Epoch: 6330 | MAE Train Loss: 0.0778399258852005 | MAE Test Loss: 0.1900036633014679 \n",
            "OrderedDict({'weights': tensor([0.3110]), 'bias': tensor([0.4562])})\n",
            "Epoch: 6340 | MAE Train Loss: 0.07780501991510391 | MAE Test Loss: 0.18989355862140656 \n",
            "OrderedDict({'weights': tensor([0.3112]), 'bias': tensor([0.4562])})\n",
            "Epoch: 6350 | MAE Train Loss: 0.07777012139558792 | MAE Test Loss: 0.18978342413902283 \n",
            "OrderedDict({'weights': tensor([0.3113]), 'bias': tensor([0.4561])})\n",
            "Epoch: 6360 | MAE Train Loss: 0.07773521542549133 | MAE Test Loss: 0.1896732598543167 \n",
            "OrderedDict({'weights': tensor([0.3115]), 'bias': tensor([0.4561])})\n",
            "Epoch: 6370 | MAE Train Loss: 0.07770030945539474 | MAE Test Loss: 0.18956312537193298 \n",
            "OrderedDict({'weights': tensor([0.3117]), 'bias': tensor([0.4560])})\n",
            "Epoch: 6380 | MAE Train Loss: 0.07766540348529816 | MAE Test Loss: 0.18945300579071045 \n",
            "OrderedDict({'weights': tensor([0.3119]), 'bias': tensor([0.4560])})\n",
            "Epoch: 6390 | MAE Train Loss: 0.07763049751520157 | MAE Test Loss: 0.18934282660484314 \n",
            "OrderedDict({'weights': tensor([0.3121]), 'bias': tensor([0.4559])})\n",
            "Epoch: 6400 | MAE Train Loss: 0.07759559899568558 | MAE Test Loss: 0.189232736825943 \n",
            "OrderedDict({'weights': tensor([0.3122]), 'bias': tensor([0.4559])})\n",
            "Epoch: 6410 | MAE Train Loss: 0.07756069302558899 | MAE Test Loss: 0.18912257254123688 \n",
            "OrderedDict({'weights': tensor([0.3124]), 'bias': tensor([0.4558])})\n",
            "Epoch: 6420 | MAE Train Loss: 0.0775257870554924 | MAE Test Loss: 0.18901243805885315 \n",
            "OrderedDict({'weights': tensor([0.3126]), 'bias': tensor([0.4558])})\n",
            "Epoch: 6430 | MAE Train Loss: 0.07749088108539581 | MAE Test Loss: 0.18890228867530823 \n",
            "OrderedDict({'weights': tensor([0.3128]), 'bias': tensor([0.4557])})\n",
            "Epoch: 6440 | MAE Train Loss: 0.07745597511529922 | MAE Test Loss: 0.1887921839952469 \n",
            "OrderedDict({'weights': tensor([0.3130]), 'bias': tensor([0.4557])})\n",
            "Epoch: 6450 | MAE Train Loss: 0.07742108404636383 | MAE Test Loss: 0.18868204951286316 \n",
            "OrderedDict({'weights': tensor([0.3131]), 'bias': tensor([0.4556])})\n",
            "Epoch: 6460 | MAE Train Loss: 0.07738616317510605 | MAE Test Loss: 0.18857188522815704 \n",
            "OrderedDict({'weights': tensor([0.3133]), 'bias': tensor([0.4556])})\n",
            "Epoch: 6470 | MAE Train Loss: 0.07735126465559006 | MAE Test Loss: 0.18846175074577332 \n",
            "OrderedDict({'weights': tensor([0.3135]), 'bias': tensor([0.4555])})\n",
            "Epoch: 6480 | MAE Train Loss: 0.07731635868549347 | MAE Test Loss: 0.18835163116455078 \n",
            "OrderedDict({'weights': tensor([0.3137]), 'bias': tensor([0.4555])})\n",
            "Epoch: 6490 | MAE Train Loss: 0.07728145271539688 | MAE Test Loss: 0.18824145197868347 \n",
            "OrderedDict({'weights': tensor([0.3139]), 'bias': tensor([0.4554])})\n",
            "Epoch: 6500 | MAE Train Loss: 0.07724656164646149 | MAE Test Loss: 0.18813136219978333 \n",
            "OrderedDict({'weights': tensor([0.3140]), 'bias': tensor([0.4554])})\n",
            "Epoch: 6510 | MAE Train Loss: 0.0772116556763649 | MAE Test Loss: 0.1880211979150772 \n",
            "OrderedDict({'weights': tensor([0.3142]), 'bias': tensor([0.4553])})\n",
            "Epoch: 6520 | MAE Train Loss: 0.07717674225568771 | MAE Test Loss: 0.18791106343269348 \n",
            "OrderedDict({'weights': tensor([0.3144]), 'bias': tensor([0.4553])})\n",
            "Epoch: 6530 | MAE Train Loss: 0.07714183628559113 | MAE Test Loss: 0.18780091404914856 \n",
            "OrderedDict({'weights': tensor([0.3146]), 'bias': tensor([0.4552])})\n",
            "Epoch: 6540 | MAE Train Loss: 0.07710693031549454 | MAE Test Loss: 0.18769080936908722 \n",
            "OrderedDict({'weights': tensor([0.3148]), 'bias': tensor([0.4552])})\n",
            "Epoch: 6550 | MAE Train Loss: 0.07707203179597855 | MAE Test Loss: 0.1875806748867035 \n",
            "OrderedDict({'weights': tensor([0.3149]), 'bias': tensor([0.4551])})\n",
            "Epoch: 6560 | MAE Train Loss: 0.07703712582588196 | MAE Test Loss: 0.18747051060199738 \n",
            "OrderedDict({'weights': tensor([0.3151]), 'bias': tensor([0.4551])})\n",
            "Epoch: 6570 | MAE Train Loss: 0.07700221985578537 | MAE Test Loss: 0.18736037611961365 \n",
            "OrderedDict({'weights': tensor([0.3153]), 'bias': tensor([0.4550])})\n",
            "Epoch: 6580 | MAE Train Loss: 0.07696731388568878 | MAE Test Loss: 0.1872502565383911 \n",
            "OrderedDict({'weights': tensor([0.3155]), 'bias': tensor([0.4550])})\n",
            "Epoch: 6590 | MAE Train Loss: 0.0769324079155922 | MAE Test Loss: 0.1871400773525238 \n",
            "OrderedDict({'weights': tensor([0.3157]), 'bias': tensor([0.4549])})\n",
            "Epoch: 6600 | MAE Train Loss: 0.0768975093960762 | MAE Test Loss: 0.18702998757362366 \n",
            "OrderedDict({'weights': tensor([0.3158]), 'bias': tensor([0.4549])})\n",
            "Epoch: 6610 | MAE Train Loss: 0.07686260342597961 | MAE Test Loss: 0.18691982328891754 \n",
            "OrderedDict({'weights': tensor([0.3160]), 'bias': tensor([0.4548])})\n",
            "Epoch: 6620 | MAE Train Loss: 0.07682769745588303 | MAE Test Loss: 0.1868096888065338 \n",
            "OrderedDict({'weights': tensor([0.3162]), 'bias': tensor([0.4548])})\n",
            "Epoch: 6630 | MAE Train Loss: 0.07679279148578644 | MAE Test Loss: 0.1866995394229889 \n",
            "OrderedDict({'weights': tensor([0.3164]), 'bias': tensor([0.4547])})\n",
            "Epoch: 6640 | MAE Train Loss: 0.07675788551568985 | MAE Test Loss: 0.18658943474292755 \n",
            "OrderedDict({'weights': tensor([0.3166]), 'bias': tensor([0.4547])})\n",
            "Epoch: 6650 | MAE Train Loss: 0.07672299444675446 | MAE Test Loss: 0.18647930026054382 \n",
            "OrderedDict({'weights': tensor([0.3167]), 'bias': tensor([0.4546])})\n",
            "Epoch: 6660 | MAE Train Loss: 0.07668807357549667 | MAE Test Loss: 0.1863691359758377 \n",
            "OrderedDict({'weights': tensor([0.3169]), 'bias': tensor([0.4546])})\n",
            "Epoch: 6670 | MAE Train Loss: 0.07665317505598068 | MAE Test Loss: 0.18625900149345398 \n",
            "OrderedDict({'weights': tensor([0.3171]), 'bias': tensor([0.4545])})\n",
            "Epoch: 6680 | MAE Train Loss: 0.0766182690858841 | MAE Test Loss: 0.18614888191223145 \n",
            "OrderedDict({'weights': tensor([0.3173]), 'bias': tensor([0.4545])})\n",
            "Epoch: 6690 | MAE Train Loss: 0.0765833631157875 | MAE Test Loss: 0.18603870272636414 \n",
            "OrderedDict({'weights': tensor([0.3175]), 'bias': tensor([0.4544])})\n",
            "Epoch: 6700 | MAE Train Loss: 0.07654847204685211 | MAE Test Loss: 0.185928612947464 \n",
            "OrderedDict({'weights': tensor([0.3176]), 'bias': tensor([0.4544])})\n",
            "Epoch: 6710 | MAE Train Loss: 0.07651356607675552 | MAE Test Loss: 0.18581844866275787 \n",
            "OrderedDict({'weights': tensor([0.3178]), 'bias': tensor([0.4543])})\n",
            "Epoch: 6720 | MAE Train Loss: 0.07647865265607834 | MAE Test Loss: 0.18570831418037415 \n",
            "OrderedDict({'weights': tensor([0.3180]), 'bias': tensor([0.4543])})\n",
            "Epoch: 6730 | MAE Train Loss: 0.07644374668598175 | MAE Test Loss: 0.18559816479682922 \n",
            "OrderedDict({'weights': tensor([0.3182]), 'bias': tensor([0.4542])})\n",
            "Epoch: 6740 | MAE Train Loss: 0.07640884071588516 | MAE Test Loss: 0.18548806011676788 \n",
            "OrderedDict({'weights': tensor([0.3184]), 'bias': tensor([0.4542])})\n",
            "Epoch: 6750 | MAE Train Loss: 0.07637394219636917 | MAE Test Loss: 0.18537792563438416 \n",
            "OrderedDict({'weights': tensor([0.3185]), 'bias': tensor([0.4541])})\n",
            "Epoch: 6760 | MAE Train Loss: 0.07633903622627258 | MAE Test Loss: 0.18526776134967804 \n",
            "OrderedDict({'weights': tensor([0.3187]), 'bias': tensor([0.4541])})\n",
            "Epoch: 6770 | MAE Train Loss: 0.076304130256176 | MAE Test Loss: 0.1851576268672943 \n",
            "OrderedDict({'weights': tensor([0.3189]), 'bias': tensor([0.4540])})\n",
            "Epoch: 6780 | MAE Train Loss: 0.0762692242860794 | MAE Test Loss: 0.18504750728607178 \n",
            "OrderedDict({'weights': tensor([0.3191]), 'bias': tensor([0.4540])})\n",
            "Epoch: 6790 | MAE Train Loss: 0.07623431831598282 | MAE Test Loss: 0.18493732810020447 \n",
            "OrderedDict({'weights': tensor([0.3193]), 'bias': tensor([0.4539])})\n",
            "Epoch: 6800 | MAE Train Loss: 0.07619941979646683 | MAE Test Loss: 0.18482723832130432 \n",
            "OrderedDict({'weights': tensor([0.3194]), 'bias': tensor([0.4539])})\n",
            "Epoch: 6810 | MAE Train Loss: 0.07616451382637024 | MAE Test Loss: 0.1847170740365982 \n",
            "OrderedDict({'weights': tensor([0.3196]), 'bias': tensor([0.4538])})\n",
            "Epoch: 6820 | MAE Train Loss: 0.07612960785627365 | MAE Test Loss: 0.18460693955421448 \n",
            "OrderedDict({'weights': tensor([0.3198]), 'bias': tensor([0.4538])})\n",
            "Epoch: 6830 | MAE Train Loss: 0.07609470188617706 | MAE Test Loss: 0.18449679017066956 \n",
            "OrderedDict({'weights': tensor([0.3200]), 'bias': tensor([0.4537])})\n",
            "Epoch: 6840 | MAE Train Loss: 0.07605979591608047 | MAE Test Loss: 0.18438668549060822 \n",
            "OrderedDict({'weights': tensor([0.3202]), 'bias': tensor([0.4537])})\n",
            "Epoch: 6850 | MAE Train Loss: 0.07602488994598389 | MAE Test Loss: 0.1842765510082245 \n",
            "OrderedDict({'weights': tensor([0.3203]), 'bias': tensor([0.4536])})\n",
            "Epoch: 6860 | MAE Train Loss: 0.0759899839758873 | MAE Test Loss: 0.18416638672351837 \n",
            "OrderedDict({'weights': tensor([0.3205]), 'bias': tensor([0.4536])})\n",
            "Epoch: 6870 | MAE Train Loss: 0.07595508545637131 | MAE Test Loss: 0.18405625224113464 \n",
            "OrderedDict({'weights': tensor([0.3207]), 'bias': tensor([0.4535])})\n",
            "Epoch: 6880 | MAE Train Loss: 0.07592017948627472 | MAE Test Loss: 0.1839461326599121 \n",
            "OrderedDict({'weights': tensor([0.3209]), 'bias': tensor([0.4535])})\n",
            "Epoch: 6890 | MAE Train Loss: 0.07588527351617813 | MAE Test Loss: 0.1838359534740448 \n",
            "OrderedDict({'weights': tensor([0.3211]), 'bias': tensor([0.4534])})\n",
            "Epoch: 6900 | MAE Train Loss: 0.07585038244724274 | MAE Test Loss: 0.18372586369514465 \n",
            "OrderedDict({'weights': tensor([0.3212]), 'bias': tensor([0.4534])})\n",
            "Epoch: 6910 | MAE Train Loss: 0.07581547647714615 | MAE Test Loss: 0.18361569941043854 \n",
            "OrderedDict({'weights': tensor([0.3214]), 'bias': tensor([0.4533])})\n",
            "Epoch: 6920 | MAE Train Loss: 0.07578056305646896 | MAE Test Loss: 0.1835055649280548 \n",
            "OrderedDict({'weights': tensor([0.3216]), 'bias': tensor([0.4533])})\n",
            "Epoch: 6930 | MAE Train Loss: 0.07574565708637238 | MAE Test Loss: 0.1833954155445099 \n",
            "OrderedDict({'weights': tensor([0.3218]), 'bias': tensor([0.4532])})\n",
            "Epoch: 6940 | MAE Train Loss: 0.07571075111627579 | MAE Test Loss: 0.18328531086444855 \n",
            "OrderedDict({'weights': tensor([0.3220]), 'bias': tensor([0.4532])})\n",
            "Epoch: 6950 | MAE Train Loss: 0.0756758525967598 | MAE Test Loss: 0.18317517638206482 \n",
            "OrderedDict({'weights': tensor([0.3221]), 'bias': tensor([0.4531])})\n",
            "Epoch: 6960 | MAE Train Loss: 0.07564094662666321 | MAE Test Loss: 0.1830650120973587 \n",
            "OrderedDict({'weights': tensor([0.3223]), 'bias': tensor([0.4531])})\n",
            "Epoch: 6970 | MAE Train Loss: 0.07560604065656662 | MAE Test Loss: 0.18295487761497498 \n",
            "OrderedDict({'weights': tensor([0.3225]), 'bias': tensor([0.4530])})\n",
            "Epoch: 6980 | MAE Train Loss: 0.07557113468647003 | MAE Test Loss: 0.18284475803375244 \n",
            "OrderedDict({'weights': tensor([0.3227]), 'bias': tensor([0.4530])})\n",
            "Epoch: 6990 | MAE Train Loss: 0.07553622871637344 | MAE Test Loss: 0.18273457884788513 \n",
            "OrderedDict({'weights': tensor([0.3229]), 'bias': tensor([0.4529])})\n",
            "Epoch: 7000 | MAE Train Loss: 0.07550133019685745 | MAE Test Loss: 0.18262448906898499 \n",
            "OrderedDict({'weights': tensor([0.3230]), 'bias': tensor([0.4529])})\n",
            "Epoch: 7010 | MAE Train Loss: 0.07546642422676086 | MAE Test Loss: 0.18251432478427887 \n",
            "OrderedDict({'weights': tensor([0.3232]), 'bias': tensor([0.4528])})\n",
            "Epoch: 7020 | MAE Train Loss: 0.07543151825666428 | MAE Test Loss: 0.18240419030189514 \n",
            "OrderedDict({'weights': tensor([0.3234]), 'bias': tensor([0.4528])})\n",
            "Epoch: 7030 | MAE Train Loss: 0.07539661228656769 | MAE Test Loss: 0.18229404091835022 \n",
            "OrderedDict({'weights': tensor([0.3236]), 'bias': tensor([0.4527])})\n",
            "Epoch: 7040 | MAE Train Loss: 0.0753617063164711 | MAE Test Loss: 0.18218393623828888 \n",
            "OrderedDict({'weights': tensor([0.3238]), 'bias': tensor([0.4527])})\n",
            "Epoch: 7050 | MAE Train Loss: 0.07532680034637451 | MAE Test Loss: 0.18207380175590515 \n",
            "OrderedDict({'weights': tensor([0.3239]), 'bias': tensor([0.4526])})\n",
            "Epoch: 7060 | MAE Train Loss: 0.07529189437627792 | MAE Test Loss: 0.18196363747119904 \n",
            "OrderedDict({'weights': tensor([0.3241]), 'bias': tensor([0.4526])})\n",
            "Epoch: 7070 | MAE Train Loss: 0.07525699585676193 | MAE Test Loss: 0.1818535029888153 \n",
            "OrderedDict({'weights': tensor([0.3243]), 'bias': tensor([0.4525])})\n",
            "Epoch: 7080 | MAE Train Loss: 0.07522208988666534 | MAE Test Loss: 0.18174338340759277 \n",
            "OrderedDict({'weights': tensor([0.3245]), 'bias': tensor([0.4525])})\n",
            "Epoch: 7090 | MAE Train Loss: 0.07518718391656876 | MAE Test Loss: 0.18163320422172546 \n",
            "OrderedDict({'weights': tensor([0.3247]), 'bias': tensor([0.4524])})\n",
            "Epoch: 7100 | MAE Train Loss: 0.07515229284763336 | MAE Test Loss: 0.18152311444282532 \n",
            "OrderedDict({'weights': tensor([0.3248]), 'bias': tensor([0.4524])})\n",
            "Epoch: 7110 | MAE Train Loss: 0.07511738687753677 | MAE Test Loss: 0.1814129501581192 \n",
            "OrderedDict({'weights': tensor([0.3250]), 'bias': tensor([0.4523])})\n",
            "Epoch: 7120 | MAE Train Loss: 0.07508247345685959 | MAE Test Loss: 0.18130281567573547 \n",
            "OrderedDict({'weights': tensor([0.3252]), 'bias': tensor([0.4523])})\n",
            "Epoch: 7130 | MAE Train Loss: 0.075047567486763 | MAE Test Loss: 0.18119266629219055 \n",
            "OrderedDict({'weights': tensor([0.3254]), 'bias': tensor([0.4522])})\n",
            "Epoch: 7140 | MAE Train Loss: 0.07501266151666641 | MAE Test Loss: 0.1810825616121292 \n",
            "OrderedDict({'weights': tensor([0.3256]), 'bias': tensor([0.4522])})\n",
            "Epoch: 7150 | MAE Train Loss: 0.07497776299715042 | MAE Test Loss: 0.18097242712974548 \n",
            "OrderedDict({'weights': tensor([0.3257]), 'bias': tensor([0.4521])})\n",
            "Epoch: 7160 | MAE Train Loss: 0.07494285702705383 | MAE Test Loss: 0.18086226284503937 \n",
            "OrderedDict({'weights': tensor([0.3259]), 'bias': tensor([0.4521])})\n",
            "Epoch: 7170 | MAE Train Loss: 0.07490795105695724 | MAE Test Loss: 0.18075212836265564 \n",
            "OrderedDict({'weights': tensor([0.3261]), 'bias': tensor([0.4520])})\n",
            "Epoch: 7180 | MAE Train Loss: 0.07487304508686066 | MAE Test Loss: 0.1806420087814331 \n",
            "OrderedDict({'weights': tensor([0.3263]), 'bias': tensor([0.4520])})\n",
            "Epoch: 7190 | MAE Train Loss: 0.07483813911676407 | MAE Test Loss: 0.1805318295955658 \n",
            "OrderedDict({'weights': tensor([0.3265]), 'bias': tensor([0.4519])})\n",
            "Epoch: 7200 | MAE Train Loss: 0.07480324059724808 | MAE Test Loss: 0.18042173981666565 \n",
            "OrderedDict({'weights': tensor([0.3266]), 'bias': tensor([0.4519])})\n",
            "Epoch: 7210 | MAE Train Loss: 0.07476833462715149 | MAE Test Loss: 0.18031157553195953 \n",
            "OrderedDict({'weights': tensor([0.3268]), 'bias': tensor([0.4518])})\n",
            "Epoch: 7220 | MAE Train Loss: 0.0747334286570549 | MAE Test Loss: 0.1802014410495758 \n",
            "OrderedDict({'weights': tensor([0.3270]), 'bias': tensor([0.4518])})\n",
            "Epoch: 7230 | MAE Train Loss: 0.07469852268695831 | MAE Test Loss: 0.18009129166603088 \n",
            "OrderedDict({'weights': tensor([0.3272]), 'bias': tensor([0.4517])})\n",
            "Epoch: 7240 | MAE Train Loss: 0.07466361671686172 | MAE Test Loss: 0.17998118698596954 \n",
            "OrderedDict({'weights': tensor([0.3274]), 'bias': tensor([0.4517])})\n",
            "Epoch: 7250 | MAE Train Loss: 0.07462871074676514 | MAE Test Loss: 0.17987105250358582 \n",
            "OrderedDict({'weights': tensor([0.3275]), 'bias': tensor([0.4516])})\n",
            "Epoch: 7260 | MAE Train Loss: 0.07459380477666855 | MAE Test Loss: 0.1797608882188797 \n",
            "OrderedDict({'weights': tensor([0.3277]), 'bias': tensor([0.4516])})\n",
            "Epoch: 7270 | MAE Train Loss: 0.07455890625715256 | MAE Test Loss: 0.17965075373649597 \n",
            "OrderedDict({'weights': tensor([0.3279]), 'bias': tensor([0.4515])})\n",
            "Epoch: 7280 | MAE Train Loss: 0.07452400028705597 | MAE Test Loss: 0.17954063415527344 \n",
            "OrderedDict({'weights': tensor([0.3281]), 'bias': tensor([0.4515])})\n",
            "Epoch: 7290 | MAE Train Loss: 0.07448909431695938 | MAE Test Loss: 0.17943045496940613 \n",
            "OrderedDict({'weights': tensor([0.3283]), 'bias': tensor([0.4514])})\n",
            "Epoch: 7300 | MAE Train Loss: 0.07445420324802399 | MAE Test Loss: 0.17932036519050598 \n",
            "OrderedDict({'weights': tensor([0.3284]), 'bias': tensor([0.4514])})\n",
            "Epoch: 7310 | MAE Train Loss: 0.0744192972779274 | MAE Test Loss: 0.17921020090579987 \n",
            "OrderedDict({'weights': tensor([0.3286]), 'bias': tensor([0.4513])})\n",
            "Epoch: 7320 | MAE Train Loss: 0.07438438385725021 | MAE Test Loss: 0.17910006642341614 \n",
            "OrderedDict({'weights': tensor([0.3288]), 'bias': tensor([0.4513])})\n",
            "Epoch: 7330 | MAE Train Loss: 0.07434947788715363 | MAE Test Loss: 0.17898991703987122 \n",
            "OrderedDict({'weights': tensor([0.3290]), 'bias': tensor([0.4512])})\n",
            "Epoch: 7340 | MAE Train Loss: 0.07431457191705704 | MAE Test Loss: 0.17887981235980988 \n",
            "OrderedDict({'weights': tensor([0.3292]), 'bias': tensor([0.4512])})\n",
            "Epoch: 7350 | MAE Train Loss: 0.07427966594696045 | MAE Test Loss: 0.17876967787742615 \n",
            "OrderedDict({'weights': tensor([0.3293]), 'bias': tensor([0.4511])})\n",
            "Epoch: 7360 | MAE Train Loss: 0.07424476742744446 | MAE Test Loss: 0.17865951359272003 \n",
            "OrderedDict({'weights': tensor([0.3295]), 'bias': tensor([0.4511])})\n",
            "Epoch: 7370 | MAE Train Loss: 0.07420985400676727 | MAE Test Loss: 0.1785493791103363 \n",
            "OrderedDict({'weights': tensor([0.3297]), 'bias': tensor([0.4510])})\n",
            "Epoch: 7380 | MAE Train Loss: 0.07417495548725128 | MAE Test Loss: 0.17843925952911377 \n",
            "OrderedDict({'weights': tensor([0.3299]), 'bias': tensor([0.4510])})\n",
            "Epoch: 7390 | MAE Train Loss: 0.0741400495171547 | MAE Test Loss: 0.17832908034324646 \n",
            "OrderedDict({'weights': tensor([0.3301]), 'bias': tensor([0.4509])})\n",
            "Epoch: 7400 | MAE Train Loss: 0.0741051509976387 | MAE Test Loss: 0.1782189905643463 \n",
            "OrderedDict({'weights': tensor([0.3302]), 'bias': tensor([0.4509])})\n",
            "Epoch: 7410 | MAE Train Loss: 0.07407024502754211 | MAE Test Loss: 0.1781088262796402 \n",
            "OrderedDict({'weights': tensor([0.3304]), 'bias': tensor([0.4508])})\n",
            "Epoch: 7420 | MAE Train Loss: 0.07403533160686493 | MAE Test Loss: 0.17799869179725647 \n",
            "OrderedDict({'weights': tensor([0.3306]), 'bias': tensor([0.4508])})\n",
            "Epoch: 7430 | MAE Train Loss: 0.07400043308734894 | MAE Test Loss: 0.17788854241371155 \n",
            "OrderedDict({'weights': tensor([0.3308]), 'bias': tensor([0.4507])})\n",
            "Epoch: 7440 | MAE Train Loss: 0.07396552711725235 | MAE Test Loss: 0.1777784377336502 \n",
            "OrderedDict({'weights': tensor([0.3310]), 'bias': tensor([0.4507])})\n",
            "Epoch: 7450 | MAE Train Loss: 0.07393062114715576 | MAE Test Loss: 0.17766830325126648 \n",
            "OrderedDict({'weights': tensor([0.3311]), 'bias': tensor([0.4506])})\n",
            "Epoch: 7460 | MAE Train Loss: 0.07389571517705917 | MAE Test Loss: 0.17755813896656036 \n",
            "OrderedDict({'weights': tensor([0.3313]), 'bias': tensor([0.4506])})\n",
            "Epoch: 7470 | MAE Train Loss: 0.07386080920696259 | MAE Test Loss: 0.17744800448417664 \n",
            "OrderedDict({'weights': tensor([0.3315]), 'bias': tensor([0.4505])})\n",
            "Epoch: 7480 | MAE Train Loss: 0.0738259106874466 | MAE Test Loss: 0.1773378849029541 \n",
            "OrderedDict({'weights': tensor([0.3317]), 'bias': tensor([0.4505])})\n",
            "Epoch: 7490 | MAE Train Loss: 0.07379100471735 | MAE Test Loss: 0.1772277057170868 \n",
            "OrderedDict({'weights': tensor([0.3319]), 'bias': tensor([0.4504])})\n",
            "Epoch: 7500 | MAE Train Loss: 0.07375610619783401 | MAE Test Loss: 0.17711761593818665 \n",
            "OrderedDict({'weights': tensor([0.3320]), 'bias': tensor([0.4504])})\n",
            "Epoch: 7510 | MAE Train Loss: 0.07372120767831802 | MAE Test Loss: 0.17700745165348053 \n",
            "OrderedDict({'weights': tensor([0.3322]), 'bias': tensor([0.4503])})\n",
            "Epoch: 7520 | MAE Train Loss: 0.07368628680706024 | MAE Test Loss: 0.1768973171710968 \n",
            "OrderedDict({'weights': tensor([0.3324]), 'bias': tensor([0.4503])})\n",
            "Epoch: 7530 | MAE Train Loss: 0.07365138828754425 | MAE Test Loss: 0.17678716778755188 \n",
            "OrderedDict({'weights': tensor([0.3326]), 'bias': tensor([0.4502])})\n",
            "Epoch: 7540 | MAE Train Loss: 0.07361648231744766 | MAE Test Loss: 0.17667706310749054 \n",
            "OrderedDict({'weights': tensor([0.3328]), 'bias': tensor([0.4502])})\n",
            "Epoch: 7550 | MAE Train Loss: 0.07358157634735107 | MAE Test Loss: 0.1765669286251068 \n",
            "OrderedDict({'weights': tensor([0.3329]), 'bias': tensor([0.4501])})\n",
            "Epoch: 7560 | MAE Train Loss: 0.07354667782783508 | MAE Test Loss: 0.1764567643404007 \n",
            "OrderedDict({'weights': tensor([0.3331]), 'bias': tensor([0.4501])})\n",
            "Epoch: 7570 | MAE Train Loss: 0.0735117644071579 | MAE Test Loss: 0.17634662985801697 \n",
            "OrderedDict({'weights': tensor([0.3333]), 'bias': tensor([0.4500])})\n",
            "Epoch: 7580 | MAE Train Loss: 0.0734768658876419 | MAE Test Loss: 0.17623651027679443 \n",
            "OrderedDict({'weights': tensor([0.3335]), 'bias': tensor([0.4500])})\n",
            "Epoch: 7590 | MAE Train Loss: 0.07344195991754532 | MAE Test Loss: 0.17612633109092712 \n",
            "OrderedDict({'weights': tensor([0.3337]), 'bias': tensor([0.4499])})\n",
            "Epoch: 7600 | MAE Train Loss: 0.07340706139802933 | MAE Test Loss: 0.17601624131202698 \n",
            "OrderedDict({'weights': tensor([0.3338]), 'bias': tensor([0.4499])})\n",
            "Epoch: 7610 | MAE Train Loss: 0.07337215542793274 | MAE Test Loss: 0.17590607702732086 \n",
            "OrderedDict({'weights': tensor([0.3340]), 'bias': tensor([0.4498])})\n",
            "Epoch: 7620 | MAE Train Loss: 0.07333724200725555 | MAE Test Loss: 0.17579594254493713 \n",
            "OrderedDict({'weights': tensor([0.3342]), 'bias': tensor([0.4498])})\n",
            "Epoch: 7630 | MAE Train Loss: 0.07330234348773956 | MAE Test Loss: 0.1756857931613922 \n",
            "OrderedDict({'weights': tensor([0.3344]), 'bias': tensor([0.4497])})\n",
            "Epoch: 7640 | MAE Train Loss: 0.07326743751764297 | MAE Test Loss: 0.17557568848133087 \n",
            "OrderedDict({'weights': tensor([0.3346]), 'bias': tensor([0.4497])})\n",
            "Epoch: 7650 | MAE Train Loss: 0.07323253154754639 | MAE Test Loss: 0.17546555399894714 \n",
            "OrderedDict({'weights': tensor([0.3347]), 'bias': tensor([0.4496])})\n",
            "Epoch: 7660 | MAE Train Loss: 0.0731976255774498 | MAE Test Loss: 0.17535538971424103 \n",
            "OrderedDict({'weights': tensor([0.3349]), 'bias': tensor([0.4496])})\n",
            "Epoch: 7670 | MAE Train Loss: 0.07316271960735321 | MAE Test Loss: 0.1752452552318573 \n",
            "OrderedDict({'weights': tensor([0.3351]), 'bias': tensor([0.4495])})\n",
            "Epoch: 7680 | MAE Train Loss: 0.07312782108783722 | MAE Test Loss: 0.17513513565063477 \n",
            "OrderedDict({'weights': tensor([0.3353]), 'bias': tensor([0.4495])})\n",
            "Epoch: 7690 | MAE Train Loss: 0.07309291511774063 | MAE Test Loss: 0.17502495646476746 \n",
            "OrderedDict({'weights': tensor([0.3355]), 'bias': tensor([0.4494])})\n",
            "Epoch: 7700 | MAE Train Loss: 0.07305801659822464 | MAE Test Loss: 0.1749148666858673 \n",
            "OrderedDict({'weights': tensor([0.3356]), 'bias': tensor([0.4494])})\n",
            "Epoch: 7710 | MAE Train Loss: 0.07302311807870865 | MAE Test Loss: 0.1748047024011612 \n",
            "OrderedDict({'weights': tensor([0.3358]), 'bias': tensor([0.4493])})\n",
            "Epoch: 7720 | MAE Train Loss: 0.07298819720745087 | MAE Test Loss: 0.17469456791877747 \n",
            "OrderedDict({'weights': tensor([0.3360]), 'bias': tensor([0.4493])})\n",
            "Epoch: 7730 | MAE Train Loss: 0.07295329868793488 | MAE Test Loss: 0.17458441853523254 \n",
            "OrderedDict({'weights': tensor([0.3362]), 'bias': tensor([0.4492])})\n",
            "Epoch: 7740 | MAE Train Loss: 0.07291839271783829 | MAE Test Loss: 0.1744743138551712 \n",
            "OrderedDict({'weights': tensor([0.3364]), 'bias': tensor([0.4492])})\n",
            "Epoch: 7750 | MAE Train Loss: 0.0728834867477417 | MAE Test Loss: 0.17436417937278748 \n",
            "OrderedDict({'weights': tensor([0.3365]), 'bias': tensor([0.4491])})\n",
            "Epoch: 7760 | MAE Train Loss: 0.07284858822822571 | MAE Test Loss: 0.17425401508808136 \n",
            "OrderedDict({'weights': tensor([0.3367]), 'bias': tensor([0.4491])})\n",
            "Epoch: 7770 | MAE Train Loss: 0.07281367480754852 | MAE Test Loss: 0.17414388060569763 \n",
            "OrderedDict({'weights': tensor([0.3369]), 'bias': tensor([0.4490])})\n",
            "Epoch: 7780 | MAE Train Loss: 0.07277877628803253 | MAE Test Loss: 0.1740337610244751 \n",
            "OrderedDict({'weights': tensor([0.3371]), 'bias': tensor([0.4490])})\n",
            "Epoch: 7790 | MAE Train Loss: 0.07274387031793594 | MAE Test Loss: 0.1739235818386078 \n",
            "OrderedDict({'weights': tensor([0.3373]), 'bias': tensor([0.4489])})\n",
            "Epoch: 7800 | MAE Train Loss: 0.07270897179841995 | MAE Test Loss: 0.17381349205970764 \n",
            "OrderedDict({'weights': tensor([0.3374]), 'bias': tensor([0.4489])})\n",
            "Epoch: 7810 | MAE Train Loss: 0.07267406582832336 | MAE Test Loss: 0.17370332777500153 \n",
            "OrderedDict({'weights': tensor([0.3376]), 'bias': tensor([0.4488])})\n",
            "Epoch: 7820 | MAE Train Loss: 0.07263915240764618 | MAE Test Loss: 0.1735931932926178 \n",
            "OrderedDict({'weights': tensor([0.3378]), 'bias': tensor([0.4488])})\n",
            "Epoch: 7830 | MAE Train Loss: 0.07260425388813019 | MAE Test Loss: 0.17348304390907288 \n",
            "OrderedDict({'weights': tensor([0.3380]), 'bias': tensor([0.4487])})\n",
            "Epoch: 7840 | MAE Train Loss: 0.0725693553686142 | MAE Test Loss: 0.17337293922901154 \n",
            "OrderedDict({'weights': tensor([0.3382]), 'bias': tensor([0.4487])})\n",
            "Epoch: 7850 | MAE Train Loss: 0.07253444194793701 | MAE Test Loss: 0.1732628047466278 \n",
            "OrderedDict({'weights': tensor([0.3383]), 'bias': tensor([0.4486])})\n",
            "Epoch: 7860 | MAE Train Loss: 0.07249953597784042 | MAE Test Loss: 0.1731526404619217 \n",
            "OrderedDict({'weights': tensor([0.3385]), 'bias': tensor([0.4486])})\n",
            "Epoch: 7870 | MAE Train Loss: 0.07246463000774384 | MAE Test Loss: 0.17304250597953796 \n",
            "OrderedDict({'weights': tensor([0.3387]), 'bias': tensor([0.4485])})\n",
            "Epoch: 7880 | MAE Train Loss: 0.07242973148822784 | MAE Test Loss: 0.17293238639831543 \n",
            "OrderedDict({'weights': tensor([0.3389]), 'bias': tensor([0.4485])})\n",
            "Epoch: 7890 | MAE Train Loss: 0.07239482551813126 | MAE Test Loss: 0.17282220721244812 \n",
            "OrderedDict({'weights': tensor([0.3391]), 'bias': tensor([0.4484])})\n",
            "Epoch: 7900 | MAE Train Loss: 0.07235992699861526 | MAE Test Loss: 0.17271211743354797 \n",
            "OrderedDict({'weights': tensor([0.3392]), 'bias': tensor([0.4484])})\n",
            "Epoch: 7910 | MAE Train Loss: 0.07232502847909927 | MAE Test Loss: 0.17260195314884186 \n",
            "OrderedDict({'weights': tensor([0.3394]), 'bias': tensor([0.4483])})\n",
            "Epoch: 7920 | MAE Train Loss: 0.07229010760784149 | MAE Test Loss: 0.17249181866645813 \n",
            "OrderedDict({'weights': tensor([0.3396]), 'bias': tensor([0.4483])})\n",
            "Epoch: 7930 | MAE Train Loss: 0.0722552090883255 | MAE Test Loss: 0.1723816692829132 \n",
            "OrderedDict({'weights': tensor([0.3398]), 'bias': tensor([0.4482])})\n",
            "Epoch: 7940 | MAE Train Loss: 0.07222030311822891 | MAE Test Loss: 0.17227156460285187 \n",
            "OrderedDict({'weights': tensor([0.3400]), 'bias': tensor([0.4482])})\n",
            "Epoch: 7950 | MAE Train Loss: 0.07218539714813232 | MAE Test Loss: 0.17216143012046814 \n",
            "OrderedDict({'weights': tensor([0.3401]), 'bias': tensor([0.4481])})\n",
            "Epoch: 7960 | MAE Train Loss: 0.07215049862861633 | MAE Test Loss: 0.17205126583576202 \n",
            "OrderedDict({'weights': tensor([0.3403]), 'bias': tensor([0.4481])})\n",
            "Epoch: 7970 | MAE Train Loss: 0.07211558520793915 | MAE Test Loss: 0.1719411313533783 \n",
            "OrderedDict({'weights': tensor([0.3405]), 'bias': tensor([0.4480])})\n",
            "Epoch: 7980 | MAE Train Loss: 0.07208068668842316 | MAE Test Loss: 0.17183101177215576 \n",
            "OrderedDict({'weights': tensor([0.3407]), 'bias': tensor([0.4480])})\n",
            "Epoch: 7990 | MAE Train Loss: 0.07204578071832657 | MAE Test Loss: 0.17172083258628845 \n",
            "OrderedDict({'weights': tensor([0.3409]), 'bias': tensor([0.4479])})\n",
            "Epoch: 8000 | MAE Train Loss: 0.07201088219881058 | MAE Test Loss: 0.17161071300506592 \n",
            "OrderedDict({'weights': tensor([0.3410]), 'bias': tensor([0.4479])})\n",
            "Epoch: 8010 | MAE Train Loss: 0.07197597622871399 | MAE Test Loss: 0.1715005785226822 \n",
            "OrderedDict({'weights': tensor([0.3412]), 'bias': tensor([0.4478])})\n",
            "Epoch: 8020 | MAE Train Loss: 0.0719410628080368 | MAE Test Loss: 0.17139045894145966 \n",
            "OrderedDict({'weights': tensor([0.3414]), 'bias': tensor([0.4478])})\n",
            "Epoch: 8030 | MAE Train Loss: 0.07190616428852081 | MAE Test Loss: 0.17128029465675354 \n",
            "OrderedDict({'weights': tensor([0.3416]), 'bias': tensor([0.4477])})\n",
            "Epoch: 8040 | MAE Train Loss: 0.07187126576900482 | MAE Test Loss: 0.1711701601743698 \n",
            "OrderedDict({'weights': tensor([0.3418]), 'bias': tensor([0.4477])})\n",
            "Epoch: 8050 | MAE Train Loss: 0.07183635234832764 | MAE Test Loss: 0.17106004059314728 \n",
            "OrderedDict({'weights': tensor([0.3419]), 'bias': tensor([0.4476])})\n",
            "Epoch: 8060 | MAE Train Loss: 0.07180144637823105 | MAE Test Loss: 0.17094989120960236 \n",
            "OrderedDict({'weights': tensor([0.3421]), 'bias': tensor([0.4476])})\n",
            "Epoch: 8070 | MAE Train Loss: 0.07176654040813446 | MAE Test Loss: 0.17083974182605743 \n",
            "OrderedDict({'weights': tensor([0.3423]), 'bias': tensor([0.4475])})\n",
            "Epoch: 8080 | MAE Train Loss: 0.07173164188861847 | MAE Test Loss: 0.1707296371459961 \n",
            "OrderedDict({'weights': tensor([0.3425]), 'bias': tensor([0.4475])})\n",
            "Epoch: 8090 | MAE Train Loss: 0.07169673591852188 | MAE Test Loss: 0.17061945796012878 \n",
            "OrderedDict({'weights': tensor([0.3427]), 'bias': tensor([0.4474])})\n",
            "Epoch: 8100 | MAE Train Loss: 0.07166183739900589 | MAE Test Loss: 0.17050936818122864 \n",
            "OrderedDict({'weights': tensor([0.3428]), 'bias': tensor([0.4474])})\n",
            "Epoch: 8110 | MAE Train Loss: 0.0716269388794899 | MAE Test Loss: 0.17039920389652252 \n",
            "OrderedDict({'weights': tensor([0.3430]), 'bias': tensor([0.4473])})\n",
            "Epoch: 8120 | MAE Train Loss: 0.07159201800823212 | MAE Test Loss: 0.1702890843153 \n",
            "OrderedDict({'weights': tensor([0.3432]), 'bias': tensor([0.4473])})\n",
            "Epoch: 8130 | MAE Train Loss: 0.07155711948871613 | MAE Test Loss: 0.17017892003059387 \n",
            "OrderedDict({'weights': tensor([0.3434]), 'bias': tensor([0.4472])})\n",
            "Epoch: 8140 | MAE Train Loss: 0.07152221351861954 | MAE Test Loss: 0.17006878554821014 \n",
            "OrderedDict({'weights': tensor([0.3436]), 'bias': tensor([0.4472])})\n",
            "Epoch: 8150 | MAE Train Loss: 0.07148730754852295 | MAE Test Loss: 0.1699586659669876 \n",
            "OrderedDict({'weights': tensor([0.3437]), 'bias': tensor([0.4471])})\n",
            "Epoch: 8160 | MAE Train Loss: 0.07145240902900696 | MAE Test Loss: 0.1698485165834427 \n",
            "OrderedDict({'weights': tensor([0.3439]), 'bias': tensor([0.4471])})\n",
            "Epoch: 8170 | MAE Train Loss: 0.07141749560832977 | MAE Test Loss: 0.16973836719989777 \n",
            "OrderedDict({'weights': tensor([0.3441]), 'bias': tensor([0.4470])})\n",
            "Epoch: 8180 | MAE Train Loss: 0.07138259708881378 | MAE Test Loss: 0.16962826251983643 \n",
            "OrderedDict({'weights': tensor([0.3443]), 'bias': tensor([0.4470])})\n",
            "Epoch: 8190 | MAE Train Loss: 0.0713476911187172 | MAE Test Loss: 0.16951808333396912 \n",
            "OrderedDict({'weights': tensor([0.3445]), 'bias': tensor([0.4469])})\n",
            "Epoch: 8200 | MAE Train Loss: 0.0713127925992012 | MAE Test Loss: 0.16940799355506897 \n",
            "OrderedDict({'weights': tensor([0.3446]), 'bias': tensor([0.4469])})\n",
            "Epoch: 8210 | MAE Train Loss: 0.07127788662910461 | MAE Test Loss: 0.16929782927036285 \n",
            "OrderedDict({'weights': tensor([0.3448]), 'bias': tensor([0.4468])})\n",
            "Epoch: 8220 | MAE Train Loss: 0.07124297320842743 | MAE Test Loss: 0.16918770968914032 \n",
            "OrderedDict({'weights': tensor([0.3450]), 'bias': tensor([0.4468])})\n",
            "Epoch: 8230 | MAE Train Loss: 0.07120807468891144 | MAE Test Loss: 0.1690775454044342 \n",
            "OrderedDict({'weights': tensor([0.3452]), 'bias': tensor([0.4467])})\n",
            "Epoch: 8240 | MAE Train Loss: 0.07117317616939545 | MAE Test Loss: 0.16896741092205048 \n",
            "OrderedDict({'weights': tensor([0.3454]), 'bias': tensor([0.4467])})\n",
            "Epoch: 8250 | MAE Train Loss: 0.07113826274871826 | MAE Test Loss: 0.16885729134082794 \n",
            "OrderedDict({'weights': tensor([0.3455]), 'bias': tensor([0.4466])})\n",
            "Epoch: 8260 | MAE Train Loss: 0.07110335677862167 | MAE Test Loss: 0.16874714195728302 \n",
            "OrderedDict({'weights': tensor([0.3457]), 'bias': tensor([0.4466])})\n",
            "Epoch: 8270 | MAE Train Loss: 0.07106845080852509 | MAE Test Loss: 0.1686369925737381 \n",
            "OrderedDict({'weights': tensor([0.3459]), 'bias': tensor([0.4465])})\n",
            "Epoch: 8280 | MAE Train Loss: 0.0710335522890091 | MAE Test Loss: 0.16852688789367676 \n",
            "OrderedDict({'weights': tensor([0.3461]), 'bias': tensor([0.4465])})\n",
            "Epoch: 8290 | MAE Train Loss: 0.0709986463189125 | MAE Test Loss: 0.16841670870780945 \n",
            "OrderedDict({'weights': tensor([0.3463]), 'bias': tensor([0.4464])})\n",
            "Epoch: 8300 | MAE Train Loss: 0.07096374779939651 | MAE Test Loss: 0.1683066189289093 \n",
            "OrderedDict({'weights': tensor([0.3464]), 'bias': tensor([0.4464])})\n",
            "Epoch: 8310 | MAE Train Loss: 0.07092884927988052 | MAE Test Loss: 0.16819645464420319 \n",
            "OrderedDict({'weights': tensor([0.3466]), 'bias': tensor([0.4463])})\n",
            "Epoch: 8320 | MAE Train Loss: 0.07089392840862274 | MAE Test Loss: 0.16808633506298065 \n",
            "OrderedDict({'weights': tensor([0.3468]), 'bias': tensor([0.4463])})\n",
            "Epoch: 8330 | MAE Train Loss: 0.07085902988910675 | MAE Test Loss: 0.16797617077827454 \n",
            "OrderedDict({'weights': tensor([0.3470]), 'bias': tensor([0.4462])})\n",
            "Epoch: 8340 | MAE Train Loss: 0.07082412391901016 | MAE Test Loss: 0.1678660362958908 \n",
            "OrderedDict({'weights': tensor([0.3472]), 'bias': tensor([0.4462])})\n",
            "Epoch: 8350 | MAE Train Loss: 0.07078922539949417 | MAE Test Loss: 0.16775591671466827 \n",
            "OrderedDict({'weights': tensor([0.3473]), 'bias': tensor([0.4461])})\n",
            "Epoch: 8360 | MAE Train Loss: 0.07075431942939758 | MAE Test Loss: 0.16764576733112335 \n",
            "OrderedDict({'weights': tensor([0.3475]), 'bias': tensor([0.4461])})\n",
            "Epoch: 8370 | MAE Train Loss: 0.0707194060087204 | MAE Test Loss: 0.16753561794757843 \n",
            "OrderedDict({'weights': tensor([0.3477]), 'bias': tensor([0.4460])})\n",
            "Epoch: 8380 | MAE Train Loss: 0.0706845074892044 | MAE Test Loss: 0.1674255132675171 \n",
            "OrderedDict({'weights': tensor([0.3479]), 'bias': tensor([0.4460])})\n",
            "Epoch: 8390 | MAE Train Loss: 0.07064960151910782 | MAE Test Loss: 0.16731533408164978 \n",
            "OrderedDict({'weights': tensor([0.3481]), 'bias': tensor([0.4459])})\n",
            "Epoch: 8400 | MAE Train Loss: 0.07061470299959183 | MAE Test Loss: 0.16720524430274963 \n",
            "OrderedDict({'weights': tensor([0.3482]), 'bias': tensor([0.4459])})\n",
            "Epoch: 8410 | MAE Train Loss: 0.07057979702949524 | MAE Test Loss: 0.16709508001804352 \n",
            "OrderedDict({'weights': tensor([0.3484]), 'bias': tensor([0.4458])})\n",
            "Epoch: 8420 | MAE Train Loss: 0.07054488360881805 | MAE Test Loss: 0.16698496043682098 \n",
            "OrderedDict({'weights': tensor([0.3486]), 'bias': tensor([0.4458])})\n",
            "Epoch: 8430 | MAE Train Loss: 0.07050998508930206 | MAE Test Loss: 0.16687479615211487 \n",
            "OrderedDict({'weights': tensor([0.3488]), 'bias': tensor([0.4457])})\n",
            "Epoch: 8440 | MAE Train Loss: 0.07047508656978607 | MAE Test Loss: 0.16676466166973114 \n",
            "OrderedDict({'weights': tensor([0.3490]), 'bias': tensor([0.4457])})\n",
            "Epoch: 8450 | MAE Train Loss: 0.07044018059968948 | MAE Test Loss: 0.1666545420885086 \n",
            "OrderedDict({'weights': tensor([0.3491]), 'bias': tensor([0.4456])})\n",
            "Epoch: 8460 | MAE Train Loss: 0.0704052671790123 | MAE Test Loss: 0.16654439270496368 \n",
            "OrderedDict({'weights': tensor([0.3493]), 'bias': tensor([0.4456])})\n",
            "Epoch: 8470 | MAE Train Loss: 0.07037036120891571 | MAE Test Loss: 0.16643424332141876 \n",
            "OrderedDict({'weights': tensor([0.3495]), 'bias': tensor([0.4455])})\n",
            "Epoch: 8480 | MAE Train Loss: 0.07033546268939972 | MAE Test Loss: 0.16632413864135742 \n",
            "OrderedDict({'weights': tensor([0.3497]), 'bias': tensor([0.4455])})\n",
            "Epoch: 8490 | MAE Train Loss: 0.07030055671930313 | MAE Test Loss: 0.1662139594554901 \n",
            "OrderedDict({'weights': tensor([0.3499]), 'bias': tensor([0.4454])})\n",
            "Epoch: 8500 | MAE Train Loss: 0.07026565819978714 | MAE Test Loss: 0.16610386967658997 \n",
            "OrderedDict({'weights': tensor([0.3500]), 'bias': tensor([0.4454])})\n",
            "Epoch: 8510 | MAE Train Loss: 0.07023075968027115 | MAE Test Loss: 0.16599370539188385 \n",
            "OrderedDict({'weights': tensor([0.3502]), 'bias': tensor([0.4453])})\n",
            "Epoch: 8520 | MAE Train Loss: 0.07019583880901337 | MAE Test Loss: 0.16588358581066132 \n",
            "OrderedDict({'weights': tensor([0.3504]), 'bias': tensor([0.4453])})\n",
            "Epoch: 8530 | MAE Train Loss: 0.07016094028949738 | MAE Test Loss: 0.1657734215259552 \n",
            "OrderedDict({'weights': tensor([0.3506]), 'bias': tensor([0.4452])})\n",
            "Epoch: 8540 | MAE Train Loss: 0.07012603431940079 | MAE Test Loss: 0.16566328704357147 \n",
            "OrderedDict({'weights': tensor([0.3508]), 'bias': tensor([0.4452])})\n",
            "Epoch: 8550 | MAE Train Loss: 0.0700911357998848 | MAE Test Loss: 0.16555316746234894 \n",
            "OrderedDict({'weights': tensor([0.3509]), 'bias': tensor([0.4451])})\n",
            "Epoch: 8560 | MAE Train Loss: 0.07005622982978821 | MAE Test Loss: 0.16544301807880402 \n",
            "OrderedDict({'weights': tensor([0.3511]), 'bias': tensor([0.4451])})\n",
            "Epoch: 8570 | MAE Train Loss: 0.07002131640911102 | MAE Test Loss: 0.1653328686952591 \n",
            "OrderedDict({'weights': tensor([0.3513]), 'bias': tensor([0.4450])})\n",
            "Epoch: 8580 | MAE Train Loss: 0.06998641788959503 | MAE Test Loss: 0.16522276401519775 \n",
            "OrderedDict({'weights': tensor([0.3515]), 'bias': tensor([0.4450])})\n",
            "Epoch: 8590 | MAE Train Loss: 0.06995151191949844 | MAE Test Loss: 0.16511258482933044 \n",
            "OrderedDict({'weights': tensor([0.3517]), 'bias': tensor([0.4449])})\n",
            "Epoch: 8600 | MAE Train Loss: 0.06991661339998245 | MAE Test Loss: 0.1650024950504303 \n",
            "OrderedDict({'weights': tensor([0.3518]), 'bias': tensor([0.4449])})\n",
            "Epoch: 8610 | MAE Train Loss: 0.06988170742988586 | MAE Test Loss: 0.16489233076572418 \n",
            "OrderedDict({'weights': tensor([0.3520]), 'bias': tensor([0.4448])})\n",
            "Epoch: 8620 | MAE Train Loss: 0.06984679400920868 | MAE Test Loss: 0.16478221118450165 \n",
            "OrderedDict({'weights': tensor([0.3522]), 'bias': tensor([0.4448])})\n",
            "Epoch: 8630 | MAE Train Loss: 0.06981189548969269 | MAE Test Loss: 0.16467204689979553 \n",
            "OrderedDict({'weights': tensor([0.3524]), 'bias': tensor([0.4447])})\n",
            "Epoch: 8640 | MAE Train Loss: 0.0697769969701767 | MAE Test Loss: 0.1645619124174118 \n",
            "OrderedDict({'weights': tensor([0.3526]), 'bias': tensor([0.4447])})\n",
            "Epoch: 8650 | MAE Train Loss: 0.06974209100008011 | MAE Test Loss: 0.16445179283618927 \n",
            "OrderedDict({'weights': tensor([0.3527]), 'bias': tensor([0.4446])})\n",
            "Epoch: 8660 | MAE Train Loss: 0.06970717757940292 | MAE Test Loss: 0.16434164345264435 \n",
            "OrderedDict({'weights': tensor([0.3529]), 'bias': tensor([0.4446])})\n",
            "Epoch: 8670 | MAE Train Loss: 0.06967227160930634 | MAE Test Loss: 0.16423149406909943 \n",
            "OrderedDict({'weights': tensor([0.3531]), 'bias': tensor([0.4445])})\n",
            "Epoch: 8680 | MAE Train Loss: 0.06963737308979034 | MAE Test Loss: 0.16412138938903809 \n",
            "OrderedDict({'weights': tensor([0.3533]), 'bias': tensor([0.4445])})\n",
            "Epoch: 8690 | MAE Train Loss: 0.06960246711969376 | MAE Test Loss: 0.16401121020317078 \n",
            "OrderedDict({'weights': tensor([0.3535]), 'bias': tensor([0.4444])})\n",
            "Epoch: 8700 | MAE Train Loss: 0.06956756860017776 | MAE Test Loss: 0.16390112042427063 \n",
            "OrderedDict({'weights': tensor([0.3536]), 'bias': tensor([0.4444])})\n",
            "Epoch: 8710 | MAE Train Loss: 0.06953267008066177 | MAE Test Loss: 0.16379095613956451 \n",
            "OrderedDict({'weights': tensor([0.3538]), 'bias': tensor([0.4443])})\n",
            "Epoch: 8720 | MAE Train Loss: 0.06949774920940399 | MAE Test Loss: 0.16368083655834198 \n",
            "OrderedDict({'weights': tensor([0.3540]), 'bias': tensor([0.4443])})\n",
            "Epoch: 8730 | MAE Train Loss: 0.069462850689888 | MAE Test Loss: 0.16357067227363586 \n",
            "OrderedDict({'weights': tensor([0.3542]), 'bias': tensor([0.4442])})\n",
            "Epoch: 8740 | MAE Train Loss: 0.06942794471979141 | MAE Test Loss: 0.16346053779125214 \n",
            "OrderedDict({'weights': tensor([0.3544]), 'bias': tensor([0.4442])})\n",
            "Epoch: 8750 | MAE Train Loss: 0.06939304620027542 | MAE Test Loss: 0.1633504182100296 \n",
            "OrderedDict({'weights': tensor([0.3545]), 'bias': tensor([0.4441])})\n",
            "Epoch: 8760 | MAE Train Loss: 0.06935814023017883 | MAE Test Loss: 0.16324026882648468 \n",
            "OrderedDict({'weights': tensor([0.3547]), 'bias': tensor([0.4441])})\n",
            "Epoch: 8770 | MAE Train Loss: 0.06932322680950165 | MAE Test Loss: 0.16313011944293976 \n",
            "OrderedDict({'weights': tensor([0.3549]), 'bias': tensor([0.4440])})\n",
            "Epoch: 8780 | MAE Train Loss: 0.06928832828998566 | MAE Test Loss: 0.16302001476287842 \n",
            "OrderedDict({'weights': tensor([0.3551]), 'bias': tensor([0.4440])})\n",
            "Epoch: 8790 | MAE Train Loss: 0.06925342231988907 | MAE Test Loss: 0.1629098355770111 \n",
            "OrderedDict({'weights': tensor([0.3553]), 'bias': tensor([0.4439])})\n",
            "Epoch: 8800 | MAE Train Loss: 0.06921852380037308 | MAE Test Loss: 0.16279974579811096 \n",
            "OrderedDict({'weights': tensor([0.3554]), 'bias': tensor([0.4439])})\n",
            "Epoch: 8810 | MAE Train Loss: 0.06918361783027649 | MAE Test Loss: 0.16268958151340485 \n",
            "OrderedDict({'weights': tensor([0.3556]), 'bias': tensor([0.4438])})\n",
            "Epoch: 8820 | MAE Train Loss: 0.0691487044095993 | MAE Test Loss: 0.1625794619321823 \n",
            "OrderedDict({'weights': tensor([0.3558]), 'bias': tensor([0.4438])})\n",
            "Epoch: 8830 | MAE Train Loss: 0.06911380589008331 | MAE Test Loss: 0.1624692976474762 \n",
            "OrderedDict({'weights': tensor([0.3560]), 'bias': tensor([0.4437])})\n",
            "Epoch: 8840 | MAE Train Loss: 0.06907890737056732 | MAE Test Loss: 0.16235916316509247 \n",
            "OrderedDict({'weights': tensor([0.3562]), 'bias': tensor([0.4437])})\n",
            "Epoch: 8850 | MAE Train Loss: 0.06904400140047073 | MAE Test Loss: 0.16224904358386993 \n",
            "OrderedDict({'weights': tensor([0.3563]), 'bias': tensor([0.4436])})\n",
            "Epoch: 8860 | MAE Train Loss: 0.06900908797979355 | MAE Test Loss: 0.162138894200325 \n",
            "OrderedDict({'weights': tensor([0.3565]), 'bias': tensor([0.4436])})\n",
            "Epoch: 8870 | MAE Train Loss: 0.06897418200969696 | MAE Test Loss: 0.1620287448167801 \n",
            "OrderedDict({'weights': tensor([0.3567]), 'bias': tensor([0.4435])})\n",
            "Epoch: 8880 | MAE Train Loss: 0.06893928349018097 | MAE Test Loss: 0.16191864013671875 \n",
            "OrderedDict({'weights': tensor([0.3569]), 'bias': tensor([0.4435])})\n",
            "Epoch: 8890 | MAE Train Loss: 0.06890437752008438 | MAE Test Loss: 0.16180846095085144 \n",
            "OrderedDict({'weights': tensor([0.3571]), 'bias': tensor([0.4434])})\n",
            "Epoch: 8900 | MAE Train Loss: 0.06886947900056839 | MAE Test Loss: 0.1616983711719513 \n",
            "OrderedDict({'weights': tensor([0.3572]), 'bias': tensor([0.4434])})\n",
            "Epoch: 8910 | MAE Train Loss: 0.0688345804810524 | MAE Test Loss: 0.16158820688724518 \n",
            "OrderedDict({'weights': tensor([0.3574]), 'bias': tensor([0.4433])})\n",
            "Epoch: 8920 | MAE Train Loss: 0.06879965960979462 | MAE Test Loss: 0.16147808730602264 \n",
            "OrderedDict({'weights': tensor([0.3576]), 'bias': tensor([0.4433])})\n",
            "Epoch: 8930 | MAE Train Loss: 0.06876476109027863 | MAE Test Loss: 0.16136792302131653 \n",
            "OrderedDict({'weights': tensor([0.3578]), 'bias': tensor([0.4432])})\n",
            "Epoch: 8940 | MAE Train Loss: 0.06872985512018204 | MAE Test Loss: 0.1612577885389328 \n",
            "OrderedDict({'weights': tensor([0.3580]), 'bias': tensor([0.4432])})\n",
            "Epoch: 8950 | MAE Train Loss: 0.06869495660066605 | MAE Test Loss: 0.16114766895771027 \n",
            "OrderedDict({'weights': tensor([0.3581]), 'bias': tensor([0.4431])})\n",
            "Epoch: 8960 | MAE Train Loss: 0.06866005063056946 | MAE Test Loss: 0.16103751957416534 \n",
            "OrderedDict({'weights': tensor([0.3583]), 'bias': tensor([0.4431])})\n",
            "Epoch: 8970 | MAE Train Loss: 0.06862513720989227 | MAE Test Loss: 0.16092737019062042 \n",
            "OrderedDict({'weights': tensor([0.3585]), 'bias': tensor([0.4430])})\n",
            "Epoch: 8980 | MAE Train Loss: 0.06859023869037628 | MAE Test Loss: 0.16081726551055908 \n",
            "OrderedDict({'weights': tensor([0.3587]), 'bias': tensor([0.4430])})\n",
            "Epoch: 8990 | MAE Train Loss: 0.0685553327202797 | MAE Test Loss: 0.16070708632469177 \n",
            "OrderedDict({'weights': tensor([0.3589]), 'bias': tensor([0.4429])})\n",
            "Epoch: 9000 | MAE Train Loss: 0.0685204342007637 | MAE Test Loss: 0.16059699654579163 \n",
            "OrderedDict({'weights': tensor([0.3590]), 'bias': tensor([0.4429])})\n",
            "Epoch: 9010 | MAE Train Loss: 0.06848552823066711 | MAE Test Loss: 0.1604868322610855 \n",
            "OrderedDict({'weights': tensor([0.3592]), 'bias': tensor([0.4428])})\n",
            "Epoch: 9020 | MAE Train Loss: 0.06845061480998993 | MAE Test Loss: 0.16037671267986298 \n",
            "OrderedDict({'weights': tensor([0.3594]), 'bias': tensor([0.4428])})\n",
            "Epoch: 9030 | MAE Train Loss: 0.06841571629047394 | MAE Test Loss: 0.16026654839515686 \n",
            "OrderedDict({'weights': tensor([0.3596]), 'bias': tensor([0.4427])})\n",
            "Epoch: 9040 | MAE Train Loss: 0.06838081777095795 | MAE Test Loss: 0.16015641391277313 \n",
            "OrderedDict({'weights': tensor([0.3598]), 'bias': tensor([0.4427])})\n",
            "Epoch: 9050 | MAE Train Loss: 0.06834591180086136 | MAE Test Loss: 0.1600462943315506 \n",
            "OrderedDict({'weights': tensor([0.3599]), 'bias': tensor([0.4426])})\n",
            "Epoch: 9060 | MAE Train Loss: 0.06831099838018417 | MAE Test Loss: 0.15993614494800568 \n",
            "OrderedDict({'weights': tensor([0.3601]), 'bias': tensor([0.4426])})\n",
            "Epoch: 9070 | MAE Train Loss: 0.06827609241008759 | MAE Test Loss: 0.15982599556446075 \n",
            "OrderedDict({'weights': tensor([0.3603]), 'bias': tensor([0.4425])})\n",
            "Epoch: 9080 | MAE Train Loss: 0.0682411938905716 | MAE Test Loss: 0.15971589088439941 \n",
            "OrderedDict({'weights': tensor([0.3605]), 'bias': tensor([0.4425])})\n",
            "Epoch: 9090 | MAE Train Loss: 0.068206287920475 | MAE Test Loss: 0.1596057116985321 \n",
            "OrderedDict({'weights': tensor([0.3607]), 'bias': tensor([0.4424])})\n",
            "Epoch: 9100 | MAE Train Loss: 0.06817138940095901 | MAE Test Loss: 0.15949562191963196 \n",
            "OrderedDict({'weights': tensor([0.3608]), 'bias': tensor([0.4424])})\n",
            "Epoch: 9110 | MAE Train Loss: 0.06813649088144302 | MAE Test Loss: 0.15938545763492584 \n",
            "OrderedDict({'weights': tensor([0.3610]), 'bias': tensor([0.4423])})\n",
            "Epoch: 9120 | MAE Train Loss: 0.06810157001018524 | MAE Test Loss: 0.1592753380537033 \n",
            "OrderedDict({'weights': tensor([0.3612]), 'bias': tensor([0.4423])})\n",
            "Epoch: 9130 | MAE Train Loss: 0.06806667149066925 | MAE Test Loss: 0.1591651737689972 \n",
            "OrderedDict({'weights': tensor([0.3614]), 'bias': tensor([0.4422])})\n",
            "Epoch: 9140 | MAE Train Loss: 0.06803202629089355 | MAE Test Loss: 0.15907564759254456 \n",
            "OrderedDict({'weights': tensor([0.3615]), 'bias': tensor([0.4421])})\n",
            "Epoch: 9150 | MAE Train Loss: 0.06799772381782532 | MAE Test Loss: 0.1589929312467575 \n",
            "OrderedDict({'weights': tensor([0.3617]), 'bias': tensor([0.4421])})\n",
            "Epoch: 9160 | MAE Train Loss: 0.06796333938837051 | MAE Test Loss: 0.15891025960445404 \n",
            "OrderedDict({'weights': tensor([0.3619]), 'bias': tensor([0.4420])})\n",
            "Epoch: 9170 | MAE Train Loss: 0.0679289922118187 | MAE Test Loss: 0.15883103013038635 \n",
            "OrderedDict({'weights': tensor([0.3621]), 'bias': tensor([0.4419])})\n",
            "Epoch: 9180 | MAE Train Loss: 0.0678945928812027 | MAE Test Loss: 0.1587483435869217 \n",
            "OrderedDict({'weights': tensor([0.3622]), 'bias': tensor([0.4419])})\n",
            "Epoch: 9190 | MAE Train Loss: 0.06786025315523148 | MAE Test Loss: 0.1586725264787674 \n",
            "OrderedDict({'weights': tensor([0.3624]), 'bias': tensor([0.4418])})\n",
            "Epoch: 9200 | MAE Train Loss: 0.06782589852809906 | MAE Test Loss: 0.15858986973762512 \n",
            "OrderedDict({'weights': tensor([0.3626]), 'bias': tensor([0.4417])})\n",
            "Epoch: 9210 | MAE Train Loss: 0.06779150664806366 | MAE Test Loss: 0.15850713849067688 \n",
            "OrderedDict({'weights': tensor([0.3627]), 'bias': tensor([0.4416])})\n",
            "Epoch: 9220 | MAE Train Loss: 0.06775716692209244 | MAE Test Loss: 0.15843133628368378 \n",
            "OrderedDict({'weights': tensor([0.3629]), 'bias': tensor([0.4416])})\n",
            "Epoch: 9230 | MAE Train Loss: 0.06772283464670181 | MAE Test Loss: 0.15834864974021912 \n",
            "OrderedDict({'weights': tensor([0.3631]), 'bias': tensor([0.4415])})\n",
            "Epoch: 9240 | MAE Train Loss: 0.06768842041492462 | MAE Test Loss: 0.15826594829559326 \n",
            "OrderedDict({'weights': tensor([0.3633]), 'bias': tensor([0.4414])})\n",
            "Epoch: 9250 | MAE Train Loss: 0.067654088139534 | MAE Test Loss: 0.15819016098976135 \n",
            "OrderedDict({'weights': tensor([0.3634]), 'bias': tensor([0.4414])})\n",
            "Epoch: 9260 | MAE Train Loss: 0.0676197037100792 | MAE Test Loss: 0.15811088681221008 \n",
            "OrderedDict({'weights': tensor([0.3636]), 'bias': tensor([0.4413])})\n",
            "Epoch: 9270 | MAE Train Loss: 0.06758533418178558 | MAE Test Loss: 0.15802475810050964 \n",
            "OrderedDict({'weights': tensor([0.3638]), 'bias': tensor([0.4412])})\n",
            "Epoch: 9280 | MAE Train Loss: 0.06755100935697556 | MAE Test Loss: 0.15794894099235535 \n",
            "OrderedDict({'weights': tensor([0.3639]), 'bias': tensor([0.4411])})\n",
            "Epoch: 9290 | MAE Train Loss: 0.06751665472984314 | MAE Test Loss: 0.15786626935005188 \n",
            "OrderedDict({'weights': tensor([0.3641]), 'bias': tensor([0.4411])})\n",
            "Epoch: 9300 | MAE Train Loss: 0.06748224794864655 | MAE Test Loss: 0.1577835977077484 \n",
            "OrderedDict({'weights': tensor([0.3643]), 'bias': tensor([0.4410])})\n",
            "Epoch: 9310 | MAE Train Loss: 0.06744790822267532 | MAE Test Loss: 0.15770435333251953 \n",
            "OrderedDict({'weights': tensor([0.3645]), 'bias': tensor([0.4409])})\n",
            "Epoch: 9320 | MAE Train Loss: 0.06741353869438171 | MAE Test Loss: 0.15762850642204285 \n",
            "OrderedDict({'weights': tensor([0.3646]), 'bias': tensor([0.4409])})\n",
            "Epoch: 9330 | MAE Train Loss: 0.06737922132015228 | MAE Test Loss: 0.15754583477973938 \n",
            "OrderedDict({'weights': tensor([0.3648]), 'bias': tensor([0.4408])})\n",
            "Epoch: 9340 | MAE Train Loss: 0.06734482198953629 | MAE Test Loss: 0.15746314823627472 \n",
            "OrderedDict({'weights': tensor([0.3650]), 'bias': tensor([0.4407])})\n",
            "Epoch: 9350 | MAE Train Loss: 0.06731047481298447 | MAE Test Loss: 0.15738730132579803 \n",
            "OrderedDict({'weights': tensor([0.3651]), 'bias': tensor([0.4406])})\n",
            "Epoch: 9360 | MAE Train Loss: 0.06727613508701324 | MAE Test Loss: 0.15730464458465576 \n",
            "OrderedDict({'weights': tensor([0.3653]), 'bias': tensor([0.4406])})\n",
            "Epoch: 9370 | MAE Train Loss: 0.06724173575639725 | MAE Test Loss: 0.1572219431400299 \n",
            "OrderedDict({'weights': tensor([0.3655]), 'bias': tensor([0.4405])})\n",
            "Epoch: 9380 | MAE Train Loss: 0.06720738112926483 | MAE Test Loss: 0.1571461260318756 \n",
            "OrderedDict({'weights': tensor([0.3657]), 'bias': tensor([0.4404])})\n",
            "Epoch: 9390 | MAE Train Loss: 0.0671730563044548 | MAE Test Loss: 0.15706345438957214 \n",
            "OrderedDict({'weights': tensor([0.3658]), 'bias': tensor([0.4404])})\n",
            "Epoch: 9400 | MAE Train Loss: 0.0671386867761612 | MAE Test Loss: 0.15698421001434326 \n",
            "OrderedDict({'weights': tensor([0.3660]), 'bias': tensor([0.4403])})\n",
            "Epoch: 9410 | MAE Train Loss: 0.06710430979728699 | MAE Test Loss: 0.1569015234708786 \n",
            "OrderedDict({'weights': tensor([0.3662]), 'bias': tensor([0.4402])})\n",
            "Epoch: 9420 | MAE Train Loss: 0.06706991046667099 | MAE Test Loss: 0.1568256914615631 \n",
            "OrderedDict({'weights': tensor([0.3663]), 'bias': tensor([0.4401])})\n",
            "Epoch: 9430 | MAE Train Loss: 0.06703560799360275 | MAE Test Loss: 0.15674300491809845 \n",
            "OrderedDict({'weights': tensor([0.3665]), 'bias': tensor([0.4401])})\n",
            "Epoch: 9440 | MAE Train Loss: 0.06700122356414795 | MAE Test Loss: 0.1566603183746338 \n",
            "OrderedDict({'weights': tensor([0.3667]), 'bias': tensor([0.4400])})\n",
            "Epoch: 9450 | MAE Train Loss: 0.06696684658527374 | MAE Test Loss: 0.1565845012664795 \n",
            "OrderedDict({'weights': tensor([0.3668]), 'bias': tensor([0.4399])})\n",
            "Epoch: 9460 | MAE Train Loss: 0.06693252176046371 | MAE Test Loss: 0.15650181472301483 \n",
            "OrderedDict({'weights': tensor([0.3670]), 'bias': tensor([0.4399])})\n",
            "Epoch: 9470 | MAE Train Loss: 0.06689812988042831 | MAE Test Loss: 0.15641912817955017 \n",
            "OrderedDict({'weights': tensor([0.3672]), 'bias': tensor([0.4398])})\n",
            "Epoch: 9480 | MAE Train Loss: 0.0668637603521347 | MAE Test Loss: 0.15634331107139587 \n",
            "OrderedDict({'weights': tensor([0.3674]), 'bias': tensor([0.4397])})\n",
            "Epoch: 9490 | MAE Train Loss: 0.0668293908238411 | MAE Test Loss: 0.15625721216201782 \n",
            "OrderedDict({'weights': tensor([0.3675]), 'bias': tensor([0.4396])})\n",
            "Epoch: 9500 | MAE Train Loss: 0.06679506599903107 | MAE Test Loss: 0.15618140995502472 \n",
            "OrderedDict({'weights': tensor([0.3677]), 'bias': tensor([0.4396])})\n",
            "Epoch: 9510 | MAE Train Loss: 0.06676067411899567 | MAE Test Loss: 0.15610215067863464 \n",
            "OrderedDict({'weights': tensor([0.3679]), 'bias': tensor([0.4395])})\n",
            "Epoch: 9520 | MAE Train Loss: 0.06672636419534683 | MAE Test Loss: 0.15601946413516998 \n",
            "OrderedDict({'weights': tensor([0.3680]), 'bias': tensor([0.4394])})\n",
            "Epoch: 9530 | MAE Train Loss: 0.06669196486473083 | MAE Test Loss: 0.15593676269054413 \n",
            "OrderedDict({'weights': tensor([0.3682]), 'bias': tensor([0.4394])})\n",
            "Epoch: 9540 | MAE Train Loss: 0.06665760278701782 | MAE Test Loss: 0.15586097538471222 \n",
            "OrderedDict({'weights': tensor([0.3684]), 'bias': tensor([0.4393])})\n",
            "Epoch: 9550 | MAE Train Loss: 0.06662321090698242 | MAE Test Loss: 0.15577486157417297 \n",
            "OrderedDict({'weights': tensor([0.3686]), 'bias': tensor([0.4392])})\n",
            "Epoch: 9560 | MAE Train Loss: 0.06658890098333359 | MAE Test Loss: 0.1556990146636963 \n",
            "OrderedDict({'weights': tensor([0.3687]), 'bias': tensor([0.4391])})\n",
            "Epoch: 9570 | MAE Train Loss: 0.06655453145503998 | MAE Test Loss: 0.15561632812023163 \n",
            "OrderedDict({'weights': tensor([0.3689]), 'bias': tensor([0.4391])})\n",
            "Epoch: 9580 | MAE Train Loss: 0.06652013212442398 | MAE Test Loss: 0.15553364157676697 \n",
            "OrderedDict({'weights': tensor([0.3691]), 'bias': tensor([0.4390])})\n",
            "Epoch: 9590 | MAE Train Loss: 0.06648582220077515 | MAE Test Loss: 0.15545782446861267 \n",
            "OrderedDict({'weights': tensor([0.3692]), 'bias': tensor([0.4389])})\n",
            "Epoch: 9600 | MAE Train Loss: 0.06645144522190094 | MAE Test Loss: 0.1553751528263092 \n",
            "OrderedDict({'weights': tensor([0.3694]), 'bias': tensor([0.4388])})\n",
            "Epoch: 9610 | MAE Train Loss: 0.06641705334186554 | MAE Test Loss: 0.1552993357181549 \n",
            "OrderedDict({'weights': tensor([0.3696]), 'bias': tensor([0.4388])})\n",
            "Epoch: 9620 | MAE Train Loss: 0.0663827508687973 | MAE Test Loss: 0.15521661937236786 \n",
            "OrderedDict({'weights': tensor([0.3698]), 'bias': tensor([0.4387])})\n",
            "Epoch: 9630 | MAE Train Loss: 0.0663483589887619 | MAE Test Loss: 0.1551339477300644 \n",
            "OrderedDict({'weights': tensor([0.3699]), 'bias': tensor([0.4386])})\n",
            "Epoch: 9640 | MAE Train Loss: 0.06631401926279068 | MAE Test Loss: 0.1550547182559967 \n",
            "OrderedDict({'weights': tensor([0.3701]), 'bias': tensor([0.4386])})\n",
            "Epoch: 9650 | MAE Train Loss: 0.06627961993217468 | MAE Test Loss: 0.15497203171253204 \n",
            "OrderedDict({'weights': tensor([0.3703]), 'bias': tensor([0.4385])})\n",
            "Epoch: 9660 | MAE Train Loss: 0.06624528020620346 | MAE Test Loss: 0.15489621460437775 \n",
            "OrderedDict({'weights': tensor([0.3704]), 'bias': tensor([0.4384])})\n",
            "Epoch: 9670 | MAE Train Loss: 0.06621092557907104 | MAE Test Loss: 0.15481355786323547 \n",
            "OrderedDict({'weights': tensor([0.3706]), 'bias': tensor([0.4383])})\n",
            "Epoch: 9680 | MAE Train Loss: 0.06617653369903564 | MAE Test Loss: 0.15473082661628723 \n",
            "OrderedDict({'weights': tensor([0.3708]), 'bias': tensor([0.4383])})\n",
            "Epoch: 9690 | MAE Train Loss: 0.06614218652248383 | MAE Test Loss: 0.15465502440929413 \n",
            "OrderedDict({'weights': tensor([0.3710]), 'bias': tensor([0.4382])})\n",
            "Epoch: 9700 | MAE Train Loss: 0.0661078542470932 | MAE Test Loss: 0.15457233786582947 \n",
            "OrderedDict({'weights': tensor([0.3711]), 'bias': tensor([0.4381])})\n",
            "Epoch: 9710 | MAE Train Loss: 0.06607344001531601 | MAE Test Loss: 0.1544896364212036 \n",
            "OrderedDict({'weights': tensor([0.3713]), 'bias': tensor([0.4381])})\n",
            "Epoch: 9720 | MAE Train Loss: 0.06603912264108658 | MAE Test Loss: 0.1544138491153717 \n",
            "OrderedDict({'weights': tensor([0.3715]), 'bias': tensor([0.4380])})\n",
            "Epoch: 9730 | MAE Train Loss: 0.06600473076105118 | MAE Test Loss: 0.15433457493782043 \n",
            "OrderedDict({'weights': tensor([0.3716]), 'bias': tensor([0.4379])})\n",
            "Epoch: 9740 | MAE Train Loss: 0.06597035378217697 | MAE Test Loss: 0.15424844622612 \n",
            "OrderedDict({'weights': tensor([0.3718]), 'bias': tensor([0.4378])})\n",
            "Epoch: 9750 | MAE Train Loss: 0.06593603640794754 | MAE Test Loss: 0.1541726291179657 \n",
            "OrderedDict({'weights': tensor([0.3720]), 'bias': tensor([0.4378])})\n",
            "Epoch: 9760 | MAE Train Loss: 0.06590168178081512 | MAE Test Loss: 0.15408995747566223 \n",
            "OrderedDict({'weights': tensor([0.3721]), 'bias': tensor([0.4377])})\n",
            "Epoch: 9770 | MAE Train Loss: 0.06586727499961853 | MAE Test Loss: 0.15400728583335876 \n",
            "OrderedDict({'weights': tensor([0.3723]), 'bias': tensor([0.4376])})\n",
            "Epoch: 9780 | MAE Train Loss: 0.06583292782306671 | MAE Test Loss: 0.15392804145812988 \n",
            "OrderedDict({'weights': tensor([0.3725]), 'bias': tensor([0.4376])})\n",
            "Epoch: 9790 | MAE Train Loss: 0.0657985657453537 | MAE Test Loss: 0.1538521945476532 \n",
            "OrderedDict({'weights': tensor([0.3727]), 'bias': tensor([0.4375])})\n",
            "Epoch: 9800 | MAE Train Loss: 0.06576424837112427 | MAE Test Loss: 0.15376952290534973 \n",
            "OrderedDict({'weights': tensor([0.3728]), 'bias': tensor([0.4374])})\n",
            "Epoch: 9810 | MAE Train Loss: 0.06572984158992767 | MAE Test Loss: 0.15368683636188507 \n",
            "OrderedDict({'weights': tensor([0.3730]), 'bias': tensor([0.4373])})\n",
            "Epoch: 9820 | MAE Train Loss: 0.06569548696279526 | MAE Test Loss: 0.1536109894514084 \n",
            "OrderedDict({'weights': tensor([0.3732]), 'bias': tensor([0.4373])})\n",
            "Epoch: 9830 | MAE Train Loss: 0.06566116213798523 | MAE Test Loss: 0.1535283327102661 \n",
            "OrderedDict({'weights': tensor([0.3733]), 'bias': tensor([0.4372])})\n",
            "Epoch: 9840 | MAE Train Loss: 0.06562675535678864 | MAE Test Loss: 0.15344563126564026 \n",
            "OrderedDict({'weights': tensor([0.3735]), 'bias': tensor([0.4371])})\n",
            "Epoch: 9850 | MAE Train Loss: 0.06559240818023682 | MAE Test Loss: 0.15336981415748596 \n",
            "OrderedDict({'weights': tensor([0.3737]), 'bias': tensor([0.4370])})\n",
            "Epoch: 9860 | MAE Train Loss: 0.06555808335542679 | MAE Test Loss: 0.1532871425151825 \n",
            "OrderedDict({'weights': tensor([0.3739]), 'bias': tensor([0.4370])})\n",
            "Epoch: 9870 | MAE Train Loss: 0.06552372127771378 | MAE Test Loss: 0.1532078981399536 \n",
            "OrderedDict({'weights': tensor([0.3740]), 'bias': tensor([0.4369])})\n",
            "Epoch: 9880 | MAE Train Loss: 0.06548933684825897 | MAE Test Loss: 0.15312521159648895 \n",
            "OrderedDict({'weights': tensor([0.3742]), 'bias': tensor([0.4368])})\n",
            "Epoch: 9890 | MAE Train Loss: 0.06545493751764297 | MAE Test Loss: 0.15304937958717346 \n",
            "OrderedDict({'weights': tensor([0.3744]), 'bias': tensor([0.4368])})\n",
            "Epoch: 9900 | MAE Train Loss: 0.06542063504457474 | MAE Test Loss: 0.1529666930437088 \n",
            "OrderedDict({'weights': tensor([0.3745]), 'bias': tensor([0.4367])})\n",
            "Epoch: 9910 | MAE Train Loss: 0.06538624316453934 | MAE Test Loss: 0.15288400650024414 \n",
            "OrderedDict({'weights': tensor([0.3747]), 'bias': tensor([0.4366])})\n",
            "Epoch: 9920 | MAE Train Loss: 0.06535186618566513 | MAE Test Loss: 0.15280818939208984 \n",
            "OrderedDict({'weights': tensor([0.3749]), 'bias': tensor([0.4365])})\n",
            "Epoch: 9930 | MAE Train Loss: 0.0653175488114357 | MAE Test Loss: 0.15272550284862518 \n",
            "OrderedDict({'weights': tensor([0.3751]), 'bias': tensor([0.4365])})\n",
            "Epoch: 9940 | MAE Train Loss: 0.0652831643819809 | MAE Test Loss: 0.15264281630516052 \n",
            "OrderedDict({'weights': tensor([0.3752]), 'bias': tensor([0.4364])})\n",
            "Epoch: 9950 | MAE Train Loss: 0.06524877995252609 | MAE Test Loss: 0.15256699919700623 \n",
            "OrderedDict({'weights': tensor([0.3754]), 'bias': tensor([0.4363])})\n",
            "Epoch: 9960 | MAE Train Loss: 0.06521441042423248 | MAE Test Loss: 0.15248090028762817 \n",
            "OrderedDict({'weights': tensor([0.3756]), 'bias': tensor([0.4363])})\n",
            "Epoch: 9970 | MAE Train Loss: 0.06518009305000305 | MAE Test Loss: 0.15240509808063507 \n",
            "OrderedDict({'weights': tensor([0.3757]), 'bias': tensor([0.4362])})\n",
            "Epoch: 9980 | MAE Train Loss: 0.06514570116996765 | MAE Test Loss: 0.152325838804245 \n",
            "OrderedDict({'weights': tensor([0.3759]), 'bias': tensor([0.4361])})\n",
            "Epoch: 9990 | MAE Train Loss: 0.06511138379573822 | MAE Test Loss: 0.15224315226078033 \n",
            "OrderedDict({'weights': tensor([0.3761]), 'bias': tensor([0.4360])})\n",
            "Epoch: 10000 | MAE Train Loss: 0.06507699191570282 | MAE Test Loss: 0.15216045081615448 \n",
            "OrderedDict({'weights': tensor([0.3763]), 'bias': tensor([0.4360])})\n",
            "Epoch: 10010 | MAE Train Loss: 0.06504262983798981 | MAE Test Loss: 0.15208466351032257 \n",
            "OrderedDict({'weights': tensor([0.3764]), 'bias': tensor([0.4359])})\n",
            "Epoch: 10020 | MAE Train Loss: 0.0650082379579544 | MAE Test Loss: 0.15199854969978333 \n",
            "OrderedDict({'weights': tensor([0.3766]), 'bias': tensor([0.4358])})\n",
            "Epoch: 10030 | MAE Train Loss: 0.06497392803430557 | MAE Test Loss: 0.15192270278930664 \n",
            "OrderedDict({'weights': tensor([0.3768]), 'bias': tensor([0.4358])})\n",
            "Epoch: 10040 | MAE Train Loss: 0.06493955850601196 | MAE Test Loss: 0.15184001624584198 \n",
            "OrderedDict({'weights': tensor([0.3769]), 'bias': tensor([0.4357])})\n",
            "Epoch: 10050 | MAE Train Loss: 0.06490515172481537 | MAE Test Loss: 0.15175732970237732 \n",
            "OrderedDict({'weights': tensor([0.3771]), 'bias': tensor([0.4356])})\n",
            "Epoch: 10060 | MAE Train Loss: 0.06487084925174713 | MAE Test Loss: 0.15168151259422302 \n",
            "OrderedDict({'weights': tensor([0.3773]), 'bias': tensor([0.4355])})\n",
            "Epoch: 10070 | MAE Train Loss: 0.06483646482229233 | MAE Test Loss: 0.15159884095191956 \n",
            "OrderedDict({'weights': tensor([0.3774]), 'bias': tensor([0.4355])})\n",
            "Epoch: 10080 | MAE Train Loss: 0.06480206549167633 | MAE Test Loss: 0.15152302384376526 \n",
            "OrderedDict({'weights': tensor([0.3776]), 'bias': tensor([0.4354])})\n",
            "Epoch: 10090 | MAE Train Loss: 0.06476777046918869 | MAE Test Loss: 0.1514403074979782 \n",
            "OrderedDict({'weights': tensor([0.3778]), 'bias': tensor([0.4353])})\n",
            "Epoch: 10100 | MAE Train Loss: 0.06473338603973389 | MAE Test Loss: 0.15135763585567474 \n",
            "OrderedDict({'weights': tensor([0.3780]), 'bias': tensor([0.4353])})\n",
            "Epoch: 10110 | MAE Train Loss: 0.06469903886318207 | MAE Test Loss: 0.15127840638160706 \n",
            "OrderedDict({'weights': tensor([0.3781]), 'bias': tensor([0.4352])})\n",
            "Epoch: 10120 | MAE Train Loss: 0.06466464698314667 | MAE Test Loss: 0.1511957198381424 \n",
            "OrderedDict({'weights': tensor([0.3783]), 'bias': tensor([0.4351])})\n",
            "Epoch: 10130 | MAE Train Loss: 0.06463030725717545 | MAE Test Loss: 0.1511199027299881 \n",
            "OrderedDict({'weights': tensor([0.3785]), 'bias': tensor([0.4350])})\n",
            "Epoch: 10140 | MAE Train Loss: 0.06459595263004303 | MAE Test Loss: 0.15103724598884583 \n",
            "OrderedDict({'weights': tensor([0.3786]), 'bias': tensor([0.4350])})\n",
            "Epoch: 10150 | MAE Train Loss: 0.06456156075000763 | MAE Test Loss: 0.15095451474189758 \n",
            "OrderedDict({'weights': tensor([0.3788]), 'bias': tensor([0.4349])})\n",
            "Epoch: 10160 | MAE Train Loss: 0.06452721357345581 | MAE Test Loss: 0.15087871253490448 \n",
            "OrderedDict({'weights': tensor([0.3790]), 'bias': tensor([0.4348])})\n",
            "Epoch: 10170 | MAE Train Loss: 0.06449288129806519 | MAE Test Loss: 0.15079602599143982 \n",
            "OrderedDict({'weights': tensor([0.3792]), 'bias': tensor([0.4348])})\n",
            "Epoch: 10180 | MAE Train Loss: 0.064458467066288 | MAE Test Loss: 0.15071332454681396 \n",
            "OrderedDict({'weights': tensor([0.3793]), 'bias': tensor([0.4347])})\n",
            "Epoch: 10190 | MAE Train Loss: 0.06442414224147797 | MAE Test Loss: 0.15063753724098206 \n",
            "OrderedDict({'weights': tensor([0.3795]), 'bias': tensor([0.4346])})\n",
            "Epoch: 10200 | MAE Train Loss: 0.06438975036144257 | MAE Test Loss: 0.1505582630634308 \n",
            "OrderedDict({'weights': tensor([0.3797]), 'bias': tensor([0.4345])})\n",
            "Epoch: 10210 | MAE Train Loss: 0.06435538083314896 | MAE Test Loss: 0.15047213435173035 \n",
            "OrderedDict({'weights': tensor([0.3798]), 'bias': tensor([0.4345])})\n",
            "Epoch: 10220 | MAE Train Loss: 0.06432105600833893 | MAE Test Loss: 0.15039631724357605 \n",
            "OrderedDict({'weights': tensor([0.3800]), 'bias': tensor([0.4344])})\n",
            "Epoch: 10230 | MAE Train Loss: 0.06428670883178711 | MAE Test Loss: 0.15031364560127258 \n",
            "OrderedDict({'weights': tensor([0.3802]), 'bias': tensor([0.4343])})\n",
            "Epoch: 10240 | MAE Train Loss: 0.06425230205059052 | MAE Test Loss: 0.15023097395896912 \n",
            "OrderedDict({'weights': tensor([0.3804]), 'bias': tensor([0.4343])})\n",
            "Epoch: 10250 | MAE Train Loss: 0.0642179548740387 | MAE Test Loss: 0.15015172958374023 \n",
            "OrderedDict({'weights': tensor([0.3805]), 'bias': tensor([0.4342])})\n",
            "Epoch: 10260 | MAE Train Loss: 0.06418358534574509 | MAE Test Loss: 0.15007588267326355 \n",
            "OrderedDict({'weights': tensor([0.3807]), 'bias': tensor([0.4341])})\n",
            "Epoch: 10270 | MAE Train Loss: 0.06414927542209625 | MAE Test Loss: 0.14999321103096008 \n",
            "OrderedDict({'weights': tensor([0.3809]), 'bias': tensor([0.4340])})\n",
            "Epoch: 10280 | MAE Train Loss: 0.06411486864089966 | MAE Test Loss: 0.14991052448749542 \n",
            "OrderedDict({'weights': tensor([0.3810]), 'bias': tensor([0.4340])})\n",
            "Epoch: 10290 | MAE Train Loss: 0.06408051401376724 | MAE Test Loss: 0.14983467757701874 \n",
            "OrderedDict({'weights': tensor([0.3812]), 'bias': tensor([0.4339])})\n",
            "Epoch: 10300 | MAE Train Loss: 0.06404618918895721 | MAE Test Loss: 0.14975202083587646 \n",
            "OrderedDict({'weights': tensor([0.3814]), 'bias': tensor([0.4338])})\n",
            "Epoch: 10310 | MAE Train Loss: 0.06401178240776062 | MAE Test Loss: 0.1496693193912506 \n",
            "OrderedDict({'weights': tensor([0.3816]), 'bias': tensor([0.4338])})\n",
            "Epoch: 10320 | MAE Train Loss: 0.0639774352312088 | MAE Test Loss: 0.1495935022830963 \n",
            "OrderedDict({'weights': tensor([0.3817]), 'bias': tensor([0.4337])})\n",
            "Epoch: 10330 | MAE Train Loss: 0.06394310295581818 | MAE Test Loss: 0.14951083064079285 \n",
            "OrderedDict({'weights': tensor([0.3819]), 'bias': tensor([0.4336])})\n",
            "Epoch: 10340 | MAE Train Loss: 0.06390874087810516 | MAE Test Loss: 0.14943158626556396 \n",
            "OrderedDict({'weights': tensor([0.3821]), 'bias': tensor([0.4335])})\n",
            "Epoch: 10350 | MAE Train Loss: 0.06387435644865036 | MAE Test Loss: 0.1493488997220993 \n",
            "OrderedDict({'weights': tensor([0.3822]), 'bias': tensor([0.4335])})\n",
            "Epoch: 10360 | MAE Train Loss: 0.06383997201919556 | MAE Test Loss: 0.1492730677127838 \n",
            "OrderedDict({'weights': tensor([0.3824]), 'bias': tensor([0.4334])})\n",
            "Epoch: 10370 | MAE Train Loss: 0.06380565464496613 | MAE Test Loss: 0.14919038116931915 \n",
            "OrderedDict({'weights': tensor([0.3826]), 'bias': tensor([0.4333])})\n",
            "Epoch: 10380 | MAE Train Loss: 0.06377127021551132 | MAE Test Loss: 0.1491076946258545 \n",
            "OrderedDict({'weights': tensor([0.3827]), 'bias': tensor([0.4332])})\n",
            "Epoch: 10390 | MAE Train Loss: 0.06373688578605652 | MAE Test Loss: 0.1490318775177002 \n",
            "OrderedDict({'weights': tensor([0.3829]), 'bias': tensor([0.4332])})\n",
            "Epoch: 10400 | MAE Train Loss: 0.06370256841182709 | MAE Test Loss: 0.14894919097423553 \n",
            "OrderedDict({'weights': tensor([0.3831]), 'bias': tensor([0.4331])})\n",
            "Epoch: 10410 | MAE Train Loss: 0.06366818398237228 | MAE Test Loss: 0.14886650443077087 \n",
            "OrderedDict({'weights': tensor([0.3833]), 'bias': tensor([0.4330])})\n",
            "Epoch: 10420 | MAE Train Loss: 0.06363380700349808 | MAE Test Loss: 0.14879068732261658 \n",
            "OrderedDict({'weights': tensor([0.3834]), 'bias': tensor([0.4330])})\n",
            "Epoch: 10430 | MAE Train Loss: 0.06359943747520447 | MAE Test Loss: 0.14870458841323853 \n",
            "OrderedDict({'weights': tensor([0.3836]), 'bias': tensor([0.4329])})\n",
            "Epoch: 10440 | MAE Train Loss: 0.06356512010097504 | MAE Test Loss: 0.14862878620624542 \n",
            "OrderedDict({'weights': tensor([0.3838]), 'bias': tensor([0.4328])})\n",
            "Epoch: 10450 | MAE Train Loss: 0.06353072822093964 | MAE Test Loss: 0.14854952692985535 \n",
            "OrderedDict({'weights': tensor([0.3839]), 'bias': tensor([0.4327])})\n",
            "Epoch: 10460 | MAE Train Loss: 0.0634964108467102 | MAE Test Loss: 0.14846684038639069 \n",
            "OrderedDict({'weights': tensor([0.3841]), 'bias': tensor([0.4327])})\n",
            "Epoch: 10470 | MAE Train Loss: 0.0634620189666748 | MAE Test Loss: 0.14838413894176483 \n",
            "OrderedDict({'weights': tensor([0.3843]), 'bias': tensor([0.4326])})\n",
            "Epoch: 10480 | MAE Train Loss: 0.0634276494383812 | MAE Test Loss: 0.14830835163593292 \n",
            "OrderedDict({'weights': tensor([0.3845]), 'bias': tensor([0.4325])})\n",
            "Epoch: 10490 | MAE Train Loss: 0.0633932575583458 | MAE Test Loss: 0.14822223782539368 \n",
            "OrderedDict({'weights': tensor([0.3846]), 'bias': tensor([0.4325])})\n",
            "Epoch: 10500 | MAE Train Loss: 0.06335894763469696 | MAE Test Loss: 0.148146390914917 \n",
            "OrderedDict({'weights': tensor([0.3848]), 'bias': tensor([0.4324])})\n",
            "Epoch: 10510 | MAE Train Loss: 0.06332458555698395 | MAE Test Loss: 0.14806370437145233 \n",
            "OrderedDict({'weights': tensor([0.3850]), 'bias': tensor([0.4323])})\n",
            "Epoch: 10520 | MAE Train Loss: 0.06329017877578735 | MAE Test Loss: 0.14798101782798767 \n",
            "OrderedDict({'weights': tensor([0.3851]), 'bias': tensor([0.4322])})\n",
            "Epoch: 10530 | MAE Train Loss: 0.06325586885213852 | MAE Test Loss: 0.14790520071983337 \n",
            "OrderedDict({'weights': tensor([0.3853]), 'bias': tensor([0.4322])})\n",
            "Epoch: 10540 | MAE Train Loss: 0.06322149187326431 | MAE Test Loss: 0.1478225290775299 \n",
            "OrderedDict({'weights': tensor([0.3855]), 'bias': tensor([0.4321])})\n",
            "Epoch: 10550 | MAE Train Loss: 0.06318709254264832 | MAE Test Loss: 0.1477467119693756 \n",
            "OrderedDict({'weights': tensor([0.3857]), 'bias': tensor([0.4320])})\n",
            "Epoch: 10560 | MAE Train Loss: 0.06315279752016068 | MAE Test Loss: 0.14766399562358856 \n",
            "OrderedDict({'weights': tensor([0.3858]), 'bias': tensor([0.4320])})\n",
            "Epoch: 10570 | MAE Train Loss: 0.06311841309070587 | MAE Test Loss: 0.1475813239812851 \n",
            "OrderedDict({'weights': tensor([0.3860]), 'bias': tensor([0.4319])})\n",
            "Epoch: 10580 | MAE Train Loss: 0.06308406591415405 | MAE Test Loss: 0.1475020945072174 \n",
            "OrderedDict({'weights': tensor([0.3862]), 'bias': tensor([0.4318])})\n",
            "Epoch: 10590 | MAE Train Loss: 0.06304966658353806 | MAE Test Loss: 0.14741940796375275 \n",
            "OrderedDict({'weights': tensor([0.3863]), 'bias': tensor([0.4317])})\n",
            "Epoch: 10600 | MAE Train Loss: 0.06301532685756683 | MAE Test Loss: 0.14734359085559845 \n",
            "OrderedDict({'weights': tensor([0.3865]), 'bias': tensor([0.4317])})\n",
            "Epoch: 10610 | MAE Train Loss: 0.06298097223043442 | MAE Test Loss: 0.14726093411445618 \n",
            "OrderedDict({'weights': tensor([0.3867]), 'bias': tensor([0.4316])})\n",
            "Epoch: 10620 | MAE Train Loss: 0.06294658035039902 | MAE Test Loss: 0.14717820286750793 \n",
            "OrderedDict({'weights': tensor([0.3869]), 'bias': tensor([0.4315])})\n",
            "Epoch: 10630 | MAE Train Loss: 0.0629122406244278 | MAE Test Loss: 0.14710240066051483 \n",
            "OrderedDict({'weights': tensor([0.3870]), 'bias': tensor([0.4314])})\n",
            "Epoch: 10640 | MAE Train Loss: 0.06287790834903717 | MAE Test Loss: 0.14701971411705017 \n",
            "OrderedDict({'weights': tensor([0.3872]), 'bias': tensor([0.4314])})\n",
            "Epoch: 10650 | MAE Train Loss: 0.06284348666667938 | MAE Test Loss: 0.14693701267242432 \n",
            "OrderedDict({'weights': tensor([0.3874]), 'bias': tensor([0.4313])})\n",
            "Epoch: 10660 | MAE Train Loss: 0.06280916929244995 | MAE Test Loss: 0.1468612253665924 \n",
            "OrderedDict({'weights': tensor([0.3875]), 'bias': tensor([0.4312])})\n",
            "Epoch: 10670 | MAE Train Loss: 0.06277477741241455 | MAE Test Loss: 0.14678195118904114 \n",
            "OrderedDict({'weights': tensor([0.3877]), 'bias': tensor([0.4312])})\n",
            "Epoch: 10680 | MAE Train Loss: 0.06274040043354034 | MAE Test Loss: 0.1466958224773407 \n",
            "OrderedDict({'weights': tensor([0.3879]), 'bias': tensor([0.4311])})\n",
            "Epoch: 10690 | MAE Train Loss: 0.06270608305931091 | MAE Test Loss: 0.1466200053691864 \n",
            "OrderedDict({'weights': tensor([0.3880]), 'bias': tensor([0.4310])})\n",
            "Epoch: 10700 | MAE Train Loss: 0.0626717358827591 | MAE Test Loss: 0.14653733372688293 \n",
            "OrderedDict({'weights': tensor([0.3882]), 'bias': tensor([0.4309])})\n",
            "Epoch: 10710 | MAE Train Loss: 0.0626373216509819 | MAE Test Loss: 0.14645466208457947 \n",
            "OrderedDict({'weights': tensor([0.3884]), 'bias': tensor([0.4309])})\n",
            "Epoch: 10720 | MAE Train Loss: 0.06260298192501068 | MAE Test Loss: 0.1463753879070282 \n",
            "OrderedDict({'weights': tensor([0.3886]), 'bias': tensor([0.4308])})\n",
            "Epoch: 10730 | MAE Train Loss: 0.06256861239671707 | MAE Test Loss: 0.1462995707988739 \n",
            "OrderedDict({'weights': tensor([0.3887]), 'bias': tensor([0.4307])})\n",
            "Epoch: 10740 | MAE Train Loss: 0.06253429502248764 | MAE Test Loss: 0.14621689915657043 \n",
            "OrderedDict({'weights': tensor([0.3889]), 'bias': tensor([0.4307])})\n",
            "Epoch: 10750 | MAE Train Loss: 0.062499891966581345 | MAE Test Loss: 0.14613421261310577 \n",
            "OrderedDict({'weights': tensor([0.3891]), 'bias': tensor([0.4306])})\n",
            "Epoch: 10760 | MAE Train Loss: 0.06246553733944893 | MAE Test Loss: 0.1460583657026291 \n",
            "OrderedDict({'weights': tensor([0.3892]), 'bias': tensor([0.4305])})\n",
            "Epoch: 10770 | MAE Train Loss: 0.0624312087893486 | MAE Test Loss: 0.14597570896148682 \n",
            "OrderedDict({'weights': tensor([0.3894]), 'bias': tensor([0.4304])})\n",
            "Epoch: 10780 | MAE Train Loss: 0.062396805733442307 | MAE Test Loss: 0.14589300751686096 \n",
            "OrderedDict({'weights': tensor([0.3896]), 'bias': tensor([0.4304])})\n",
            "Epoch: 10790 | MAE Train Loss: 0.062362462282180786 | MAE Test Loss: 0.14581719040870667 \n",
            "OrderedDict({'weights': tensor([0.3898]), 'bias': tensor([0.4303])})\n",
            "Epoch: 10800 | MAE Train Loss: 0.06232813000679016 | MAE Test Loss: 0.1457345187664032 \n",
            "OrderedDict({'weights': tensor([0.3899]), 'bias': tensor([0.4302])})\n",
            "Epoch: 10810 | MAE Train Loss: 0.06229376792907715 | MAE Test Loss: 0.14565527439117432 \n",
            "OrderedDict({'weights': tensor([0.3901]), 'bias': tensor([0.4302])})\n",
            "Epoch: 10820 | MAE Train Loss: 0.062259383499622345 | MAE Test Loss: 0.14557258784770966 \n",
            "OrderedDict({'weights': tensor([0.3903]), 'bias': tensor([0.4301])})\n",
            "Epoch: 10830 | MAE Train Loss: 0.06222499534487724 | MAE Test Loss: 0.14549677073955536 \n",
            "OrderedDict({'weights': tensor([0.3904]), 'bias': tensor([0.4300])})\n",
            "Epoch: 10840 | MAE Train Loss: 0.06219068169593811 | MAE Test Loss: 0.1454140692949295 \n",
            "OrderedDict({'weights': tensor([0.3906]), 'bias': tensor([0.4299])})\n",
            "Epoch: 10850 | MAE Train Loss: 0.06215629726648331 | MAE Test Loss: 0.14533138275146484 \n",
            "OrderedDict({'weights': tensor([0.3908]), 'bias': tensor([0.4299])})\n",
            "Epoch: 10860 | MAE Train Loss: 0.062121909111738205 | MAE Test Loss: 0.14525556564331055 \n",
            "OrderedDict({'weights': tensor([0.3910]), 'bias': tensor([0.4298])})\n",
            "Epoch: 10870 | MAE Train Loss: 0.06208759546279907 | MAE Test Loss: 0.1451728790998459 \n",
            "OrderedDict({'weights': tensor([0.3911]), 'bias': tensor([0.4297])})\n",
            "Epoch: 10880 | MAE Train Loss: 0.06205321103334427 | MAE Test Loss: 0.14509019255638123 \n",
            "OrderedDict({'weights': tensor([0.3913]), 'bias': tensor([0.4297])})\n",
            "Epoch: 10890 | MAE Train Loss: 0.062018830329179764 | MAE Test Loss: 0.14501437544822693 \n",
            "OrderedDict({'weights': tensor([0.3915]), 'bias': tensor([0.4296])})\n",
            "Epoch: 10900 | MAE Train Loss: 0.061984460800886154 | MAE Test Loss: 0.14492827653884888 \n",
            "OrderedDict({'weights': tensor([0.3916]), 'bias': tensor([0.4295])})\n",
            "Epoch: 10910 | MAE Train Loss: 0.061950139701366425 | MAE Test Loss: 0.14485245943069458 \n",
            "OrderedDict({'weights': tensor([0.3918]), 'bias': tensor([0.4294])})\n",
            "Epoch: 10920 | MAE Train Loss: 0.061915747821331024 | MAE Test Loss: 0.1447732150554657 \n",
            "OrderedDict({'weights': tensor([0.3920]), 'bias': tensor([0.4294])})\n",
            "Epoch: 10930 | MAE Train Loss: 0.06188143417239189 | MAE Test Loss: 0.14469052851200104 \n",
            "OrderedDict({'weights': tensor([0.3921]), 'bias': tensor([0.4293])})\n",
            "Epoch: 10940 | MAE Train Loss: 0.06184704229235649 | MAE Test Loss: 0.14460782706737518 \n",
            "OrderedDict({'weights': tensor([0.3923]), 'bias': tensor([0.4292])})\n",
            "Epoch: 10950 | MAE Train Loss: 0.06181267648935318 | MAE Test Loss: 0.14453203976154327 \n",
            "OrderedDict({'weights': tensor([0.3925]), 'bias': tensor([0.4292])})\n",
            "Epoch: 10960 | MAE Train Loss: 0.06177828833460808 | MAE Test Loss: 0.14444592595100403 \n",
            "OrderedDict({'weights': tensor([0.3927]), 'bias': tensor([0.4291])})\n",
            "Epoch: 10970 | MAE Train Loss: 0.061743974685668945 | MAE Test Loss: 0.14437007904052734 \n",
            "OrderedDict({'weights': tensor([0.3928]), 'bias': tensor([0.4290])})\n",
            "Epoch: 10980 | MAE Train Loss: 0.061709605157375336 | MAE Test Loss: 0.14428739249706268 \n",
            "OrderedDict({'weights': tensor([0.3930]), 'bias': tensor([0.4289])})\n",
            "Epoch: 10990 | MAE Train Loss: 0.06167520210146904 | MAE Test Loss: 0.14420470595359802 \n",
            "OrderedDict({'weights': tensor([0.3932]), 'bias': tensor([0.4289])})\n",
            "Epoch: 11000 | MAE Train Loss: 0.061640895903110504 | MAE Test Loss: 0.14412888884544373 \n",
            "OrderedDict({'weights': tensor([0.3933]), 'bias': tensor([0.4288])})\n",
            "Epoch: 11010 | MAE Train Loss: 0.061606515198946 | MAE Test Loss: 0.14404621720314026 \n",
            "OrderedDict({'weights': tensor([0.3935]), 'bias': tensor([0.4287])})\n",
            "Epoch: 11020 | MAE Train Loss: 0.06157211586833 | MAE Test Loss: 0.14397040009498596 \n",
            "OrderedDict({'weights': tensor([0.3937]), 'bias': tensor([0.4286])})\n",
            "Epoch: 11030 | MAE Train Loss: 0.06153782084584236 | MAE Test Loss: 0.1438876837491989 \n",
            "OrderedDict({'weights': tensor([0.3939]), 'bias': tensor([0.4286])})\n",
            "Epoch: 11040 | MAE Train Loss: 0.06150343269109726 | MAE Test Loss: 0.14380502700805664 \n",
            "OrderedDict({'weights': tensor([0.3940]), 'bias': tensor([0.4285])})\n",
            "Epoch: 11050 | MAE Train Loss: 0.06146908923983574 | MAE Test Loss: 0.14372578263282776 \n",
            "OrderedDict({'weights': tensor([0.3942]), 'bias': tensor([0.4284])})\n",
            "Epoch: 11060 | MAE Train Loss: 0.06143469363451004 | MAE Test Loss: 0.1436430960893631 \n",
            "OrderedDict({'weights': tensor([0.3944]), 'bias': tensor([0.4284])})\n",
            "Epoch: 11070 | MAE Train Loss: 0.06140035390853882 | MAE Test Loss: 0.1435672491788864 \n",
            "OrderedDict({'weights': tensor([0.3945]), 'bias': tensor([0.4283])})\n",
            "Epoch: 11080 | MAE Train Loss: 0.0613659992814064 | MAE Test Loss: 0.14348459243774414 \n",
            "OrderedDict({'weights': tensor([0.3947]), 'bias': tensor([0.4282])})\n",
            "Epoch: 11090 | MAE Train Loss: 0.061331607401371 | MAE Test Loss: 0.14340190589427948 \n",
            "OrderedDict({'weights': tensor([0.3949]), 'bias': tensor([0.4282])})\n",
            "Epoch: 11100 | MAE Train Loss: 0.06129726022481918 | MAE Test Loss: 0.14332608878612518 \n",
            "OrderedDict({'weights': tensor([0.3951]), 'bias': tensor([0.4281])})\n",
            "Epoch: 11110 | MAE Train Loss: 0.06126292794942856 | MAE Test Loss: 0.14324340224266052 \n",
            "OrderedDict({'weights': tensor([0.3952]), 'bias': tensor([0.4280])})\n",
            "Epoch: 11120 | MAE Train Loss: 0.06122851371765137 | MAE Test Loss: 0.14316070079803467 \n",
            "OrderedDict({'weights': tensor([0.3954]), 'bias': tensor([0.4279])})\n",
            "Epoch: 11130 | MAE Train Loss: 0.06119419261813164 | MAE Test Loss: 0.14308491349220276 \n",
            "OrderedDict({'weights': tensor([0.3956]), 'bias': tensor([0.4279])})\n",
            "Epoch: 11140 | MAE Train Loss: 0.06115980073809624 | MAE Test Loss: 0.1430056393146515 \n",
            "OrderedDict({'weights': tensor([0.3957]), 'bias': tensor([0.4278])})\n",
            "Epoch: 11150 | MAE Train Loss: 0.06112542748451233 | MAE Test Loss: 0.14291951060295105 \n",
            "OrderedDict({'weights': tensor([0.3959]), 'bias': tensor([0.4277])})\n",
            "Epoch: 11160 | MAE Train Loss: 0.0610911063849926 | MAE Test Loss: 0.14284369349479675 \n",
            "OrderedDict({'weights': tensor([0.3961]), 'bias': tensor([0.4276])})\n",
            "Epoch: 11170 | MAE Train Loss: 0.061056751757860184 | MAE Test Loss: 0.1427610218524933 \n",
            "OrderedDict({'weights': tensor([0.3963]), 'bias': tensor([0.4276])})\n",
            "Epoch: 11180 | MAE Train Loss: 0.06102234870195389 | MAE Test Loss: 0.14267835021018982 \n",
            "OrderedDict({'weights': tensor([0.3964]), 'bias': tensor([0.4275])})\n",
            "Epoch: 11190 | MAE Train Loss: 0.06098800152540207 | MAE Test Loss: 0.14259907603263855 \n",
            "OrderedDict({'weights': tensor([0.3966]), 'bias': tensor([0.4274])})\n",
            "Epoch: 11200 | MAE Train Loss: 0.06095363572239876 | MAE Test Loss: 0.14252325892448425 \n",
            "OrderedDict({'weights': tensor([0.3968]), 'bias': tensor([0.4274])})\n",
            "Epoch: 11210 | MAE Train Loss: 0.060919322073459625 | MAE Test Loss: 0.1424405872821808 \n",
            "OrderedDict({'weights': tensor([0.3969]), 'bias': tensor([0.4273])})\n",
            "Epoch: 11220 | MAE Train Loss: 0.06088491529226303 | MAE Test Loss: 0.14235790073871613 \n",
            "OrderedDict({'weights': tensor([0.3971]), 'bias': tensor([0.4272])})\n",
            "Epoch: 11230 | MAE Train Loss: 0.060850560665130615 | MAE Test Loss: 0.14228205382823944 \n",
            "OrderedDict({'weights': tensor([0.3973]), 'bias': tensor([0.4271])})\n",
            "Epoch: 11240 | MAE Train Loss: 0.06081623584032059 | MAE Test Loss: 0.14219939708709717 \n",
            "OrderedDict({'weights': tensor([0.3974]), 'bias': tensor([0.4271])})\n",
            "Epoch: 11250 | MAE Train Loss: 0.06078182905912399 | MAE Test Loss: 0.1421166956424713 \n",
            "OrderedDict({'weights': tensor([0.3976]), 'bias': tensor([0.4270])})\n",
            "Epoch: 11260 | MAE Train Loss: 0.06074748560786247 | MAE Test Loss: 0.14204087853431702 \n",
            "OrderedDict({'weights': tensor([0.3978]), 'bias': tensor([0.4269])})\n",
            "Epoch: 11270 | MAE Train Loss: 0.06071315333247185 | MAE Test Loss: 0.14195820689201355 \n",
            "OrderedDict({'weights': tensor([0.3980]), 'bias': tensor([0.4269])})\n",
            "Epoch: 11280 | MAE Train Loss: 0.060678791254758835 | MAE Test Loss: 0.14187896251678467 \n",
            "OrderedDict({'weights': tensor([0.3981]), 'bias': tensor([0.4268])})\n",
            "Epoch: 11290 | MAE Train Loss: 0.06064440682530403 | MAE Test Loss: 0.14179627597332 \n",
            "OrderedDict({'weights': tensor([0.3983]), 'bias': tensor([0.4267])})\n",
            "Epoch: 11300 | MAE Train Loss: 0.060610007494688034 | MAE Test Loss: 0.1417204588651657 \n",
            "OrderedDict({'weights': tensor([0.3985]), 'bias': tensor([0.4266])})\n",
            "Epoch: 11310 | MAE Train Loss: 0.0605757050216198 | MAE Test Loss: 0.14163775742053986 \n",
            "OrderedDict({'weights': tensor([0.3986]), 'bias': tensor([0.4266])})\n",
            "Epoch: 11320 | MAE Train Loss: 0.06054132059216499 | MAE Test Loss: 0.1415550708770752 \n",
            "OrderedDict({'weights': tensor([0.3988]), 'bias': tensor([0.4265])})\n",
            "Epoch: 11330 | MAE Train Loss: 0.06050693988800049 | MAE Test Loss: 0.1414792537689209 \n",
            "OrderedDict({'weights': tensor([0.3990]), 'bias': tensor([0.4264])})\n",
            "Epoch: 11340 | MAE Train Loss: 0.06047261878848076 | MAE Test Loss: 0.14139656722545624 \n",
            "OrderedDict({'weights': tensor([0.3992]), 'bias': tensor([0.4264])})\n",
            "Epoch: 11350 | MAE Train Loss: 0.060438234359025955 | MAE Test Loss: 0.14131388068199158 \n",
            "OrderedDict({'weights': tensor([0.3993]), 'bias': tensor([0.4263])})\n",
            "Epoch: 11360 | MAE Train Loss: 0.06040385365486145 | MAE Test Loss: 0.14123806357383728 \n",
            "OrderedDict({'weights': tensor([0.3995]), 'bias': tensor([0.4262])})\n",
            "Epoch: 11370 | MAE Train Loss: 0.06036948412656784 | MAE Test Loss: 0.14115196466445923 \n",
            "OrderedDict({'weights': tensor([0.3997]), 'bias': tensor([0.4261])})\n",
            "Epoch: 11380 | MAE Train Loss: 0.06033516675233841 | MAE Test Loss: 0.14107614755630493 \n",
            "OrderedDict({'weights': tensor([0.3998]), 'bias': tensor([0.4261])})\n",
            "Epoch: 11390 | MAE Train Loss: 0.06030077487230301 | MAE Test Loss: 0.14099690318107605 \n",
            "OrderedDict({'weights': tensor([0.4000]), 'bias': tensor([0.4260])})\n",
            "Epoch: 11400 | MAE Train Loss: 0.06026645749807358 | MAE Test Loss: 0.1409142166376114 \n",
            "OrderedDict({'weights': tensor([0.4002]), 'bias': tensor([0.4259])})\n",
            "Epoch: 11410 | MAE Train Loss: 0.06023206561803818 | MAE Test Loss: 0.14083151519298553 \n",
            "OrderedDict({'weights': tensor([0.4004]), 'bias': tensor([0.4259])})\n",
            "Epoch: 11420 | MAE Train Loss: 0.060197699815034866 | MAE Test Loss: 0.14075572788715363 \n",
            "OrderedDict({'weights': tensor([0.4005]), 'bias': tensor([0.4258])})\n",
            "Epoch: 11430 | MAE Train Loss: 0.060163311660289764 | MAE Test Loss: 0.14066961407661438 \n",
            "OrderedDict({'weights': tensor([0.4007]), 'bias': tensor([0.4257])})\n",
            "Epoch: 11440 | MAE Train Loss: 0.06012899801135063 | MAE Test Loss: 0.1405937671661377 \n",
            "OrderedDict({'weights': tensor([0.4009]), 'bias': tensor([0.4256])})\n",
            "Epoch: 11450 | MAE Train Loss: 0.06009463220834732 | MAE Test Loss: 0.14051108062267303 \n",
            "OrderedDict({'weights': tensor([0.4010]), 'bias': tensor([0.4256])})\n",
            "Epoch: 11460 | MAE Train Loss: 0.060060225427150726 | MAE Test Loss: 0.14042839407920837 \n",
            "OrderedDict({'weights': tensor([0.4012]), 'bias': tensor([0.4255])})\n",
            "Epoch: 11470 | MAE Train Loss: 0.06002591922879219 | MAE Test Loss: 0.14035257697105408 \n",
            "OrderedDict({'weights': tensor([0.4014]), 'bias': tensor([0.4254])})\n",
            "Epoch: 11480 | MAE Train Loss: 0.059991538524627686 | MAE Test Loss: 0.1402699053287506 \n",
            "OrderedDict({'weights': tensor([0.4016]), 'bias': tensor([0.4253])})\n",
            "Epoch: 11490 | MAE Train Loss: 0.05995713919401169 | MAE Test Loss: 0.1401940882205963 \n",
            "OrderedDict({'weights': tensor([0.4017]), 'bias': tensor([0.4253])})\n",
            "Epoch: 11500 | MAE Train Loss: 0.05992284417152405 | MAE Test Loss: 0.14011137187480927 \n",
            "OrderedDict({'weights': tensor([0.4019]), 'bias': tensor([0.4252])})\n",
            "Epoch: 11510 | MAE Train Loss: 0.059888459742069244 | MAE Test Loss: 0.140028715133667 \n",
            "OrderedDict({'weights': tensor([0.4021]), 'bias': tensor([0.4251])})\n",
            "Epoch: 11520 | MAE Train Loss: 0.059854112565517426 | MAE Test Loss: 0.1399494707584381 \n",
            "OrderedDict({'weights': tensor([0.4022]), 'bias': tensor([0.4251])})\n",
            "Epoch: 11530 | MAE Train Loss: 0.05981971696019173 | MAE Test Loss: 0.13986678421497345 \n",
            "OrderedDict({'weights': tensor([0.4024]), 'bias': tensor([0.4250])})\n",
            "Epoch: 11540 | MAE Train Loss: 0.059785377234220505 | MAE Test Loss: 0.13979093730449677 \n",
            "OrderedDict({'weights': tensor([0.4026]), 'bias': tensor([0.4249])})\n",
            "Epoch: 11550 | MAE Train Loss: 0.05975102260708809 | MAE Test Loss: 0.1397082805633545 \n",
            "OrderedDict({'weights': tensor([0.4027]), 'bias': tensor([0.4248])})\n",
            "Epoch: 11560 | MAE Train Loss: 0.05971663072705269 | MAE Test Loss: 0.13962559401988983 \n",
            "OrderedDict({'weights': tensor([0.4029]), 'bias': tensor([0.4248])})\n",
            "Epoch: 11570 | MAE Train Loss: 0.05968228727579117 | MAE Test Loss: 0.13954977691173553 \n",
            "OrderedDict({'weights': tensor([0.4031]), 'bias': tensor([0.4247])})\n",
            "Epoch: 11580 | MAE Train Loss: 0.05964795500040054 | MAE Test Loss: 0.13946709036827087 \n",
            "OrderedDict({'weights': tensor([0.4033]), 'bias': tensor([0.4246])})\n",
            "Epoch: 11590 | MAE Train Loss: 0.059613537043333054 | MAE Test Loss: 0.13938438892364502 \n",
            "OrderedDict({'weights': tensor([0.4034]), 'bias': tensor([0.4246])})\n",
            "Epoch: 11600 | MAE Train Loss: 0.059579215943813324 | MAE Test Loss: 0.1393086016178131 \n",
            "OrderedDict({'weights': tensor([0.4036]), 'bias': tensor([0.4245])})\n",
            "Epoch: 11610 | MAE Train Loss: 0.059544824063777924 | MAE Test Loss: 0.13922932744026184 \n",
            "OrderedDict({'weights': tensor([0.4038]), 'bias': tensor([0.4244])})\n",
            "Epoch: 11620 | MAE Train Loss: 0.059510450810194016 | MAE Test Loss: 0.1391431987285614 \n",
            "OrderedDict({'weights': tensor([0.4039]), 'bias': tensor([0.4243])})\n",
            "Epoch: 11630 | MAE Train Loss: 0.059476129710674286 | MAE Test Loss: 0.1390673816204071 \n",
            "OrderedDict({'weights': tensor([0.4041]), 'bias': tensor([0.4243])})\n",
            "Epoch: 11640 | MAE Train Loss: 0.05944177508354187 | MAE Test Loss: 0.13898470997810364 \n",
            "OrderedDict({'weights': tensor([0.4043]), 'bias': tensor([0.4242])})\n",
            "Epoch: 11650 | MAE Train Loss: 0.059407372027635574 | MAE Test Loss: 0.13890203833580017 \n",
            "OrderedDict({'weights': tensor([0.4045]), 'bias': tensor([0.4241])})\n",
            "Epoch: 11660 | MAE Train Loss: 0.059373028576374054 | MAE Test Loss: 0.1388227641582489 \n",
            "OrderedDict({'weights': tensor([0.4046]), 'bias': tensor([0.4241])})\n",
            "Epoch: 11670 | MAE Train Loss: 0.059338659048080444 | MAE Test Loss: 0.1387469470500946 \n",
            "OrderedDict({'weights': tensor([0.4048]), 'bias': tensor([0.4240])})\n",
            "Epoch: 11680 | MAE Train Loss: 0.05930434539914131 | MAE Test Loss: 0.13866427540779114 \n",
            "OrderedDict({'weights': tensor([0.4050]), 'bias': tensor([0.4239])})\n",
            "Epoch: 11690 | MAE Train Loss: 0.059269942343235016 | MAE Test Loss: 0.13858158886432648 \n",
            "OrderedDict({'weights': tensor([0.4051]), 'bias': tensor([0.4238])})\n",
            "Epoch: 11700 | MAE Train Loss: 0.0592355839908123 | MAE Test Loss: 0.1385057419538498 \n",
            "OrderedDict({'weights': tensor([0.4053]), 'bias': tensor([0.4238])})\n",
            "Epoch: 11710 | MAE Train Loss: 0.059201259166002274 | MAE Test Loss: 0.13842308521270752 \n",
            "OrderedDict({'weights': tensor([0.4055]), 'bias': tensor([0.4237])})\n",
            "Epoch: 11720 | MAE Train Loss: 0.05916685611009598 | MAE Test Loss: 0.13834038376808167 \n",
            "OrderedDict({'weights': tensor([0.4057]), 'bias': tensor([0.4236])})\n",
            "Epoch: 11730 | MAE Train Loss: 0.05913250893354416 | MAE Test Loss: 0.13826456665992737 \n",
            "OrderedDict({'weights': tensor([0.4058]), 'bias': tensor([0.4236])})\n",
            "Epoch: 11740 | MAE Train Loss: 0.059098176658153534 | MAE Test Loss: 0.1381818950176239 \n",
            "OrderedDict({'weights': tensor([0.4060]), 'bias': tensor([0.4235])})\n",
            "Epoch: 11750 | MAE Train Loss: 0.05906381458044052 | MAE Test Loss: 0.13810265064239502 \n",
            "OrderedDict({'weights': tensor([0.4062]), 'bias': tensor([0.4234])})\n",
            "Epoch: 11760 | MAE Train Loss: 0.05902943015098572 | MAE Test Loss: 0.13801996409893036 \n",
            "OrderedDict({'weights': tensor([0.4063]), 'bias': tensor([0.4233])})\n",
            "Epoch: 11770 | MAE Train Loss: 0.05899503082036972 | MAE Test Loss: 0.13794414699077606 \n",
            "OrderedDict({'weights': tensor([0.4065]), 'bias': tensor([0.4233])})\n",
            "Epoch: 11780 | MAE Train Loss: 0.05896072834730148 | MAE Test Loss: 0.1378614455461502 \n",
            "OrderedDict({'weights': tensor([0.4067]), 'bias': tensor([0.4232])})\n",
            "Epoch: 11790 | MAE Train Loss: 0.05892634391784668 | MAE Test Loss: 0.13777875900268555 \n",
            "OrderedDict({'weights': tensor([0.4069]), 'bias': tensor([0.4231])})\n",
            "Epoch: 11800 | MAE Train Loss: 0.058891963213682175 | MAE Test Loss: 0.13770294189453125 \n",
            "OrderedDict({'weights': tensor([0.4070]), 'bias': tensor([0.4230])})\n",
            "Epoch: 11810 | MAE Train Loss: 0.058857642114162445 | MAE Test Loss: 0.1376202553510666 \n",
            "OrderedDict({'weights': tensor([0.4072]), 'bias': tensor([0.4230])})\n",
            "Epoch: 11820 | MAE Train Loss: 0.05882325768470764 | MAE Test Loss: 0.13753756880760193 \n",
            "OrderedDict({'weights': tensor([0.4074]), 'bias': tensor([0.4229])})\n",
            "Epoch: 11830 | MAE Train Loss: 0.05878887698054314 | MAE Test Loss: 0.13746175169944763 \n",
            "OrderedDict({'weights': tensor([0.4075]), 'bias': tensor([0.4228])})\n",
            "Epoch: 11840 | MAE Train Loss: 0.058754511177539825 | MAE Test Loss: 0.13737565279006958 \n",
            "OrderedDict({'weights': tensor([0.4077]), 'bias': tensor([0.4228])})\n",
            "Epoch: 11850 | MAE Train Loss: 0.058720190078020096 | MAE Test Loss: 0.13729983568191528 \n",
            "OrderedDict({'weights': tensor([0.4079]), 'bias': tensor([0.4227])})\n",
            "Epoch: 11860 | MAE Train Loss: 0.058685798197984695 | MAE Test Loss: 0.1372205913066864 \n",
            "OrderedDict({'weights': tensor([0.4080]), 'bias': tensor([0.4226])})\n",
            "Epoch: 11870 | MAE Train Loss: 0.05865148454904556 | MAE Test Loss: 0.13713790476322174 \n",
            "OrderedDict({'weights': tensor([0.4082]), 'bias': tensor([0.4225])})\n",
            "Epoch: 11880 | MAE Train Loss: 0.05861709266901016 | MAE Test Loss: 0.1370552033185959 \n",
            "OrderedDict({'weights': tensor([0.4084]), 'bias': tensor([0.4225])})\n",
            "Epoch: 11890 | MAE Train Loss: 0.058582715690135956 | MAE Test Loss: 0.13697941601276398 \n",
            "OrderedDict({'weights': tensor([0.4086]), 'bias': tensor([0.4224])})\n",
            "Epoch: 11900 | MAE Train Loss: 0.05854833871126175 | MAE Test Loss: 0.13689330220222473 \n",
            "OrderedDict({'weights': tensor([0.4087]), 'bias': tensor([0.4223])})\n",
            "Epoch: 11910 | MAE Train Loss: 0.05851402133703232 | MAE Test Loss: 0.13681745529174805 \n",
            "OrderedDict({'weights': tensor([0.4089]), 'bias': tensor([0.4223])})\n",
            "Epoch: 11920 | MAE Train Loss: 0.05847965553402901 | MAE Test Loss: 0.1367347687482834 \n",
            "OrderedDict({'weights': tensor([0.4091]), 'bias': tensor([0.4222])})\n",
            "Epoch: 11930 | MAE Train Loss: 0.05844525247812271 | MAE Test Loss: 0.13665208220481873 \n",
            "OrderedDict({'weights': tensor([0.4092]), 'bias': tensor([0.4221])})\n",
            "Epoch: 11940 | MAE Train Loss: 0.05841094255447388 | MAE Test Loss: 0.13657626509666443 \n",
            "OrderedDict({'weights': tensor([0.4094]), 'bias': tensor([0.4220])})\n",
            "Epoch: 11950 | MAE Train Loss: 0.05837656930088997 | MAE Test Loss: 0.13649359345436096 \n",
            "OrderedDict({'weights': tensor([0.4096]), 'bias': tensor([0.4220])})\n",
            "Epoch: 11960 | MAE Train Loss: 0.05834216624498367 | MAE Test Loss: 0.13641777634620667 \n",
            "OrderedDict({'weights': tensor([0.4098]), 'bias': tensor([0.4219])})\n",
            "Epoch: 11970 | MAE Train Loss: 0.058307867497205734 | MAE Test Loss: 0.13633506000041962 \n",
            "OrderedDict({'weights': tensor([0.4099]), 'bias': tensor([0.4218])})\n",
            "Epoch: 11980 | MAE Train Loss: 0.05827348306775093 | MAE Test Loss: 0.13625240325927734 \n",
            "OrderedDict({'weights': tensor([0.4101]), 'bias': tensor([0.4218])})\n",
            "Epoch: 11990 | MAE Train Loss: 0.05823913961648941 | MAE Test Loss: 0.13617315888404846 \n",
            "OrderedDict({'weights': tensor([0.4103]), 'bias': tensor([0.4217])})\n",
            "Epoch: 12000 | MAE Train Loss: 0.05820474028587341 | MAE Test Loss: 0.1360904723405838 \n",
            "OrderedDict({'weights': tensor([0.4104]), 'bias': tensor([0.4216])})\n",
            "Epoch: 12010 | MAE Train Loss: 0.05817040055990219 | MAE Test Loss: 0.13601462543010712 \n",
            "OrderedDict({'weights': tensor([0.4106]), 'bias': tensor([0.4215])})\n",
            "Epoch: 12020 | MAE Train Loss: 0.058136045932769775 | MAE Test Loss: 0.13593196868896484 \n",
            "OrderedDict({'weights': tensor([0.4108]), 'bias': tensor([0.4215])})\n",
            "Epoch: 12030 | MAE Train Loss: 0.05810164660215378 | MAE Test Loss: 0.13584928214550018 \n",
            "OrderedDict({'weights': tensor([0.4110]), 'bias': tensor([0.4214])})\n",
            "Epoch: 12040 | MAE Train Loss: 0.058067310601472855 | MAE Test Loss: 0.1357734650373459 \n",
            "OrderedDict({'weights': tensor([0.4111]), 'bias': tensor([0.4213])})\n",
            "Epoch: 12050 | MAE Train Loss: 0.05803297832608223 | MAE Test Loss: 0.13569077849388123 \n",
            "OrderedDict({'weights': tensor([0.4113]), 'bias': tensor([0.4213])})\n",
            "Epoch: 12060 | MAE Train Loss: 0.05799856036901474 | MAE Test Loss: 0.13560807704925537 \n",
            "OrderedDict({'weights': tensor([0.4115]), 'bias': tensor([0.4212])})\n",
            "Epoch: 12070 | MAE Train Loss: 0.05796424299478531 | MAE Test Loss: 0.13553228974342346 \n",
            "OrderedDict({'weights': tensor([0.4116]), 'bias': tensor([0.4211])})\n",
            "Epoch: 12080 | MAE Train Loss: 0.05792985111474991 | MAE Test Loss: 0.1354530155658722 \n",
            "OrderedDict({'weights': tensor([0.4118]), 'bias': tensor([0.4210])})\n",
            "Epoch: 12090 | MAE Train Loss: 0.0578954741358757 | MAE Test Loss: 0.13536688685417175 \n",
            "OrderedDict({'weights': tensor([0.4120]), 'bias': tensor([0.4210])})\n",
            "Epoch: 12100 | MAE Train Loss: 0.05786115676164627 | MAE Test Loss: 0.13529106974601746 \n",
            "OrderedDict({'weights': tensor([0.4122]), 'bias': tensor([0.4209])})\n",
            "Epoch: 12110 | MAE Train Loss: 0.057826798409223557 | MAE Test Loss: 0.135208398103714 \n",
            "OrderedDict({'weights': tensor([0.4123]), 'bias': tensor([0.4208])})\n",
            "Epoch: 12120 | MAE Train Loss: 0.05779239535331726 | MAE Test Loss: 0.13512572646141052 \n",
            "OrderedDict({'weights': tensor([0.4125]), 'bias': tensor([0.4208])})\n",
            "Epoch: 12130 | MAE Train Loss: 0.05775805190205574 | MAE Test Loss: 0.13504645228385925 \n",
            "OrderedDict({'weights': tensor([0.4127]), 'bias': tensor([0.4207])})\n",
            "Epoch: 12140 | MAE Train Loss: 0.05772368237376213 | MAE Test Loss: 0.13497063517570496 \n",
            "OrderedDict({'weights': tensor([0.4128]), 'bias': tensor([0.4206])})\n",
            "Epoch: 12150 | MAE Train Loss: 0.057689368724823 | MAE Test Loss: 0.1348879635334015 \n",
            "OrderedDict({'weights': tensor([0.4130]), 'bias': tensor([0.4205])})\n",
            "Epoch: 12160 | MAE Train Loss: 0.0576549656689167 | MAE Test Loss: 0.13480527698993683 \n",
            "OrderedDict({'weights': tensor([0.4132]), 'bias': tensor([0.4205])})\n",
            "Epoch: 12170 | MAE Train Loss: 0.05762060731649399 | MAE Test Loss: 0.13472943007946014 \n",
            "OrderedDict({'weights': tensor([0.4133]), 'bias': tensor([0.4204])})\n",
            "Epoch: 12180 | MAE Train Loss: 0.05758628249168396 | MAE Test Loss: 0.13464677333831787 \n",
            "OrderedDict({'weights': tensor([0.4135]), 'bias': tensor([0.4203])})\n",
            "Epoch: 12190 | MAE Train Loss: 0.057551879435777664 | MAE Test Loss: 0.13456407189369202 \n",
            "OrderedDict({'weights': tensor([0.4137]), 'bias': tensor([0.4203])})\n",
            "Epoch: 12200 | MAE Train Loss: 0.057517535984516144 | MAE Test Loss: 0.13448825478553772 \n",
            "OrderedDict({'weights': tensor([0.4139]), 'bias': tensor([0.4202])})\n",
            "Epoch: 12210 | MAE Train Loss: 0.05748320370912552 | MAE Test Loss: 0.13440558314323425 \n",
            "OrderedDict({'weights': tensor([0.4140]), 'bias': tensor([0.4201])})\n",
            "Epoch: 12220 | MAE Train Loss: 0.057448841631412506 | MAE Test Loss: 0.13432633876800537 \n",
            "OrderedDict({'weights': tensor([0.4142]), 'bias': tensor([0.4200])})\n",
            "Epoch: 12230 | MAE Train Loss: 0.057414453476667404 | MAE Test Loss: 0.1342436522245407 \n",
            "OrderedDict({'weights': tensor([0.4144]), 'bias': tensor([0.4200])})\n",
            "Epoch: 12240 | MAE Train Loss: 0.057380057871341705 | MAE Test Loss: 0.1341678351163864 \n",
            "OrderedDict({'weights': tensor([0.4145]), 'bias': tensor([0.4199])})\n",
            "Epoch: 12250 | MAE Train Loss: 0.05734575539827347 | MAE Test Loss: 0.13408513367176056 \n",
            "OrderedDict({'weights': tensor([0.4147]), 'bias': tensor([0.4198])})\n",
            "Epoch: 12260 | MAE Train Loss: 0.057311367243528366 | MAE Test Loss: 0.1340024471282959 \n",
            "OrderedDict({'weights': tensor([0.4149]), 'bias': tensor([0.4197])})\n",
            "Epoch: 12270 | MAE Train Loss: 0.05727698653936386 | MAE Test Loss: 0.1339266300201416 \n",
            "OrderedDict({'weights': tensor([0.4151]), 'bias': tensor([0.4197])})\n",
            "Epoch: 12280 | MAE Train Loss: 0.05724266916513443 | MAE Test Loss: 0.13384394347667694 \n",
            "OrderedDict({'weights': tensor([0.4152]), 'bias': tensor([0.4196])})\n",
            "Epoch: 12290 | MAE Train Loss: 0.05720828101038933 | MAE Test Loss: 0.13376125693321228 \n",
            "OrderedDict({'weights': tensor([0.4154]), 'bias': tensor([0.4195])})\n",
            "Epoch: 12300 | MAE Train Loss: 0.05717390030622482 | MAE Test Loss: 0.13368543982505798 \n",
            "OrderedDict({'weights': tensor([0.4156]), 'bias': tensor([0.4195])})\n",
            "Epoch: 12310 | MAE Train Loss: 0.05713953450322151 | MAE Test Loss: 0.13359934091567993 \n",
            "OrderedDict({'weights': tensor([0.4157]), 'bias': tensor([0.4194])})\n",
            "Epoch: 12320 | MAE Train Loss: 0.05710521340370178 | MAE Test Loss: 0.13352352380752563 \n",
            "OrderedDict({'weights': tensor([0.4159]), 'bias': tensor([0.4193])})\n",
            "Epoch: 12330 | MAE Train Loss: 0.05707082897424698 | MAE Test Loss: 0.13344427943229675 \n",
            "OrderedDict({'weights': tensor([0.4161]), 'bias': tensor([0.4192])})\n",
            "Epoch: 12340 | MAE Train Loss: 0.05703651160001755 | MAE Test Loss: 0.1333615928888321 \n",
            "OrderedDict({'weights': tensor([0.4163]), 'bias': tensor([0.4192])})\n",
            "Epoch: 12350 | MAE Train Loss: 0.05700210854411125 | MAE Test Loss: 0.13327889144420624 \n",
            "OrderedDict({'weights': tensor([0.4164]), 'bias': tensor([0.4191])})\n",
            "Epoch: 12360 | MAE Train Loss: 0.05696774274110794 | MAE Test Loss: 0.13320310413837433 \n",
            "OrderedDict({'weights': tensor([0.4166]), 'bias': tensor([0.4190])})\n",
            "Epoch: 12370 | MAE Train Loss: 0.056933362036943436 | MAE Test Loss: 0.13311699032783508 \n",
            "OrderedDict({'weights': tensor([0.4168]), 'bias': tensor([0.4190])})\n",
            "Epoch: 12380 | MAE Train Loss: 0.0568990483880043 | MAE Test Loss: 0.1330411434173584 \n",
            "OrderedDict({'weights': tensor([0.4169]), 'bias': tensor([0.4189])})\n",
            "Epoch: 12390 | MAE Train Loss: 0.05686467885971069 | MAE Test Loss: 0.13295845687389374 \n",
            "OrderedDict({'weights': tensor([0.4171]), 'bias': tensor([0.4188])})\n",
            "Epoch: 12400 | MAE Train Loss: 0.0568302758038044 | MAE Test Loss: 0.13287577033042908 \n",
            "OrderedDict({'weights': tensor([0.4173]), 'bias': tensor([0.4187])})\n",
            "Epoch: 12410 | MAE Train Loss: 0.05679596588015556 | MAE Test Loss: 0.13279995322227478 \n",
            "OrderedDict({'weights': tensor([0.4174]), 'bias': tensor([0.4187])})\n",
            "Epoch: 12420 | MAE Train Loss: 0.056761592626571655 | MAE Test Loss: 0.1327172815799713 \n",
            "OrderedDict({'weights': tensor([0.4176]), 'bias': tensor([0.4186])})\n",
            "Epoch: 12430 | MAE Train Loss: 0.05672718957066536 | MAE Test Loss: 0.13264146447181702 \n",
            "OrderedDict({'weights': tensor([0.4178]), 'bias': tensor([0.4185])})\n",
            "Epoch: 12440 | MAE Train Loss: 0.05669288709759712 | MAE Test Loss: 0.13255874812602997 \n",
            "OrderedDict({'weights': tensor([0.4180]), 'bias': tensor([0.4185])})\n",
            "Epoch: 12450 | MAE Train Loss: 0.05665850639343262 | MAE Test Loss: 0.1324760913848877 \n",
            "OrderedDict({'weights': tensor([0.4181]), 'bias': tensor([0.4184])})\n",
            "Epoch: 12460 | MAE Train Loss: 0.0566241629421711 | MAE Test Loss: 0.1323968470096588 \n",
            "OrderedDict({'weights': tensor([0.4183]), 'bias': tensor([0.4183])})\n",
            "Epoch: 12470 | MAE Train Loss: 0.0565897636115551 | MAE Test Loss: 0.13231416046619415 \n",
            "OrderedDict({'weights': tensor([0.4185]), 'bias': tensor([0.4182])})\n",
            "Epoch: 12480 | MAE Train Loss: 0.056555427610874176 | MAE Test Loss: 0.13223831355571747 \n",
            "OrderedDict({'weights': tensor([0.4186]), 'bias': tensor([0.4182])})\n",
            "Epoch: 12490 | MAE Train Loss: 0.05652106925845146 | MAE Test Loss: 0.1321556568145752 \n",
            "OrderedDict({'weights': tensor([0.4188]), 'bias': tensor([0.4181])})\n",
            "Epoch: 12500 | MAE Train Loss: 0.05648667365312576 | MAE Test Loss: 0.13207297027111053 \n",
            "OrderedDict({'weights': tensor([0.4190]), 'bias': tensor([0.4180])})\n",
            "Epoch: 12510 | MAE Train Loss: 0.05645233392715454 | MAE Test Loss: 0.13199715316295624 \n",
            "OrderedDict({'weights': tensor([0.4192]), 'bias': tensor([0.4180])})\n",
            "Epoch: 12520 | MAE Train Loss: 0.056418001651763916 | MAE Test Loss: 0.13191446661949158 \n",
            "OrderedDict({'weights': tensor([0.4193]), 'bias': tensor([0.4179])})\n",
            "Epoch: 12530 | MAE Train Loss: 0.056383587419986725 | MAE Test Loss: 0.13183176517486572 \n",
            "OrderedDict({'weights': tensor([0.4195]), 'bias': tensor([0.4178])})\n",
            "Epoch: 12540 | MAE Train Loss: 0.056349266320466995 | MAE Test Loss: 0.1317559778690338 \n",
            "OrderedDict({'weights': tensor([0.4197]), 'bias': tensor([0.4177])})\n",
            "Epoch: 12550 | MAE Train Loss: 0.056314874440431595 | MAE Test Loss: 0.13167670369148254 \n",
            "OrderedDict({'weights': tensor([0.4198]), 'bias': tensor([0.4177])})\n",
            "Epoch: 12560 | MAE Train Loss: 0.05628050118684769 | MAE Test Loss: 0.1315905749797821 \n",
            "OrderedDict({'weights': tensor([0.4200]), 'bias': tensor([0.4176])})\n",
            "Epoch: 12570 | MAE Train Loss: 0.056246183812618256 | MAE Test Loss: 0.1315147578716278 \n",
            "OrderedDict({'weights': tensor([0.4202]), 'bias': tensor([0.4175])})\n",
            "Epoch: 12580 | MAE Train Loss: 0.05621182173490524 | MAE Test Loss: 0.13143208622932434 \n",
            "OrderedDict({'weights': tensor([0.4204]), 'bias': tensor([0.4175])})\n",
            "Epoch: 12590 | MAE Train Loss: 0.05617741495370865 | MAE Test Loss: 0.13134941458702087 \n",
            "OrderedDict({'weights': tensor([0.4205]), 'bias': tensor([0.4174])})\n",
            "Epoch: 12600 | MAE Train Loss: 0.05614307522773743 | MAE Test Loss: 0.1312701404094696 \n",
            "OrderedDict({'weights': tensor([0.4207]), 'bias': tensor([0.4173])})\n",
            "Epoch: 12610 | MAE Train Loss: 0.05610870569944382 | MAE Test Loss: 0.1311943233013153 \n",
            "OrderedDict({'weights': tensor([0.4209]), 'bias': tensor([0.4172])})\n",
            "Epoch: 12620 | MAE Train Loss: 0.056074392050504684 | MAE Test Loss: 0.13111165165901184 \n",
            "OrderedDict({'weights': tensor([0.4210]), 'bias': tensor([0.4172])})\n",
            "Epoch: 12630 | MAE Train Loss: 0.05603998899459839 | MAE Test Loss: 0.13102896511554718 \n",
            "OrderedDict({'weights': tensor([0.4212]), 'bias': tensor([0.4171])})\n",
            "Epoch: 12640 | MAE Train Loss: 0.05600563436746597 | MAE Test Loss: 0.1309531182050705 \n",
            "OrderedDict({'weights': tensor([0.4214]), 'bias': tensor([0.4170])})\n",
            "Epoch: 12650 | MAE Train Loss: 0.05597130209207535 | MAE Test Loss: 0.13087046146392822 \n",
            "OrderedDict({'weights': tensor([0.4216]), 'bias': tensor([0.4169])})\n",
            "Epoch: 12660 | MAE Train Loss: 0.05593690276145935 | MAE Test Loss: 0.13078776001930237 \n",
            "OrderedDict({'weights': tensor([0.4217]), 'bias': tensor([0.4169])})\n",
            "Epoch: 12670 | MAE Train Loss: 0.05590255931019783 | MAE Test Loss: 0.13071194291114807 \n",
            "OrderedDict({'weights': tensor([0.4219]), 'bias': tensor([0.4168])})\n",
            "Epoch: 12680 | MAE Train Loss: 0.05586821958422661 | MAE Test Loss: 0.1306292712688446 \n",
            "OrderedDict({'weights': tensor([0.4221]), 'bias': tensor([0.4167])})\n",
            "Epoch: 12690 | MAE Train Loss: 0.05583386495709419 | MAE Test Loss: 0.13055002689361572 \n",
            "OrderedDict({'weights': tensor([0.4222]), 'bias': tensor([0.4167])})\n",
            "Epoch: 12700 | MAE Train Loss: 0.05579947307705879 | MAE Test Loss: 0.13046734035015106 \n",
            "OrderedDict({'weights': tensor([0.4224]), 'bias': tensor([0.4166])})\n",
            "Epoch: 12710 | MAE Train Loss: 0.05576508492231369 | MAE Test Loss: 0.13039152324199677 \n",
            "OrderedDict({'weights': tensor([0.4226]), 'bias': tensor([0.4165])})\n",
            "Epoch: 12720 | MAE Train Loss: 0.055730778723955154 | MAE Test Loss: 0.1303088217973709 \n",
            "OrderedDict({'weights': tensor([0.4227]), 'bias': tensor([0.4164])})\n",
            "Epoch: 12730 | MAE Train Loss: 0.05569639056921005 | MAE Test Loss: 0.13022613525390625 \n",
            "OrderedDict({'weights': tensor([0.4229]), 'bias': tensor([0.4164])})\n",
            "Epoch: 12740 | MAE Train Loss: 0.055662013590335846 | MAE Test Loss: 0.13015031814575195 \n",
            "OrderedDict({'weights': tensor([0.4231]), 'bias': tensor([0.4163])})\n",
            "Epoch: 12750 | MAE Train Loss: 0.055627692490816116 | MAE Test Loss: 0.1300676316022873 \n",
            "OrderedDict({'weights': tensor([0.4233]), 'bias': tensor([0.4162])})\n",
            "Epoch: 12760 | MAE Train Loss: 0.055593304336071014 | MAE Test Loss: 0.12998494505882263 \n",
            "OrderedDict({'weights': tensor([0.4234]), 'bias': tensor([0.4162])})\n",
            "Epoch: 12770 | MAE Train Loss: 0.05555892735719681 | MAE Test Loss: 0.12990912795066833 \n",
            "OrderedDict({'weights': tensor([0.4236]), 'bias': tensor([0.4161])})\n",
            "Epoch: 12780 | MAE Train Loss: 0.0555245578289032 | MAE Test Loss: 0.12982302904129028 \n",
            "OrderedDict({'weights': tensor([0.4238]), 'bias': tensor([0.4160])})\n",
            "Epoch: 12790 | MAE Train Loss: 0.05549023300409317 | MAE Test Loss: 0.129747211933136 \n",
            "OrderedDict({'weights': tensor([0.4239]), 'bias': tensor([0.4159])})\n",
            "Epoch: 12800 | MAE Train Loss: 0.055455852299928665 | MAE Test Loss: 0.1296679675579071 \n",
            "OrderedDict({'weights': tensor([0.4241]), 'bias': tensor([0.4159])})\n",
            "Epoch: 12810 | MAE Train Loss: 0.05542153865098953 | MAE Test Loss: 0.12958528101444244 \n",
            "OrderedDict({'weights': tensor([0.4243]), 'bias': tensor([0.4158])})\n",
            "Epoch: 12820 | MAE Train Loss: 0.05538713186979294 | MAE Test Loss: 0.1295025795698166 \n",
            "OrderedDict({'weights': tensor([0.4245]), 'bias': tensor([0.4157])})\n",
            "Epoch: 12830 | MAE Train Loss: 0.05535276606678963 | MAE Test Loss: 0.12942679226398468 \n",
            "OrderedDict({'weights': tensor([0.4246]), 'bias': tensor([0.4157])})\n",
            "Epoch: 12840 | MAE Train Loss: 0.05531838536262512 | MAE Test Loss: 0.12934067845344543 \n",
            "OrderedDict({'weights': tensor([0.4248]), 'bias': tensor([0.4156])})\n",
            "Epoch: 12850 | MAE Train Loss: 0.05528407171368599 | MAE Test Loss: 0.12926483154296875 \n",
            "OrderedDict({'weights': tensor([0.4250]), 'bias': tensor([0.4155])})\n",
            "Epoch: 12860 | MAE Train Loss: 0.05524970218539238 | MAE Test Loss: 0.1291821449995041 \n",
            "OrderedDict({'weights': tensor([0.4251]), 'bias': tensor([0.4154])})\n",
            "Epoch: 12870 | MAE Train Loss: 0.055215299129486084 | MAE Test Loss: 0.12909945845603943 \n",
            "OrderedDict({'weights': tensor([0.4253]), 'bias': tensor([0.4154])})\n",
            "Epoch: 12880 | MAE Train Loss: 0.05518098920583725 | MAE Test Loss: 0.12902364134788513 \n",
            "OrderedDict({'weights': tensor([0.4255]), 'bias': tensor([0.4153])})\n",
            "Epoch: 12890 | MAE Train Loss: 0.05514661595225334 | MAE Test Loss: 0.12894096970558167 \n",
            "OrderedDict({'weights': tensor([0.4257]), 'bias': tensor([0.4152])})\n",
            "Epoch: 12900 | MAE Train Loss: 0.055112212896347046 | MAE Test Loss: 0.12886515259742737 \n",
            "OrderedDict({'weights': tensor([0.4258]), 'bias': tensor([0.4151])})\n",
            "Epoch: 12910 | MAE Train Loss: 0.05507791042327881 | MAE Test Loss: 0.12878243625164032 \n",
            "OrderedDict({'weights': tensor([0.4260]), 'bias': tensor([0.4151])})\n",
            "Epoch: 12920 | MAE Train Loss: 0.055043529719114304 | MAE Test Loss: 0.12869977951049805 \n",
            "OrderedDict({'weights': tensor([0.4262]), 'bias': tensor([0.4150])})\n",
            "Epoch: 12930 | MAE Train Loss: 0.05500918626785278 | MAE Test Loss: 0.12862053513526917 \n",
            "OrderedDict({'weights': tensor([0.4263]), 'bias': tensor([0.4149])})\n",
            "Epoch: 12940 | MAE Train Loss: 0.054974786937236786 | MAE Test Loss: 0.1285378485918045 \n",
            "OrderedDict({'weights': tensor([0.4265]), 'bias': tensor([0.4149])})\n",
            "Epoch: 12950 | MAE Train Loss: 0.05494045093655586 | MAE Test Loss: 0.12846200168132782 \n",
            "OrderedDict({'weights': tensor([0.4267]), 'bias': tensor([0.4148])})\n",
            "Epoch: 12960 | MAE Train Loss: 0.05490609258413315 | MAE Test Loss: 0.12837934494018555 \n",
            "OrderedDict({'weights': tensor([0.4269]), 'bias': tensor([0.4147])})\n",
            "Epoch: 12970 | MAE Train Loss: 0.05487169697880745 | MAE Test Loss: 0.1282966583967209 \n",
            "OrderedDict({'weights': tensor([0.4270]), 'bias': tensor([0.4147])})\n",
            "Epoch: 12980 | MAE Train Loss: 0.05483735725283623 | MAE Test Loss: 0.1282208412885666 \n",
            "OrderedDict({'weights': tensor([0.4272]), 'bias': tensor([0.4146])})\n",
            "Epoch: 12990 | MAE Train Loss: 0.0548030249774456 | MAE Test Loss: 0.12813815474510193 \n",
            "OrderedDict({'weights': tensor([0.4274]), 'bias': tensor([0.4145])})\n",
            "Epoch: 13000 | MAE Train Loss: 0.05476861074566841 | MAE Test Loss: 0.12805545330047607 \n",
            "OrderedDict({'weights': tensor([0.4275]), 'bias': tensor([0.4144])})\n",
            "Epoch: 13010 | MAE Train Loss: 0.05473428964614868 | MAE Test Loss: 0.12797966599464417 \n",
            "OrderedDict({'weights': tensor([0.4277]), 'bias': tensor([0.4144])})\n",
            "Epoch: 13020 | MAE Train Loss: 0.05469989776611328 | MAE Test Loss: 0.1279003918170929 \n",
            "OrderedDict({'weights': tensor([0.4279]), 'bias': tensor([0.4143])})\n",
            "Epoch: 13030 | MAE Train Loss: 0.05466552451252937 | MAE Test Loss: 0.12781426310539246 \n",
            "OrderedDict({'weights': tensor([0.4281]), 'bias': tensor([0.4142])})\n",
            "Epoch: 13040 | MAE Train Loss: 0.05463121086359024 | MAE Test Loss: 0.12773844599723816 \n",
            "OrderedDict({'weights': tensor([0.4282]), 'bias': tensor([0.4141])})\n",
            "Epoch: 13050 | MAE Train Loss: 0.05459684878587723 | MAE Test Loss: 0.1276557743549347 \n",
            "OrderedDict({'weights': tensor([0.4284]), 'bias': tensor([0.4141])})\n",
            "Epoch: 13060 | MAE Train Loss: 0.054562438279390335 | MAE Test Loss: 0.12757310271263123 \n",
            "OrderedDict({'weights': tensor([0.4286]), 'bias': tensor([0.4140])})\n",
            "Epoch: 13070 | MAE Train Loss: 0.05452809855341911 | MAE Test Loss: 0.12749382853507996 \n",
            "OrderedDict({'weights': tensor([0.4287]), 'bias': tensor([0.4139])})\n",
            "Epoch: 13080 | MAE Train Loss: 0.0544937327504158 | MAE Test Loss: 0.12741801142692566 \n",
            "OrderedDict({'weights': tensor([0.4289]), 'bias': tensor([0.4139])})\n",
            "Epoch: 13090 | MAE Train Loss: 0.05445941537618637 | MAE Test Loss: 0.1273353397846222 \n",
            "OrderedDict({'weights': tensor([0.4291]), 'bias': tensor([0.4138])})\n",
            "Epoch: 13100 | MAE Train Loss: 0.054425012320280075 | MAE Test Loss: 0.12725265324115753 \n",
            "OrderedDict({'weights': tensor([0.4292]), 'bias': tensor([0.4137])})\n",
            "Epoch: 13110 | MAE Train Loss: 0.05439066141843796 | MAE Test Loss: 0.12717683613300323 \n",
            "OrderedDict({'weights': tensor([0.4294]), 'bias': tensor([0.4136])})\n",
            "Epoch: 13120 | MAE Train Loss: 0.054356325417757034 | MAE Test Loss: 0.12709414958953857 \n",
            "OrderedDict({'weights': tensor([0.4296]), 'bias': tensor([0.4136])})\n",
            "Epoch: 13130 | MAE Train Loss: 0.05432192608714104 | MAE Test Loss: 0.12701144814491272 \n",
            "OrderedDict({'weights': tensor([0.4298]), 'bias': tensor([0.4135])})\n",
            "Epoch: 13140 | MAE Train Loss: 0.05428758263587952 | MAE Test Loss: 0.12693564593791962 \n",
            "OrderedDict({'weights': tensor([0.4299]), 'bias': tensor([0.4134])})\n",
            "Epoch: 13150 | MAE Train Loss: 0.05425325036048889 | MAE Test Loss: 0.12685295939445496 \n",
            "OrderedDict({'weights': tensor([0.4301]), 'bias': tensor([0.4134])})\n",
            "Epoch: 13160 | MAE Train Loss: 0.05421888828277588 | MAE Test Loss: 0.12677371501922607 \n",
            "OrderedDict({'weights': tensor([0.4303]), 'bias': tensor([0.4133])})\n",
            "Epoch: 13170 | MAE Train Loss: 0.05418449640274048 | MAE Test Loss: 0.12669101357460022 \n",
            "OrderedDict({'weights': tensor([0.4304]), 'bias': tensor([0.4132])})\n",
            "Epoch: 13180 | MAE Train Loss: 0.054150111973285675 | MAE Test Loss: 0.12661519646644592 \n",
            "OrderedDict({'weights': tensor([0.4306]), 'bias': tensor([0.4131])})\n",
            "Epoch: 13190 | MAE Train Loss: 0.05411580204963684 | MAE Test Loss: 0.12653250992298126 \n",
            "OrderedDict({'weights': tensor([0.4308]), 'bias': tensor([0.4131])})\n",
            "Epoch: 13200 | MAE Train Loss: 0.05408141762018204 | MAE Test Loss: 0.1264498233795166 \n",
            "OrderedDict({'weights': tensor([0.4310]), 'bias': tensor([0.4130])})\n",
            "Epoch: 13210 | MAE Train Loss: 0.05404703691601753 | MAE Test Loss: 0.1263740062713623 \n",
            "OrderedDict({'weights': tensor([0.4311]), 'bias': tensor([0.4129])})\n",
            "Epoch: 13220 | MAE Train Loss: 0.0540127158164978 | MAE Test Loss: 0.12629131972789764 \n",
            "OrderedDict({'weights': tensor([0.4313]), 'bias': tensor([0.4129])})\n",
            "Epoch: 13230 | MAE Train Loss: 0.053978331387043 | MAE Test Loss: 0.12620863318443298 \n",
            "OrderedDict({'weights': tensor([0.4315]), 'bias': tensor([0.4128])})\n",
            "Epoch: 13240 | MAE Train Loss: 0.053943950682878494 | MAE Test Loss: 0.1261328160762787 \n",
            "OrderedDict({'weights': tensor([0.4316]), 'bias': tensor([0.4127])})\n",
            "Epoch: 13250 | MAE Train Loss: 0.053909581154584885 | MAE Test Loss: 0.12604671716690063 \n",
            "OrderedDict({'weights': tensor([0.4318]), 'bias': tensor([0.4126])})\n",
            "Epoch: 13260 | MAE Train Loss: 0.05387525632977486 | MAE Test Loss: 0.12597090005874634 \n",
            "OrderedDict({'weights': tensor([0.4320]), 'bias': tensor([0.4126])})\n",
            "Epoch: 13270 | MAE Train Loss: 0.05384087562561035 | MAE Test Loss: 0.12589165568351746 \n",
            "OrderedDict({'weights': tensor([0.4322]), 'bias': tensor([0.4125])})\n",
            "Epoch: 13280 | MAE Train Loss: 0.05380656197667122 | MAE Test Loss: 0.1258089691400528 \n",
            "OrderedDict({'weights': tensor([0.4323]), 'bias': tensor([0.4124])})\n",
            "Epoch: 13290 | MAE Train Loss: 0.05377215892076492 | MAE Test Loss: 0.12572626769542694 \n",
            "OrderedDict({'weights': tensor([0.4325]), 'bias': tensor([0.4124])})\n",
            "Epoch: 13300 | MAE Train Loss: 0.053737789392471313 | MAE Test Loss: 0.12565048038959503 \n",
            "OrderedDict({'weights': tensor([0.4327]), 'bias': tensor([0.4123])})\n",
            "Epoch: 13310 | MAE Train Loss: 0.05370340868830681 | MAE Test Loss: 0.1255643665790558 \n",
            "OrderedDict({'weights': tensor([0.4328]), 'bias': tensor([0.4122])})\n",
            "Epoch: 13320 | MAE Train Loss: 0.05366910248994827 | MAE Test Loss: 0.1254885196685791 \n",
            "OrderedDict({'weights': tensor([0.4330]), 'bias': tensor([0.4121])})\n",
            "Epoch: 13330 | MAE Train Loss: 0.053634725511074066 | MAE Test Loss: 0.12540583312511444 \n",
            "OrderedDict({'weights': tensor([0.4332]), 'bias': tensor([0.4121])})\n",
            "Epoch: 13340 | MAE Train Loss: 0.05360032245516777 | MAE Test Loss: 0.12532314658164978 \n",
            "OrderedDict({'weights': tensor([0.4333]), 'bias': tensor([0.4120])})\n",
            "Epoch: 13350 | MAE Train Loss: 0.053566016256809235 | MAE Test Loss: 0.12524732947349548 \n",
            "OrderedDict({'weights': tensor([0.4335]), 'bias': tensor([0.4119])})\n",
            "Epoch: 13360 | MAE Train Loss: 0.053531646728515625 | MAE Test Loss: 0.12516465783119202 \n",
            "OrderedDict({'weights': tensor([0.4337]), 'bias': tensor([0.4119])})\n",
            "Epoch: 13370 | MAE Train Loss: 0.05349723622202873 | MAE Test Loss: 0.12508884072303772 \n",
            "OrderedDict({'weights': tensor([0.4339]), 'bias': tensor([0.4118])})\n",
            "Epoch: 13380 | MAE Train Loss: 0.053462933748960495 | MAE Test Loss: 0.12500612437725067 \n",
            "OrderedDict({'weights': tensor([0.4340]), 'bias': tensor([0.4117])})\n",
            "Epoch: 13390 | MAE Train Loss: 0.05342855304479599 | MAE Test Loss: 0.1249234676361084 \n",
            "OrderedDict({'weights': tensor([0.4342]), 'bias': tensor([0.4116])})\n",
            "Epoch: 13400 | MAE Train Loss: 0.05339420959353447 | MAE Test Loss: 0.12484421581029892 \n",
            "OrderedDict({'weights': tensor([0.4344]), 'bias': tensor([0.4116])})\n",
            "Epoch: 13410 | MAE Train Loss: 0.05335981398820877 | MAE Test Loss: 0.12476153671741486 \n",
            "OrderedDict({'weights': tensor([0.4345]), 'bias': tensor([0.4115])})\n",
            "Epoch: 13420 | MAE Train Loss: 0.05332547426223755 | MAE Test Loss: 0.12468568980693817 \n",
            "OrderedDict({'weights': tensor([0.4347]), 'bias': tensor([0.4114])})\n",
            "Epoch: 13430 | MAE Train Loss: 0.05329111963510513 | MAE Test Loss: 0.1246030330657959 \n",
            "OrderedDict({'weights': tensor([0.4349]), 'bias': tensor([0.4113])})\n",
            "Epoch: 13440 | MAE Train Loss: 0.053256720304489136 | MAE Test Loss: 0.12452032417058945 \n",
            "OrderedDict({'weights': tensor([0.4351]), 'bias': tensor([0.4113])})\n",
            "Epoch: 13450 | MAE Train Loss: 0.053222380578517914 | MAE Test Loss: 0.12444452941417694 \n",
            "OrderedDict({'weights': tensor([0.4352]), 'bias': tensor([0.4112])})\n",
            "Epoch: 13460 | MAE Train Loss: 0.05318804830312729 | MAE Test Loss: 0.12436182796955109 \n",
            "OrderedDict({'weights': tensor([0.4354]), 'bias': tensor([0.4111])})\n",
            "Epoch: 13470 | MAE Train Loss: 0.0531536340713501 | MAE Test Loss: 0.12427914142608643 \n",
            "OrderedDict({'weights': tensor([0.4356]), 'bias': tensor([0.4111])})\n",
            "Epoch: 13480 | MAE Train Loss: 0.05311930924654007 | MAE Test Loss: 0.12420334666967392 \n",
            "OrderedDict({'weights': tensor([0.4357]), 'bias': tensor([0.4110])})\n",
            "Epoch: 13490 | MAE Train Loss: 0.05308492109179497 | MAE Test Loss: 0.12412407249212265 \n",
            "OrderedDict({'weights': tensor([0.4359]), 'bias': tensor([0.4109])})\n",
            "Epoch: 13500 | MAE Train Loss: 0.05305054783821106 | MAE Test Loss: 0.1240379586815834 \n",
            "OrderedDict({'weights': tensor([0.4361]), 'bias': tensor([0.4108])})\n",
            "Epoch: 13510 | MAE Train Loss: 0.05301623418927193 | MAE Test Loss: 0.12396214157342911 \n",
            "OrderedDict({'weights': tensor([0.4363]), 'bias': tensor([0.4108])})\n",
            "Epoch: 13520 | MAE Train Loss: 0.052981872111558914 | MAE Test Loss: 0.12387945502996445 \n",
            "OrderedDict({'weights': tensor([0.4364]), 'bias': tensor([0.4107])})\n",
            "Epoch: 13530 | MAE Train Loss: 0.05294746160507202 | MAE Test Loss: 0.12379679828882217 \n",
            "OrderedDict({'weights': tensor([0.4366]), 'bias': tensor([0.4106])})\n",
            "Epoch: 13540 | MAE Train Loss: 0.0529131218791008 | MAE Test Loss: 0.1237175241112709 \n",
            "OrderedDict({'weights': tensor([0.4368]), 'bias': tensor([0.4106])})\n",
            "Epoch: 13550 | MAE Train Loss: 0.05287875607609749 | MAE Test Loss: 0.12364170700311661 \n",
            "OrderedDict({'weights': tensor([0.4369]), 'bias': tensor([0.4105])})\n",
            "Epoch: 13560 | MAE Train Loss: 0.052844442427158356 | MAE Test Loss: 0.12355902045965195 \n",
            "OrderedDict({'weights': tensor([0.4371]), 'bias': tensor([0.4104])})\n",
            "Epoch: 13570 | MAE Train Loss: 0.05281003564596176 | MAE Test Loss: 0.12347634136676788 \n",
            "OrderedDict({'weights': tensor([0.4373]), 'bias': tensor([0.4103])})\n",
            "Epoch: 13580 | MAE Train Loss: 0.05277568846940994 | MAE Test Loss: 0.12340052425861359 \n",
            "OrderedDict({'weights': tensor([0.4375]), 'bias': tensor([0.4103])})\n",
            "Epoch: 13590 | MAE Train Loss: 0.05274134874343872 | MAE Test Loss: 0.12331783771514893 \n",
            "OrderedDict({'weights': tensor([0.4376]), 'bias': tensor([0.4102])})\n",
            "Epoch: 13600 | MAE Train Loss: 0.05270694941282272 | MAE Test Loss: 0.12323512881994247 \n",
            "OrderedDict({'weights': tensor([0.4378]), 'bias': tensor([0.4101])})\n",
            "Epoch: 13610 | MAE Train Loss: 0.0526726059615612 | MAE Test Loss: 0.12315933406352997 \n",
            "OrderedDict({'weights': tensor([0.4380]), 'bias': tensor([0.4101])})\n",
            "Epoch: 13620 | MAE Train Loss: 0.05263827368617058 | MAE Test Loss: 0.1230766549706459 \n",
            "OrderedDict({'weights': tensor([0.4381]), 'bias': tensor([0.4100])})\n",
            "Epoch: 13630 | MAE Train Loss: 0.052603911608457565 | MAE Test Loss: 0.12299740314483643 \n",
            "OrderedDict({'weights': tensor([0.4383]), 'bias': tensor([0.4099])})\n",
            "Epoch: 13640 | MAE Train Loss: 0.052569519728422165 | MAE Test Loss: 0.12291469424962997 \n",
            "OrderedDict({'weights': tensor([0.4385]), 'bias': tensor([0.4098])})\n",
            "Epoch: 13650 | MAE Train Loss: 0.05253513529896736 | MAE Test Loss: 0.12283887714147568 \n",
            "OrderedDict({'weights': tensor([0.4386]), 'bias': tensor([0.4098])})\n",
            "Epoch: 13660 | MAE Train Loss: 0.05250082537531853 | MAE Test Loss: 0.12275619804859161 \n",
            "OrderedDict({'weights': tensor([0.4388]), 'bias': tensor([0.4097])})\n",
            "Epoch: 13670 | MAE Train Loss: 0.052466440945863724 | MAE Test Loss: 0.12267351150512695 \n",
            "OrderedDict({'weights': tensor([0.4390]), 'bias': tensor([0.4096])})\n",
            "Epoch: 13680 | MAE Train Loss: 0.05243206024169922 | MAE Test Loss: 0.12259769439697266 \n",
            "OrderedDict({'weights': tensor([0.4392]), 'bias': tensor([0.4095])})\n",
            "Epoch: 13690 | MAE Train Loss: 0.05239773914217949 | MAE Test Loss: 0.122515007853508 \n",
            "OrderedDict({'weights': tensor([0.4393]), 'bias': tensor([0.4095])})\n",
            "Epoch: 13700 | MAE Train Loss: 0.052363354712724686 | MAE Test Loss: 0.12243232876062393 \n",
            "OrderedDict({'weights': tensor([0.4395]), 'bias': tensor([0.4094])})\n",
            "Epoch: 13710 | MAE Train Loss: 0.05232897400856018 | MAE Test Loss: 0.12235651165246964 \n",
            "OrderedDict({'weights': tensor([0.4397]), 'bias': tensor([0.4093])})\n",
            "Epoch: 13720 | MAE Train Loss: 0.05229460448026657 | MAE Test Loss: 0.12227040529251099 \n",
            "OrderedDict({'weights': tensor([0.4398]), 'bias': tensor([0.4093])})\n",
            "Epoch: 13730 | MAE Train Loss: 0.05226027965545654 | MAE Test Loss: 0.12219458818435669 \n",
            "OrderedDict({'weights': tensor([0.4400]), 'bias': tensor([0.4092])})\n",
            "Epoch: 13740 | MAE Train Loss: 0.05222589895129204 | MAE Test Loss: 0.1221153512597084 \n",
            "OrderedDict({'weights': tensor([0.4402]), 'bias': tensor([0.4091])})\n",
            "Epoch: 13750 | MAE Train Loss: 0.052191585302352905 | MAE Test Loss: 0.12203265726566315 \n",
            "OrderedDict({'weights': tensor([0.4404]), 'bias': tensor([0.4090])})\n",
            "Epoch: 13760 | MAE Train Loss: 0.05215718224644661 | MAE Test Loss: 0.12194995582103729 \n",
            "OrderedDict({'weights': tensor([0.4405]), 'bias': tensor([0.4090])})\n",
            "Epoch: 13770 | MAE Train Loss: 0.0521228089928627 | MAE Test Loss: 0.12187416851520538 \n",
            "OrderedDict({'weights': tensor([0.4407]), 'bias': tensor([0.4089])})\n",
            "Epoch: 13780 | MAE Train Loss: 0.052088432013988495 | MAE Test Loss: 0.12178804725408554 \n",
            "OrderedDict({'weights': tensor([0.4409]), 'bias': tensor([0.4088])})\n",
            "Epoch: 13790 | MAE Train Loss: 0.05205412581562996 | MAE Test Loss: 0.12171220779418945 \n",
            "OrderedDict({'weights': tensor([0.4410]), 'bias': tensor([0.4088])})\n",
            "Epoch: 13800 | MAE Train Loss: 0.05201975256204605 | MAE Test Loss: 0.12162952125072479 \n",
            "OrderedDict({'weights': tensor([0.4412]), 'bias': tensor([0.4087])})\n",
            "Epoch: 13810 | MAE Train Loss: 0.05198534578084946 | MAE Test Loss: 0.12154684215784073 \n",
            "OrderedDict({'weights': tensor([0.4414]), 'bias': tensor([0.4086])})\n",
            "Epoch: 13820 | MAE Train Loss: 0.05195103958249092 | MAE Test Loss: 0.12147101014852524 \n",
            "OrderedDict({'weights': tensor([0.4416]), 'bias': tensor([0.4085])})\n",
            "Epoch: 13830 | MAE Train Loss: 0.05191667005419731 | MAE Test Loss: 0.12138833850622177 \n",
            "OrderedDict({'weights': tensor([0.4417]), 'bias': tensor([0.4085])})\n",
            "Epoch: 13840 | MAE Train Loss: 0.05188225954771042 | MAE Test Loss: 0.12131252139806747 \n",
            "OrderedDict({'weights': tensor([0.4419]), 'bias': tensor([0.4084])})\n",
            "Epoch: 13850 | MAE Train Loss: 0.05184795707464218 | MAE Test Loss: 0.12122981250286102 \n",
            "OrderedDict({'weights': tensor([0.4421]), 'bias': tensor([0.4083])})\n",
            "Epoch: 13860 | MAE Train Loss: 0.051813580095767975 | MAE Test Loss: 0.12114715576171875 \n",
            "OrderedDict({'weights': tensor([0.4422]), 'bias': tensor([0.4083])})\n",
            "Epoch: 13870 | MAE Train Loss: 0.051779232919216156 | MAE Test Loss: 0.12106790393590927 \n",
            "OrderedDict({'weights': tensor([0.4424]), 'bias': tensor([0.4082])})\n",
            "Epoch: 13880 | MAE Train Loss: 0.05174483731389046 | MAE Test Loss: 0.12098522484302521 \n",
            "OrderedDict({'weights': tensor([0.4426]), 'bias': tensor([0.4081])})\n",
            "Epoch: 13890 | MAE Train Loss: 0.051710497587919235 | MAE Test Loss: 0.12090937793254852 \n",
            "OrderedDict({'weights': tensor([0.4428]), 'bias': tensor([0.4080])})\n",
            "Epoch: 13900 | MAE Train Loss: 0.05167614296078682 | MAE Test Loss: 0.12082672119140625 \n",
            "OrderedDict({'weights': tensor([0.4429]), 'bias': tensor([0.4080])})\n",
            "Epoch: 13910 | MAE Train Loss: 0.05164174363017082 | MAE Test Loss: 0.1207440122961998 \n",
            "OrderedDict({'weights': tensor([0.4431]), 'bias': tensor([0.4079])})\n",
            "Epoch: 13920 | MAE Train Loss: 0.0516074113547802 | MAE Test Loss: 0.12066821753978729 \n",
            "OrderedDict({'weights': tensor([0.4433]), 'bias': tensor([0.4078])})\n",
            "Epoch: 13930 | MAE Train Loss: 0.051573075354099274 | MAE Test Loss: 0.12058551609516144 \n",
            "OrderedDict({'weights': tensor([0.4434]), 'bias': tensor([0.4078])})\n",
            "Epoch: 13940 | MAE Train Loss: 0.051538657397031784 | MAE Test Loss: 0.12050282955169678 \n",
            "OrderedDict({'weights': tensor([0.4436]), 'bias': tensor([0.4077])})\n",
            "Epoch: 13950 | MAE Train Loss: 0.051504332572221756 | MAE Test Loss: 0.12042703479528427 \n",
            "OrderedDict({'weights': tensor([0.4438]), 'bias': tensor([0.4076])})\n",
            "Epoch: 13960 | MAE Train Loss: 0.051469944417476654 | MAE Test Loss: 0.120347760617733 \n",
            "OrderedDict({'weights': tensor([0.4439]), 'bias': tensor([0.4075])})\n",
            "Epoch: 13970 | MAE Train Loss: 0.051435571163892746 | MAE Test Loss: 0.12026164680719376 \n",
            "OrderedDict({'weights': tensor([0.4441]), 'bias': tensor([0.4075])})\n",
            "Epoch: 13980 | MAE Train Loss: 0.05140125751495361 | MAE Test Loss: 0.12018582969903946 \n",
            "OrderedDict({'weights': tensor([0.4443]), 'bias': tensor([0.4074])})\n",
            "Epoch: 13990 | MAE Train Loss: 0.0513668954372406 | MAE Test Loss: 0.1201031431555748 \n",
            "OrderedDict({'weights': tensor([0.4445]), 'bias': tensor([0.4073])})\n",
            "Epoch: 14000 | MAE Train Loss: 0.05133248493075371 | MAE Test Loss: 0.12002048641443253 \n",
            "OrderedDict({'weights': tensor([0.4446]), 'bias': tensor([0.4073])})\n",
            "Epoch: 14010 | MAE Train Loss: 0.051298148930072784 | MAE Test Loss: 0.11994121223688126 \n",
            "OrderedDict({'weights': tensor([0.4448]), 'bias': tensor([0.4072])})\n",
            "Epoch: 14020 | MAE Train Loss: 0.051263779401779175 | MAE Test Loss: 0.11986539512872696 \n",
            "OrderedDict({'weights': tensor([0.4450]), 'bias': tensor([0.4071])})\n",
            "Epoch: 14030 | MAE Train Loss: 0.05122946575284004 | MAE Test Loss: 0.1197827085852623 \n",
            "OrderedDict({'weights': tensor([0.4451]), 'bias': tensor([0.4070])})\n",
            "Epoch: 14040 | MAE Train Loss: 0.051195062696933746 | MAE Test Loss: 0.11970002949237823 \n",
            "OrderedDict({'weights': tensor([0.4453]), 'bias': tensor([0.4070])})\n",
            "Epoch: 14050 | MAE Train Loss: 0.05116071179509163 | MAE Test Loss: 0.11962421238422394 \n",
            "OrderedDict({'weights': tensor([0.4455]), 'bias': tensor([0.4069])})\n",
            "Epoch: 14060 | MAE Train Loss: 0.05112637206912041 | MAE Test Loss: 0.11954152584075928 \n",
            "OrderedDict({'weights': tensor([0.4457]), 'bias': tensor([0.4068])})\n",
            "Epoch: 14070 | MAE Train Loss: 0.05109197646379471 | MAE Test Loss: 0.11945881694555283 \n",
            "OrderedDict({'weights': tensor([0.4458]), 'bias': tensor([0.4068])})\n",
            "Epoch: 14080 | MAE Train Loss: 0.05105762928724289 | MAE Test Loss: 0.11938302218914032 \n",
            "OrderedDict({'weights': tensor([0.4460]), 'bias': tensor([0.4067])})\n",
            "Epoch: 14090 | MAE Train Loss: 0.051023297011852264 | MAE Test Loss: 0.11930034309625626 \n",
            "OrderedDict({'weights': tensor([0.4462]), 'bias': tensor([0.4066])})\n",
            "Epoch: 14100 | MAE Train Loss: 0.05098893493413925 | MAE Test Loss: 0.11922109127044678 \n",
            "OrderedDict({'weights': tensor([0.4463]), 'bias': tensor([0.4065])})\n",
            "Epoch: 14110 | MAE Train Loss: 0.05095454305410385 | MAE Test Loss: 0.11913838237524033 \n",
            "OrderedDict({'weights': tensor([0.4465]), 'bias': tensor([0.4065])})\n",
            "Epoch: 14120 | MAE Train Loss: 0.05092015862464905 | MAE Test Loss: 0.11906256526708603 \n",
            "OrderedDict({'weights': tensor([0.4467]), 'bias': tensor([0.4064])})\n",
            "Epoch: 14130 | MAE Train Loss: 0.050885848701000214 | MAE Test Loss: 0.11897988617420197 \n",
            "OrderedDict({'weights': tensor([0.4469]), 'bias': tensor([0.4063])})\n",
            "Epoch: 14140 | MAE Train Loss: 0.05085146427154541 | MAE Test Loss: 0.1188971996307373 \n",
            "OrderedDict({'weights': tensor([0.4470]), 'bias': tensor([0.4063])})\n",
            "Epoch: 14150 | MAE Train Loss: 0.050817083567380905 | MAE Test Loss: 0.11882138252258301 \n",
            "OrderedDict({'weights': tensor([0.4472]), 'bias': tensor([0.4062])})\n",
            "Epoch: 14160 | MAE Train Loss: 0.050782762467861176 | MAE Test Loss: 0.11873869597911835 \n",
            "OrderedDict({'weights': tensor([0.4474]), 'bias': tensor([0.4061])})\n",
            "Epoch: 14170 | MAE Train Loss: 0.05074837803840637 | MAE Test Loss: 0.11865601688623428 \n",
            "OrderedDict({'weights': tensor([0.4475]), 'bias': tensor([0.4060])})\n",
            "Epoch: 14180 | MAE Train Loss: 0.05071399733424187 | MAE Test Loss: 0.11858019977807999 \n",
            "OrderedDict({'weights': tensor([0.4477]), 'bias': tensor([0.4060])})\n",
            "Epoch: 14190 | MAE Train Loss: 0.050679631531238556 | MAE Test Loss: 0.11849409341812134 \n",
            "OrderedDict({'weights': tensor([0.4479]), 'bias': tensor([0.4059])})\n",
            "Epoch: 14200 | MAE Train Loss: 0.05064530298113823 | MAE Test Loss: 0.11841827630996704 \n",
            "OrderedDict({'weights': tensor([0.4480]), 'bias': tensor([0.4058])})\n",
            "Epoch: 14210 | MAE Train Loss: 0.050610922276973724 | MAE Test Loss: 0.11833903938531876 \n",
            "OrderedDict({'weights': tensor([0.4482]), 'bias': tensor([0.4057])})\n",
            "Epoch: 14220 | MAE Train Loss: 0.05057660862803459 | MAE Test Loss: 0.1182563453912735 \n",
            "OrderedDict({'weights': tensor([0.4484]), 'bias': tensor([0.4057])})\n",
            "Epoch: 14230 | MAE Train Loss: 0.050542205572128296 | MAE Test Loss: 0.11817364394664764 \n",
            "OrderedDict({'weights': tensor([0.4486]), 'bias': tensor([0.4056])})\n",
            "Epoch: 14240 | MAE Train Loss: 0.05050783231854439 | MAE Test Loss: 0.11809785664081573 \n",
            "OrderedDict({'weights': tensor([0.4487]), 'bias': tensor([0.4055])})\n",
            "Epoch: 14250 | MAE Train Loss: 0.05047345906496048 | MAE Test Loss: 0.11801173537969589 \n",
            "OrderedDict({'weights': tensor([0.4489]), 'bias': tensor([0.4055])})\n",
            "Epoch: 14260 | MAE Train Loss: 0.050439149141311646 | MAE Test Loss: 0.1179358959197998 \n",
            "OrderedDict({'weights': tensor([0.4491]), 'bias': tensor([0.4054])})\n",
            "Epoch: 14270 | MAE Train Loss: 0.05040477588772774 | MAE Test Loss: 0.11785320937633514 \n",
            "OrderedDict({'weights': tensor([0.4492]), 'bias': tensor([0.4053])})\n",
            "Epoch: 14280 | MAE Train Loss: 0.05037037283182144 | MAE Test Loss: 0.11777053028345108 \n",
            "OrderedDict({'weights': tensor([0.4494]), 'bias': tensor([0.4052])})\n",
            "Epoch: 14290 | MAE Train Loss: 0.05033606290817261 | MAE Test Loss: 0.11769469827413559 \n",
            "OrderedDict({'weights': tensor([0.4496]), 'bias': tensor([0.4052])})\n",
            "Epoch: 14300 | MAE Train Loss: 0.050301693379879 | MAE Test Loss: 0.11761202663183212 \n",
            "OrderedDict({'weights': tensor([0.4498]), 'bias': tensor([0.4051])})\n",
            "Epoch: 14310 | MAE Train Loss: 0.050267286598682404 | MAE Test Loss: 0.11753620952367783 \n",
            "OrderedDict({'weights': tensor([0.4499]), 'bias': tensor([0.4050])})\n",
            "Epoch: 14320 | MAE Train Loss: 0.050232984125614166 | MAE Test Loss: 0.11745350062847137 \n",
            "OrderedDict({'weights': tensor([0.4501]), 'bias': tensor([0.4050])})\n",
            "Epoch: 14330 | MAE Train Loss: 0.05019860342144966 | MAE Test Loss: 0.1173708438873291 \n",
            "OrderedDict({'weights': tensor([0.4503]), 'bias': tensor([0.4049])})\n",
            "Epoch: 14340 | MAE Train Loss: 0.05016425997018814 | MAE Test Loss: 0.11729159206151962 \n",
            "OrderedDict({'weights': tensor([0.4504]), 'bias': tensor([0.4048])})\n",
            "Epoch: 14350 | MAE Train Loss: 0.050129860639572144 | MAE Test Loss: 0.11720891296863556 \n",
            "OrderedDict({'weights': tensor([0.4506]), 'bias': tensor([0.4047])})\n",
            "Epoch: 14360 | MAE Train Loss: 0.05009552091360092 | MAE Test Loss: 0.11713306605815887 \n",
            "OrderedDict({'weights': tensor([0.4508]), 'bias': tensor([0.4047])})\n",
            "Epoch: 14370 | MAE Train Loss: 0.050061166286468506 | MAE Test Loss: 0.1170504093170166 \n",
            "OrderedDict({'weights': tensor([0.4510]), 'bias': tensor([0.4046])})\n",
            "Epoch: 14380 | MAE Train Loss: 0.05002676695585251 | MAE Test Loss: 0.11696770042181015 \n",
            "OrderedDict({'weights': tensor([0.4511]), 'bias': tensor([0.4045])})\n",
            "Epoch: 14390 | MAE Train Loss: 0.049992434680461884 | MAE Test Loss: 0.11689190566539764 \n",
            "OrderedDict({'weights': tensor([0.4513]), 'bias': tensor([0.4045])})\n",
            "Epoch: 14400 | MAE Train Loss: 0.04995809867978096 | MAE Test Loss: 0.11680920422077179 \n",
            "OrderedDict({'weights': tensor([0.4515]), 'bias': tensor([0.4044])})\n",
            "Epoch: 14410 | MAE Train Loss: 0.04992368072271347 | MAE Test Loss: 0.11672651767730713 \n",
            "OrderedDict({'weights': tensor([0.4516]), 'bias': tensor([0.4043])})\n",
            "Epoch: 14420 | MAE Train Loss: 0.04988935589790344 | MAE Test Loss: 0.11665072292089462 \n",
            "OrderedDict({'weights': tensor([0.4518]), 'bias': tensor([0.4042])})\n",
            "Epoch: 14430 | MAE Train Loss: 0.04985497146844864 | MAE Test Loss: 0.11657144874334335 \n",
            "OrderedDict({'weights': tensor([0.4520]), 'bias': tensor([0.4042])})\n",
            "Epoch: 14440 | MAE Train Loss: 0.04982059821486473 | MAE Test Loss: 0.11648533493280411 \n",
            "OrderedDict({'weights': tensor([0.4522]), 'bias': tensor([0.4041])})\n",
            "Epoch: 14450 | MAE Train Loss: 0.049786277115345 | MAE Test Loss: 0.11640951782464981 \n",
            "OrderedDict({'weights': tensor([0.4523]), 'bias': tensor([0.4040])})\n",
            "Epoch: 14460 | MAE Train Loss: 0.04975191876292229 | MAE Test Loss: 0.11632683128118515 \n",
            "OrderedDict({'weights': tensor([0.4525]), 'bias': tensor([0.4040])})\n",
            "Epoch: 14470 | MAE Train Loss: 0.049717508256435394 | MAE Test Loss: 0.11624417454004288 \n",
            "OrderedDict({'weights': tensor([0.4527]), 'bias': tensor([0.4039])})\n",
            "Epoch: 14480 | MAE Train Loss: 0.04968317225575447 | MAE Test Loss: 0.11616490036249161 \n",
            "OrderedDict({'weights': tensor([0.4528]), 'bias': tensor([0.4038])})\n",
            "Epoch: 14490 | MAE Train Loss: 0.04964879900217056 | MAE Test Loss: 0.11608908325433731 \n",
            "OrderedDict({'weights': tensor([0.4530]), 'bias': tensor([0.4037])})\n",
            "Epoch: 14500 | MAE Train Loss: 0.04961448907852173 | MAE Test Loss: 0.11600639671087265 \n",
            "OrderedDict({'weights': tensor([0.4532]), 'bias': tensor([0.4037])})\n",
            "Epoch: 14510 | MAE Train Loss: 0.04958008602261543 | MAE Test Loss: 0.11592371761798859 \n",
            "OrderedDict({'weights': tensor([0.4534]), 'bias': tensor([0.4036])})\n",
            "Epoch: 14520 | MAE Train Loss: 0.04954573139548302 | MAE Test Loss: 0.11584790050983429 \n",
            "OrderedDict({'weights': tensor([0.4535]), 'bias': tensor([0.4035])})\n",
            "Epoch: 14530 | MAE Train Loss: 0.04951139912009239 | MAE Test Loss: 0.11576521396636963 \n",
            "OrderedDict({'weights': tensor([0.4537]), 'bias': tensor([0.4034])})\n",
            "Epoch: 14540 | MAE Train Loss: 0.049476999789476395 | MAE Test Loss: 0.11568250507116318 \n",
            "OrderedDict({'weights': tensor([0.4539]), 'bias': tensor([0.4034])})\n",
            "Epoch: 14550 | MAE Train Loss: 0.049442656338214874 | MAE Test Loss: 0.11560671031475067 \n",
            "OrderedDict({'weights': tensor([0.4540]), 'bias': tensor([0.4033])})\n",
            "Epoch: 14560 | MAE Train Loss: 0.04940832406282425 | MAE Test Loss: 0.11552403122186661 \n",
            "OrderedDict({'weights': tensor([0.4542]), 'bias': tensor([0.4032])})\n",
            "Epoch: 14570 | MAE Train Loss: 0.04937396198511124 | MAE Test Loss: 0.11544477939605713 \n",
            "OrderedDict({'weights': tensor([0.4544]), 'bias': tensor([0.4032])})\n",
            "Epoch: 14580 | MAE Train Loss: 0.049339570105075836 | MAE Test Loss: 0.11536207050085068 \n",
            "OrderedDict({'weights': tensor([0.4545]), 'bias': tensor([0.4031])})\n",
            "Epoch: 14590 | MAE Train Loss: 0.049305181950330734 | MAE Test Loss: 0.11528625339269638 \n",
            "OrderedDict({'weights': tensor([0.4547]), 'bias': tensor([0.4030])})\n",
            "Epoch: 14600 | MAE Train Loss: 0.0492708757519722 | MAE Test Loss: 0.11520357429981232 \n",
            "OrderedDict({'weights': tensor([0.4549]), 'bias': tensor([0.4029])})\n",
            "Epoch: 14610 | MAE Train Loss: 0.0492364875972271 | MAE Test Loss: 0.11512088775634766 \n",
            "OrderedDict({'weights': tensor([0.4551]), 'bias': tensor([0.4029])})\n",
            "Epoch: 14620 | MAE Train Loss: 0.04920210689306259 | MAE Test Loss: 0.11504507064819336 \n",
            "OrderedDict({'weights': tensor([0.4552]), 'bias': tensor([0.4028])})\n",
            "Epoch: 14630 | MAE Train Loss: 0.04916778951883316 | MAE Test Loss: 0.1149623841047287 \n",
            "OrderedDict({'weights': tensor([0.4554]), 'bias': tensor([0.4027])})\n",
            "Epoch: 14640 | MAE Train Loss: 0.04913339763879776 | MAE Test Loss: 0.11487970501184464 \n",
            "OrderedDict({'weights': tensor([0.4556]), 'bias': tensor([0.4027])})\n",
            "Epoch: 14650 | MAE Train Loss: 0.04909902438521385 | MAE Test Loss: 0.11480388790369034 \n",
            "OrderedDict({'weights': tensor([0.4557]), 'bias': tensor([0.4026])})\n",
            "Epoch: 14660 | MAE Train Loss: 0.04906465485692024 | MAE Test Loss: 0.11471778154373169 \n",
            "OrderedDict({'weights': tensor([0.4559]), 'bias': tensor([0.4025])})\n",
            "Epoch: 14670 | MAE Train Loss: 0.049030326306819916 | MAE Test Loss: 0.11464196443557739 \n",
            "OrderedDict({'weights': tensor([0.4561]), 'bias': tensor([0.4024])})\n",
            "Epoch: 14680 | MAE Train Loss: 0.04899594932794571 | MAE Test Loss: 0.11456272751092911 \n",
            "OrderedDict({'weights': tensor([0.4563]), 'bias': tensor([0.4024])})\n",
            "Epoch: 14690 | MAE Train Loss: 0.04896163195371628 | MAE Test Loss: 0.11448003351688385 \n",
            "OrderedDict({'weights': tensor([0.4564]), 'bias': tensor([0.4023])})\n",
            "Epoch: 14700 | MAE Train Loss: 0.04892722889780998 | MAE Test Loss: 0.114397332072258 \n",
            "OrderedDict({'weights': tensor([0.4566]), 'bias': tensor([0.4022])})\n",
            "Epoch: 14710 | MAE Train Loss: 0.048892855644226074 | MAE Test Loss: 0.11432154476642609 \n",
            "OrderedDict({'weights': tensor([0.4568]), 'bias': tensor([0.4022])})\n",
            "Epoch: 14720 | MAE Train Loss: 0.048858482390642166 | MAE Test Loss: 0.11423542350530624 \n",
            "OrderedDict({'weights': tensor([0.4569]), 'bias': tensor([0.4021])})\n",
            "Epoch: 14730 | MAE Train Loss: 0.04882417246699333 | MAE Test Loss: 0.11415958404541016 \n",
            "OrderedDict({'weights': tensor([0.4571]), 'bias': tensor([0.4020])})\n",
            "Epoch: 14740 | MAE Train Loss: 0.048789799213409424 | MAE Test Loss: 0.1140768975019455 \n",
            "OrderedDict({'weights': tensor([0.4573]), 'bias': tensor([0.4019])})\n",
            "Epoch: 14750 | MAE Train Loss: 0.04875539615750313 | MAE Test Loss: 0.11399421840906143 \n",
            "OrderedDict({'weights': tensor([0.4575]), 'bias': tensor([0.4019])})\n",
            "Epoch: 14760 | MAE Train Loss: 0.048721086233854294 | MAE Test Loss: 0.11391838639974594 \n",
            "OrderedDict({'weights': tensor([0.4576]), 'bias': tensor([0.4018])})\n",
            "Epoch: 14770 | MAE Train Loss: 0.04868672043085098 | MAE Test Loss: 0.11383571475744247 \n",
            "OrderedDict({'weights': tensor([0.4578]), 'bias': tensor([0.4017])})\n",
            "Epoch: 14780 | MAE Train Loss: 0.04865230992436409 | MAE Test Loss: 0.11375989764928818 \n",
            "OrderedDict({'weights': tensor([0.4580]), 'bias': tensor([0.4017])})\n",
            "Epoch: 14790 | MAE Train Loss: 0.04861801117658615 | MAE Test Loss: 0.11367718875408173 \n",
            "OrderedDict({'weights': tensor([0.4581]), 'bias': tensor([0.4016])})\n",
            "Epoch: 14800 | MAE Train Loss: 0.048583630472421646 | MAE Test Loss: 0.11359453201293945 \n",
            "OrderedDict({'weights': tensor([0.4583]), 'bias': tensor([0.4015])})\n",
            "Epoch: 14810 | MAE Train Loss: 0.04854928329586983 | MAE Test Loss: 0.11351528018712997 \n",
            "OrderedDict({'weights': tensor([0.4585]), 'bias': tensor([0.4014])})\n",
            "Epoch: 14820 | MAE Train Loss: 0.04851488023996353 | MAE Test Loss: 0.11343258619308472 \n",
            "OrderedDict({'weights': tensor([0.4587]), 'bias': tensor([0.4014])})\n",
            "Epoch: 14830 | MAE Train Loss: 0.048480547964572906 | MAE Test Loss: 0.11335675418376923 \n",
            "OrderedDict({'weights': tensor([0.4588]), 'bias': tensor([0.4013])})\n",
            "Epoch: 14840 | MAE Train Loss: 0.04844618961215019 | MAE Test Loss: 0.11327409744262695 \n",
            "OrderedDict({'weights': tensor([0.4590]), 'bias': tensor([0.4012])})\n",
            "Epoch: 14850 | MAE Train Loss: 0.04841179400682449 | MAE Test Loss: 0.1131913885474205 \n",
            "OrderedDict({'weights': tensor([0.4592]), 'bias': tensor([0.4012])})\n",
            "Epoch: 14860 | MAE Train Loss: 0.04837745800614357 | MAE Test Loss: 0.113115593791008 \n",
            "OrderedDict({'weights': tensor([0.4593]), 'bias': tensor([0.4011])})\n",
            "Epoch: 14870 | MAE Train Loss: 0.048343122005462646 | MAE Test Loss: 0.11303289234638214 \n",
            "OrderedDict({'weights': tensor([0.4595]), 'bias': tensor([0.4010])})\n",
            "Epoch: 14880 | MAE Train Loss: 0.048308707773685455 | MAE Test Loss: 0.11295020580291748 \n",
            "OrderedDict({'weights': tensor([0.4597]), 'bias': tensor([0.4009])})\n",
            "Epoch: 14890 | MAE Train Loss: 0.04827437922358513 | MAE Test Loss: 0.11287441104650497 \n",
            "OrderedDict({'weights': tensor([0.4598]), 'bias': tensor([0.4009])})\n",
            "Epoch: 14900 | MAE Train Loss: 0.048239998519420624 | MAE Test Loss: 0.1127951368689537 \n",
            "OrderedDict({'weights': tensor([0.4600]), 'bias': tensor([0.4008])})\n",
            "Epoch: 14910 | MAE Train Loss: 0.04820562154054642 | MAE Test Loss: 0.11270902305841446 \n",
            "OrderedDict({'weights': tensor([0.4602]), 'bias': tensor([0.4007])})\n",
            "Epoch: 14920 | MAE Train Loss: 0.048171304166316986 | MAE Test Loss: 0.11263320595026016 \n",
            "OrderedDict({'weights': tensor([0.4604]), 'bias': tensor([0.4006])})\n",
            "Epoch: 14930 | MAE Train Loss: 0.04813694208860397 | MAE Test Loss: 0.1125505194067955 \n",
            "OrderedDict({'weights': tensor([0.4605]), 'bias': tensor([0.4006])})\n",
            "Epoch: 14940 | MAE Train Loss: 0.04810253530740738 | MAE Test Loss: 0.11246786266565323 \n",
            "OrderedDict({'weights': tensor([0.4607]), 'bias': tensor([0.4005])})\n",
            "Epoch: 14950 | MAE Train Loss: 0.04806819558143616 | MAE Test Loss: 0.11238858848810196 \n",
            "OrderedDict({'weights': tensor([0.4609]), 'bias': tensor([0.4004])})\n",
            "Epoch: 14960 | MAE Train Loss: 0.04803382605314255 | MAE Test Loss: 0.11231277137994766 \n",
            "OrderedDict({'weights': tensor([0.4610]), 'bias': tensor([0.4004])})\n",
            "Epoch: 14970 | MAE Train Loss: 0.047999512404203415 | MAE Test Loss: 0.112230084836483 \n",
            "OrderedDict({'weights': tensor([0.4612]), 'bias': tensor([0.4003])})\n",
            "Epoch: 14980 | MAE Train Loss: 0.04796510934829712 | MAE Test Loss: 0.11214740574359894 \n",
            "OrderedDict({'weights': tensor([0.4614]), 'bias': tensor([0.4002])})\n",
            "Epoch: 14990 | MAE Train Loss: 0.0479307547211647 | MAE Test Loss: 0.11207157373428345 \n",
            "OrderedDict({'weights': tensor([0.4616]), 'bias': tensor([0.4001])})\n",
            "Epoch: 15000 | MAE Train Loss: 0.04789642244577408 | MAE Test Loss: 0.11198890209197998 \n",
            "OrderedDict({'weights': tensor([0.4617]), 'bias': tensor([0.4001])})\n",
            "Epoch: 15010 | MAE Train Loss: 0.04786202311515808 | MAE Test Loss: 0.11190620809793472 \n",
            "OrderedDict({'weights': tensor([0.4619]), 'bias': tensor([0.4000])})\n",
            "Epoch: 15020 | MAE Train Loss: 0.04782767966389656 | MAE Test Loss: 0.11183039098978043 \n",
            "OrderedDict({'weights': tensor([0.4621]), 'bias': tensor([0.3999])})\n",
            "Epoch: 15030 | MAE Train Loss: 0.04779333993792534 | MAE Test Loss: 0.11174771934747696 \n",
            "OrderedDict({'weights': tensor([0.4622]), 'bias': tensor([0.3999])})\n",
            "Epoch: 15040 | MAE Train Loss: 0.04775898531079292 | MAE Test Loss: 0.11166846752166748 \n",
            "OrderedDict({'weights': tensor([0.4624]), 'bias': tensor([0.3998])})\n",
            "Epoch: 15050 | MAE Train Loss: 0.04772459343075752 | MAE Test Loss: 0.11158575862646103 \n",
            "OrderedDict({'weights': tensor([0.4626]), 'bias': tensor([0.3997])})\n",
            "Epoch: 15060 | MAE Train Loss: 0.04769020527601242 | MAE Test Loss: 0.11150995641946793 \n",
            "OrderedDict({'weights': tensor([0.4628]), 'bias': tensor([0.3996])})\n",
            "Epoch: 15070 | MAE Train Loss: 0.047655899077653885 | MAE Test Loss: 0.11142726242542267 \n",
            "OrderedDict({'weights': tensor([0.4629]), 'bias': tensor([0.3996])})\n",
            "Epoch: 15080 | MAE Train Loss: 0.04762151092290878 | MAE Test Loss: 0.11134457588195801 \n",
            "OrderedDict({'weights': tensor([0.4631]), 'bias': tensor([0.3995])})\n",
            "Epoch: 15090 | MAE Train Loss: 0.047587133944034576 | MAE Test Loss: 0.11126875877380371 \n",
            "OrderedDict({'weights': tensor([0.4633]), 'bias': tensor([0.3994])})\n",
            "Epoch: 15100 | MAE Train Loss: 0.04755281284451485 | MAE Test Loss: 0.11118607223033905 \n",
            "OrderedDict({'weights': tensor([0.4634]), 'bias': tensor([0.3994])})\n",
            "Epoch: 15110 | MAE Train Loss: 0.047518424689769745 | MAE Test Loss: 0.11110339313745499 \n",
            "OrderedDict({'weights': tensor([0.4636]), 'bias': tensor([0.3993])})\n",
            "Epoch: 15120 | MAE Train Loss: 0.04748404771089554 | MAE Test Loss: 0.11102757602930069 \n",
            "OrderedDict({'weights': tensor([0.4638]), 'bias': tensor([0.3992])})\n",
            "Epoch: 15130 | MAE Train Loss: 0.04744967818260193 | MAE Test Loss: 0.11094146966934204 \n",
            "OrderedDict({'weights': tensor([0.4639]), 'bias': tensor([0.3991])})\n",
            "Epoch: 15140 | MAE Train Loss: 0.0474153533577919 | MAE Test Loss: 0.11086565256118774 \n",
            "OrderedDict({'weights': tensor([0.4641]), 'bias': tensor([0.3991])})\n",
            "Epoch: 15150 | MAE Train Loss: 0.047380972653627396 | MAE Test Loss: 0.11078640073537827 \n",
            "OrderedDict({'weights': tensor([0.4643]), 'bias': tensor([0.3990])})\n",
            "Epoch: 15160 | MAE Train Loss: 0.047346655279397964 | MAE Test Loss: 0.11070370674133301 \n",
            "OrderedDict({'weights': tensor([0.4645]), 'bias': tensor([0.3989])})\n",
            "Epoch: 15170 | MAE Train Loss: 0.04731225222349167 | MAE Test Loss: 0.11062102019786835 \n",
            "OrderedDict({'weights': tensor([0.4646]), 'bias': tensor([0.3989])})\n",
            "Epoch: 15180 | MAE Train Loss: 0.04727787896990776 | MAE Test Loss: 0.11054523289203644 \n",
            "OrderedDict({'weights': tensor([0.4648]), 'bias': tensor([0.3988])})\n",
            "Epoch: 15190 | MAE Train Loss: 0.04724350571632385 | MAE Test Loss: 0.1104591116309166 \n",
            "OrderedDict({'weights': tensor([0.4650]), 'bias': tensor([0.3987])})\n",
            "Epoch: 15200 | MAE Train Loss: 0.04720919579267502 | MAE Test Loss: 0.11038327217102051 \n",
            "OrderedDict({'weights': tensor([0.4651]), 'bias': tensor([0.3986])})\n",
            "Epoch: 15210 | MAE Train Loss: 0.04717482253909111 | MAE Test Loss: 0.11030058562755585 \n",
            "OrderedDict({'weights': tensor([0.4653]), 'bias': tensor([0.3986])})\n",
            "Epoch: 15220 | MAE Train Loss: 0.047140419483184814 | MAE Test Loss: 0.11021790653467178 \n",
            "OrderedDict({'weights': tensor([0.4655]), 'bias': tensor([0.3985])})\n",
            "Epoch: 15230 | MAE Train Loss: 0.04710610955953598 | MAE Test Loss: 0.11014208942651749 \n",
            "OrderedDict({'weights': tensor([0.4657]), 'bias': tensor([0.3984])})\n",
            "Epoch: 15240 | MAE Train Loss: 0.04707174375653267 | MAE Test Loss: 0.11005940288305283 \n",
            "OrderedDict({'weights': tensor([0.4658]), 'bias': tensor([0.3984])})\n",
            "Epoch: 15250 | MAE Train Loss: 0.047037333250045776 | MAE Test Loss: 0.10998358577489853 \n",
            "OrderedDict({'weights': tensor([0.4660]), 'bias': tensor([0.3983])})\n",
            "Epoch: 15260 | MAE Train Loss: 0.04700303450226784 | MAE Test Loss: 0.10990089178085327 \n",
            "OrderedDict({'weights': tensor([0.4662]), 'bias': tensor([0.3982])})\n",
            "Epoch: 15270 | MAE Train Loss: 0.04696865379810333 | MAE Test Loss: 0.1098182201385498 \n",
            "OrderedDict({'weights': tensor([0.4663]), 'bias': tensor([0.3981])})\n",
            "Epoch: 15280 | MAE Train Loss: 0.046934306621551514 | MAE Test Loss: 0.10973896831274033 \n",
            "OrderedDict({'weights': tensor([0.4665]), 'bias': tensor([0.3981])})\n",
            "Epoch: 15290 | MAE Train Loss: 0.046899907290935516 | MAE Test Loss: 0.10965628921985626 \n",
            "OrderedDict({'weights': tensor([0.4667]), 'bias': tensor([0.3980])})\n",
            "Epoch: 15300 | MAE Train Loss: 0.046865563839673996 | MAE Test Loss: 0.10958044230937958 \n",
            "OrderedDict({'weights': tensor([0.4669]), 'bias': tensor([0.3979])})\n",
            "Epoch: 15310 | MAE Train Loss: 0.04683121293783188 | MAE Test Loss: 0.1094977855682373 \n",
            "OrderedDict({'weights': tensor([0.4670]), 'bias': tensor([0.3978])})\n",
            "Epoch: 15320 | MAE Train Loss: 0.04679681733250618 | MAE Test Loss: 0.10941509157419205 \n",
            "OrderedDict({'weights': tensor([0.4672]), 'bias': tensor([0.3978])})\n",
            "Epoch: 15330 | MAE Train Loss: 0.04676248878240585 | MAE Test Loss: 0.10933927446603775 \n",
            "OrderedDict({'weights': tensor([0.4674]), 'bias': tensor([0.3977])})\n",
            "Epoch: 15340 | MAE Train Loss: 0.04672814533114433 | MAE Test Loss: 0.10925658047199249 \n",
            "OrderedDict({'weights': tensor([0.4675]), 'bias': tensor([0.3976])})\n",
            "Epoch: 15350 | MAE Train Loss: 0.04669373109936714 | MAE Test Loss: 0.10917389392852783 \n",
            "OrderedDict({'weights': tensor([0.4677]), 'bias': tensor([0.3976])})\n",
            "Epoch: 15360 | MAE Train Loss: 0.046659402549266815 | MAE Test Loss: 0.10909809917211533 \n",
            "OrderedDict({'weights': tensor([0.4679]), 'bias': tensor([0.3975])})\n",
            "Epoch: 15370 | MAE Train Loss: 0.04662502184510231 | MAE Test Loss: 0.10901882499456406 \n",
            "OrderedDict({'weights': tensor([0.4681]), 'bias': tensor([0.3974])})\n",
            "Epoch: 15380 | MAE Train Loss: 0.0465906485915184 | MAE Test Loss: 0.10893271118402481 \n",
            "OrderedDict({'weights': tensor([0.4682]), 'bias': tensor([0.3973])})\n",
            "Epoch: 15390 | MAE Train Loss: 0.04655632749199867 | MAE Test Loss: 0.10885689407587051 \n",
            "OrderedDict({'weights': tensor([0.4684]), 'bias': tensor([0.3973])})\n",
            "Epoch: 15400 | MAE Train Loss: 0.04652196913957596 | MAE Test Loss: 0.10877420753240585 \n",
            "OrderedDict({'weights': tensor([0.4686]), 'bias': tensor([0.3972])})\n",
            "Epoch: 15410 | MAE Train Loss: 0.046487558633089066 | MAE Test Loss: 0.10869153589010239 \n",
            "OrderedDict({'weights': tensor([0.4687]), 'bias': tensor([0.3971])})\n",
            "Epoch: 15420 | MAE Train Loss: 0.046453218907117844 | MAE Test Loss: 0.10861227661371231 \n",
            "OrderedDict({'weights': tensor([0.4689]), 'bias': tensor([0.3971])})\n",
            "Epoch: 15430 | MAE Train Loss: 0.046418849378824234 | MAE Test Loss: 0.10853645950555801 \n",
            "OrderedDict({'weights': tensor([0.4691]), 'bias': tensor([0.3970])})\n",
            "Epoch: 15440 | MAE Train Loss: 0.0463845357298851 | MAE Test Loss: 0.10845377296209335 \n",
            "OrderedDict({'weights': tensor([0.4692]), 'bias': tensor([0.3969])})\n",
            "Epoch: 15450 | MAE Train Loss: 0.046350132673978806 | MAE Test Loss: 0.10837109386920929 \n",
            "OrderedDict({'weights': tensor([0.4694]), 'bias': tensor([0.3968])})\n",
            "Epoch: 15460 | MAE Train Loss: 0.04631578177213669 | MAE Test Loss: 0.1082952618598938 \n",
            "OrderedDict({'weights': tensor([0.4696]), 'bias': tensor([0.3968])})\n",
            "Epoch: 15470 | MAE Train Loss: 0.04628144949674606 | MAE Test Loss: 0.10821259021759033 \n",
            "OrderedDict({'weights': tensor([0.4698]), 'bias': tensor([0.3967])})\n",
            "Epoch: 15480 | MAE Train Loss: 0.04624704644083977 | MAE Test Loss: 0.10812989622354507 \n",
            "OrderedDict({'weights': tensor([0.4699]), 'bias': tensor([0.3966])})\n",
            "Epoch: 15490 | MAE Train Loss: 0.04621270298957825 | MAE Test Loss: 0.10805407911539078 \n",
            "OrderedDict({'weights': tensor([0.4701]), 'bias': tensor([0.3966])})\n",
            "Epoch: 15500 | MAE Train Loss: 0.046178363263607025 | MAE Test Loss: 0.10797140747308731 \n",
            "OrderedDict({'weights': tensor([0.4703]), 'bias': tensor([0.3965])})\n",
            "Epoch: 15510 | MAE Train Loss: 0.04614400863647461 | MAE Test Loss: 0.10789215564727783 \n",
            "OrderedDict({'weights': tensor([0.4704]), 'bias': tensor([0.3964])})\n",
            "Epoch: 15520 | MAE Train Loss: 0.04610961675643921 | MAE Test Loss: 0.10780944675207138 \n",
            "OrderedDict({'weights': tensor([0.4706]), 'bias': tensor([0.3963])})\n",
            "Epoch: 15530 | MAE Train Loss: 0.046075232326984406 | MAE Test Loss: 0.10773364454507828 \n",
            "OrderedDict({'weights': tensor([0.4708]), 'bias': tensor([0.3963])})\n",
            "Epoch: 15540 | MAE Train Loss: 0.04604092240333557 | MAE Test Loss: 0.10765095055103302 \n",
            "OrderedDict({'weights': tensor([0.4710]), 'bias': tensor([0.3962])})\n",
            "Epoch: 15550 | MAE Train Loss: 0.04600653052330017 | MAE Test Loss: 0.10756826400756836 \n",
            "OrderedDict({'weights': tensor([0.4711]), 'bias': tensor([0.3961])})\n",
            "Epoch: 15560 | MAE Train Loss: 0.04597215726971626 | MAE Test Loss: 0.10749244689941406 \n",
            "OrderedDict({'weights': tensor([0.4713]), 'bias': tensor([0.3961])})\n",
            "Epoch: 15570 | MAE Train Loss: 0.04593783617019653 | MAE Test Loss: 0.1074097603559494 \n",
            "OrderedDict({'weights': tensor([0.4715]), 'bias': tensor([0.3960])})\n",
            "Epoch: 15580 | MAE Train Loss: 0.04590344801545143 | MAE Test Loss: 0.10732708126306534 \n",
            "OrderedDict({'weights': tensor([0.4716]), 'bias': tensor([0.3959])})\n",
            "Epoch: 15590 | MAE Train Loss: 0.04586907476186752 | MAE Test Loss: 0.10725126415491104 \n",
            "OrderedDict({'weights': tensor([0.4718]), 'bias': tensor([0.3958])})\n",
            "Epoch: 15600 | MAE Train Loss: 0.045834701508283615 | MAE Test Loss: 0.10716515779495239 \n",
            "OrderedDict({'weights': tensor([0.4720]), 'bias': tensor([0.3958])})\n",
            "Epoch: 15610 | MAE Train Loss: 0.04580037668347359 | MAE Test Loss: 0.1070893406867981 \n",
            "OrderedDict({'weights': tensor([0.4722]), 'bias': tensor([0.3957])})\n",
            "Epoch: 15620 | MAE Train Loss: 0.04576599597930908 | MAE Test Loss: 0.10701008886098862 \n",
            "OrderedDict({'weights': tensor([0.4723]), 'bias': tensor([0.3956])})\n",
            "Epoch: 15630 | MAE Train Loss: 0.04573167860507965 | MAE Test Loss: 0.10692739486694336 \n",
            "OrderedDict({'weights': tensor([0.4725]), 'bias': tensor([0.3956])})\n",
            "Epoch: 15640 | MAE Train Loss: 0.045697279274463654 | MAE Test Loss: 0.1068447083234787 \n",
            "OrderedDict({'weights': tensor([0.4727]), 'bias': tensor([0.3955])})\n",
            "Epoch: 15650 | MAE Train Loss: 0.04566290229558945 | MAE Test Loss: 0.10676892101764679 \n",
            "OrderedDict({'weights': tensor([0.4728]), 'bias': tensor([0.3954])})\n",
            "Epoch: 15660 | MAE Train Loss: 0.04562852904200554 | MAE Test Loss: 0.10668279975652695 \n",
            "OrderedDict({'weights': tensor([0.4730]), 'bias': tensor([0.3953])})\n",
            "Epoch: 15670 | MAE Train Loss: 0.045594222843647 | MAE Test Loss: 0.10660696029663086 \n",
            "OrderedDict({'weights': tensor([0.4732]), 'bias': tensor([0.3953])})\n",
            "Epoch: 15680 | MAE Train Loss: 0.0455598458647728 | MAE Test Loss: 0.1065242737531662 \n",
            "OrderedDict({'weights': tensor([0.4734]), 'bias': tensor([0.3952])})\n",
            "Epoch: 15690 | MAE Train Loss: 0.0455254428088665 | MAE Test Loss: 0.10644159466028214 \n",
            "OrderedDict({'weights': tensor([0.4735]), 'bias': tensor([0.3951])})\n",
            "Epoch: 15700 | MAE Train Loss: 0.045491136610507965 | MAE Test Loss: 0.10636577755212784 \n",
            "OrderedDict({'weights': tensor([0.4737]), 'bias': tensor([0.3950])})\n",
            "Epoch: 15710 | MAE Train Loss: 0.045456767082214355 | MAE Test Loss: 0.10628309100866318 \n",
            "OrderedDict({'weights': tensor([0.4739]), 'bias': tensor([0.3950])})\n",
            "Epoch: 15720 | MAE Train Loss: 0.04542236402630806 | MAE Test Loss: 0.10620727390050888 \n",
            "OrderedDict({'weights': tensor([0.4740]), 'bias': tensor([0.3949])})\n",
            "Epoch: 15730 | MAE Train Loss: 0.045388057827949524 | MAE Test Loss: 0.10612457990646362 \n",
            "OrderedDict({'weights': tensor([0.4742]), 'bias': tensor([0.3948])})\n",
            "Epoch: 15740 | MAE Train Loss: 0.04535367712378502 | MAE Test Loss: 0.10604190826416016 \n",
            "OrderedDict({'weights': tensor([0.4744]), 'bias': tensor([0.3948])})\n",
            "Epoch: 15750 | MAE Train Loss: 0.0453193299472332 | MAE Test Loss: 0.10596265643835068 \n",
            "OrderedDict({'weights': tensor([0.4745]), 'bias': tensor([0.3947])})\n",
            "Epoch: 15760 | MAE Train Loss: 0.0452849306166172 | MAE Test Loss: 0.10587997734546661 \n",
            "OrderedDict({'weights': tensor([0.4747]), 'bias': tensor([0.3946])})\n",
            "Epoch: 15770 | MAE Train Loss: 0.04525058716535568 | MAE Test Loss: 0.10580413043498993 \n",
            "OrderedDict({'weights': tensor([0.4749]), 'bias': tensor([0.3945])})\n",
            "Epoch: 15780 | MAE Train Loss: 0.045216239988803864 | MAE Test Loss: 0.10572147369384766 \n",
            "OrderedDict({'weights': tensor([0.4751]), 'bias': tensor([0.3945])})\n",
            "Epoch: 15790 | MAE Train Loss: 0.045181840658187866 | MAE Test Loss: 0.1056387796998024 \n",
            "OrderedDict({'weights': tensor([0.4752]), 'bias': tensor([0.3944])})\n",
            "Epoch: 15800 | MAE Train Loss: 0.04514751210808754 | MAE Test Loss: 0.1055629625916481 \n",
            "OrderedDict({'weights': tensor([0.4754]), 'bias': tensor([0.3943])})\n",
            "Epoch: 15810 | MAE Train Loss: 0.04511316865682602 | MAE Test Loss: 0.10548026859760284 \n",
            "OrderedDict({'weights': tensor([0.4756]), 'bias': tensor([0.3943])})\n",
            "Epoch: 15820 | MAE Train Loss: 0.04507875442504883 | MAE Test Loss: 0.10539758205413818 \n",
            "OrderedDict({'weights': tensor([0.4757]), 'bias': tensor([0.3942])})\n",
            "Epoch: 15830 | MAE Train Loss: 0.0450444296002388 | MAE Test Loss: 0.10532178729772568 \n",
            "OrderedDict({'weights': tensor([0.4759]), 'bias': tensor([0.3941])})\n",
            "Epoch: 15840 | MAE Train Loss: 0.045010045170784 | MAE Test Loss: 0.10524251312017441 \n",
            "OrderedDict({'weights': tensor([0.4761]), 'bias': tensor([0.3940])})\n",
            "Epoch: 15850 | MAE Train Loss: 0.04497567191720009 | MAE Test Loss: 0.10515639930963516 \n",
            "OrderedDict({'weights': tensor([0.4763]), 'bias': tensor([0.3940])})\n",
            "Epoch: 15860 | MAE Train Loss: 0.04494135081768036 | MAE Test Loss: 0.10508058220148087 \n",
            "OrderedDict({'weights': tensor([0.4764]), 'bias': tensor([0.3939])})\n",
            "Epoch: 15870 | MAE Train Loss: 0.044906992465257645 | MAE Test Loss: 0.1049978956580162 \n",
            "OrderedDict({'weights': tensor([0.4766]), 'bias': tensor([0.3938])})\n",
            "Epoch: 15880 | MAE Train Loss: 0.04487258195877075 | MAE Test Loss: 0.10491522401571274 \n",
            "OrderedDict({'weights': tensor([0.4768]), 'bias': tensor([0.3938])})\n",
            "Epoch: 15890 | MAE Train Loss: 0.04483824223279953 | MAE Test Loss: 0.10483596473932266 \n",
            "OrderedDict({'weights': tensor([0.4769]), 'bias': tensor([0.3937])})\n",
            "Epoch: 15900 | MAE Train Loss: 0.04480387270450592 | MAE Test Loss: 0.10476014763116837 \n",
            "OrderedDict({'weights': tensor([0.4771]), 'bias': tensor([0.3936])})\n",
            "Epoch: 15910 | MAE Train Loss: 0.044769562780857086 | MAE Test Loss: 0.1046774610877037 \n",
            "OrderedDict({'weights': tensor([0.4773]), 'bias': tensor([0.3935])})\n",
            "Epoch: 15920 | MAE Train Loss: 0.04473515599966049 | MAE Test Loss: 0.10459478199481964 \n",
            "OrderedDict({'weights': tensor([0.4775]), 'bias': tensor([0.3935])})\n",
            "Epoch: 15930 | MAE Train Loss: 0.044700805097818375 | MAE Test Loss: 0.10451894998550415 \n",
            "OrderedDict({'weights': tensor([0.4776]), 'bias': tensor([0.3934])})\n",
            "Epoch: 15940 | MAE Train Loss: 0.04466647282242775 | MAE Test Loss: 0.10443627834320068 \n",
            "OrderedDict({'weights': tensor([0.4778]), 'bias': tensor([0.3933])})\n",
            "Epoch: 15950 | MAE Train Loss: 0.044632069766521454 | MAE Test Loss: 0.10435358434915543 \n",
            "OrderedDict({'weights': tensor([0.4780]), 'bias': tensor([0.3933])})\n",
            "Epoch: 15960 | MAE Train Loss: 0.044597726315259933 | MAE Test Loss: 0.10427776724100113 \n",
            "OrderedDict({'weights': tensor([0.4781]), 'bias': tensor([0.3932])})\n",
            "Epoch: 15970 | MAE Train Loss: 0.04456339031457901 | MAE Test Loss: 0.10419509559869766 \n",
            "OrderedDict({'weights': tensor([0.4783]), 'bias': tensor([0.3931])})\n",
            "Epoch: 15980 | MAE Train Loss: 0.044529031962156296 | MAE Test Loss: 0.10411584377288818 \n",
            "OrderedDict({'weights': tensor([0.4785]), 'bias': tensor([0.3930])})\n",
            "Epoch: 15990 | MAE Train Loss: 0.044494640082120895 | MAE Test Loss: 0.10403313487768173 \n",
            "OrderedDict({'weights': tensor([0.4787]), 'bias': tensor([0.3930])})\n",
            "Epoch: 16000 | MAE Train Loss: 0.04446025565266609 | MAE Test Loss: 0.10395733267068863 \n",
            "OrderedDict({'weights': tensor([0.4788]), 'bias': tensor([0.3929])})\n",
            "Epoch: 16010 | MAE Train Loss: 0.04442594572901726 | MAE Test Loss: 0.10387463867664337 \n",
            "OrderedDict({'weights': tensor([0.4790]), 'bias': tensor([0.3928])})\n",
            "Epoch: 16020 | MAE Train Loss: 0.04439155384898186 | MAE Test Loss: 0.10379195213317871 \n",
            "OrderedDict({'weights': tensor([0.4792]), 'bias': tensor([0.3928])})\n",
            "Epoch: 16030 | MAE Train Loss: 0.04435718059539795 | MAE Test Loss: 0.10371613502502441 \n",
            "OrderedDict({'weights': tensor([0.4793]), 'bias': tensor([0.3927])})\n",
            "Epoch: 16040 | MAE Train Loss: 0.04432285949587822 | MAE Test Loss: 0.10363344848155975 \n",
            "OrderedDict({'weights': tensor([0.4795]), 'bias': tensor([0.3926])})\n",
            "Epoch: 16050 | MAE Train Loss: 0.04428847134113312 | MAE Test Loss: 0.10355076938867569 \n",
            "OrderedDict({'weights': tensor([0.4797]), 'bias': tensor([0.3925])})\n",
            "Epoch: 16060 | MAE Train Loss: 0.04425409808754921 | MAE Test Loss: 0.10347495228052139 \n",
            "OrderedDict({'weights': tensor([0.4798]), 'bias': tensor([0.3925])})\n",
            "Epoch: 16070 | MAE Train Loss: 0.0442197248339653 | MAE Test Loss: 0.10338884592056274 \n",
            "OrderedDict({'weights': tensor([0.4800]), 'bias': tensor([0.3924])})\n",
            "Epoch: 16080 | MAE Train Loss: 0.04418540000915527 | MAE Test Loss: 0.10331302881240845 \n",
            "OrderedDict({'weights': tensor([0.4802]), 'bias': tensor([0.3923])})\n",
            "Epoch: 16090 | MAE Train Loss: 0.04415101930499077 | MAE Test Loss: 0.10323377698659897 \n",
            "OrderedDict({'weights': tensor([0.4804]), 'bias': tensor([0.3922])})\n",
            "Epoch: 16100 | MAE Train Loss: 0.04411670193076134 | MAE Test Loss: 0.10315108299255371 \n",
            "OrderedDict({'weights': tensor([0.4805]), 'bias': tensor([0.3922])})\n",
            "Epoch: 16110 | MAE Train Loss: 0.04408230260014534 | MAE Test Loss: 0.10306839644908905 \n",
            "OrderedDict({'weights': tensor([0.4807]), 'bias': tensor([0.3921])})\n",
            "Epoch: 16120 | MAE Train Loss: 0.04404792934656143 | MAE Test Loss: 0.10299260914325714 \n",
            "OrderedDict({'weights': tensor([0.4809]), 'bias': tensor([0.3920])})\n",
            "Epoch: 16130 | MAE Train Loss: 0.044013552367687225 | MAE Test Loss: 0.1029064878821373 \n",
            "OrderedDict({'weights': tensor([0.4810]), 'bias': tensor([0.3920])})\n",
            "Epoch: 16140 | MAE Train Loss: 0.04397924616932869 | MAE Test Loss: 0.10283064842224121 \n",
            "OrderedDict({'weights': tensor([0.4812]), 'bias': tensor([0.3919])})\n",
            "Epoch: 16150 | MAE Train Loss: 0.04394487291574478 | MAE Test Loss: 0.10274796187877655 \n",
            "OrderedDict({'weights': tensor([0.4814]), 'bias': tensor([0.3918])})\n",
            "Epoch: 16160 | MAE Train Loss: 0.04391046613454819 | MAE Test Loss: 0.10266528278589249 \n",
            "OrderedDict({'weights': tensor([0.4816]), 'bias': tensor([0.3917])})\n",
            "Epoch: 16170 | MAE Train Loss: 0.04387615993618965 | MAE Test Loss: 0.10258946567773819 \n",
            "OrderedDict({'weights': tensor([0.4817]), 'bias': tensor([0.3917])})\n",
            "Epoch: 16180 | MAE Train Loss: 0.04384179040789604 | MAE Test Loss: 0.10250677913427353 \n",
            "OrderedDict({'weights': tensor([0.4819]), 'bias': tensor([0.3916])})\n",
            "Epoch: 16190 | MAE Train Loss: 0.043807387351989746 | MAE Test Loss: 0.10243096202611923 \n",
            "OrderedDict({'weights': tensor([0.4821]), 'bias': tensor([0.3915])})\n",
            "Epoch: 16200 | MAE Train Loss: 0.04377308115363121 | MAE Test Loss: 0.10234826803207397 \n",
            "OrderedDict({'weights': tensor([0.4822]), 'bias': tensor([0.3915])})\n",
            "Epoch: 16210 | MAE Train Loss: 0.043738700449466705 | MAE Test Loss: 0.10226559638977051 \n",
            "OrderedDict({'weights': tensor([0.4824]), 'bias': tensor([0.3914])})\n",
            "Epoch: 16220 | MAE Train Loss: 0.043704353272914886 | MAE Test Loss: 0.10218634456396103 \n",
            "OrderedDict({'weights': tensor([0.4826]), 'bias': tensor([0.3913])})\n",
            "Epoch: 16230 | MAE Train Loss: 0.04366995394229889 | MAE Test Loss: 0.10210366547107697 \n",
            "OrderedDict({'weights': tensor([0.4828]), 'bias': tensor([0.3912])})\n",
            "Epoch: 16240 | MAE Train Loss: 0.04363561421632767 | MAE Test Loss: 0.10202781856060028 \n",
            "OrderedDict({'weights': tensor([0.4829]), 'bias': tensor([0.3912])})\n",
            "Epoch: 16250 | MAE Train Loss: 0.04360126331448555 | MAE Test Loss: 0.10194516181945801 \n",
            "OrderedDict({'weights': tensor([0.4831]), 'bias': tensor([0.3911])})\n",
            "Epoch: 16260 | MAE Train Loss: 0.04356686398386955 | MAE Test Loss: 0.10186246782541275 \n",
            "OrderedDict({'weights': tensor([0.4833]), 'bias': tensor([0.3910])})\n",
            "Epoch: 16270 | MAE Train Loss: 0.043532535433769226 | MAE Test Loss: 0.10178665071725845 \n",
            "OrderedDict({'weights': tensor([0.4834]), 'bias': tensor([0.3910])})\n",
            "Epoch: 16280 | MAE Train Loss: 0.043498195707798004 | MAE Test Loss: 0.1017039567232132 \n",
            "OrderedDict({'weights': tensor([0.4836]), 'bias': tensor([0.3909])})\n",
            "Epoch: 16290 | MAE Train Loss: 0.043463777750730515 | MAE Test Loss: 0.10162127017974854 \n",
            "OrderedDict({'weights': tensor([0.4838]), 'bias': tensor([0.3908])})\n",
            "Epoch: 16300 | MAE Train Loss: 0.043429452925920486 | MAE Test Loss: 0.10154547542333603 \n",
            "OrderedDict({'weights': tensor([0.4839]), 'bias': tensor([0.3907])})\n",
            "Epoch: 16310 | MAE Train Loss: 0.04339506849646568 | MAE Test Loss: 0.10146620124578476 \n",
            "OrderedDict({'weights': tensor([0.4841]), 'bias': tensor([0.3907])})\n",
            "Epoch: 16320 | MAE Train Loss: 0.043360695242881775 | MAE Test Loss: 0.10138008743524551 \n",
            "OrderedDict({'weights': tensor([0.4843]), 'bias': tensor([0.3906])})\n",
            "Epoch: 16330 | MAE Train Loss: 0.043326374143362045 | MAE Test Loss: 0.10130427032709122 \n",
            "OrderedDict({'weights': tensor([0.4845]), 'bias': tensor([0.3905])})\n",
            "Epoch: 16340 | MAE Train Loss: 0.04329201579093933 | MAE Test Loss: 0.10122158378362656 \n",
            "OrderedDict({'weights': tensor([0.4846]), 'bias': tensor([0.3905])})\n",
            "Epoch: 16350 | MAE Train Loss: 0.04325760528445244 | MAE Test Loss: 0.10113891214132309 \n",
            "OrderedDict({'weights': tensor([0.4848]), 'bias': tensor([0.3904])})\n",
            "Epoch: 16360 | MAE Train Loss: 0.043223269283771515 | MAE Test Loss: 0.10105965286493301 \n",
            "OrderedDict({'weights': tensor([0.4850]), 'bias': tensor([0.3903])})\n",
            "Epoch: 16370 | MAE Train Loss: 0.04318889603018761 | MAE Test Loss: 0.10098383575677872 \n",
            "OrderedDict({'weights': tensor([0.4851]), 'bias': tensor([0.3902])})\n",
            "Epoch: 16380 | MAE Train Loss: 0.04315458610653877 | MAE Test Loss: 0.10090114921331406 \n",
            "OrderedDict({'weights': tensor([0.4853]), 'bias': tensor([0.3902])})\n",
            "Epoch: 16390 | MAE Train Loss: 0.04312018305063248 | MAE Test Loss: 0.10081847012042999 \n",
            "OrderedDict({'weights': tensor([0.4855]), 'bias': tensor([0.3901])})\n",
            "Epoch: 16400 | MAE Train Loss: 0.04308582842350006 | MAE Test Loss: 0.1007426381111145 \n",
            "OrderedDict({'weights': tensor([0.4857]), 'bias': tensor([0.3900])})\n",
            "Epoch: 16410 | MAE Train Loss: 0.043051499873399734 | MAE Test Loss: 0.10065996646881104 \n",
            "OrderedDict({'weights': tensor([0.4858]), 'bias': tensor([0.3900])})\n",
            "Epoch: 16420 | MAE Train Loss: 0.04301709681749344 | MAE Test Loss: 0.10057727247476578 \n",
            "OrderedDict({'weights': tensor([0.4860]), 'bias': tensor([0.3899])})\n",
            "Epoch: 16430 | MAE Train Loss: 0.04298274964094162 | MAE Test Loss: 0.10050145536661148 \n",
            "OrderedDict({'weights': tensor([0.4862]), 'bias': tensor([0.3898])})\n",
            "Epoch: 16440 | MAE Train Loss: 0.042948413640260696 | MAE Test Loss: 0.10041878372430801 \n",
            "OrderedDict({'weights': tensor([0.4863]), 'bias': tensor([0.3897])})\n",
            "Epoch: 16450 | MAE Train Loss: 0.04291405528783798 | MAE Test Loss: 0.10033953189849854 \n",
            "OrderedDict({'weights': tensor([0.4865]), 'bias': tensor([0.3897])})\n",
            "Epoch: 16460 | MAE Train Loss: 0.04287966340780258 | MAE Test Loss: 0.10025682300329208 \n",
            "OrderedDict({'weights': tensor([0.4867]), 'bias': tensor([0.3896])})\n",
            "Epoch: 16470 | MAE Train Loss: 0.04284527897834778 | MAE Test Loss: 0.10018102079629898 \n",
            "OrderedDict({'weights': tensor([0.4869]), 'bias': tensor([0.3895])})\n",
            "Epoch: 16480 | MAE Train Loss: 0.042810969054698944 | MAE Test Loss: 0.10009832680225372 \n",
            "OrderedDict({'weights': tensor([0.4870]), 'bias': tensor([0.3894])})\n",
            "Epoch: 16490 | MAE Train Loss: 0.042776577174663544 | MAE Test Loss: 0.10001564025878906 \n",
            "OrderedDict({'weights': tensor([0.4872]), 'bias': tensor([0.3894])})\n",
            "Epoch: 16500 | MAE Train Loss: 0.042742203921079636 | MAE Test Loss: 0.09993983060121536 \n",
            "OrderedDict({'weights': tensor([0.4874]), 'bias': tensor([0.3893])})\n",
            "Epoch: 16510 | MAE Train Loss: 0.042707882821559906 | MAE Test Loss: 0.0998571440577507 \n",
            "OrderedDict({'weights': tensor([0.4875]), 'bias': tensor([0.3892])})\n",
            "Epoch: 16520 | MAE Train Loss: 0.042673494666814804 | MAE Test Loss: 0.09977445751428604 \n",
            "OrderedDict({'weights': tensor([0.4877]), 'bias': tensor([0.3892])})\n",
            "Epoch: 16530 | MAE Train Loss: 0.042639121413230896 | MAE Test Loss: 0.09969864785671234 \n",
            "OrderedDict({'weights': tensor([0.4879]), 'bias': tensor([0.3891])})\n",
            "Epoch: 16540 | MAE Train Loss: 0.042604751884937286 | MAE Test Loss: 0.0996125340461731 \n",
            "OrderedDict({'weights': tensor([0.4881]), 'bias': tensor([0.3890])})\n",
            "Epoch: 16550 | MAE Train Loss: 0.04257042333483696 | MAE Test Loss: 0.0995367169380188 \n",
            "OrderedDict({'weights': tensor([0.4882]), 'bias': tensor([0.3889])})\n",
            "Epoch: 16560 | MAE Train Loss: 0.042536042630672455 | MAE Test Loss: 0.09945746511220932 \n",
            "OrderedDict({'weights': tensor([0.4884]), 'bias': tensor([0.3889])})\n",
            "Epoch: 16570 | MAE Train Loss: 0.042501725256443024 | MAE Test Loss: 0.09937477856874466 \n",
            "OrderedDict({'weights': tensor([0.4886]), 'bias': tensor([0.3888])})\n",
            "Epoch: 16580 | MAE Train Loss: 0.042467325925827026 | MAE Test Loss: 0.09929209202528 \n",
            "OrderedDict({'weights': tensor([0.4887]), 'bias': tensor([0.3887])})\n",
            "Epoch: 16590 | MAE Train Loss: 0.04243295267224312 | MAE Test Loss: 0.0992162898182869 \n",
            "OrderedDict({'weights': tensor([0.4889]), 'bias': tensor([0.3887])})\n",
            "Epoch: 16600 | MAE Train Loss: 0.04239857941865921 | MAE Test Loss: 0.09913016855716705 \n",
            "OrderedDict({'weights': tensor([0.4891]), 'bias': tensor([0.3886])})\n",
            "Epoch: 16610 | MAE Train Loss: 0.042364269495010376 | MAE Test Loss: 0.09905433654785156 \n",
            "OrderedDict({'weights': tensor([0.4892]), 'bias': tensor([0.3885])})\n",
            "Epoch: 16620 | MAE Train Loss: 0.04232989624142647 | MAE Test Loss: 0.0989716500043869 \n",
            "OrderedDict({'weights': tensor([0.4894]), 'bias': tensor([0.3884])})\n",
            "Epoch: 16630 | MAE Train Loss: 0.04229549318552017 | MAE Test Loss: 0.09888897091150284 \n",
            "OrderedDict({'weights': tensor([0.4896]), 'bias': tensor([0.3884])})\n",
            "Epoch: 16640 | MAE Train Loss: 0.04226118326187134 | MAE Test Loss: 0.09881314635276794 \n",
            "OrderedDict({'weights': tensor([0.4898]), 'bias': tensor([0.3883])})\n",
            "Epoch: 16650 | MAE Train Loss: 0.04222681373357773 | MAE Test Loss: 0.09873045980930328 \n",
            "OrderedDict({'weights': tensor([0.4899]), 'bias': tensor([0.3882])})\n",
            "Epoch: 16660 | MAE Train Loss: 0.04219241067767143 | MAE Test Loss: 0.09865464270114899 \n",
            "OrderedDict({'weights': tensor([0.4901]), 'bias': tensor([0.3882])})\n",
            "Epoch: 16670 | MAE Train Loss: 0.0421581044793129 | MAE Test Loss: 0.09857195615768433 \n",
            "OrderedDict({'weights': tensor([0.4903]), 'bias': tensor([0.3881])})\n",
            "Epoch: 16680 | MAE Train Loss: 0.04212372750043869 | MAE Test Loss: 0.09848928451538086 \n",
            "OrderedDict({'weights': tensor([0.4904]), 'bias': tensor([0.3880])})\n",
            "Epoch: 16690 | MAE Train Loss: 0.04208938032388687 | MAE Test Loss: 0.09841003268957138 \n",
            "OrderedDict({'weights': tensor([0.4906]), 'bias': tensor([0.3879])})\n",
            "Epoch: 16700 | MAE Train Loss: 0.042054977267980576 | MAE Test Loss: 0.09832734614610672 \n",
            "OrderedDict({'weights': tensor([0.4908]), 'bias': tensor([0.3879])})\n",
            "Epoch: 16710 | MAE Train Loss: 0.042020637542009354 | MAE Test Loss: 0.09825151413679123 \n",
            "OrderedDict({'weights': tensor([0.4910]), 'bias': tensor([0.3878])})\n",
            "Epoch: 16720 | MAE Train Loss: 0.041986286640167236 | MAE Test Loss: 0.09816885739564896 \n",
            "OrderedDict({'weights': tensor([0.4911]), 'bias': tensor([0.3877])})\n",
            "Epoch: 16730 | MAE Train Loss: 0.04195188730955124 | MAE Test Loss: 0.0980861559510231 \n",
            "OrderedDict({'weights': tensor([0.4913]), 'bias': tensor([0.3877])})\n",
            "Epoch: 16740 | MAE Train Loss: 0.04191755875945091 | MAE Test Loss: 0.0980103388428688 \n",
            "OrderedDict({'weights': tensor([0.4915]), 'bias': tensor([0.3876])})\n",
            "Epoch: 16750 | MAE Train Loss: 0.04188321903347969 | MAE Test Loss: 0.09792764484882355 \n",
            "OrderedDict({'weights': tensor([0.4916]), 'bias': tensor([0.3875])})\n",
            "Epoch: 16760 | MAE Train Loss: 0.0418488010764122 | MAE Test Loss: 0.09784496575593948 \n",
            "OrderedDict({'weights': tensor([0.4918]), 'bias': tensor([0.3874])})\n",
            "Epoch: 16770 | MAE Train Loss: 0.04181447625160217 | MAE Test Loss: 0.09776915609836578 \n",
            "OrderedDict({'weights': tensor([0.4920]), 'bias': tensor([0.3874])})\n",
            "Epoch: 16780 | MAE Train Loss: 0.04178009182214737 | MAE Test Loss: 0.09768989682197571 \n",
            "OrderedDict({'weights': tensor([0.4922]), 'bias': tensor([0.3873])})\n",
            "Epoch: 16790 | MAE Train Loss: 0.04174571856856346 | MAE Test Loss: 0.09760378301143646 \n",
            "OrderedDict({'weights': tensor([0.4923]), 'bias': tensor([0.3872])})\n",
            "Epoch: 16800 | MAE Train Loss: 0.04171139746904373 | MAE Test Loss: 0.09752795100212097 \n",
            "OrderedDict({'weights': tensor([0.4925]), 'bias': tensor([0.3871])})\n",
            "Epoch: 16810 | MAE Train Loss: 0.04167703911662102 | MAE Test Loss: 0.09744527190923691 \n",
            "OrderedDict({'weights': tensor([0.4927]), 'bias': tensor([0.3871])})\n",
            "Epoch: 16820 | MAE Train Loss: 0.041642628610134125 | MAE Test Loss: 0.09736260026693344 \n",
            "OrderedDict({'weights': tensor([0.4928]), 'bias': tensor([0.3870])})\n",
            "Epoch: 16830 | MAE Train Loss: 0.0416082926094532 | MAE Test Loss: 0.09728334844112396 \n",
            "OrderedDict({'weights': tensor([0.4930]), 'bias': tensor([0.3869])})\n",
            "Epoch: 16840 | MAE Train Loss: 0.04157391935586929 | MAE Test Loss: 0.09720752388238907 \n",
            "OrderedDict({'weights': tensor([0.4932]), 'bias': tensor([0.3869])})\n",
            "Epoch: 16850 | MAE Train Loss: 0.04153960943222046 | MAE Test Loss: 0.09712483733892441 \n",
            "OrderedDict({'weights': tensor([0.4934]), 'bias': tensor([0.3868])})\n",
            "Epoch: 16860 | MAE Train Loss: 0.04150520637631416 | MAE Test Loss: 0.09704215079545975 \n",
            "OrderedDict({'weights': tensor([0.4935]), 'bias': tensor([0.3867])})\n",
            "Epoch: 16870 | MAE Train Loss: 0.04147085174918175 | MAE Test Loss: 0.09696632623672485 \n",
            "OrderedDict({'weights': tensor([0.4937]), 'bias': tensor([0.3866])})\n",
            "Epoch: 16880 | MAE Train Loss: 0.04143652319908142 | MAE Test Loss: 0.09688365459442139 \n",
            "OrderedDict({'weights': tensor([0.4939]), 'bias': tensor([0.3866])})\n",
            "Epoch: 16890 | MAE Train Loss: 0.041402120143175125 | MAE Test Loss: 0.09680096060037613 \n",
            "OrderedDict({'weights': tensor([0.4940]), 'bias': tensor([0.3865])})\n",
            "Epoch: 16900 | MAE Train Loss: 0.041367776691913605 | MAE Test Loss: 0.09672514349222183 \n",
            "OrderedDict({'weights': tensor([0.4942]), 'bias': tensor([0.3864])})\n",
            "Epoch: 16910 | MAE Train Loss: 0.04133343696594238 | MAE Test Loss: 0.09664246439933777 \n",
            "OrderedDict({'weights': tensor([0.4944]), 'bias': tensor([0.3864])})\n",
            "Epoch: 16920 | MAE Train Loss: 0.04129908233880997 | MAE Test Loss: 0.09656321257352829 \n",
            "OrderedDict({'weights': tensor([0.4945]), 'bias': tensor([0.3863])})\n",
            "Epoch: 16930 | MAE Train Loss: 0.04126469045877457 | MAE Test Loss: 0.09648051857948303 \n",
            "OrderedDict({'weights': tensor([0.4947]), 'bias': tensor([0.3862])})\n",
            "Epoch: 16940 | MAE Train Loss: 0.041230302304029465 | MAE Test Loss: 0.09640470892190933 \n",
            "OrderedDict({'weights': tensor([0.4949]), 'bias': tensor([0.3861])})\n",
            "Epoch: 16950 | MAE Train Loss: 0.04119599610567093 | MAE Test Loss: 0.09632201492786407 \n",
            "OrderedDict({'weights': tensor([0.4951]), 'bias': tensor([0.3861])})\n",
            "Epoch: 16960 | MAE Train Loss: 0.04116160422563553 | MAE Test Loss: 0.09623933583498001 \n",
            "OrderedDict({'weights': tensor([0.4952]), 'bias': tensor([0.3860])})\n",
            "Epoch: 16970 | MAE Train Loss: 0.04112722724676132 | MAE Test Loss: 0.09616351872682571 \n",
            "OrderedDict({'weights': tensor([0.4954]), 'bias': tensor([0.3859])})\n",
            "Epoch: 16980 | MAE Train Loss: 0.04109290987253189 | MAE Test Loss: 0.09608083218336105 \n",
            "OrderedDict({'weights': tensor([0.4956]), 'bias': tensor([0.3859])})\n",
            "Epoch: 16990 | MAE Train Loss: 0.04105851799249649 | MAE Test Loss: 0.09599814563989639 \n",
            "OrderedDict({'weights': tensor([0.4957]), 'bias': tensor([0.3858])})\n",
            "Epoch: 17000 | MAE Train Loss: 0.04102414473891258 | MAE Test Loss: 0.09592233598232269 \n",
            "OrderedDict({'weights': tensor([0.4959]), 'bias': tensor([0.3857])})\n",
            "Epoch: 17010 | MAE Train Loss: 0.04098977521061897 | MAE Test Loss: 0.09583622217178345 \n",
            "OrderedDict({'weights': tensor([0.4961]), 'bias': tensor([0.3856])})\n",
            "Epoch: 17020 | MAE Train Loss: 0.040955446660518646 | MAE Test Loss: 0.09576040506362915 \n",
            "OrderedDict({'weights': tensor([0.4963]), 'bias': tensor([0.3856])})\n",
            "Epoch: 17030 | MAE Train Loss: 0.04092106968164444 | MAE Test Loss: 0.09568115323781967 \n",
            "OrderedDict({'weights': tensor([0.4964]), 'bias': tensor([0.3855])})\n",
            "Epoch: 17040 | MAE Train Loss: 0.04088675230741501 | MAE Test Loss: 0.09559846669435501 \n",
            "OrderedDict({'weights': tensor([0.4966]), 'bias': tensor([0.3854])})\n",
            "Epoch: 17050 | MAE Train Loss: 0.04085234925150871 | MAE Test Loss: 0.09551578015089035 \n",
            "OrderedDict({'weights': tensor([0.4968]), 'bias': tensor([0.3854])})\n",
            "Epoch: 17060 | MAE Train Loss: 0.040817975997924805 | MAE Test Loss: 0.09543997794389725 \n",
            "OrderedDict({'weights': tensor([0.4969]), 'bias': tensor([0.3853])})\n",
            "Epoch: 17070 | MAE Train Loss: 0.0407836027443409 | MAE Test Loss: 0.0953538566827774 \n",
            "OrderedDict({'weights': tensor([0.4971]), 'bias': tensor([0.3852])})\n",
            "Epoch: 17080 | MAE Train Loss: 0.04074929282069206 | MAE Test Loss: 0.09527802467346191 \n",
            "OrderedDict({'weights': tensor([0.4973]), 'bias': tensor([0.3851])})\n",
            "Epoch: 17090 | MAE Train Loss: 0.040714919567108154 | MAE Test Loss: 0.09519533812999725 \n",
            "OrderedDict({'weights': tensor([0.4975]), 'bias': tensor([0.3851])})\n",
            "Epoch: 17100 | MAE Train Loss: 0.04068051651120186 | MAE Test Loss: 0.09511265903711319 \n",
            "OrderedDict({'weights': tensor([0.4976]), 'bias': tensor([0.3850])})\n",
            "Epoch: 17110 | MAE Train Loss: 0.040646206587553024 | MAE Test Loss: 0.0950368344783783 \n",
            "OrderedDict({'weights': tensor([0.4978]), 'bias': tensor([0.3849])})\n",
            "Epoch: 17120 | MAE Train Loss: 0.04061184078454971 | MAE Test Loss: 0.09495414793491364 \n",
            "OrderedDict({'weights': tensor([0.4980]), 'bias': tensor([0.3849])})\n",
            "Epoch: 17130 | MAE Train Loss: 0.04057743400335312 | MAE Test Loss: 0.09487833082675934 \n",
            "OrderedDict({'weights': tensor([0.4981]), 'bias': tensor([0.3848])})\n",
            "Epoch: 17140 | MAE Train Loss: 0.04054313153028488 | MAE Test Loss: 0.09479564428329468 \n",
            "OrderedDict({'weights': tensor([0.4983]), 'bias': tensor([0.3847])})\n",
            "Epoch: 17150 | MAE Train Loss: 0.04050875082612038 | MAE Test Loss: 0.09471297264099121 \n",
            "OrderedDict({'weights': tensor([0.4985]), 'bias': tensor([0.3846])})\n",
            "Epoch: 17160 | MAE Train Loss: 0.04047440364956856 | MAE Test Loss: 0.09463372081518173 \n",
            "OrderedDict({'weights': tensor([0.4987]), 'bias': tensor([0.3846])})\n",
            "Epoch: 17170 | MAE Train Loss: 0.04044000059366226 | MAE Test Loss: 0.09455103427171707 \n",
            "OrderedDict({'weights': tensor([0.4988]), 'bias': tensor([0.3845])})\n",
            "Epoch: 17180 | MAE Train Loss: 0.04040566086769104 | MAE Test Loss: 0.09447520226240158 \n",
            "OrderedDict({'weights': tensor([0.4990]), 'bias': tensor([0.3844])})\n",
            "Epoch: 17190 | MAE Train Loss: 0.04037130996584892 | MAE Test Loss: 0.09439254552125931 \n",
            "OrderedDict({'weights': tensor([0.4992]), 'bias': tensor([0.3844])})\n",
            "Epoch: 17200 | MAE Train Loss: 0.040336914360523224 | MAE Test Loss: 0.09430984407663345 \n",
            "OrderedDict({'weights': tensor([0.4993]), 'bias': tensor([0.3843])})\n",
            "Epoch: 17210 | MAE Train Loss: 0.0403025820851326 | MAE Test Loss: 0.09423402696847916 \n",
            "OrderedDict({'weights': tensor([0.4995]), 'bias': tensor([0.3842])})\n",
            "Epoch: 17220 | MAE Train Loss: 0.04026824235916138 | MAE Test Loss: 0.0941513329744339 \n",
            "OrderedDict({'weights': tensor([0.4997]), 'bias': tensor([0.3841])})\n",
            "Epoch: 17230 | MAE Train Loss: 0.040233828127384186 | MAE Test Loss: 0.09406865388154984 \n",
            "OrderedDict({'weights': tensor([0.4998]), 'bias': tensor([0.3841])})\n",
            "Epoch: 17240 | MAE Train Loss: 0.04019949957728386 | MAE Test Loss: 0.09399284422397614 \n",
            "OrderedDict({'weights': tensor([0.5000]), 'bias': tensor([0.3840])})\n",
            "Epoch: 17250 | MAE Train Loss: 0.040165118873119354 | MAE Test Loss: 0.09391360729932785 \n",
            "OrderedDict({'weights': tensor([0.5002]), 'bias': tensor([0.3839])})\n",
            "Epoch: 17260 | MAE Train Loss: 0.04013075679540634 | MAE Test Loss: 0.0938275158405304 \n",
            "OrderedDict({'weights': tensor([0.5004]), 'bias': tensor([0.3838])})\n",
            "Epoch: 17270 | MAE Train Loss: 0.040096431970596313 | MAE Test Loss: 0.0937517061829567 \n",
            "OrderedDict({'weights': tensor([0.5005]), 'bias': tensor([0.3838])})\n",
            "Epoch: 17280 | MAE Train Loss: 0.0400620736181736 | MAE Test Loss: 0.09366901218891144 \n",
            "OrderedDict({'weights': tensor([0.5007]), 'bias': tensor([0.3837])})\n",
            "Epoch: 17290 | MAE Train Loss: 0.0400276705622673 | MAE Test Loss: 0.09358632564544678 \n",
            "OrderedDict({'weights': tensor([0.5009]), 'bias': tensor([0.3836])})\n",
            "Epoch: 17300 | MAE Train Loss: 0.03999333083629608 | MAE Test Loss: 0.09350710362195969 \n",
            "OrderedDict({'weights': tensor([0.5010]), 'bias': tensor([0.3836])})\n",
            "Epoch: 17310 | MAE Train Loss: 0.03995897248387337 | MAE Test Loss: 0.0934312641620636 \n",
            "OrderedDict({'weights': tensor([0.5012]), 'bias': tensor([0.3835])})\n",
            "Epoch: 17320 | MAE Train Loss: 0.03992459923028946 | MAE Test Loss: 0.09334520995616913 \n",
            "OrderedDict({'weights': tensor([0.5014]), 'bias': tensor([0.3834])})\n",
            "Epoch: 17330 | MAE Train Loss: 0.03989028558135033 | MAE Test Loss: 0.09326937794685364 \n",
            "OrderedDict({'weights': tensor([0.5016]), 'bias': tensor([0.3833])})\n",
            "Epoch: 17340 | MAE Train Loss: 0.03985590860247612 | MAE Test Loss: 0.09318669885396957 \n",
            "OrderedDict({'weights': tensor([0.5017]), 'bias': tensor([0.3833])})\n",
            "Epoch: 17350 | MAE Train Loss: 0.039821501821279526 | MAE Test Loss: 0.09310746937990189 \n",
            "OrderedDict({'weights': tensor([0.5019]), 'bias': tensor([0.3832])})\n",
            "Epoch: 17360 | MAE Train Loss: 0.0397871658205986 | MAE Test Loss: 0.09302478283643723 \n",
            "OrderedDict({'weights': tensor([0.5021]), 'bias': tensor([0.3831])})\n",
            "Epoch: 17370 | MAE Train Loss: 0.03975283354520798 | MAE Test Loss: 0.09294556081295013 \n",
            "OrderedDict({'weights': tensor([0.5022]), 'bias': tensor([0.3831])})\n",
            "Epoch: 17380 | MAE Train Loss: 0.03971843048930168 | MAE Test Loss: 0.09286974370479584 \n",
            "OrderedDict({'weights': tensor([0.5024]), 'bias': tensor([0.3830])})\n",
            "Epoch: 17390 | MAE Train Loss: 0.03968413546681404 | MAE Test Loss: 0.09278705716133118 \n",
            "OrderedDict({'weights': tensor([0.5026]), 'bias': tensor([0.3829])})\n",
            "Epoch: 17400 | MAE Train Loss: 0.03964974731206894 | MAE Test Loss: 0.09270438551902771 \n",
            "OrderedDict({'weights': tensor([0.5028]), 'bias': tensor([0.3828])})\n",
            "Epoch: 17410 | MAE Train Loss: 0.039615415036678314 | MAE Test Loss: 0.09262514114379883 \n",
            "OrderedDict({'weights': tensor([0.5029]), 'bias': tensor([0.3828])})\n",
            "Epoch: 17420 | MAE Train Loss: 0.0395810641348362 | MAE Test Loss: 0.09254591912031174 \n",
            "OrderedDict({'weights': tensor([0.5031]), 'bias': tensor([0.3827])})\n",
            "Epoch: 17430 | MAE Train Loss: 0.03954667970538139 | MAE Test Loss: 0.09246324002742767 \n",
            "OrderedDict({'weights': tensor([0.5033]), 'bias': tensor([0.3826])})\n",
            "Epoch: 17440 | MAE Train Loss: 0.03951228782534599 | MAE Test Loss: 0.09238742291927338 \n",
            "OrderedDict({'weights': tensor([0.5034]), 'bias': tensor([0.3826])})\n",
            "Epoch: 17450 | MAE Train Loss: 0.03947798162698746 | MAE Test Loss: 0.09230474382638931 \n",
            "OrderedDict({'weights': tensor([0.5036]), 'bias': tensor([0.3825])})\n",
            "Epoch: 17460 | MAE Train Loss: 0.03944360092282295 | MAE Test Loss: 0.09222551435232162 \n",
            "OrderedDict({'weights': tensor([0.5038]), 'bias': tensor([0.3824])})\n",
            "Epoch: 17470 | MAE Train Loss: 0.039409246295690536 | MAE Test Loss: 0.09214281290769577 \n",
            "OrderedDict({'weights': tensor([0.5040]), 'bias': tensor([0.3823])})\n",
            "Epoch: 17480 | MAE Train Loss: 0.03937489911913872 | MAE Test Loss: 0.09206359833478928 \n",
            "OrderedDict({'weights': tensor([0.5041]), 'bias': tensor([0.3823])})\n",
            "Epoch: 17490 | MAE Train Loss: 0.039340510964393616 | MAE Test Loss: 0.09198091179132462 \n",
            "OrderedDict({'weights': tensor([0.5043]), 'bias': tensor([0.3822])})\n",
            "Epoch: 17500 | MAE Train Loss: 0.03930613771080971 | MAE Test Loss: 0.09190510213375092 \n",
            "OrderedDict({'weights': tensor([0.5045]), 'bias': tensor([0.3821])})\n",
            "Epoch: 17510 | MAE Train Loss: 0.039271771907806396 | MAE Test Loss: 0.09181901067495346 \n",
            "OrderedDict({'weights': tensor([0.5046]), 'bias': tensor([0.3821])})\n",
            "Epoch: 17520 | MAE Train Loss: 0.03923744708299637 | MAE Test Loss: 0.09174320101737976 \n",
            "OrderedDict({'weights': tensor([0.5048]), 'bias': tensor([0.3820])})\n",
            "Epoch: 17530 | MAE Train Loss: 0.03920306637883186 | MAE Test Loss: 0.09166395664215088 \n",
            "OrderedDict({'weights': tensor([0.5050]), 'bias': tensor([0.3819])})\n",
            "Epoch: 17540 | MAE Train Loss: 0.03916875272989273 | MAE Test Loss: 0.09158127009868622 \n",
            "OrderedDict({'weights': tensor([0.5051]), 'bias': tensor([0.3818])})\n",
            "Epoch: 17550 | MAE Train Loss: 0.039134349673986435 | MAE Test Loss: 0.09149859845638275 \n",
            "OrderedDict({'weights': tensor([0.5053]), 'bias': tensor([0.3818])})\n",
            "Epoch: 17560 | MAE Train Loss: 0.039099980145692825 | MAE Test Loss: 0.09142276644706726 \n",
            "OrderedDict({'weights': tensor([0.5055]), 'bias': tensor([0.3817])})\n",
            "Epoch: 17570 | MAE Train Loss: 0.039065610617399216 | MAE Test Loss: 0.0913366749882698 \n",
            "OrderedDict({'weights': tensor([0.5057]), 'bias': tensor([0.3816])})\n",
            "Epoch: 17580 | MAE Train Loss: 0.03903127834200859 | MAE Test Loss: 0.09125746786594391 \n",
            "OrderedDict({'weights': tensor([0.5058]), 'bias': tensor([0.3816])})\n",
            "Epoch: 17590 | MAE Train Loss: 0.03899691253900528 | MAE Test Loss: 0.09118162840604782 \n",
            "OrderedDict({'weights': tensor([0.5060]), 'bias': tensor([0.3815])})\n",
            "Epoch: 17600 | MAE Train Loss: 0.03896259516477585 | MAE Test Loss: 0.09109897166490555 \n",
            "OrderedDict({'weights': tensor([0.5062]), 'bias': tensor([0.3814])})\n",
            "Epoch: 17610 | MAE Train Loss: 0.03892819210886955 | MAE Test Loss: 0.09101627767086029 \n",
            "OrderedDict({'weights': tensor([0.5063]), 'bias': tensor([0.3813])})\n",
            "Epoch: 17620 | MAE Train Loss: 0.03889385610818863 | MAE Test Loss: 0.0909370556473732 \n",
            "OrderedDict({'weights': tensor([0.5065]), 'bias': tensor([0.3813])})\n",
            "Epoch: 17630 | MAE Train Loss: 0.03885945677757263 | MAE Test Loss: 0.09085782617330551 \n",
            "OrderedDict({'weights': tensor([0.5067]), 'bias': tensor([0.3812])})\n",
            "Epoch: 17640 | MAE Train Loss: 0.03882511332631111 | MAE Test Loss: 0.09077514708042145 \n",
            "OrderedDict({'weights': tensor([0.5069]), 'bias': tensor([0.3811])})\n",
            "Epoch: 17650 | MAE Train Loss: 0.0387907549738884 | MAE Test Loss: 0.09069932997226715 \n",
            "OrderedDict({'weights': tensor([0.5070]), 'bias': tensor([0.3810])})\n",
            "Epoch: 17660 | MAE Train Loss: 0.03875643387436867 | MAE Test Loss: 0.0906166359782219 \n",
            "OrderedDict({'weights': tensor([0.5072]), 'bias': tensor([0.3810])})\n",
            "Epoch: 17670 | MAE Train Loss: 0.03872207552194595 | MAE Test Loss: 0.0905374139547348 \n",
            "OrderedDict({'weights': tensor([0.5074]), 'bias': tensor([0.3809])})\n",
            "Epoch: 17680 | MAE Train Loss: 0.03868768736720085 | MAE Test Loss: 0.09045473486185074 \n",
            "OrderedDict({'weights': tensor([0.5075]), 'bias': tensor([0.3808])})\n",
            "Epoch: 17690 | MAE Train Loss: 0.038653355091810226 | MAE Test Loss: 0.09037549048662186 \n",
            "OrderedDict({'weights': tensor([0.5077]), 'bias': tensor([0.3808])})\n",
            "Epoch: 17700 | MAE Train Loss: 0.038618944585323334 | MAE Test Loss: 0.09029281139373779 \n",
            "OrderedDict({'weights': tensor([0.5079]), 'bias': tensor([0.3807])})\n",
            "Epoch: 17710 | MAE Train Loss: 0.03858460858464241 | MAE Test Loss: 0.09021700173616409 \n",
            "OrderedDict({'weights': tensor([0.5081]), 'bias': tensor([0.3806])})\n",
            "Epoch: 17720 | MAE Train Loss: 0.038550276309251785 | MAE Test Loss: 0.09013429284095764 \n",
            "OrderedDict({'weights': tensor([0.5082]), 'bias': tensor([0.3805])})\n",
            "Epoch: 17730 | MAE Train Loss: 0.038515932857990265 | MAE Test Loss: 0.09005509316921234 \n",
            "OrderedDict({'weights': tensor([0.5084]), 'bias': tensor([0.3805])})\n",
            "Epoch: 17740 | MAE Train Loss: 0.038481540977954865 | MAE Test Loss: 0.08997587114572525 \n",
            "OrderedDict({'weights': tensor([0.5086]), 'bias': tensor([0.3804])})\n",
            "Epoch: 17750 | MAE Train Loss: 0.03844720125198364 | MAE Test Loss: 0.08989317715167999 \n",
            "OrderedDict({'weights': tensor([0.5087]), 'bias': tensor([0.3803])})\n",
            "Epoch: 17760 | MAE Train Loss: 0.03841278702020645 | MAE Test Loss: 0.08981049805879593 \n",
            "OrderedDict({'weights': tensor([0.5089]), 'bias': tensor([0.3803])})\n",
            "Epoch: 17770 | MAE Train Loss: 0.038378458470106125 | MAE Test Loss: 0.08973468840122223 \n",
            "OrderedDict({'weights': tensor([0.5091]), 'bias': tensor([0.3802])})\n",
            "Epoch: 17780 | MAE Train Loss: 0.03834407776594162 | MAE Test Loss: 0.08965545147657394 \n",
            "OrderedDict({'weights': tensor([0.5092]), 'bias': tensor([0.3801])})\n",
            "Epoch: 17790 | MAE Train Loss: 0.03830971568822861 | MAE Test Loss: 0.08956936001777649 \n",
            "OrderedDict({'weights': tensor([0.5094]), 'bias': tensor([0.3800])})\n",
            "Epoch: 17800 | MAE Train Loss: 0.03827539086341858 | MAE Test Loss: 0.08949355036020279 \n",
            "OrderedDict({'weights': tensor([0.5096]), 'bias': tensor([0.3800])})\n",
            "Epoch: 17810 | MAE Train Loss: 0.038241032510995865 | MAE Test Loss: 0.08941085636615753 \n",
            "OrderedDict({'weights': tensor([0.5098]), 'bias': tensor([0.3799])})\n",
            "Epoch: 17820 | MAE Train Loss: 0.03820662945508957 | MAE Test Loss: 0.08932816982269287 \n",
            "OrderedDict({'weights': tensor([0.5099]), 'bias': tensor([0.3798])})\n",
            "Epoch: 17830 | MAE Train Loss: 0.03817228972911835 | MAE Test Loss: 0.08924894779920578 \n",
            "OrderedDict({'weights': tensor([0.5101]), 'bias': tensor([0.3798])})\n",
            "Epoch: 17840 | MAE Train Loss: 0.03813793137669563 | MAE Test Loss: 0.08917310833930969 \n",
            "OrderedDict({'weights': tensor([0.5103]), 'bias': tensor([0.3797])})\n",
            "Epoch: 17850 | MAE Train Loss: 0.038103558123111725 | MAE Test Loss: 0.08908705413341522 \n",
            "OrderedDict({'weights': tensor([0.5104]), 'bias': tensor([0.3796])})\n",
            "Epoch: 17860 | MAE Train Loss: 0.03806924447417259 | MAE Test Loss: 0.08901122957468033 \n",
            "OrderedDict({'weights': tensor([0.5106]), 'bias': tensor([0.3795])})\n",
            "Epoch: 17870 | MAE Train Loss: 0.038034867495298386 | MAE Test Loss: 0.08892853558063507 \n",
            "OrderedDict({'weights': tensor([0.5108]), 'bias': tensor([0.3795])})\n",
            "Epoch: 17880 | MAE Train Loss: 0.03800046071410179 | MAE Test Loss: 0.08884931355714798 \n",
            "OrderedDict({'weights': tensor([0.5110]), 'bias': tensor([0.3794])})\n",
            "Epoch: 17890 | MAE Train Loss: 0.03796612471342087 | MAE Test Loss: 0.08876662701368332 \n",
            "OrderedDict({'weights': tensor([0.5111]), 'bias': tensor([0.3793])})\n",
            "Epoch: 17900 | MAE Train Loss: 0.03793179243803024 | MAE Test Loss: 0.08868740499019623 \n",
            "OrderedDict({'weights': tensor([0.5113]), 'bias': tensor([0.3793])})\n",
            "Epoch: 17910 | MAE Train Loss: 0.03789738938212395 | MAE Test Loss: 0.08861158043146133 \n",
            "OrderedDict({'weights': tensor([0.5115]), 'bias': tensor([0.3792])})\n",
            "Epoch: 17920 | MAE Train Loss: 0.03786309435963631 | MAE Test Loss: 0.08852890133857727 \n",
            "OrderedDict({'weights': tensor([0.5116]), 'bias': tensor([0.3791])})\n",
            "Epoch: 17930 | MAE Train Loss: 0.037828706204891205 | MAE Test Loss: 0.0884462296962738 \n",
            "OrderedDict({'weights': tensor([0.5118]), 'bias': tensor([0.3790])})\n",
            "Epoch: 17940 | MAE Train Loss: 0.03779437392950058 | MAE Test Loss: 0.08836699277162552 \n",
            "OrderedDict({'weights': tensor([0.5120]), 'bias': tensor([0.3790])})\n",
            "Epoch: 17950 | MAE Train Loss: 0.03776002302765846 | MAE Test Loss: 0.08828776329755783 \n",
            "OrderedDict({'weights': tensor([0.5122]), 'bias': tensor([0.3789])})\n",
            "Epoch: 17960 | MAE Train Loss: 0.03772563859820366 | MAE Test Loss: 0.08820508420467377 \n",
            "OrderedDict({'weights': tensor([0.5123]), 'bias': tensor([0.3788])})\n",
            "Epoch: 17970 | MAE Train Loss: 0.03769124671816826 | MAE Test Loss: 0.08812926709651947 \n",
            "OrderedDict({'weights': tensor([0.5125]), 'bias': tensor([0.3787])})\n",
            "Epoch: 17980 | MAE Train Loss: 0.03765694051980972 | MAE Test Loss: 0.0880465880036354 \n",
            "OrderedDict({'weights': tensor([0.5127]), 'bias': tensor([0.3787])})\n",
            "Epoch: 17990 | MAE Train Loss: 0.03762255236506462 | MAE Test Loss: 0.08796735107898712 \n",
            "OrderedDict({'weights': tensor([0.5128]), 'bias': tensor([0.3786])})\n",
            "Epoch: 18000 | MAE Train Loss: 0.0375882051885128 | MAE Test Loss: 0.08788465708494186 \n",
            "OrderedDict({'weights': tensor([0.5130]), 'bias': tensor([0.3785])})\n",
            "Epoch: 18010 | MAE Train Loss: 0.03755385801196098 | MAE Test Loss: 0.08780544251203537 \n",
            "OrderedDict({'weights': tensor([0.5132]), 'bias': tensor([0.3785])})\n",
            "Epoch: 18020 | MAE Train Loss: 0.03751946985721588 | MAE Test Loss: 0.0877227634191513 \n",
            "OrderedDict({'weights': tensor([0.5134]), 'bias': tensor([0.3784])})\n",
            "Epoch: 18030 | MAE Train Loss: 0.03748509660363197 | MAE Test Loss: 0.08764694631099701 \n",
            "OrderedDict({'weights': tensor([0.5135]), 'bias': tensor([0.3783])})\n",
            "Epoch: 18040 | MAE Train Loss: 0.03745073080062866 | MAE Test Loss: 0.08756085485219955 \n",
            "OrderedDict({'weights': tensor([0.5137]), 'bias': tensor([0.3782])})\n",
            "Epoch: 18050 | MAE Train Loss: 0.037416405975818634 | MAE Test Loss: 0.08748504519462585 \n",
            "OrderedDict({'weights': tensor([0.5139]), 'bias': tensor([0.3782])})\n",
            "Epoch: 18060 | MAE Train Loss: 0.03738202527165413 | MAE Test Loss: 0.08740580826997757 \n",
            "OrderedDict({'weights': tensor([0.5140]), 'bias': tensor([0.3781])})\n",
            "Epoch: 18070 | MAE Train Loss: 0.037347711622714996 | MAE Test Loss: 0.08732311427593231 \n",
            "OrderedDict({'weights': tensor([0.5142]), 'bias': tensor([0.3780])})\n",
            "Epoch: 18080 | MAE Train Loss: 0.0373133085668087 | MAE Test Loss: 0.08724044263362885 \n",
            "OrderedDict({'weights': tensor([0.5144]), 'bias': tensor([0.3780])})\n",
            "Epoch: 18090 | MAE Train Loss: 0.03727893903851509 | MAE Test Loss: 0.08716461062431335 \n",
            "OrderedDict({'weights': tensor([0.5145]), 'bias': tensor([0.3779])})\n",
            "Epoch: 18100 | MAE Train Loss: 0.03724456951022148 | MAE Test Loss: 0.0870785266160965 \n",
            "OrderedDict({'weights': tensor([0.5147]), 'bias': tensor([0.3778])})\n",
            "Epoch: 18110 | MAE Train Loss: 0.037210237234830856 | MAE Test Loss: 0.08699931204319 \n",
            "OrderedDict({'weights': tensor([0.5149]), 'bias': tensor([0.3777])})\n",
            "Epoch: 18120 | MAE Train Loss: 0.037175871431827545 | MAE Test Loss: 0.08692347258329391 \n",
            "OrderedDict({'weights': tensor([0.5151]), 'bias': tensor([0.3777])})\n",
            "Epoch: 18130 | MAE Train Loss: 0.037141554057598114 | MAE Test Loss: 0.08684081584215164 \n",
            "OrderedDict({'weights': tensor([0.5152]), 'bias': tensor([0.3776])})\n",
            "Epoch: 18140 | MAE Train Loss: 0.03710715100169182 | MAE Test Loss: 0.08675812184810638 \n",
            "OrderedDict({'weights': tensor([0.5154]), 'bias': tensor([0.3775])})\n",
            "Epoch: 18150 | MAE Train Loss: 0.037072815001010895 | MAE Test Loss: 0.0866788923740387 \n",
            "OrderedDict({'weights': tensor([0.5156]), 'bias': tensor([0.3775])})\n",
            "Epoch: 18160 | MAE Train Loss: 0.0370384156703949 | MAE Test Loss: 0.0865996703505516 \n",
            "OrderedDict({'weights': tensor([0.5157]), 'bias': tensor([0.3774])})\n",
            "Epoch: 18170 | MAE Train Loss: 0.03700407221913338 | MAE Test Loss: 0.08651699125766754 \n",
            "OrderedDict({'weights': tensor([0.5159]), 'bias': tensor([0.3773])})\n",
            "Epoch: 18180 | MAE Train Loss: 0.03696971386671066 | MAE Test Loss: 0.08644117414951324 \n",
            "OrderedDict({'weights': tensor([0.5161]), 'bias': tensor([0.3772])})\n",
            "Epoch: 18190 | MAE Train Loss: 0.03693539276719093 | MAE Test Loss: 0.08635848760604858 \n",
            "OrderedDict({'weights': tensor([0.5163]), 'bias': tensor([0.3772])})\n",
            "Epoch: 18200 | MAE Train Loss: 0.03690103441476822 | MAE Test Loss: 0.0862792581319809 \n",
            "OrderedDict({'weights': tensor([0.5164]), 'bias': tensor([0.3771])})\n",
            "Epoch: 18210 | MAE Train Loss: 0.03686664626002312 | MAE Test Loss: 0.08619657903909683 \n",
            "OrderedDict({'weights': tensor([0.5166]), 'bias': tensor([0.3770])})\n",
            "Epoch: 18220 | MAE Train Loss: 0.03683231398463249 | MAE Test Loss: 0.08611734211444855 \n",
            "OrderedDict({'weights': tensor([0.5168]), 'bias': tensor([0.3770])})\n",
            "Epoch: 18230 | MAE Train Loss: 0.0367979034781456 | MAE Test Loss: 0.08603464812040329 \n",
            "OrderedDict({'weights': tensor([0.5169]), 'bias': tensor([0.3769])})\n",
            "Epoch: 18240 | MAE Train Loss: 0.036763567477464676 | MAE Test Loss: 0.08595884591341019 \n",
            "OrderedDict({'weights': tensor([0.5171]), 'bias': tensor([0.3768])})\n",
            "Epoch: 18250 | MAE Train Loss: 0.03672923520207405 | MAE Test Loss: 0.08587613701820374 \n",
            "OrderedDict({'weights': tensor([0.5173]), 'bias': tensor([0.3767])})\n",
            "Epoch: 18260 | MAE Train Loss: 0.03669489175081253 | MAE Test Loss: 0.08579693734645844 \n",
            "OrderedDict({'weights': tensor([0.5175]), 'bias': tensor([0.3767])})\n",
            "Epoch: 18270 | MAE Train Loss: 0.03666049987077713 | MAE Test Loss: 0.08571770787239075 \n",
            "OrderedDict({'weights': tensor([0.5176]), 'bias': tensor([0.3766])})\n",
            "Epoch: 18280 | MAE Train Loss: 0.03662616014480591 | MAE Test Loss: 0.08563502132892609 \n",
            "OrderedDict({'weights': tensor([0.5178]), 'bias': tensor([0.3765])})\n",
            "Epoch: 18290 | MAE Train Loss: 0.03659174591302872 | MAE Test Loss: 0.08555234223604202 \n",
            "OrderedDict({'weights': tensor([0.5180]), 'bias': tensor([0.3765])})\n",
            "Epoch: 18300 | MAE Train Loss: 0.03655741736292839 | MAE Test Loss: 0.08547653257846832 \n",
            "OrderedDict({'weights': tensor([0.5181]), 'bias': tensor([0.3764])})\n",
            "Epoch: 18310 | MAE Train Loss: 0.036523036658763885 | MAE Test Loss: 0.08539730310440063 \n",
            "OrderedDict({'weights': tensor([0.5183]), 'bias': tensor([0.3763])})\n",
            "Epoch: 18320 | MAE Train Loss: 0.03648867458105087 | MAE Test Loss: 0.08531120419502258 \n",
            "OrderedDict({'weights': tensor([0.5185]), 'bias': tensor([0.3762])})\n",
            "Epoch: 18330 | MAE Train Loss: 0.036454349756240845 | MAE Test Loss: 0.08523539453744888 \n",
            "OrderedDict({'weights': tensor([0.5187]), 'bias': tensor([0.3762])})\n",
            "Epoch: 18340 | MAE Train Loss: 0.03641999140381813 | MAE Test Loss: 0.08515270054340363 \n",
            "OrderedDict({'weights': tensor([0.5188]), 'bias': tensor([0.3761])})\n",
            "Epoch: 18350 | MAE Train Loss: 0.036385588347911835 | MAE Test Loss: 0.08507002145051956 \n",
            "OrderedDict({'weights': tensor([0.5190]), 'bias': tensor([0.3760])})\n",
            "Epoch: 18360 | MAE Train Loss: 0.03635124862194061 | MAE Test Loss: 0.08499079197645187 \n",
            "OrderedDict({'weights': tensor([0.5192]), 'bias': tensor([0.3760])})\n",
            "Epoch: 18370 | MAE Train Loss: 0.0363168902695179 | MAE Test Loss: 0.08491495251655579 \n",
            "OrderedDict({'weights': tensor([0.5193]), 'bias': tensor([0.3759])})\n",
            "Epoch: 18380 | MAE Train Loss: 0.03628251701593399 | MAE Test Loss: 0.08482889831066132 \n",
            "OrderedDict({'weights': tensor([0.5195]), 'bias': tensor([0.3758])})\n",
            "Epoch: 18390 | MAE Train Loss: 0.03624820336699486 | MAE Test Loss: 0.08475307375192642 \n",
            "OrderedDict({'weights': tensor([0.5197]), 'bias': tensor([0.3757])})\n",
            "Epoch: 18400 | MAE Train Loss: 0.03621382638812065 | MAE Test Loss: 0.08467037975788116 \n",
            "OrderedDict({'weights': tensor([0.5198]), 'bias': tensor([0.3757])})\n",
            "Epoch: 18410 | MAE Train Loss: 0.03617941960692406 | MAE Test Loss: 0.08459115773439407 \n",
            "OrderedDict({'weights': tensor([0.5200]), 'bias': tensor([0.3756])})\n",
            "Epoch: 18420 | MAE Train Loss: 0.036145083606243134 | MAE Test Loss: 0.08450847119092941 \n",
            "OrderedDict({'weights': tensor([0.5202]), 'bias': tensor([0.3755])})\n",
            "Epoch: 18430 | MAE Train Loss: 0.03611075133085251 | MAE Test Loss: 0.08442924916744232 \n",
            "OrderedDict({'weights': tensor([0.5204]), 'bias': tensor([0.3754])})\n",
            "Epoch: 18440 | MAE Train Loss: 0.03607634827494621 | MAE Test Loss: 0.08435342460870743 \n",
            "OrderedDict({'weights': tensor([0.5205]), 'bias': tensor([0.3754])})\n",
            "Epoch: 18450 | MAE Train Loss: 0.03604205325245857 | MAE Test Loss: 0.08427074551582336 \n",
            "OrderedDict({'weights': tensor([0.5207]), 'bias': tensor([0.3753])})\n",
            "Epoch: 18460 | MAE Train Loss: 0.03600766509771347 | MAE Test Loss: 0.0841880664229393 \n",
            "OrderedDict({'weights': tensor([0.5209]), 'bias': tensor([0.3752])})\n",
            "Epoch: 18470 | MAE Train Loss: 0.035973332822322845 | MAE Test Loss: 0.08410883694887161 \n",
            "OrderedDict({'weights': tensor([0.5210]), 'bias': tensor([0.3752])})\n",
            "Epoch: 18480 | MAE Train Loss: 0.03593898192048073 | MAE Test Loss: 0.08402960747480392 \n",
            "OrderedDict({'weights': tensor([0.5212]), 'bias': tensor([0.3751])})\n",
            "Epoch: 18490 | MAE Train Loss: 0.035904597491025925 | MAE Test Loss: 0.08394692838191986 \n",
            "OrderedDict({'weights': tensor([0.5214]), 'bias': tensor([0.3750])})\n",
            "Epoch: 18500 | MAE Train Loss: 0.035870205610990524 | MAE Test Loss: 0.08387111127376556 \n",
            "OrderedDict({'weights': tensor([0.5216]), 'bias': tensor([0.3749])})\n",
            "Epoch: 18510 | MAE Train Loss: 0.03583589941263199 | MAE Test Loss: 0.0837884396314621 \n",
            "OrderedDict({'weights': tensor([0.5217]), 'bias': tensor([0.3749])})\n",
            "Epoch: 18520 | MAE Train Loss: 0.03580151125788689 | MAE Test Loss: 0.08370919525623322 \n",
            "OrderedDict({'weights': tensor([0.5219]), 'bias': tensor([0.3748])})\n",
            "Epoch: 18530 | MAE Train Loss: 0.03576716408133507 | MAE Test Loss: 0.08362649381160736 \n",
            "OrderedDict({'weights': tensor([0.5221]), 'bias': tensor([0.3747])})\n",
            "Epoch: 18540 | MAE Train Loss: 0.03573281690478325 | MAE Test Loss: 0.08354729413986206 \n",
            "OrderedDict({'weights': tensor([0.5222]), 'bias': tensor([0.3747])})\n",
            "Epoch: 18550 | MAE Train Loss: 0.03569842875003815 | MAE Test Loss: 0.0834646001458168 \n",
            "OrderedDict({'weights': tensor([0.5224]), 'bias': tensor([0.3746])})\n",
            "Epoch: 18560 | MAE Train Loss: 0.03566405549645424 | MAE Test Loss: 0.0833887979388237 \n",
            "OrderedDict({'weights': tensor([0.5226]), 'bias': tensor([0.3745])})\n",
            "Epoch: 18570 | MAE Train Loss: 0.03562968969345093 | MAE Test Loss: 0.08330269902944565 \n",
            "OrderedDict({'weights': tensor([0.5228]), 'bias': tensor([0.3744])})\n",
            "Epoch: 18580 | MAE Train Loss: 0.0355953648686409 | MAE Test Loss: 0.08322688192129135 \n",
            "OrderedDict({'weights': tensor([0.5229]), 'bias': tensor([0.3744])})\n",
            "Epoch: 18590 | MAE Train Loss: 0.035560984164476395 | MAE Test Loss: 0.08314765244722366 \n",
            "OrderedDict({'weights': tensor([0.5231]), 'bias': tensor([0.3743])})\n",
            "Epoch: 18600 | MAE Train Loss: 0.03552667051553726 | MAE Test Loss: 0.0830649584531784 \n",
            "OrderedDict({'weights': tensor([0.5233]), 'bias': tensor([0.3742])})\n",
            "Epoch: 18610 | MAE Train Loss: 0.035492267459630966 | MAE Test Loss: 0.08298228681087494 \n",
            "OrderedDict({'weights': tensor([0.5234]), 'bias': tensor([0.3742])})\n",
            "Epoch: 18620 | MAE Train Loss: 0.03545789793133736 | MAE Test Loss: 0.08290645480155945 \n",
            "OrderedDict({'weights': tensor([0.5236]), 'bias': tensor([0.3741])})\n",
            "Epoch: 18630 | MAE Train Loss: 0.03542352840304375 | MAE Test Loss: 0.08282037079334259 \n",
            "OrderedDict({'weights': tensor([0.5238]), 'bias': tensor([0.3740])})\n",
            "Epoch: 18640 | MAE Train Loss: 0.03538919612765312 | MAE Test Loss: 0.0827411562204361 \n",
            "OrderedDict({'weights': tensor([0.5240]), 'bias': tensor([0.3739])})\n",
            "Epoch: 18650 | MAE Train Loss: 0.03535483032464981 | MAE Test Loss: 0.08266530930995941 \n",
            "OrderedDict({'weights': tensor([0.5241]), 'bias': tensor([0.3739])})\n",
            "Epoch: 18660 | MAE Train Loss: 0.03532051295042038 | MAE Test Loss: 0.08258266001939774 \n",
            "OrderedDict({'weights': tensor([0.5243]), 'bias': tensor([0.3738])})\n",
            "Epoch: 18670 | MAE Train Loss: 0.035286109894514084 | MAE Test Loss: 0.08249997347593307 \n",
            "OrderedDict({'weights': tensor([0.5245]), 'bias': tensor([0.3737])})\n",
            "Epoch: 18680 | MAE Train Loss: 0.03525177389383316 | MAE Test Loss: 0.08242073655128479 \n",
            "OrderedDict({'weights': tensor([0.5246]), 'bias': tensor([0.3737])})\n",
            "Epoch: 18690 | MAE Train Loss: 0.03521737456321716 | MAE Test Loss: 0.0823415145277977 \n",
            "OrderedDict({'weights': tensor([0.5248]), 'bias': tensor([0.3736])})\n",
            "Epoch: 18700 | MAE Train Loss: 0.03518303111195564 | MAE Test Loss: 0.08225883543491364 \n",
            "OrderedDict({'weights': tensor([0.5250]), 'bias': tensor([0.3735])})\n",
            "Epoch: 18710 | MAE Train Loss: 0.03514867275953293 | MAE Test Loss: 0.08218301832675934 \n",
            "OrderedDict({'weights': tensor([0.5251]), 'bias': tensor([0.3734])})\n",
            "Epoch: 18720 | MAE Train Loss: 0.0351143516600132 | MAE Test Loss: 0.08210033178329468 \n",
            "OrderedDict({'weights': tensor([0.5253]), 'bias': tensor([0.3734])})\n",
            "Epoch: 18730 | MAE Train Loss: 0.035079993307590485 | MAE Test Loss: 0.08202110230922699 \n",
            "OrderedDict({'weights': tensor([0.5255]), 'bias': tensor([0.3733])})\n",
            "Epoch: 18740 | MAE Train Loss: 0.03504560515284538 | MAE Test Loss: 0.08193843066692352 \n",
            "OrderedDict({'weights': tensor([0.5257]), 'bias': tensor([0.3732])})\n",
            "Epoch: 18750 | MAE Train Loss: 0.03501127287745476 | MAE Test Loss: 0.08185918629169464 \n",
            "OrderedDict({'weights': tensor([0.5258]), 'bias': tensor([0.3732])})\n",
            "Epoch: 18760 | MAE Train Loss: 0.034976862370967865 | MAE Test Loss: 0.08177649229764938 \n",
            "OrderedDict({'weights': tensor([0.5260]), 'bias': tensor([0.3731])})\n",
            "Epoch: 18770 | MAE Train Loss: 0.03494252637028694 | MAE Test Loss: 0.08170069009065628 \n",
            "OrderedDict({'weights': tensor([0.5262]), 'bias': tensor([0.3730])})\n",
            "Epoch: 18780 | MAE Train Loss: 0.034908194094896317 | MAE Test Loss: 0.08161798119544983 \n",
            "OrderedDict({'weights': tensor([0.5263]), 'bias': tensor([0.3729])})\n",
            "Epoch: 18790 | MAE Train Loss: 0.034873850643634796 | MAE Test Loss: 0.08153878897428513 \n",
            "OrderedDict({'weights': tensor([0.5265]), 'bias': tensor([0.3729])})\n",
            "Epoch: 18800 | MAE Train Loss: 0.034839458763599396 | MAE Test Loss: 0.08145955204963684 \n",
            "OrderedDict({'weights': tensor([0.5267]), 'bias': tensor([0.3728])})\n",
            "Epoch: 18810 | MAE Train Loss: 0.034805119037628174 | MAE Test Loss: 0.08137686550617218 \n",
            "OrderedDict({'weights': tensor([0.5269]), 'bias': tensor([0.3727])})\n",
            "Epoch: 18820 | MAE Train Loss: 0.03477070480585098 | MAE Test Loss: 0.08129418641328812 \n",
            "OrderedDict({'weights': tensor([0.5270]), 'bias': tensor([0.3726])})\n",
            "Epoch: 18830 | MAE Train Loss: 0.034736376255750656 | MAE Test Loss: 0.08121837675571442 \n",
            "OrderedDict({'weights': tensor([0.5272]), 'bias': tensor([0.3726])})\n",
            "Epoch: 18840 | MAE Train Loss: 0.03470199555158615 | MAE Test Loss: 0.08113914728164673 \n",
            "OrderedDict({'weights': tensor([0.5274]), 'bias': tensor([0.3725])})\n",
            "Epoch: 18850 | MAE Train Loss: 0.03466763347387314 | MAE Test Loss: 0.08105304837226868 \n",
            "OrderedDict({'weights': tensor([0.5275]), 'bias': tensor([0.3724])})\n",
            "Epoch: 18860 | MAE Train Loss: 0.03463331237435341 | MAE Test Loss: 0.08097724616527557 \n",
            "OrderedDict({'weights': tensor([0.5277]), 'bias': tensor([0.3724])})\n",
            "Epoch: 18870 | MAE Train Loss: 0.034598954021930695 | MAE Test Loss: 0.08089454472064972 \n",
            "OrderedDict({'weights': tensor([0.5279]), 'bias': tensor([0.3723])})\n",
            "Epoch: 18880 | MAE Train Loss: 0.0345645472407341 | MAE Test Loss: 0.08081186562776566 \n",
            "OrderedDict({'weights': tensor([0.5281]), 'bias': tensor([0.3722])})\n",
            "Epoch: 18890 | MAE Train Loss: 0.03453020751476288 | MAE Test Loss: 0.08073263615369797 \n",
            "OrderedDict({'weights': tensor([0.5282]), 'bias': tensor([0.3721])})\n",
            "Epoch: 18900 | MAE Train Loss: 0.034495849162340164 | MAE Test Loss: 0.08065679669380188 \n",
            "OrderedDict({'weights': tensor([0.5284]), 'bias': tensor([0.3721])})\n",
            "Epoch: 18910 | MAE Train Loss: 0.034461475908756256 | MAE Test Loss: 0.08057074248790741 \n",
            "OrderedDict({'weights': tensor([0.5286]), 'bias': tensor([0.3720])})\n",
            "Epoch: 18920 | MAE Train Loss: 0.034427158534526825 | MAE Test Loss: 0.08049491792917252 \n",
            "OrderedDict({'weights': tensor([0.5287]), 'bias': tensor([0.3719])})\n",
            "Epoch: 18930 | MAE Train Loss: 0.03439278528094292 | MAE Test Loss: 0.08041222393512726 \n",
            "OrderedDict({'weights': tensor([0.5289]), 'bias': tensor([0.3719])})\n",
            "Epoch: 18940 | MAE Train Loss: 0.03435837849974632 | MAE Test Loss: 0.08033300191164017 \n",
            "OrderedDict({'weights': tensor([0.5291]), 'bias': tensor([0.3718])})\n",
            "Epoch: 18950 | MAE Train Loss: 0.0343240424990654 | MAE Test Loss: 0.0802503228187561 \n",
            "OrderedDict({'weights': tensor([0.5293]), 'bias': tensor([0.3717])})\n",
            "Epoch: 18960 | MAE Train Loss: 0.034289710223674774 | MAE Test Loss: 0.08017109334468842 \n",
            "OrderedDict({'weights': tensor([0.5294]), 'bias': tensor([0.3716])})\n",
            "Epoch: 18970 | MAE Train Loss: 0.03425530716776848 | MAE Test Loss: 0.08009526878595352 \n",
            "OrderedDict({'weights': tensor([0.5296]), 'bias': tensor([0.3716])})\n",
            "Epoch: 18980 | MAE Train Loss: 0.03422101214528084 | MAE Test Loss: 0.08001258969306946 \n",
            "OrderedDict({'weights': tensor([0.5298]), 'bias': tensor([0.3715])})\n",
            "Epoch: 18990 | MAE Train Loss: 0.034186623990535736 | MAE Test Loss: 0.0799299106001854 \n",
            "OrderedDict({'weights': tensor([0.5299]), 'bias': tensor([0.3714])})\n",
            "Epoch: 19000 | MAE Train Loss: 0.03415229171514511 | MAE Test Loss: 0.0798506811261177 \n",
            "OrderedDict({'weights': tensor([0.5301]), 'bias': tensor([0.3714])})\n",
            "Epoch: 19010 | MAE Train Loss: 0.034117940813302994 | MAE Test Loss: 0.07977145165205002 \n",
            "OrderedDict({'weights': tensor([0.5303]), 'bias': tensor([0.3713])})\n",
            "Epoch: 19020 | MAE Train Loss: 0.03408355638384819 | MAE Test Loss: 0.07968877255916595 \n",
            "OrderedDict({'weights': tensor([0.5304]), 'bias': tensor([0.3712])})\n",
            "Epoch: 19030 | MAE Train Loss: 0.03404916450381279 | MAE Test Loss: 0.07961295545101166 \n",
            "OrderedDict({'weights': tensor([0.5306]), 'bias': tensor([0.3711])})\n",
            "Epoch: 19040 | MAE Train Loss: 0.034014858305454254 | MAE Test Loss: 0.07953028380870819 \n",
            "OrderedDict({'weights': tensor([0.5308]), 'bias': tensor([0.3711])})\n",
            "Epoch: 19050 | MAE Train Loss: 0.03398047015070915 | MAE Test Loss: 0.07945103943347931 \n",
            "OrderedDict({'weights': tensor([0.5310]), 'bias': tensor([0.3710])})\n",
            "Epoch: 19060 | MAE Train Loss: 0.03394612297415733 | MAE Test Loss: 0.07936833798885345 \n",
            "OrderedDict({'weights': tensor([0.5311]), 'bias': tensor([0.3709])})\n",
            "Epoch: 19070 | MAE Train Loss: 0.033911775797605515 | MAE Test Loss: 0.07928913831710815 \n",
            "OrderedDict({'weights': tensor([0.5313]), 'bias': tensor([0.3709])})\n",
            "Epoch: 19080 | MAE Train Loss: 0.03387738764286041 | MAE Test Loss: 0.0792064443230629 \n",
            "OrderedDict({'weights': tensor([0.5315]), 'bias': tensor([0.3708])})\n",
            "Epoch: 19090 | MAE Train Loss: 0.033843014389276505 | MAE Test Loss: 0.0791306421160698 \n",
            "OrderedDict({'weights': tensor([0.5316]), 'bias': tensor([0.3707])})\n",
            "Epoch: 19100 | MAE Train Loss: 0.03380864858627319 | MAE Test Loss: 0.07904454320669174 \n",
            "OrderedDict({'weights': tensor([0.5318]), 'bias': tensor([0.3706])})\n",
            "Epoch: 19110 | MAE Train Loss: 0.033774323761463165 | MAE Test Loss: 0.07896872609853745 \n",
            "OrderedDict({'weights': tensor([0.5320]), 'bias': tensor([0.3706])})\n",
            "Epoch: 19120 | MAE Train Loss: 0.03373994305729866 | MAE Test Loss: 0.07888950407505035 \n",
            "OrderedDict({'weights': tensor([0.5322]), 'bias': tensor([0.3705])})\n",
            "Epoch: 19130 | MAE Train Loss: 0.03370562940835953 | MAE Test Loss: 0.0788068026304245 \n",
            "OrderedDict({'weights': tensor([0.5323]), 'bias': tensor([0.3704])})\n",
            "Epoch: 19140 | MAE Train Loss: 0.03367122635245323 | MAE Test Loss: 0.07872413098812103 \n",
            "OrderedDict({'weights': tensor([0.5325]), 'bias': tensor([0.3704])})\n",
            "Epoch: 19150 | MAE Train Loss: 0.03363685682415962 | MAE Test Loss: 0.07864829897880554 \n",
            "OrderedDict({'weights': tensor([0.5327]), 'bias': tensor([0.3703])})\n",
            "Epoch: 19160 | MAE Train Loss: 0.03360248729586601 | MAE Test Loss: 0.07856221497058868 \n",
            "OrderedDict({'weights': tensor([0.5328]), 'bias': tensor([0.3702])})\n",
            "Epoch: 19170 | MAE Train Loss: 0.03356815502047539 | MAE Test Loss: 0.07848299294710159 \n",
            "OrderedDict({'weights': tensor([0.5330]), 'bias': tensor([0.3701])})\n",
            "Epoch: 19180 | MAE Train Loss: 0.033533789217472076 | MAE Test Loss: 0.0784071534872055 \n",
            "OrderedDict({'weights': tensor([0.5332]), 'bias': tensor([0.3701])})\n",
            "Epoch: 19190 | MAE Train Loss: 0.033499471843242645 | MAE Test Loss: 0.07832450419664383 \n",
            "OrderedDict({'weights': tensor([0.5334]), 'bias': tensor([0.3700])})\n",
            "Epoch: 19200 | MAE Train Loss: 0.03346506878733635 | MAE Test Loss: 0.07824181765317917 \n",
            "OrderedDict({'weights': tensor([0.5335]), 'bias': tensor([0.3699])})\n",
            "Epoch: 19210 | MAE Train Loss: 0.033430732786655426 | MAE Test Loss: 0.07816258072853088 \n",
            "OrderedDict({'weights': tensor([0.5337]), 'bias': tensor([0.3698])})\n",
            "Epoch: 19220 | MAE Train Loss: 0.03339633345603943 | MAE Test Loss: 0.07808335870504379 \n",
            "OrderedDict({'weights': tensor([0.5339]), 'bias': tensor([0.3698])})\n",
            "Epoch: 19230 | MAE Train Loss: 0.03336199000477791 | MAE Test Loss: 0.07800067961215973 \n",
            "OrderedDict({'weights': tensor([0.5340]), 'bias': tensor([0.3697])})\n",
            "Epoch: 19240 | MAE Train Loss: 0.033327631652355194 | MAE Test Loss: 0.07792486250400543 \n",
            "OrderedDict({'weights': tensor([0.5342]), 'bias': tensor([0.3696])})\n",
            "Epoch: 19250 | MAE Train Loss: 0.033293310552835464 | MAE Test Loss: 0.07784216850996017 \n",
            "OrderedDict({'weights': tensor([0.5344]), 'bias': tensor([0.3696])})\n",
            "Epoch: 19260 | MAE Train Loss: 0.03325895220041275 | MAE Test Loss: 0.07776294648647308 \n",
            "OrderedDict({'weights': tensor([0.5345]), 'bias': tensor([0.3695])})\n",
            "Epoch: 19270 | MAE Train Loss: 0.03322456404566765 | MAE Test Loss: 0.07768027484416962 \n",
            "OrderedDict({'weights': tensor([0.5347]), 'bias': tensor([0.3694])})\n",
            "Epoch: 19280 | MAE Train Loss: 0.03319023177027702 | MAE Test Loss: 0.07760103046894073 \n",
            "OrderedDict({'weights': tensor([0.5349]), 'bias': tensor([0.3693])})\n",
            "Epoch: 19290 | MAE Train Loss: 0.03315582126379013 | MAE Test Loss: 0.07751833647489548 \n",
            "OrderedDict({'weights': tensor([0.5351]), 'bias': tensor([0.3693])})\n",
            "Epoch: 19300 | MAE Train Loss: 0.033121488988399506 | MAE Test Loss: 0.07744253426790237 \n",
            "OrderedDict({'weights': tensor([0.5352]), 'bias': tensor([0.3692])})\n",
            "Epoch: 19310 | MAE Train Loss: 0.03308715298771858 | MAE Test Loss: 0.07735982537269592 \n",
            "OrderedDict({'weights': tensor([0.5354]), 'bias': tensor([0.3691])})\n",
            "Epoch: 19320 | MAE Train Loss: 0.03305280953645706 | MAE Test Loss: 0.07728063315153122 \n",
            "OrderedDict({'weights': tensor([0.5356]), 'bias': tensor([0.3691])})\n",
            "Epoch: 19330 | MAE Train Loss: 0.03301841765642166 | MAE Test Loss: 0.07720139622688293 \n",
            "OrderedDict({'weights': tensor([0.5357]), 'bias': tensor([0.3690])})\n",
            "Epoch: 19340 | MAE Train Loss: 0.03298407793045044 | MAE Test Loss: 0.07711870223283768 \n",
            "OrderedDict({'weights': tensor([0.5359]), 'bias': tensor([0.3689])})\n",
            "Epoch: 19350 | MAE Train Loss: 0.03294966369867325 | MAE Test Loss: 0.07703603059053421 \n",
            "OrderedDict({'weights': tensor([0.5361]), 'bias': tensor([0.3688])})\n",
            "Epoch: 19360 | MAE Train Loss: 0.03291533514857292 | MAE Test Loss: 0.07696022093296051 \n",
            "OrderedDict({'weights': tensor([0.5363]), 'bias': tensor([0.3688])})\n",
            "Epoch: 19370 | MAE Train Loss: 0.03288095444440842 | MAE Test Loss: 0.07688098400831223 \n",
            "OrderedDict({'weights': tensor([0.5364]), 'bias': tensor([0.3687])})\n",
            "Epoch: 19380 | MAE Train Loss: 0.032846592366695404 | MAE Test Loss: 0.07679489254951477 \n",
            "OrderedDict({'weights': tensor([0.5366]), 'bias': tensor([0.3686])})\n",
            "Epoch: 19390 | MAE Train Loss: 0.032812267541885376 | MAE Test Loss: 0.07671909034252167 \n",
            "OrderedDict({'weights': tensor([0.5368]), 'bias': tensor([0.3686])})\n",
            "Epoch: 19400 | MAE Train Loss: 0.03277791291475296 | MAE Test Loss: 0.07663638889789581 \n",
            "OrderedDict({'weights': tensor([0.5369]), 'bias': tensor([0.3685])})\n",
            "Epoch: 19410 | MAE Train Loss: 0.032743506133556366 | MAE Test Loss: 0.07655371725559235 \n",
            "OrderedDict({'weights': tensor([0.5371]), 'bias': tensor([0.3684])})\n",
            "Epoch: 19420 | MAE Train Loss: 0.032709166407585144 | MAE Test Loss: 0.07647447288036346 \n",
            "OrderedDict({'weights': tensor([0.5373]), 'bias': tensor([0.3683])})\n",
            "Epoch: 19430 | MAE Train Loss: 0.03267481178045273 | MAE Test Loss: 0.07639864087104797 \n",
            "OrderedDict({'weights': tensor([0.5375]), 'bias': tensor([0.3683])})\n",
            "Epoch: 19440 | MAE Train Loss: 0.03264043480157852 | MAE Test Loss: 0.0763125866651535 \n",
            "OrderedDict({'weights': tensor([0.5376]), 'bias': tensor([0.3682])})\n",
            "Epoch: 19450 | MAE Train Loss: 0.03260611742734909 | MAE Test Loss: 0.0762367695569992 \n",
            "OrderedDict({'weights': tensor([0.5378]), 'bias': tensor([0.3681])})\n",
            "Epoch: 19460 | MAE Train Loss: 0.03257174417376518 | MAE Test Loss: 0.07615406811237335 \n",
            "OrderedDict({'weights': tensor([0.5380]), 'bias': tensor([0.3681])})\n",
            "Epoch: 19470 | MAE Train Loss: 0.03253733739256859 | MAE Test Loss: 0.07607484608888626 \n",
            "OrderedDict({'weights': tensor([0.5381]), 'bias': tensor([0.3680])})\n",
            "Epoch: 19480 | MAE Train Loss: 0.032503001391887665 | MAE Test Loss: 0.0759921669960022 \n",
            "OrderedDict({'weights': tensor([0.5383]), 'bias': tensor([0.3679])})\n",
            "Epoch: 19490 | MAE Train Loss: 0.03246866911649704 | MAE Test Loss: 0.07591293752193451 \n",
            "OrderedDict({'weights': tensor([0.5385]), 'bias': tensor([0.3678])})\n",
            "Epoch: 19500 | MAE Train Loss: 0.032434266060590744 | MAE Test Loss: 0.07583711296319962 \n",
            "OrderedDict({'weights': tensor([0.5387]), 'bias': tensor([0.3678])})\n",
            "Epoch: 19510 | MAE Train Loss: 0.032399967312812805 | MAE Test Loss: 0.07575443387031555 \n",
            "OrderedDict({'weights': tensor([0.5388]), 'bias': tensor([0.3677])})\n",
            "Epoch: 19520 | MAE Train Loss: 0.032365582883358 | MAE Test Loss: 0.07567175477743149 \n",
            "OrderedDict({'weights': tensor([0.5390]), 'bias': tensor([0.3676])})\n",
            "Epoch: 19530 | MAE Train Loss: 0.03233125060796738 | MAE Test Loss: 0.0755925327539444 \n",
            "OrderedDict({'weights': tensor([0.5392]), 'bias': tensor([0.3676])})\n",
            "Epoch: 19540 | MAE Train Loss: 0.03229689970612526 | MAE Test Loss: 0.07551328837871552 \n",
            "OrderedDict({'weights': tensor([0.5393]), 'bias': tensor([0.3675])})\n",
            "Epoch: 19550 | MAE Train Loss: 0.032262515276670456 | MAE Test Loss: 0.07543061673641205 \n",
            "OrderedDict({'weights': tensor([0.5395]), 'bias': tensor([0.3674])})\n",
            "Epoch: 19560 | MAE Train Loss: 0.032228123396635056 | MAE Test Loss: 0.07535479962825775 \n",
            "OrderedDict({'weights': tensor([0.5397]), 'bias': tensor([0.3673])})\n",
            "Epoch: 19570 | MAE Train Loss: 0.03219381719827652 | MAE Test Loss: 0.07527212798595428 \n",
            "OrderedDict({'weights': tensor([0.5398]), 'bias': tensor([0.3673])})\n",
            "Epoch: 19580 | MAE Train Loss: 0.032159436494112015 | MAE Test Loss: 0.0751928836107254 \n",
            "OrderedDict({'weights': tensor([0.5400]), 'bias': tensor([0.3672])})\n",
            "Epoch: 19590 | MAE Train Loss: 0.0321250818669796 | MAE Test Loss: 0.07511018216609955 \n",
            "OrderedDict({'weights': tensor([0.5402]), 'bias': tensor([0.3671])})\n",
            "Epoch: 19600 | MAE Train Loss: 0.03209073841571808 | MAE Test Loss: 0.07503098249435425 \n",
            "OrderedDict({'weights': tensor([0.5404]), 'bias': tensor([0.3670])})\n",
            "Epoch: 19610 | MAE Train Loss: 0.03205634653568268 | MAE Test Loss: 0.07494829595088959 \n",
            "OrderedDict({'weights': tensor([0.5405]), 'bias': tensor([0.3670])})\n",
            "Epoch: 19620 | MAE Train Loss: 0.03202196955680847 | MAE Test Loss: 0.07487247884273529 \n",
            "OrderedDict({'weights': tensor([0.5407]), 'bias': tensor([0.3669])})\n",
            "Epoch: 19630 | MAE Train Loss: 0.03198760747909546 | MAE Test Loss: 0.07478638738393784 \n",
            "OrderedDict({'weights': tensor([0.5409]), 'bias': tensor([0.3668])})\n",
            "Epoch: 19640 | MAE Train Loss: 0.03195328265428543 | MAE Test Loss: 0.07471057027578354 \n",
            "OrderedDict({'weights': tensor([0.5410]), 'bias': tensor([0.3668])})\n",
            "Epoch: 19650 | MAE Train Loss: 0.031918901950120926 | MAE Test Loss: 0.07463134825229645 \n",
            "OrderedDict({'weights': tensor([0.5412]), 'bias': tensor([0.3667])})\n",
            "Epoch: 19660 | MAE Train Loss: 0.03188458830118179 | MAE Test Loss: 0.0745486468076706 \n",
            "OrderedDict({'weights': tensor([0.5414]), 'bias': tensor([0.3666])})\n",
            "Epoch: 19670 | MAE Train Loss: 0.0318501852452755 | MAE Test Loss: 0.07446597516536713 \n",
            "OrderedDict({'weights': tensor([0.5416]), 'bias': tensor([0.3665])})\n",
            "Epoch: 19680 | MAE Train Loss: 0.03181581571698189 | MAE Test Loss: 0.07439014315605164 \n",
            "OrderedDict({'weights': tensor([0.5417]), 'bias': tensor([0.3665])})\n",
            "Epoch: 19690 | MAE Train Loss: 0.03178144991397858 | MAE Test Loss: 0.07430405914783478 \n",
            "OrderedDict({'weights': tensor([0.5419]), 'bias': tensor([0.3664])})\n",
            "Epoch: 19700 | MAE Train Loss: 0.03174711391329765 | MAE Test Loss: 0.07422483712434769 \n",
            "OrderedDict({'weights': tensor([0.5421]), 'bias': tensor([0.3663])})\n",
            "Epoch: 19710 | MAE Train Loss: 0.03171274811029434 | MAE Test Loss: 0.0741489976644516 \n",
            "OrderedDict({'weights': tensor([0.5422]), 'bias': tensor([0.3663])})\n",
            "Epoch: 19720 | MAE Train Loss: 0.03167842701077461 | MAE Test Loss: 0.07406634837388992 \n",
            "OrderedDict({'weights': tensor([0.5424]), 'bias': tensor([0.3662])})\n",
            "Epoch: 19730 | MAE Train Loss: 0.031644027680158615 | MAE Test Loss: 0.07398366183042526 \n",
            "OrderedDict({'weights': tensor([0.5426]), 'bias': tensor([0.3661])})\n",
            "Epoch: 19740 | MAE Train Loss: 0.03160969167947769 | MAE Test Loss: 0.07390442490577698 \n",
            "OrderedDict({'weights': tensor([0.5428]), 'bias': tensor([0.3660])})\n",
            "Epoch: 19750 | MAE Train Loss: 0.031575292348861694 | MAE Test Loss: 0.07382520288228989 \n",
            "OrderedDict({'weights': tensor([0.5429]), 'bias': tensor([0.3660])})\n",
            "Epoch: 19760 | MAE Train Loss: 0.031540948897600174 | MAE Test Loss: 0.07374252378940582 \n",
            "OrderedDict({'weights': tensor([0.5431]), 'bias': tensor([0.3659])})\n",
            "Epoch: 19770 | MAE Train Loss: 0.03150659427046776 | MAE Test Loss: 0.07366670668125153 \n",
            "OrderedDict({'weights': tensor([0.5433]), 'bias': tensor([0.3658])})\n",
            "Epoch: 19780 | MAE Train Loss: 0.03147226944565773 | MAE Test Loss: 0.07358401268720627 \n",
            "OrderedDict({'weights': tensor([0.5434]), 'bias': tensor([0.3658])})\n",
            "Epoch: 19790 | MAE Train Loss: 0.031437914818525314 | MAE Test Loss: 0.07350479066371918 \n",
            "OrderedDict({'weights': tensor([0.5436]), 'bias': tensor([0.3657])})\n",
            "Epoch: 19800 | MAE Train Loss: 0.031403522938489914 | MAE Test Loss: 0.07342211902141571 \n",
            "OrderedDict({'weights': tensor([0.5438]), 'bias': tensor([0.3656])})\n",
            "Epoch: 19810 | MAE Train Loss: 0.03136919438838959 | MAE Test Loss: 0.07334287464618683 \n",
            "OrderedDict({'weights': tensor([0.5440]), 'bias': tensor([0.3655])})\n",
            "Epoch: 19820 | MAE Train Loss: 0.03133478760719299 | MAE Test Loss: 0.07326018065214157 \n",
            "OrderedDict({'weights': tensor([0.5441]), 'bias': tensor([0.3655])})\n",
            "Epoch: 19830 | MAE Train Loss: 0.03130044788122177 | MAE Test Loss: 0.07318437844514847 \n",
            "OrderedDict({'weights': tensor([0.5443]), 'bias': tensor([0.3654])})\n",
            "Epoch: 19840 | MAE Train Loss: 0.03126611188054085 | MAE Test Loss: 0.07310166954994202 \n",
            "OrderedDict({'weights': tensor([0.5445]), 'bias': tensor([0.3653])})\n",
            "Epoch: 19850 | MAE Train Loss: 0.031231766566634178 | MAE Test Loss: 0.07302247732877731 \n",
            "OrderedDict({'weights': tensor([0.5446]), 'bias': tensor([0.3653])})\n",
            "Epoch: 19860 | MAE Train Loss: 0.031197374686598778 | MAE Test Loss: 0.07294324040412903 \n",
            "OrderedDict({'weights': tensor([0.5448]), 'bias': tensor([0.3652])})\n",
            "Epoch: 19870 | MAE Train Loss: 0.031163036823272705 | MAE Test Loss: 0.07286054641008377 \n",
            "OrderedDict({'weights': tensor([0.5450]), 'bias': tensor([0.3651])})\n",
            "Epoch: 19880 | MAE Train Loss: 0.031128620728850365 | MAE Test Loss: 0.0727778822183609 \n",
            "OrderedDict({'weights': tensor([0.5451]), 'bias': tensor([0.3650])})\n",
            "Epoch: 19890 | MAE Train Loss: 0.031094294041395187 | MAE Test Loss: 0.0727020651102066 \n",
            "OrderedDict({'weights': tensor([0.5453]), 'bias': tensor([0.3650])})\n",
            "Epoch: 19900 | MAE Train Loss: 0.03105991519987583 | MAE Test Loss: 0.07262282818555832 \n",
            "OrderedDict({'weights': tensor([0.5455]), 'bias': tensor([0.3649])})\n",
            "Epoch: 19910 | MAE Train Loss: 0.03102554939687252 | MAE Test Loss: 0.07253673672676086 \n",
            "OrderedDict({'weights': tensor([0.5457]), 'bias': tensor([0.3648])})\n",
            "Epoch: 19920 | MAE Train Loss: 0.03099122643470764 | MAE Test Loss: 0.07246093451976776 \n",
            "OrderedDict({'weights': tensor([0.5458]), 'bias': tensor([0.3647])})\n",
            "Epoch: 19930 | MAE Train Loss: 0.030956869944930077 | MAE Test Loss: 0.0723782330751419 \n",
            "OrderedDict({'weights': tensor([0.5460]), 'bias': tensor([0.3647])})\n",
            "Epoch: 19940 | MAE Train Loss: 0.030922463163733482 | MAE Test Loss: 0.07229555398225784 \n",
            "OrderedDict({'weights': tensor([0.5462]), 'bias': tensor([0.3646])})\n",
            "Epoch: 19950 | MAE Train Loss: 0.03088812530040741 | MAE Test Loss: 0.07221631705760956 \n",
            "OrderedDict({'weights': tensor([0.5463]), 'bias': tensor([0.3645])})\n",
            "Epoch: 19960 | MAE Train Loss: 0.030853768810629845 | MAE Test Loss: 0.07214048504829407 \n",
            "OrderedDict({'weights': tensor([0.5465]), 'bias': tensor([0.3645])})\n",
            "Epoch: 19970 | MAE Train Loss: 0.030819395557045937 | MAE Test Loss: 0.0720544308423996 \n",
            "OrderedDict({'weights': tensor([0.5467]), 'bias': tensor([0.3644])})\n",
            "Epoch: 19980 | MAE Train Loss: 0.030785078182816505 | MAE Test Loss: 0.0719786137342453 \n",
            "OrderedDict({'weights': tensor([0.5469]), 'bias': tensor([0.3643])})\n",
            "Epoch: 19990 | MAE Train Loss: 0.030750703066587448 | MAE Test Loss: 0.07189591228961945 \n",
            "OrderedDict({'weights': tensor([0.5470]), 'bias': tensor([0.3642])})\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# import numpy as np\n",
        "# np.array(torch.tensor(loss_values).numpy()), test_loss_values"
      ],
      "metadata": {
        "collapsed": true,
        "id": "F-tEwq0Pxw_Y"
      },
      "execution_count": 510,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot the loss curves\n",
        "plt.plot(epoch_count, loss_values, label=\"Train loss\")\n",
        "plt.plot(epoch_count, test_loss_values, label=\"Test loss\")\n",
        "plt.title(\"Training and test loss curves\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.xlabel(\"Epochs\")\n",
        "plt.legend();"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 472
        },
        "id": "lPgptlCLsV34",
        "outputId": "fb04f6e8-bc0d-4cca-d022-88b1d5c627a3"
      },
      "execution_count": 511,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with torch.inference_mode():\n",
        "  y_preds_new = model_0(X_test)\n",
        "\n",
        "y_preds"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oR0Pk993sQdQ",
        "outputId": "a06b8f29-01e3-4d51-f431-a45fe4e9ed56"
      },
      "execution_count": 512,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.3375],\n",
              "        [0.3401],\n",
              "        [0.3427],\n",
              "        [0.3452],\n",
              "        [0.3478],\n",
              "        [0.3504],\n",
              "        [0.3530],\n",
              "        [0.3555],\n",
              "        [0.3581],\n",
              "        [0.3607]])"
            ]
          },
          "metadata": {},
          "execution_count": 512
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_0.state_dict()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d1gEyyRRwR4C",
        "outputId": "21bdbc62-efd0-4050-d3af-bbad62bef6e0"
      },
      "execution_count": 513,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "OrderedDict([('weights', tensor([0.5472])), ('bias', tensor([0.3642]))])"
            ]
          },
          "metadata": {},
          "execution_count": 513
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "weight,bias"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fx_HnM4RwcHN",
        "outputId": "9e00044b-dabb-49b2-b2ca-cb28280f878b"
      },
      "execution_count": 514,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.7, 0.3)"
            ]
          },
          "metadata": {},
          "execution_count": 514
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plot_predictions(predictions=y_preds)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 430
        },
        "id": "LL4Y_hCJviqs",
        "outputId": "bc52d5fd-fc5b-4d7a-d052-b4f0211b5f2b"
      },
      "execution_count": 515,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plot_predictions(predictions=y_preds_new)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 430
        },
        "id": "ubCA0qntkZtq",
        "outputId": "88c83424-3fe0-43be-88cd-af85982c9ea3"
      },
      "execution_count": 516,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "NOFZ6k6cqap9"
      },
      "execution_count": 516,
      "outputs": []
    }
  ]
}