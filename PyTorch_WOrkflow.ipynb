{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/shishiradk/pytorch-pratices/blob/main/PyTorch_WOrkflow.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 101,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "O3WI6humdalv",
        "outputId": "cbac8577-bdc2-4302-97a4-c997924020eb"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'2.8.0+cu126'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 101
        }
      ],
      "source": [
        "import torch\n",
        "from torch import nn # nn conntains all of Pytorch's buildinng blocks for neural networks\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# check Pythorch version\n",
        "torch.__version__"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Data preparing and loading"
      ],
      "metadata": {
        "id": "Mw9xmslNfZva"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data can e almost anything in machine learning\n",
        "\n",
        "\n",
        "* Excel spreadsheet\n",
        "\n",
        "* Image of any kind\n",
        "\n",
        "* Videos (YT has lots of data)\n",
        "\n",
        "* Audio like songs or podcasts\n",
        "\n",
        "* DNA\n",
        "\n",
        "* Text\n",
        "\n",
        "# Machine learning is a game of two parts:\\\n",
        "1. Get data into a numerical representation.\n",
        "\n",
        "2. Build a model to learn patterns in that numerical representation.\n",
        "\n",
        "using linear regression formula\n",
        "\n",
        "we'll use a linear regression formula to make a st line with known parameters"
      ],
      "metadata": {
        "id": "8aUbr40xfe2T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create *known* parameters\n",
        "weight = 0.7\n",
        "bias = 0.3\n",
        "\n",
        "#create\n",
        "start = 0\n",
        "end = 1\n",
        "step = 0.02\n",
        "X = torch.arange(start, end ,step). unsqueeze(dim=1)\n",
        "y = weight * X + bias\n",
        "\n",
        "X[:10], y[:10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MU-1TiOZfJU6",
        "outputId": "52c586fd-4120-4102-fee2-3c10423c3ab9"
      },
      "execution_count": 102,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([[0.0000],\n",
              "         [0.0200],\n",
              "         [0.0400],\n",
              "         [0.0600],\n",
              "         [0.0800],\n",
              "         [0.1000],\n",
              "         [0.1200],\n",
              "         [0.1400],\n",
              "         [0.1600],\n",
              "         [0.1800]]),\n",
              " tensor([[0.3000],\n",
              "         [0.3140],\n",
              "         [0.3280],\n",
              "         [0.3420],\n",
              "         [0.3560],\n",
              "         [0.3700],\n",
              "         [0.3840],\n",
              "         [0.3980],\n",
              "         [0.4120],\n",
              "         [0.4260]]))"
            ]
          },
          "metadata": {},
          "execution_count": 102
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(X), len(y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nXV01tdKiroA",
        "outputId": "54f3a67b-8b65-4b2d-ae91-69a45fbc04f8"
      },
      "execution_count": 103,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(50, 50)"
            ]
          },
          "metadata": {},
          "execution_count": 103
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### splitting data into training tests sets\n"
      ],
      "metadata": {
        "id": "CUSUR583j77J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## Create a train test split\n",
        "train_split = int(0.8 * len(X))\n",
        "X_train,y_train = X[:train_split], y[:train_split]\n",
        "X_test , y_test = X[train_split:],y[train_split:]\n",
        "\n",
        "len(X_train), len(y_train), len(X_test), len(y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rjqq4CEijBMr",
        "outputId": "d7718433-83eb-4a7b-f876-5ceee4270a03"
      },
      "execution_count": 104,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(40, 40, 10, 10)"
            ]
          },
          "metadata": {},
          "execution_count": 104
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data Visualization"
      ],
      "metadata": {
        "id": "nTOzEs6RTP-s"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_predictions(train_data=X_train,\n",
        "                    train_labels=y_train,\n",
        "                    test_data=X_test,\n",
        "                    test_labels=y_test,\n",
        "                    predictions=None):\n",
        "\n",
        "  \"\"\"\n",
        "  Plots training data ,test data and compares predictions.\n",
        "  \"\"\"\n",
        "\n",
        "  #Plots training data in blue\n",
        "  plt.scatter(train_data,train_labels, c=\"b\",s=4, label=\"Training data\")\n",
        "\n",
        "  # plot test data in green\n",
        "  plt.scatter(test_data,test_labels, c=\"g\" , s=4, label=\"Testing data\")\n",
        "\n",
        "  # Are there predictions?\n",
        "  if predictions is not None:\n",
        "    #Plot the predictions if they exist\n",
        "    # Check if predictions require grad and detach if necessary\n",
        "    if predictions.requires_grad:\n",
        "        predictions = predictions.detach()\n",
        "    plt.scatter(test_data,predictions, c=\"r\", s=4, label=\"Predictions\")\n",
        "\n",
        "  # show the ledgends\n",
        "  plt.legend(prop={\"size\":14});"
      ],
      "metadata": {
        "id": "vkcJXLr-lqMC"
      },
      "execution_count": 105,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_predictions();"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 430
        },
        "id": "plB7paBVVWL1",
        "outputId": "f489cc41-8223-4e4d-9828-cd68e8f6889e"
      },
      "execution_count": 106,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##2. Build model\n",
        "\n",
        "Our first Pytorch model\n"
      ],
      "metadata": {
        "id": "jbcV48f_XHmn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a Linear Regression model class\n",
        "class LinearRegressionModel(nn.Module): # <- almost everything in PyTorch is a nn.Module (think of this as neural network lego blocks)\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.weights = nn.Parameter(torch.randn(1, # <- start with random weights (this will get adjusted as the model learns)\n",
        "                                                dtype=torch.float), # <- PyTorch loves float32 by default\n",
        "                                   requires_grad=True) # <- can we update this value with gradient descent?)\n",
        "\n",
        "        self.bias = nn.Parameter(torch.randn(1, # <- start with random bias (this will get adjusted as the model learns)\n",
        "                                            dtype=torch.float), # <- PyTorch loves float32 by default\n",
        "                                requires_grad=True) # <- can we update this value with gradient descent?))\n",
        "\n",
        "    # Forward defines the computation in the model\n",
        "    def forward(self, x: torch.Tensor) -> torch.Tensor: # <- \"x\" is the input data (e.g. training/testing features)\n",
        "        return self.weights * x + self.bias # <- this is the linear regression formula (y = m*x + b)"
      ],
      "metadata": {
        "id": "DBUfGpW-WaiD"
      },
      "execution_count": 107,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### PyTorch model building essentials\n",
        "\n",
        "PyTorch has four (give or take) essential modules you can use to create almost any kind of neural network you can imagine.\n",
        "\n",
        "They are [`torch.nn`](https://pytorch.org/docs/stable/nn.html), [`torch.optim`](https://pytorch.org/docs/stable/optim.html), [`torch.utils.data.Dataset`](https://pytorch.org/docs/stable/data.html#torch.utils.data.Dataset) and [`torch.utils.data.DataLoader`](https://pytorch.org/docs/stable/data.html). For now, we'll focus on the first two and get to the other two later (though you may be able to guess what they do).\n",
        "\n",
        "| PyTorch module | What does it do? |\n",
        "| ----- | ----- |\n",
        "| [`torch.nn`](https://pytorch.org/docs/stable/nn.html) | Contains all of the building blocks for computational graphs (essentially a series of computations executed in a particular way). |\n",
        "| [`torch.nn.Parameter`](https://pytorch.org/docs/stable/generated/torch.nn.parameter.Parameter.html#parameter) | Stores tensors that can be used with `nn.Module`. If `requires_grad=True` gradients (used for updating model parameters via [**gradient descent**](https://ml-cheatsheet.readthedocs.io/en/latest/gradient_descent.html))  are calculated automatically, this is often referred to as \"autograd\".  |\n",
        "| [`torch.nn.Module`](https://pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module) | The base class for all neural network modules, all the building blocks for neural networks are subclasses. If you're building a neural network in PyTorch, your models should subclass `nn.Module`. Requires a `forward()` method be implemented. |\n",
        "| [`torch.optim`](https://pytorch.org/docs/stable/optim.html) | Contains various optimization algorithms (these tell the model parameters stored in `nn.Parameter` how to best change to improve gradient descent and in turn reduce the loss). |\n",
        "| `def forward()` | All `nn.Module` subclasses require a `forward()` method, this defines the computation that will take place on the data passed to the particular `nn.Module` (e.g. the linear regression formula above). |\n",
        "\n",
        "If the above sounds complex, think of like this, almost everything in a PyTorch neural network comes from `torch.nn`,\n",
        "* `nn.Module` contains the larger building blocks (layers)\n",
        "* `nn.Parameter` contains the smaller parameters like weights and biases (put these together to make `nn.Module`(s))\n",
        "* `forward()` tells the larger blocks how to make calculations on inputs (tensors full of data) within  `nn.Module`(s)\n",
        "* `torch.optim` contains optimization methods on how to improve the parameters within `nn.Parameter` to better represent input data\n",
        "\n",
        "![a pytorch linear model with annotations](https://raw.githubusercontent.com/mrdbourke/pytorch-deep-learning/main/images/01-pytorch-linear-model-annotated.png)\n",
        "*Basic building blocks of creating a PyTorch model by subclassing `nn.Module`. For objects that subclass `nn.Module`, the `forward()` method must be defined.*\n",
        "\n",
        "> **Resource:** See more of these essential modules and their use cases in the [PyTorch Cheat Sheet](https://pytorch.org/tutorials/beginner/ptcheat.html).\n"
      ],
      "metadata": {
        "id": "f3PDD7G9U7GQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(42)\n",
        "torch.randn(1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "86PEwGA9yC4X",
        "outputId": "b8e1ffc7-3428-4e0f-cbdf-3cea539dcd54"
      },
      "execution_count": 108,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0.3367])"
            ]
          },
          "metadata": {},
          "execution_count": 108
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "### Checking the contents of a PyTorch model\n",
        "Now we've got these out of the way, let's create a model instance with the class we've made and check its parameters using [`.parameters()`](https://pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module.parameters)."
      ],
      "metadata": {
        "id": "-QIpbVAPwnTw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a random seed\n",
        "#torch.manual_seed(42)\n",
        "\n",
        "# Create an instance of the model\n",
        "model_0 = LinearRegressionModel()\n",
        "\n",
        "# Check out the parameters\n",
        "list(model_0.parameters())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ainBsEmVZjoW",
        "outputId": "3c3f2ac5-3fa5-4d74-9c80-0b4293540281"
      },
      "execution_count": 109,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Parameter containing:\n",
              " tensor([0.1288], requires_grad=True),\n",
              " Parameter containing:\n",
              " tensor([0.2345], requires_grad=True)]"
            ]
          },
          "metadata": {},
          "execution_count": 109
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# List named parameters\n",
        "model_0.state_dict()"
      ],
      "metadata": {
        "id": "VZ50ViQhyYiQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0f9fd1c7-b0fd-4a4c-b815-343db86d5b66"
      },
      "execution_count": 110,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "OrderedDict([('weights', tensor([0.1288])), ('bias', tensor([0.2345]))])"
            ]
          },
          "metadata": {},
          "execution_count": 110
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Notice how the values for `weights` and `bias` from `model_0.state_dict()` come out as random float tensors?\n",
        "\n",
        "This is because we initialized them above using `torch.randn()`.\n",
        "\n",
        "Essentially we want to start from random parameters and get the model to update them towards parameters that fit our data best (the hardcoded `weight` and `bias` values we set when creating our straight line data).\n",
        "\n",
        "> **Exercise:** Try changing the `torch.manual_seed()` value two cells above, see what happens to the weights and bias values.\n",
        "\n",
        "Because our model starts with random values, right now it'll have poor predictive power.\n",
        "\n"
      ],
      "metadata": {
        "id": "UIa0OjYx2D22"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Hmm?\n",
        "\n",
        "You probably noticed we used [`torch.inference_mode()`](https://pytorch.org/docs/stable/generated/torch.inference_mode.html) as a [context manager](https://realpython.com/python-with-statement/) (that's what the `with torch.inference_mode():` is) to make the predictions.\n",
        "\n",
        "As the name suggests, `torch.inference_mode()` is used when using a model for inference (making predictions).\n",
        "\n",
        "`torch.inference_mode()` turns off a bunch of things (like gradient tracking, which is necessary for training but not for inference) to make **forward-passes** (data going through the `forward()` method) faster.\n",
        "\n",
        "> **Note:** In older PyTorch code, you may also see `torch.no_grad()` being used for inference. While `torch.inference_mode()` and `torch.no_grad()` do similar things,\n",
        "`torch.inference_mode()` is newer, potentially faster and preferred. See this [Tweet from PyTorch](https://twitter.com/PyTorch/status/1437838231505096708?s=20) for more.\n",
        "\n",
        "We've made some predictions, let's see what they look like."
      ],
      "metadata": {
        "id": "ZPW19T4y2bE1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_test,y_test"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HoT1FJ6L23QR",
        "outputId": "d24016b8-b8b8-456f-de6c-888630037713"
      },
      "execution_count": 111,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([[0.8000],\n",
              "         [0.8200],\n",
              "         [0.8400],\n",
              "         [0.8600],\n",
              "         [0.8800],\n",
              "         [0.9000],\n",
              "         [0.9200],\n",
              "         [0.9400],\n",
              "         [0.9600],\n",
              "         [0.9800]]),\n",
              " tensor([[0.8600],\n",
              "         [0.8740],\n",
              "         [0.8880],\n",
              "         [0.9020],\n",
              "         [0.9160],\n",
              "         [0.9300],\n",
              "         [0.9440],\n",
              "         [0.9580],\n",
              "         [0.9720],\n",
              "         [0.9860]]))"
            ]
          },
          "metadata": {},
          "execution_count": 111
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Make prediction with model\n",
        "with torch.inference_mode():\n",
        "  y_preds= model_0(X_test)\n",
        "\n",
        "# you can do something with torch.no_grad(),however, torch.inference_model() is prefered\n",
        "# with torch.no_grad():\n",
        "#   y_preds = model_0(X_test)\n",
        "\n",
        "y_preds"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pp_x9qMG1yIN",
        "outputId": "31837712-cd52-458f-e2c4-b71155799382"
      },
      "execution_count": 112,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.3375],\n",
              "        [0.3401],\n",
              "        [0.3427],\n",
              "        [0.3452],\n",
              "        [0.3478],\n",
              "        [0.3504],\n",
              "        [0.3530],\n",
              "        [0.3555],\n",
              "        [0.3581],\n",
              "        [0.3607]])"
            ]
          },
          "metadata": {},
          "execution_count": 112
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_test"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C37dVqll19NX",
        "outputId": "45843d7e-0e41-4aba-b9ca-f9688c59604d"
      },
      "execution_count": 113,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.8600],\n",
              "        [0.8740],\n",
              "        [0.8880],\n",
              "        [0.9020],\n",
              "        [0.9160],\n",
              "        [0.9300],\n",
              "        [0.9440],\n",
              "        [0.9580],\n",
              "        [0.9720],\n",
              "        [0.9860]])"
            ]
          },
          "metadata": {},
          "execution_count": 113
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plot_predictions(predictions=y_preds)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 430
        },
        "id": "Dsf7C4gw3ktX",
        "outputId": "b22a2d2a-bb57-44e5-abb0-6ad3a63199e7"
      },
      "execution_count": 114,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##3. Train Model\n",
        "\n",
        "The whole idea of training is for a model to move from some *unknown* parameters(these may be random) to some *known* parameters\n",
        "\n",
        "or in other  words from  a poor or how wrog models prdictions are is to use a loss funstion .\n",
        "\n",
        "* Note: Loss fuction may also be called cost function or criterion in different areas. For our case, we're going to refer to it as a loss function.\n",
        "\n",
        "Thimgs we need to train:\n",
        "\n",
        "**Loss function:** A function to measure how wrong your model's predictions are to the ideal outputs,lower is better.\n",
        "\n",
        "**Optimizer:** Takes into account the loss of a model and adjustss the model's parameters(weights and bias) to improve the loss function.\n",
        "\n",
        "And specifically for Pytorch,we need:\n",
        "* A training loop\n",
        "* A testing loop"
      ],
      "metadata": {
        "id": "O9sGvhCJ6z6Y"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "read torch.optimizer"
      ],
      "metadata": {
        "id": "XYj4-OTVArlX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "list(model_0.parameters())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kw96EqZC3sDK",
        "outputId": "d5ddb7d6-10fe-483a-add4-8f960bbfe9e4"
      },
      "execution_count": 115,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Parameter containing:\n",
              " tensor([0.1288], requires_grad=True),\n",
              " Parameter containing:\n",
              " tensor([0.2345], requires_grad=True)]"
            ]
          },
          "metadata": {},
          "execution_count": 115
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Check out models parameter is a value that the model sets itself\n",
        "model_0.state_dict()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O8uXt4gc9JM0",
        "outputId": "92e2e6b6-f43c-4ba3-c9dc-87b69734bc5e"
      },
      "execution_count": 116,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "OrderedDict([('weights', tensor([0.1288])), ('bias', tensor([0.2345]))])"
            ]
          },
          "metadata": {},
          "execution_count": 116
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## Setuo a loss function\n",
        "loss_fn =nn.L1Loss()\n",
        "\n",
        "# Setup an optimizer\n",
        "optimizer = torch.optim.SGD(params=model_0.parameters(),\n",
        "                            lr=0.0001) # lr= learning rate"
      ],
      "metadata": {
        "id": "0jNAjYPr9_6Y"
      },
      "execution_count": 117,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Pytorch training loop\n",
        "\n",
        "A couple of things we need in a training loop:\n",
        "\n",
        "0. Loopp through the data\n",
        "1. Forward pass  (this involves data moving through our models forward() function) to make pred on data - aslso called forward propagation\n",
        "2. Calculate the loss(compare forward pass prediction to ground truth labels)\n",
        "3. Optimizer zero grad\n",
        "4. Loss backward - move backwards through the network to calculate the gradiets of each of the parameters of our model with respect to the loss\n",
        "5. Optimizer step- use the optimizer to adjust our models parameters to try and imporive loss"
      ],
      "metadata": {
        "id": "DopXs1wfOAMf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "| Number | Step name | What does it do? | Code example |\n",
        "| ----- | ----- | ----- | ----- |\n",
        "| 1 | Forward pass | The model goes through all of the training data once, performing its `forward()` function calculations. | `model(x_train)` |\n",
        "| 2 | Calculate the loss | The model's outputs (predictions) are compared to the ground truth and evaluated to see how wrong they are. | `loss = loss_fn(y_pred, y_train)` |\n",
        "| 3 | Zero gradients | The optimizers gradients are set to zero (they are accumulated by default) so they can be recalculated for the specific training step. | `optimizer.zero_grad()` |\n",
        "| 4 | Perform backpropagation on the loss | Computes the gradient of the loss with respect for every model parameter to be updated  (each parameter with `requires_grad=True`). This is known as **backpropagation**, hence \"backwards\".  | `loss.backward()` |\n",
        "| 5 | Update the optimizer (**gradient descent**) | Update the parameters with `requires_grad=True` with respect to the loss gradients in order to improve them. | `optimizer.step()` |"
      ],
      "metadata": {
        "id": "Fh2flD0UOLFj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(42)\n",
        "\n",
        "# Set the number of epochs (how many times the model will pass over the training data)\n",
        "epochs = 30000\n",
        "\n",
        "\n",
        "# Create empty loss lists to track values\n",
        "epoch_count = []\n",
        "loss_values = []\n",
        "test_loss_values = []\n",
        "epoch_count = []\n",
        "\n",
        "  ### Training\n",
        "  #0. Loop through the data\n",
        "for epoch in range(epochs):\n",
        "\n",
        "\n",
        "    # Put model in training mode (this is the default state of a model)\n",
        "    model_0.train()\n",
        "\n",
        "    # 1. Forward pass on train data using the forward() method inside\n",
        "    y_pred = model_0(X_train)\n",
        "    # print(y_pred)\n",
        "\n",
        "    # 2. Calculate the loss (how different are our models predictions to the ground truth)\n",
        "    loss = loss_fn(y_pred, y_train)\n",
        "\n",
        "    # 3. Zero grad of the optimizer\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    # 4. Loss backwards\n",
        "    loss.backward()\n",
        "\n",
        "    # 5. Progress the optimizer\n",
        "    optimizer.step()\n",
        "\n",
        "    ### Testing\n",
        "\n",
        "    # Put the model in evaluation mode\n",
        "    model_0.eval()\n",
        "\n",
        "    with torch.inference_mode():\n",
        "      # 1. Forward pass on test data\n",
        "      test_pred = model_0(X_test)\n",
        "\n",
        "      # 2. Caculate loss on test data\n",
        "      test_loss = loss_fn(test_pred, y_test) # predictions come in torch.float datatype, so comparisons need to be done with tensors of the same type\n",
        "\n",
        "      # Print out what's happening\n",
        "      if epoch % 10 == 0:\n",
        "            epoch_count.append(epoch)\n",
        "            loss_values.append(loss.detach().numpy())\n",
        "            test_loss_values.append(test_loss.detach().numpy())\n",
        "            print(f\"Epoch: {epoch} | MAE Train Loss: {loss} | MAE Test Loss: {test_loss} \")\n",
        "            #Print out model state_dict()\n",
        "            print(model_0.state_dict())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "3blnVuY2Dawg",
        "outputId": "72a325f6-e215-43ea-aace-9d78ccbbcd9a"
      },
      "execution_count": 118,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            "Epoch: 5000 | MAE Train Loss: 0.08303127437829971 | MAE Test Loss: 0.2118622064590454 \n",
            "OrderedDict({'weights': tensor([0.2849]), 'bias': tensor([0.4576])})\n",
            "Epoch: 5010 | MAE Train Loss: 0.08298079669475555 | MAE Test Loss: 0.21161720156669617 \n",
            "OrderedDict({'weights': tensor([0.2851]), 'bias': tensor([0.4576])})\n",
            "Epoch: 5020 | MAE Train Loss: 0.08293694257736206 | MAE Test Loss: 0.21141910552978516 \n",
            "OrderedDict({'weights': tensor([0.2853]), 'bias': tensor([0.4576])})\n",
            "Epoch: 5030 | MAE Train Loss: 0.08289696276187897 | MAE Test Loss: 0.21124112606048584 \n",
            "OrderedDict({'weights': tensor([0.2855]), 'bias': tensor([0.4576])})\n",
            "Epoch: 5040 | MAE Train Loss: 0.08285696059465408 | MAE Test Loss: 0.21106314659118652 \n",
            "OrderedDict({'weights': tensor([0.2857]), 'bias': tensor([0.4576])})\n",
            "Epoch: 5050 | MAE Train Loss: 0.0828169584274292 | MAE Test Loss: 0.2108851671218872 \n",
            "OrderedDict({'weights': tensor([0.2859]), 'bias': tensor([0.4576])})\n",
            "Epoch: 5060 | MAE Train Loss: 0.08277696371078491 | MAE Test Loss: 0.2107071876525879 \n",
            "OrderedDict({'weights': tensor([0.2861]), 'bias': tensor([0.4576])})\n",
            "Epoch: 5070 | MAE Train Loss: 0.08273696154356003 | MAE Test Loss: 0.21052923798561096 \n",
            "OrderedDict({'weights': tensor([0.2863]), 'bias': tensor([0.4576])})\n",
            "Epoch: 5080 | MAE Train Loss: 0.08269698172807693 | MAE Test Loss: 0.21035125851631165 \n",
            "OrderedDict({'weights': tensor([0.2865]), 'bias': tensor([0.4576])})\n",
            "Epoch: 5090 | MAE Train Loss: 0.08265697956085205 | MAE Test Loss: 0.21017327904701233 \n",
            "OrderedDict({'weights': tensor([0.2867]), 'bias': tensor([0.4576])})\n",
            "Epoch: 5100 | MAE Train Loss: 0.08261698484420776 | MAE Test Loss: 0.209995299577713 \n",
            "OrderedDict({'weights': tensor([0.2869]), 'bias': tensor([0.4576])})\n",
            "Epoch: 5110 | MAE Train Loss: 0.08257700502872467 | MAE Test Loss: 0.2098173201084137 \n",
            "OrderedDict({'weights': tensor([0.2871]), 'bias': tensor([0.4576])})\n",
            "Epoch: 5120 | MAE Train Loss: 0.08253699541091919 | MAE Test Loss: 0.20963934063911438 \n",
            "OrderedDict({'weights': tensor([0.2873]), 'bias': tensor([0.4576])})\n",
            "Epoch: 5130 | MAE Train Loss: 0.0824970081448555 | MAE Test Loss: 0.20946137607097626 \n",
            "OrderedDict({'weights': tensor([0.2875]), 'bias': tensor([0.4576])})\n",
            "Epoch: 5140 | MAE Train Loss: 0.08245700597763062 | MAE Test Loss: 0.20928338170051575 \n",
            "OrderedDict({'weights': tensor([0.2877]), 'bias': tensor([0.4576])})\n",
            "Epoch: 5150 | MAE Train Loss: 0.08241702616214752 | MAE Test Loss: 0.20910540223121643 \n",
            "OrderedDict({'weights': tensor([0.2879]), 'bias': tensor([0.4576])})\n",
            "Epoch: 5160 | MAE Train Loss: 0.08237701654434204 | MAE Test Loss: 0.2089274376630783 \n",
            "OrderedDict({'weights': tensor([0.2881]), 'bias': tensor([0.4576])})\n",
            "Epoch: 5170 | MAE Train Loss: 0.08233702182769775 | MAE Test Loss: 0.2087494432926178 \n",
            "OrderedDict({'weights': tensor([0.2883]), 'bias': tensor([0.4576])})\n",
            "Epoch: 5180 | MAE Train Loss: 0.08229703456163406 | MAE Test Loss: 0.20857146382331848 \n",
            "OrderedDict({'weights': tensor([0.2885]), 'bias': tensor([0.4576])})\n",
            "Epoch: 5190 | MAE Train Loss: 0.08225702494382858 | MAE Test Loss: 0.20839349925518036 \n",
            "OrderedDict({'weights': tensor([0.2887]), 'bias': tensor([0.4576])})\n",
            "Epoch: 5200 | MAE Train Loss: 0.08221703767776489 | MAE Test Loss: 0.20821551978588104 \n",
            "OrderedDict({'weights': tensor([0.2889]), 'bias': tensor([0.4576])})\n",
            "Epoch: 5210 | MAE Train Loss: 0.0821770429611206 | MAE Test Loss: 0.2080375701189041 \n",
            "OrderedDict({'weights': tensor([0.2891]), 'bias': tensor([0.4576])})\n",
            "Epoch: 5220 | MAE Train Loss: 0.08213705569505692 | MAE Test Loss: 0.2078595906496048 \n",
            "OrderedDict({'weights': tensor([0.2893]), 'bias': tensor([0.4576])})\n",
            "Epoch: 5230 | MAE Train Loss: 0.08209706097841263 | MAE Test Loss: 0.2076815664768219 \n",
            "OrderedDict({'weights': tensor([0.2895]), 'bias': tensor([0.4576])})\n",
            "Epoch: 5240 | MAE Train Loss: 0.08205706626176834 | MAE Test Loss: 0.20750363171100616 \n",
            "OrderedDict({'weights': tensor([0.2897]), 'bias': tensor([0.4576])})\n",
            "Epoch: 5250 | MAE Train Loss: 0.08201706409454346 | MAE Test Loss: 0.20732566714286804 \n",
            "OrderedDict({'weights': tensor([0.2899]), 'bias': tensor([0.4576])})\n",
            "Epoch: 5260 | MAE Train Loss: 0.08197706937789917 | MAE Test Loss: 0.20714762806892395 \n",
            "OrderedDict({'weights': tensor([0.2901]), 'bias': tensor([0.4576])})\n",
            "Epoch: 5270 | MAE Train Loss: 0.08193707466125488 | MAE Test Loss: 0.20696966350078583 \n",
            "OrderedDict({'weights': tensor([0.2903]), 'bias': tensor([0.4576])})\n",
            "Epoch: 5280 | MAE Train Loss: 0.08189708739519119 | MAE Test Loss: 0.2067917138338089 \n",
            "OrderedDict({'weights': tensor([0.2905]), 'bias': tensor([0.4576])})\n",
            "Epoch: 5290 | MAE Train Loss: 0.08185708522796631 | MAE Test Loss: 0.20661373436450958 \n",
            "OrderedDict({'weights': tensor([0.2907]), 'bias': tensor([0.4576])})\n",
            "Epoch: 5300 | MAE Train Loss: 0.08181709796190262 | MAE Test Loss: 0.20643575489521027 \n",
            "OrderedDict({'weights': tensor([0.2909]), 'bias': tensor([0.4576])})\n",
            "Epoch: 5310 | MAE Train Loss: 0.08177709579467773 | MAE Test Loss: 0.20625779032707214 \n",
            "OrderedDict({'weights': tensor([0.2911]), 'bias': tensor([0.4576])})\n",
            "Epoch: 5320 | MAE Train Loss: 0.08173710107803345 | MAE Test Loss: 0.20607979595661163 \n",
            "OrderedDict({'weights': tensor([0.2913]), 'bias': tensor([0.4576])})\n",
            "Epoch: 5330 | MAE Train Loss: 0.08169712126255035 | MAE Test Loss: 0.2059018313884735 \n",
            "OrderedDict({'weights': tensor([0.2915]), 'bias': tensor([0.4576])})\n",
            "Epoch: 5340 | MAE Train Loss: 0.08165711909532547 | MAE Test Loss: 0.2057238519191742 \n",
            "OrderedDict({'weights': tensor([0.2917]), 'bias': tensor([0.4576])})\n",
            "Epoch: 5350 | MAE Train Loss: 0.08161712437868118 | MAE Test Loss: 0.20554587244987488 \n",
            "OrderedDict({'weights': tensor([0.2919]), 'bias': tensor([0.4576])})\n",
            "Epoch: 5360 | MAE Train Loss: 0.0815771222114563 | MAE Test Loss: 0.20536787807941437 \n",
            "OrderedDict({'weights': tensor([0.2921]), 'bias': tensor([0.4576])})\n",
            "Epoch: 5370 | MAE Train Loss: 0.08153713494539261 | MAE Test Loss: 0.20518994331359863 \n",
            "OrderedDict({'weights': tensor([0.2923]), 'bias': tensor([0.4576])})\n",
            "Epoch: 5380 | MAE Train Loss: 0.08149713277816772 | MAE Test Loss: 0.20501196384429932 \n",
            "OrderedDict({'weights': tensor([0.2925]), 'bias': tensor([0.4576])})\n",
            "Epoch: 5390 | MAE Train Loss: 0.08145713806152344 | MAE Test Loss: 0.204833984375 \n",
            "OrderedDict({'weights': tensor([0.2927]), 'bias': tensor([0.4576])})\n",
            "Epoch: 5400 | MAE Train Loss: 0.08141714334487915 | MAE Test Loss: 0.2046559751033783 \n",
            "OrderedDict({'weights': tensor([0.2929]), 'bias': tensor([0.4576])})\n",
            "Epoch: 5410 | MAE Train Loss: 0.08137715607881546 | MAE Test Loss: 0.20447799563407898 \n",
            "OrderedDict({'weights': tensor([0.2931]), 'bias': tensor([0.4576])})\n",
            "Epoch: 5420 | MAE Train Loss: 0.08133715391159058 | MAE Test Loss: 0.20430007576942444 \n",
            "OrderedDict({'weights': tensor([0.2933]), 'bias': tensor([0.4576])})\n",
            "Epoch: 5430 | MAE Train Loss: 0.08129717409610748 | MAE Test Loss: 0.20412206649780273 \n",
            "OrderedDict({'weights': tensor([0.2935]), 'bias': tensor([0.4576])})\n",
            "Epoch: 5440 | MAE Train Loss: 0.0812571719288826 | MAE Test Loss: 0.20394408702850342 \n",
            "OrderedDict({'weights': tensor([0.2937]), 'bias': tensor([0.4576])})\n",
            "Epoch: 5450 | MAE Train Loss: 0.08121716976165771 | MAE Test Loss: 0.2037661075592041 \n",
            "OrderedDict({'weights': tensor([0.2939]), 'bias': tensor([0.4576])})\n",
            "Epoch: 5460 | MAE Train Loss: 0.08117717504501343 | MAE Test Loss: 0.20358812808990479 \n",
            "OrderedDict({'weights': tensor([0.2941]), 'bias': tensor([0.4576])})\n",
            "Epoch: 5470 | MAE Train Loss: 0.08113717287778854 | MAE Test Loss: 0.20341014862060547 \n",
            "OrderedDict({'weights': tensor([0.2943]), 'bias': tensor([0.4576])})\n",
            "Epoch: 5480 | MAE Train Loss: 0.08109718561172485 | MAE Test Loss: 0.20323219895362854 \n",
            "OrderedDict({'weights': tensor([0.2945]), 'bias': tensor([0.4576])})\n",
            "Epoch: 5490 | MAE Train Loss: 0.08105719089508057 | MAE Test Loss: 0.20305418968200684 \n",
            "OrderedDict({'weights': tensor([0.2947]), 'bias': tensor([0.4576])})\n",
            "Epoch: 5500 | MAE Train Loss: 0.08101719617843628 | MAE Test Loss: 0.2028762400150299 \n",
            "OrderedDict({'weights': tensor([0.2949]), 'bias': tensor([0.4576])})\n",
            "Epoch: 5510 | MAE Train Loss: 0.08097721636295319 | MAE Test Loss: 0.2026982605457306 \n",
            "OrderedDict({'weights': tensor([0.2951]), 'bias': tensor([0.4576])})\n",
            "Epoch: 5520 | MAE Train Loss: 0.0809372067451477 | MAE Test Loss: 0.20252028107643127 \n",
            "OrderedDict({'weights': tensor([0.2953]), 'bias': tensor([0.4576])})\n",
            "Epoch: 5530 | MAE Train Loss: 0.08089721947908401 | MAE Test Loss: 0.20234230160713196 \n",
            "OrderedDict({'weights': tensor([0.2955]), 'bias': tensor([0.4576])})\n",
            "Epoch: 5540 | MAE Train Loss: 0.08085722476243973 | MAE Test Loss: 0.20216432213783264 \n",
            "OrderedDict({'weights': tensor([0.2957]), 'bias': tensor([0.4576])})\n",
            "Epoch: 5550 | MAE Train Loss: 0.08081723749637604 | MAE Test Loss: 0.20198635756969452 \n",
            "OrderedDict({'weights': tensor([0.2959]), 'bias': tensor([0.4576])})\n",
            "Epoch: 5560 | MAE Train Loss: 0.08077722787857056 | MAE Test Loss: 0.201808363199234 \n",
            "OrderedDict({'weights': tensor([0.2961]), 'bias': tensor([0.4576])})\n",
            "Epoch: 5570 | MAE Train Loss: 0.08073723316192627 | MAE Test Loss: 0.2016303837299347 \n",
            "OrderedDict({'weights': tensor([0.2963]), 'bias': tensor([0.4576])})\n",
            "Epoch: 5580 | MAE Train Loss: 0.08069723844528198 | MAE Test Loss: 0.20145240426063538 \n",
            "OrderedDict({'weights': tensor([0.2965]), 'bias': tensor([0.4576])})\n",
            "Epoch: 5590 | MAE Train Loss: 0.0806572437286377 | MAE Test Loss: 0.20127442479133606 \n",
            "OrderedDict({'weights': tensor([0.2967]), 'bias': tensor([0.4576])})\n",
            "Epoch: 5600 | MAE Train Loss: 0.080617256462574 | MAE Test Loss: 0.20109646022319794 \n",
            "OrderedDict({'weights': tensor([0.2969]), 'bias': tensor([0.4576])})\n",
            "Epoch: 5610 | MAE Train Loss: 0.08057725429534912 | MAE Test Loss: 0.200918510556221 \n",
            "OrderedDict({'weights': tensor([0.2971]), 'bias': tensor([0.4576])})\n",
            "Epoch: 5620 | MAE Train Loss: 0.08053726702928543 | MAE Test Loss: 0.2007405310869217 \n",
            "OrderedDict({'weights': tensor([0.2973]), 'bias': tensor([0.4576])})\n",
            "Epoch: 5630 | MAE Train Loss: 0.08049727231264114 | MAE Test Loss: 0.2005625218153 \n",
            "OrderedDict({'weights': tensor([0.2975]), 'bias': tensor([0.4576])})\n",
            "Epoch: 5640 | MAE Train Loss: 0.08045727759599686 | MAE Test Loss: 0.20038454234600067 \n",
            "OrderedDict({'weights': tensor([0.2977]), 'bias': tensor([0.4576])})\n",
            "Epoch: 5650 | MAE Train Loss: 0.08041727542877197 | MAE Test Loss: 0.20020660758018494 \n",
            "OrderedDict({'weights': tensor([0.2979]), 'bias': tensor([0.4576])})\n",
            "Epoch: 5660 | MAE Train Loss: 0.08037728071212769 | MAE Test Loss: 0.20002858340740204 \n",
            "OrderedDict({'weights': tensor([0.2981]), 'bias': tensor([0.4576])})\n",
            "Epoch: 5670 | MAE Train Loss: 0.0803372859954834 | MAE Test Loss: 0.19985060393810272 \n",
            "OrderedDict({'weights': tensor([0.2983]), 'bias': tensor([0.4576])})\n",
            "Epoch: 5680 | MAE Train Loss: 0.08029729872941971 | MAE Test Loss: 0.1996726542711258 \n",
            "OrderedDict({'weights': tensor([0.2985]), 'bias': tensor([0.4576])})\n",
            "Epoch: 5690 | MAE Train Loss: 0.08025729656219482 | MAE Test Loss: 0.19949467480182648 \n",
            "OrderedDict({'weights': tensor([0.2987]), 'bias': tensor([0.4576])})\n",
            "Epoch: 5700 | MAE Train Loss: 0.08021730929613113 | MAE Test Loss: 0.19931669533252716 \n",
            "OrderedDict({'weights': tensor([0.2989]), 'bias': tensor([0.4576])})\n",
            "Epoch: 5710 | MAE Train Loss: 0.08017731457948685 | MAE Test Loss: 0.19913871586322784 \n",
            "OrderedDict({'weights': tensor([0.2991]), 'bias': tensor([0.4576])})\n",
            "Epoch: 5720 | MAE Train Loss: 0.08013731241226196 | MAE Test Loss: 0.19896073639392853 \n",
            "OrderedDict({'weights': tensor([0.2993]), 'bias': tensor([0.4576])})\n",
            "Epoch: 5730 | MAE Train Loss: 0.08009732514619827 | MAE Test Loss: 0.1987827718257904 \n",
            "OrderedDict({'weights': tensor([0.2995]), 'bias': tensor([0.4576])})\n",
            "Epoch: 5740 | MAE Train Loss: 0.08005733042955399 | MAE Test Loss: 0.1986047923564911 \n",
            "OrderedDict({'weights': tensor([0.2997]), 'bias': tensor([0.4576])})\n",
            "Epoch: 5750 | MAE Train Loss: 0.0800173357129097 | MAE Test Loss: 0.19842681288719177 \n",
            "OrderedDict({'weights': tensor([0.2999]), 'bias': tensor([0.4576])})\n",
            "Epoch: 5760 | MAE Train Loss: 0.07997734099626541 | MAE Test Loss: 0.19824881851673126 \n",
            "OrderedDict({'weights': tensor([0.3001]), 'bias': tensor([0.4576])})\n",
            "Epoch: 5770 | MAE Train Loss: 0.07993734627962112 | MAE Test Loss: 0.19807088375091553 \n",
            "OrderedDict({'weights': tensor([0.3003]), 'bias': tensor([0.4576])})\n",
            "Epoch: 5780 | MAE Train Loss: 0.07989734411239624 | MAE Test Loss: 0.19789287447929382 \n",
            "OrderedDict({'weights': tensor([0.3005]), 'bias': tensor([0.4576])})\n",
            "Epoch: 5790 | MAE Train Loss: 0.07985734939575195 | MAE Test Loss: 0.1977149248123169 \n",
            "OrderedDict({'weights': tensor([0.3007]), 'bias': tensor([0.4576])})\n",
            "Epoch: 5800 | MAE Train Loss: 0.07981736212968826 | MAE Test Loss: 0.1975369155406952 \n",
            "OrderedDict({'weights': tensor([0.3009]), 'bias': tensor([0.4576])})\n",
            "Epoch: 5810 | MAE Train Loss: 0.07977736741304398 | MAE Test Loss: 0.19735893607139587 \n",
            "OrderedDict({'weights': tensor([0.3011]), 'bias': tensor([0.4576])})\n",
            "Epoch: 5820 | MAE Train Loss: 0.07973736524581909 | MAE Test Loss: 0.19718100130558014 \n",
            "OrderedDict({'weights': tensor([0.3013]), 'bias': tensor([0.4576])})\n",
            "Epoch: 5830 | MAE Train Loss: 0.079697385430336 | MAE Test Loss: 0.19700300693511963 \n",
            "OrderedDict({'weights': tensor([0.3015]), 'bias': tensor([0.4576])})\n",
            "Epoch: 5840 | MAE Train Loss: 0.07965738326311111 | MAE Test Loss: 0.1968250274658203 \n",
            "OrderedDict({'weights': tensor([0.3017]), 'bias': tensor([0.4576])})\n",
            "Epoch: 5850 | MAE Train Loss: 0.07961738109588623 | MAE Test Loss: 0.19664707779884338 \n",
            "OrderedDict({'weights': tensor([0.3019]), 'bias': tensor([0.4576])})\n",
            "Epoch: 5860 | MAE Train Loss: 0.07957738637924194 | MAE Test Loss: 0.19646906852722168 \n",
            "OrderedDict({'weights': tensor([0.3021]), 'bias': tensor([0.4576])})\n",
            "Epoch: 5870 | MAE Train Loss: 0.07953738421201706 | MAE Test Loss: 0.19629108905792236 \n",
            "OrderedDict({'weights': tensor([0.3023]), 'bias': tensor([0.4576])})\n",
            "Epoch: 5880 | MAE Train Loss: 0.07949739694595337 | MAE Test Loss: 0.19611310958862305 \n",
            "OrderedDict({'weights': tensor([0.3025]), 'bias': tensor([0.4576])})\n",
            "Epoch: 5890 | MAE Train Loss: 0.07945740222930908 | MAE Test Loss: 0.19593514502048492 \n",
            "OrderedDict({'weights': tensor([0.3027]), 'bias': tensor([0.4576])})\n",
            "Epoch: 5900 | MAE Train Loss: 0.0794174075126648 | MAE Test Loss: 0.1957571804523468 \n",
            "OrderedDict({'weights': tensor([0.3029]), 'bias': tensor([0.4576])})\n",
            "Epoch: 5910 | MAE Train Loss: 0.07937741279602051 | MAE Test Loss: 0.19557920098304749 \n",
            "OrderedDict({'weights': tensor([0.3031]), 'bias': tensor([0.4576])})\n",
            "Epoch: 5920 | MAE Train Loss: 0.07933741807937622 | MAE Test Loss: 0.19540122151374817 \n",
            "OrderedDict({'weights': tensor([0.3033]), 'bias': tensor([0.4576])})\n",
            "Epoch: 5930 | MAE Train Loss: 0.07929743826389313 | MAE Test Loss: 0.19522324204444885 \n",
            "OrderedDict({'weights': tensor([0.3035]), 'bias': tensor([0.4576])})\n",
            "Epoch: 5940 | MAE Train Loss: 0.07925742864608765 | MAE Test Loss: 0.19504526257514954 \n",
            "OrderedDict({'weights': tensor([0.3037]), 'bias': tensor([0.4576])})\n",
            "Epoch: 5950 | MAE Train Loss: 0.07921743392944336 | MAE Test Loss: 0.19486728310585022 \n",
            "OrderedDict({'weights': tensor([0.3039]), 'bias': tensor([0.4576])})\n",
            "Epoch: 5960 | MAE Train Loss: 0.07917743921279907 | MAE Test Loss: 0.1946893036365509 \n",
            "OrderedDict({'weights': tensor([0.3041]), 'bias': tensor([0.4576])})\n",
            "Epoch: 5970 | MAE Train Loss: 0.07913744449615479 | MAE Test Loss: 0.1945113241672516 \n",
            "OrderedDict({'weights': tensor([0.3043]), 'bias': tensor([0.4576])})\n",
            "Epoch: 5980 | MAE Train Loss: 0.0790974572300911 | MAE Test Loss: 0.19433334469795227 \n",
            "OrderedDict({'weights': tensor([0.3045]), 'bias': tensor([0.4576])})\n",
            "Epoch: 5990 | MAE Train Loss: 0.07905744761228561 | MAE Test Loss: 0.19415536522865295 \n",
            "OrderedDict({'weights': tensor([0.3047]), 'bias': tensor([0.4576])})\n",
            "Epoch: 6000 | MAE Train Loss: 0.07901746034622192 | MAE Test Loss: 0.19397740066051483 \n",
            "OrderedDict({'weights': tensor([0.3049]), 'bias': tensor([0.4576])})\n",
            "Epoch: 6010 | MAE Train Loss: 0.07897746562957764 | MAE Test Loss: 0.1937994509935379 \n",
            "OrderedDict({'weights': tensor([0.3051]), 'bias': tensor([0.4576])})\n",
            "Epoch: 6020 | MAE Train Loss: 0.07893747836351395 | MAE Test Loss: 0.1936214715242386 \n",
            "OrderedDict({'weights': tensor([0.3053]), 'bias': tensor([0.4576])})\n",
            "Epoch: 6030 | MAE Train Loss: 0.07889748364686966 | MAE Test Loss: 0.19344347715377808 \n",
            "OrderedDict({'weights': tensor([0.3055]), 'bias': tensor([0.4576])})\n",
            "Epoch: 6040 | MAE Train Loss: 0.07885748893022537 | MAE Test Loss: 0.19326548278331757 \n",
            "OrderedDict({'weights': tensor([0.3057]), 'bias': tensor([0.4576])})\n",
            "Epoch: 6050 | MAE Train Loss: 0.07881748676300049 | MAE Test Loss: 0.19308754801750183 \n",
            "OrderedDict({'weights': tensor([0.3059]), 'bias': tensor([0.4576])})\n",
            "Epoch: 6060 | MAE Train Loss: 0.0787823423743248 | MAE Test Loss: 0.19297738373279572 \n",
            "OrderedDict({'weights': tensor([0.3061]), 'bias': tensor([0.4576])})\n",
            "Epoch: 6070 | MAE Train Loss: 0.07874744385480881 | MAE Test Loss: 0.192867249250412 \n",
            "OrderedDict({'weights': tensor([0.3063]), 'bias': tensor([0.4575])})\n",
            "Epoch: 6080 | MAE Train Loss: 0.07871253788471222 | MAE Test Loss: 0.19275712966918945 \n",
            "OrderedDict({'weights': tensor([0.3065]), 'bias': tensor([0.4575])})\n",
            "Epoch: 6090 | MAE Train Loss: 0.07867763191461563 | MAE Test Loss: 0.19264695048332214 \n",
            "OrderedDict({'weights': tensor([0.3067]), 'bias': tensor([0.4574])})\n",
            "Epoch: 6100 | MAE Train Loss: 0.07864274084568024 | MAE Test Loss: 0.192536860704422 \n",
            "OrderedDict({'weights': tensor([0.3068]), 'bias': tensor([0.4574])})\n",
            "Epoch: 6110 | MAE Train Loss: 0.07860783487558365 | MAE Test Loss: 0.19242669641971588 \n",
            "OrderedDict({'weights': tensor([0.3070]), 'bias': tensor([0.4573])})\n",
            "Epoch: 6120 | MAE Train Loss: 0.07857291400432587 | MAE Test Loss: 0.19231656193733215 \n",
            "OrderedDict({'weights': tensor([0.3072]), 'bias': tensor([0.4573])})\n",
            "Epoch: 6130 | MAE Train Loss: 0.07853801548480988 | MAE Test Loss: 0.19220641255378723 \n",
            "OrderedDict({'weights': tensor([0.3074]), 'bias': tensor([0.4572])})\n",
            "Epoch: 6140 | MAE Train Loss: 0.07850310951471329 | MAE Test Loss: 0.1920963078737259 \n",
            "OrderedDict({'weights': tensor([0.3076]), 'bias': tensor([0.4572])})\n",
            "Epoch: 6150 | MAE Train Loss: 0.0784682109951973 | MAE Test Loss: 0.19198617339134216 \n",
            "OrderedDict({'weights': tensor([0.3077]), 'bias': tensor([0.4571])})\n",
            "Epoch: 6160 | MAE Train Loss: 0.07843330502510071 | MAE Test Loss: 0.19187600910663605 \n",
            "OrderedDict({'weights': tensor([0.3079]), 'bias': tensor([0.4571])})\n",
            "Epoch: 6170 | MAE Train Loss: 0.07839839905500412 | MAE Test Loss: 0.19176587462425232 \n",
            "OrderedDict({'weights': tensor([0.3081]), 'bias': tensor([0.4570])})\n",
            "Epoch: 6180 | MAE Train Loss: 0.07836349308490753 | MAE Test Loss: 0.19165575504302979 \n",
            "OrderedDict({'weights': tensor([0.3083]), 'bias': tensor([0.4570])})\n",
            "Epoch: 6190 | MAE Train Loss: 0.07832858711481094 | MAE Test Loss: 0.19154557585716248 \n",
            "OrderedDict({'weights': tensor([0.3085]), 'bias': tensor([0.4569])})\n",
            "Epoch: 6200 | MAE Train Loss: 0.07829368859529495 | MAE Test Loss: 0.19143548607826233 \n",
            "OrderedDict({'weights': tensor([0.3086]), 'bias': tensor([0.4569])})\n",
            "Epoch: 6210 | MAE Train Loss: 0.07825878262519836 | MAE Test Loss: 0.1913253217935562 \n",
            "OrderedDict({'weights': tensor([0.3088]), 'bias': tensor([0.4568])})\n",
            "Epoch: 6220 | MAE Train Loss: 0.07822386920452118 | MAE Test Loss: 0.19121518731117249 \n",
            "OrderedDict({'weights': tensor([0.3090]), 'bias': tensor([0.4568])})\n",
            "Epoch: 6230 | MAE Train Loss: 0.07818897068500519 | MAE Test Loss: 0.19110503792762756 \n",
            "OrderedDict({'weights': tensor([0.3092]), 'bias': tensor([0.4567])})\n",
            "Epoch: 6240 | MAE Train Loss: 0.0781540647149086 | MAE Test Loss: 0.19099493324756622 \n",
            "OrderedDict({'weights': tensor([0.3094]), 'bias': tensor([0.4567])})\n",
            "Epoch: 6250 | MAE Train Loss: 0.0781191736459732 | MAE Test Loss: 0.1908847987651825 \n",
            "OrderedDict({'weights': tensor([0.3095]), 'bias': tensor([0.4566])})\n",
            "Epoch: 6260 | MAE Train Loss: 0.07808425277471542 | MAE Test Loss: 0.19077463448047638 \n",
            "OrderedDict({'weights': tensor([0.3097]), 'bias': tensor([0.4566])})\n",
            "Epoch: 6270 | MAE Train Loss: 0.07804935425519943 | MAE Test Loss: 0.19066449999809265 \n",
            "OrderedDict({'weights': tensor([0.3099]), 'bias': tensor([0.4565])})\n",
            "Epoch: 6280 | MAE Train Loss: 0.07801444828510284 | MAE Test Loss: 0.19055438041687012 \n",
            "OrderedDict({'weights': tensor([0.3101]), 'bias': tensor([0.4565])})\n",
            "Epoch: 6290 | MAE Train Loss: 0.07797954231500626 | MAE Test Loss: 0.1904442012310028 \n",
            "OrderedDict({'weights': tensor([0.3103]), 'bias': tensor([0.4564])})\n",
            "Epoch: 6300 | MAE Train Loss: 0.07794465124607086 | MAE Test Loss: 0.19033411145210266 \n",
            "OrderedDict({'weights': tensor([0.3104]), 'bias': tensor([0.4564])})\n",
            "Epoch: 6310 | MAE Train Loss: 0.07790974527597427 | MAE Test Loss: 0.19022394716739655 \n",
            "OrderedDict({'weights': tensor([0.3106]), 'bias': tensor([0.4563])})\n",
            "Epoch: 6320 | MAE Train Loss: 0.07787483185529709 | MAE Test Loss: 0.19011381268501282 \n",
            "OrderedDict({'weights': tensor([0.3108]), 'bias': tensor([0.4563])})\n",
            "Epoch: 6330 | MAE Train Loss: 0.0778399258852005 | MAE Test Loss: 0.1900036633014679 \n",
            "OrderedDict({'weights': tensor([0.3110]), 'bias': tensor([0.4562])})\n",
            "Epoch: 6340 | MAE Train Loss: 0.07780501991510391 | MAE Test Loss: 0.18989355862140656 \n",
            "OrderedDict({'weights': tensor([0.3112]), 'bias': tensor([0.4562])})\n",
            "Epoch: 6350 | MAE Train Loss: 0.07777012139558792 | MAE Test Loss: 0.18978342413902283 \n",
            "OrderedDict({'weights': tensor([0.3113]), 'bias': tensor([0.4561])})\n",
            "Epoch: 6360 | MAE Train Loss: 0.07773521542549133 | MAE Test Loss: 0.1896732598543167 \n",
            "OrderedDict({'weights': tensor([0.3115]), 'bias': tensor([0.4561])})\n",
            "Epoch: 6370 | MAE Train Loss: 0.07770030945539474 | MAE Test Loss: 0.18956312537193298 \n",
            "OrderedDict({'weights': tensor([0.3117]), 'bias': tensor([0.4560])})\n",
            "Epoch: 6380 | MAE Train Loss: 0.07766540348529816 | MAE Test Loss: 0.18945300579071045 \n",
            "OrderedDict({'weights': tensor([0.3119]), 'bias': tensor([0.4560])})\n",
            "Epoch: 6390 | MAE Train Loss: 0.07763049751520157 | MAE Test Loss: 0.18934282660484314 \n",
            "OrderedDict({'weights': tensor([0.3121]), 'bias': tensor([0.4559])})\n",
            "Epoch: 6400 | MAE Train Loss: 0.07759559899568558 | MAE Test Loss: 0.189232736825943 \n",
            "OrderedDict({'weights': tensor([0.3122]), 'bias': tensor([0.4559])})\n",
            "Epoch: 6410 | MAE Train Loss: 0.07756069302558899 | MAE Test Loss: 0.18912257254123688 \n",
            "OrderedDict({'weights': tensor([0.3124]), 'bias': tensor([0.4558])})\n",
            "Epoch: 6420 | MAE Train Loss: 0.0775257870554924 | MAE Test Loss: 0.18901243805885315 \n",
            "OrderedDict({'weights': tensor([0.3126]), 'bias': tensor([0.4558])})\n",
            "Epoch: 6430 | MAE Train Loss: 0.07749088108539581 | MAE Test Loss: 0.18890228867530823 \n",
            "OrderedDict({'weights': tensor([0.3128]), 'bias': tensor([0.4557])})\n",
            "Epoch: 6440 | MAE Train Loss: 0.07745597511529922 | MAE Test Loss: 0.1887921839952469 \n",
            "OrderedDict({'weights': tensor([0.3130]), 'bias': tensor([0.4557])})\n",
            "Epoch: 6450 | MAE Train Loss: 0.07742108404636383 | MAE Test Loss: 0.18868204951286316 \n",
            "OrderedDict({'weights': tensor([0.3131]), 'bias': tensor([0.4556])})\n",
            "Epoch: 6460 | MAE Train Loss: 0.07738616317510605 | MAE Test Loss: 0.18857188522815704 \n",
            "OrderedDict({'weights': tensor([0.3133]), 'bias': tensor([0.4556])})\n",
            "Epoch: 6470 | MAE Train Loss: 0.07735126465559006 | MAE Test Loss: 0.18846175074577332 \n",
            "OrderedDict({'weights': tensor([0.3135]), 'bias': tensor([0.4555])})\n",
            "Epoch: 6480 | MAE Train Loss: 0.07731635868549347 | MAE Test Loss: 0.18835163116455078 \n",
            "OrderedDict({'weights': tensor([0.3137]), 'bias': tensor([0.4555])})\n",
            "Epoch: 6490 | MAE Train Loss: 0.07728145271539688 | MAE Test Loss: 0.18824145197868347 \n",
            "OrderedDict({'weights': tensor([0.3139]), 'bias': tensor([0.4554])})\n",
            "Epoch: 6500 | MAE Train Loss: 0.07724656164646149 | MAE Test Loss: 0.18813136219978333 \n",
            "OrderedDict({'weights': tensor([0.3140]), 'bias': tensor([0.4554])})\n",
            "Epoch: 6510 | MAE Train Loss: 0.0772116556763649 | MAE Test Loss: 0.1880211979150772 \n",
            "OrderedDict({'weights': tensor([0.3142]), 'bias': tensor([0.4553])})\n",
            "Epoch: 6520 | MAE Train Loss: 0.07717674225568771 | MAE Test Loss: 0.18791106343269348 \n",
            "OrderedDict({'weights': tensor([0.3144]), 'bias': tensor([0.4553])})\n",
            "Epoch: 6530 | MAE Train Loss: 0.07714183628559113 | MAE Test Loss: 0.18780091404914856 \n",
            "OrderedDict({'weights': tensor([0.3146]), 'bias': tensor([0.4552])})\n",
            "Epoch: 6540 | MAE Train Loss: 0.07710693031549454 | MAE Test Loss: 0.18769080936908722 \n",
            "OrderedDict({'weights': tensor([0.3148]), 'bias': tensor([0.4552])})\n",
            "Epoch: 6550 | MAE Train Loss: 0.07707203179597855 | MAE Test Loss: 0.1875806748867035 \n",
            "OrderedDict({'weights': tensor([0.3149]), 'bias': tensor([0.4551])})\n",
            "Epoch: 6560 | MAE Train Loss: 0.07703712582588196 | MAE Test Loss: 0.18747051060199738 \n",
            "OrderedDict({'weights': tensor([0.3151]), 'bias': tensor([0.4551])})\n",
            "Epoch: 6570 | MAE Train Loss: 0.07700221985578537 | MAE Test Loss: 0.18736037611961365 \n",
            "OrderedDict({'weights': tensor([0.3153]), 'bias': tensor([0.4550])})\n",
            "Epoch: 6580 | MAE Train Loss: 0.07696731388568878 | MAE Test Loss: 0.1872502565383911 \n",
            "OrderedDict({'weights': tensor([0.3155]), 'bias': tensor([0.4550])})\n",
            "Epoch: 6590 | MAE Train Loss: 0.0769324079155922 | MAE Test Loss: 0.1871400773525238 \n",
            "OrderedDict({'weights': tensor([0.3157]), 'bias': tensor([0.4549])})\n",
            "Epoch: 6600 | MAE Train Loss: 0.0768975093960762 | MAE Test Loss: 0.18702998757362366 \n",
            "OrderedDict({'weights': tensor([0.3158]), 'bias': tensor([0.4549])})\n",
            "Epoch: 6610 | MAE Train Loss: 0.07686260342597961 | MAE Test Loss: 0.18691982328891754 \n",
            "OrderedDict({'weights': tensor([0.3160]), 'bias': tensor([0.4548])})\n",
            "Epoch: 6620 | MAE Train Loss: 0.07682769745588303 | MAE Test Loss: 0.1868096888065338 \n",
            "OrderedDict({'weights': tensor([0.3162]), 'bias': tensor([0.4548])})\n",
            "Epoch: 6630 | MAE Train Loss: 0.07679279148578644 | MAE Test Loss: 0.1866995394229889 \n",
            "OrderedDict({'weights': tensor([0.3164]), 'bias': tensor([0.4547])})\n",
            "Epoch: 6640 | MAE Train Loss: 0.07675788551568985 | MAE Test Loss: 0.18658943474292755 \n",
            "OrderedDict({'weights': tensor([0.3166]), 'bias': tensor([0.4547])})\n",
            "Epoch: 6650 | MAE Train Loss: 0.07672299444675446 | MAE Test Loss: 0.18647930026054382 \n",
            "OrderedDict({'weights': tensor([0.3167]), 'bias': tensor([0.4546])})\n",
            "Epoch: 6660 | MAE Train Loss: 0.07668807357549667 | MAE Test Loss: 0.1863691359758377 \n",
            "OrderedDict({'weights': tensor([0.3169]), 'bias': tensor([0.4546])})\n",
            "Epoch: 6670 | MAE Train Loss: 0.07665317505598068 | MAE Test Loss: 0.18625900149345398 \n",
            "OrderedDict({'weights': tensor([0.3171]), 'bias': tensor([0.4545])})\n",
            "Epoch: 6680 | MAE Train Loss: 0.0766182690858841 | MAE Test Loss: 0.18614888191223145 \n",
            "OrderedDict({'weights': tensor([0.3173]), 'bias': tensor([0.4545])})\n",
            "Epoch: 6690 | MAE Train Loss: 0.0765833631157875 | MAE Test Loss: 0.18603870272636414 \n",
            "OrderedDict({'weights': tensor([0.3175]), 'bias': tensor([0.4544])})\n",
            "Epoch: 6700 | MAE Train Loss: 0.07654847204685211 | MAE Test Loss: 0.185928612947464 \n",
            "OrderedDict({'weights': tensor([0.3176]), 'bias': tensor([0.4544])})\n",
            "Epoch: 6710 | MAE Train Loss: 0.07651356607675552 | MAE Test Loss: 0.18581844866275787 \n",
            "OrderedDict({'weights': tensor([0.3178]), 'bias': tensor([0.4543])})\n",
            "Epoch: 6720 | MAE Train Loss: 0.07647865265607834 | MAE Test Loss: 0.18570831418037415 \n",
            "OrderedDict({'weights': tensor([0.3180]), 'bias': tensor([0.4543])})\n",
            "Epoch: 6730 | MAE Train Loss: 0.07644374668598175 | MAE Test Loss: 0.18559816479682922 \n",
            "OrderedDict({'weights': tensor([0.3182]), 'bias': tensor([0.4542])})\n",
            "Epoch: 6740 | MAE Train Loss: 0.07640884071588516 | MAE Test Loss: 0.18548806011676788 \n",
            "OrderedDict({'weights': tensor([0.3184]), 'bias': tensor([0.4542])})\n",
            "Epoch: 6750 | MAE Train Loss: 0.07637394219636917 | MAE Test Loss: 0.18537792563438416 \n",
            "OrderedDict({'weights': tensor([0.3185]), 'bias': tensor([0.4541])})\n",
            "Epoch: 6760 | MAE Train Loss: 0.07633903622627258 | MAE Test Loss: 0.18526776134967804 \n",
            "OrderedDict({'weights': tensor([0.3187]), 'bias': tensor([0.4541])})\n",
            "Epoch: 6770 | MAE Train Loss: 0.076304130256176 | MAE Test Loss: 0.1851576268672943 \n",
            "OrderedDict({'weights': tensor([0.3189]), 'bias': tensor([0.4540])})\n",
            "Epoch: 6780 | MAE Train Loss: 0.0762692242860794 | MAE Test Loss: 0.18504750728607178 \n",
            "OrderedDict({'weights': tensor([0.3191]), 'bias': tensor([0.4540])})\n",
            "Epoch: 6790 | MAE Train Loss: 0.07623431831598282 | MAE Test Loss: 0.18493732810020447 \n",
            "OrderedDict({'weights': tensor([0.3193]), 'bias': tensor([0.4539])})\n",
            "Epoch: 6800 | MAE Train Loss: 0.07619941979646683 | MAE Test Loss: 0.18482723832130432 \n",
            "OrderedDict({'weights': tensor([0.3194]), 'bias': tensor([0.4539])})\n",
            "Epoch: 6810 | MAE Train Loss: 0.07616451382637024 | MAE Test Loss: 0.1847170740365982 \n",
            "OrderedDict({'weights': tensor([0.3196]), 'bias': tensor([0.4538])})\n",
            "Epoch: 6820 | MAE Train Loss: 0.07612960785627365 | MAE Test Loss: 0.18460693955421448 \n",
            "OrderedDict({'weights': tensor([0.3198]), 'bias': tensor([0.4538])})\n",
            "Epoch: 6830 | MAE Train Loss: 0.07609470188617706 | MAE Test Loss: 0.18449679017066956 \n",
            "OrderedDict({'weights': tensor([0.3200]), 'bias': tensor([0.4537])})\n",
            "Epoch: 6840 | MAE Train Loss: 0.07605979591608047 | MAE Test Loss: 0.18438668549060822 \n",
            "OrderedDict({'weights': tensor([0.3202]), 'bias': tensor([0.4537])})\n",
            "Epoch: 6850 | MAE Train Loss: 0.07602488994598389 | MAE Test Loss: 0.1842765510082245 \n",
            "OrderedDict({'weights': tensor([0.3203]), 'bias': tensor([0.4536])})\n",
            "Epoch: 6860 | MAE Train Loss: 0.0759899839758873 | MAE Test Loss: 0.18416638672351837 \n",
            "OrderedDict({'weights': tensor([0.3205]), 'bias': tensor([0.4536])})\n",
            "Epoch: 6870 | MAE Train Loss: 0.07595508545637131 | MAE Test Loss: 0.18405625224113464 \n",
            "OrderedDict({'weights': tensor([0.3207]), 'bias': tensor([0.4535])})\n",
            "Epoch: 6880 | MAE Train Loss: 0.07592017948627472 | MAE Test Loss: 0.1839461326599121 \n",
            "OrderedDict({'weights': tensor([0.3209]), 'bias': tensor([0.4535])})\n",
            "Epoch: 6890 | MAE Train Loss: 0.07588527351617813 | MAE Test Loss: 0.1838359534740448 \n",
            "OrderedDict({'weights': tensor([0.3211]), 'bias': tensor([0.4534])})\n",
            "Epoch: 6900 | MAE Train Loss: 0.07585038244724274 | MAE Test Loss: 0.18372586369514465 \n",
            "OrderedDict({'weights': tensor([0.3212]), 'bias': tensor([0.4534])})\n",
            "Epoch: 6910 | MAE Train Loss: 0.07581547647714615 | MAE Test Loss: 0.18361569941043854 \n",
            "OrderedDict({'weights': tensor([0.3214]), 'bias': tensor([0.4533])})\n",
            "Epoch: 6920 | MAE Train Loss: 0.07578056305646896 | MAE Test Loss: 0.1835055649280548 \n",
            "OrderedDict({'weights': tensor([0.3216]), 'bias': tensor([0.4533])})\n",
            "Epoch: 6930 | MAE Train Loss: 0.07574565708637238 | MAE Test Loss: 0.1833954155445099 \n",
            "OrderedDict({'weights': tensor([0.3218]), 'bias': tensor([0.4532])})\n",
            "Epoch: 6940 | MAE Train Loss: 0.07571075111627579 | MAE Test Loss: 0.18328531086444855 \n",
            "OrderedDict({'weights': tensor([0.3220]), 'bias': tensor([0.4532])})\n",
            "Epoch: 6950 | MAE Train Loss: 0.0756758525967598 | MAE Test Loss: 0.18317517638206482 \n",
            "OrderedDict({'weights': tensor([0.3221]), 'bias': tensor([0.4531])})\n",
            "Epoch: 6960 | MAE Train Loss: 0.07564094662666321 | MAE Test Loss: 0.1830650120973587 \n",
            "OrderedDict({'weights': tensor([0.3223]), 'bias': tensor([0.4531])})\n",
            "Epoch: 6970 | MAE Train Loss: 0.07560604065656662 | MAE Test Loss: 0.18295487761497498 \n",
            "OrderedDict({'weights': tensor([0.3225]), 'bias': tensor([0.4530])})\n",
            "Epoch: 6980 | MAE Train Loss: 0.07557113468647003 | MAE Test Loss: 0.18284475803375244 \n",
            "OrderedDict({'weights': tensor([0.3227]), 'bias': tensor([0.4530])})\n",
            "Epoch: 6990 | MAE Train Loss: 0.07553622871637344 | MAE Test Loss: 0.18273457884788513 \n",
            "OrderedDict({'weights': tensor([0.3229]), 'bias': tensor([0.4529])})\n",
            "Epoch: 7000 | MAE Train Loss: 0.07550133019685745 | MAE Test Loss: 0.18262448906898499 \n",
            "OrderedDict({'weights': tensor([0.3230]), 'bias': tensor([0.4529])})\n",
            "Epoch: 7010 | MAE Train Loss: 0.07546642422676086 | MAE Test Loss: 0.18251432478427887 \n",
            "OrderedDict({'weights': tensor([0.3232]), 'bias': tensor([0.4528])})\n",
            "Epoch: 7020 | MAE Train Loss: 0.07543151825666428 | MAE Test Loss: 0.18240419030189514 \n",
            "OrderedDict({'weights': tensor([0.3234]), 'bias': tensor([0.4528])})\n",
            "Epoch: 7030 | MAE Train Loss: 0.07539661228656769 | MAE Test Loss: 0.18229404091835022 \n",
            "OrderedDict({'weights': tensor([0.3236]), 'bias': tensor([0.4527])})\n",
            "Epoch: 7040 | MAE Train Loss: 0.0753617063164711 | MAE Test Loss: 0.18218393623828888 \n",
            "OrderedDict({'weights': tensor([0.3238]), 'bias': tensor([0.4527])})\n",
            "Epoch: 7050 | MAE Train Loss: 0.07532680034637451 | MAE Test Loss: 0.18207380175590515 \n",
            "OrderedDict({'weights': tensor([0.3239]), 'bias': tensor([0.4526])})\n",
            "Epoch: 7060 | MAE Train Loss: 0.07529189437627792 | MAE Test Loss: 0.18196363747119904 \n",
            "OrderedDict({'weights': tensor([0.3241]), 'bias': tensor([0.4526])})\n",
            "Epoch: 7070 | MAE Train Loss: 0.07525699585676193 | MAE Test Loss: 0.1818535029888153 \n",
            "OrderedDict({'weights': tensor([0.3243]), 'bias': tensor([0.4525])})\n",
            "Epoch: 7080 | MAE Train Loss: 0.07522208988666534 | MAE Test Loss: 0.18174338340759277 \n",
            "OrderedDict({'weights': tensor([0.3245]), 'bias': tensor([0.4525])})\n",
            "Epoch: 7090 | MAE Train Loss: 0.07518718391656876 | MAE Test Loss: 0.18163320422172546 \n",
            "OrderedDict({'weights': tensor([0.3247]), 'bias': tensor([0.4524])})\n",
            "Epoch: 7100 | MAE Train Loss: 0.07515229284763336 | MAE Test Loss: 0.18152311444282532 \n",
            "OrderedDict({'weights': tensor([0.3248]), 'bias': tensor([0.4524])})\n",
            "Epoch: 7110 | MAE Train Loss: 0.07511738687753677 | MAE Test Loss: 0.1814129501581192 \n",
            "OrderedDict({'weights': tensor([0.3250]), 'bias': tensor([0.4523])})\n",
            "Epoch: 7120 | MAE Train Loss: 0.07508247345685959 | MAE Test Loss: 0.18130281567573547 \n",
            "OrderedDict({'weights': tensor([0.3252]), 'bias': tensor([0.4523])})\n",
            "Epoch: 7130 | MAE Train Loss: 0.075047567486763 | MAE Test Loss: 0.18119266629219055 \n",
            "OrderedDict({'weights': tensor([0.3254]), 'bias': tensor([0.4522])})\n",
            "Epoch: 7140 | MAE Train Loss: 0.07501266151666641 | MAE Test Loss: 0.1810825616121292 \n",
            "OrderedDict({'weights': tensor([0.3256]), 'bias': tensor([0.4522])})\n",
            "Epoch: 7150 | MAE Train Loss: 0.07497776299715042 | MAE Test Loss: 0.18097242712974548 \n",
            "OrderedDict({'weights': tensor([0.3257]), 'bias': tensor([0.4521])})\n",
            "Epoch: 7160 | MAE Train Loss: 0.07494285702705383 | MAE Test Loss: 0.18086226284503937 \n",
            "OrderedDict({'weights': tensor([0.3259]), 'bias': tensor([0.4521])})\n",
            "Epoch: 7170 | MAE Train Loss: 0.07490795105695724 | MAE Test Loss: 0.18075212836265564 \n",
            "OrderedDict({'weights': tensor([0.3261]), 'bias': tensor([0.4520])})\n",
            "Epoch: 7180 | MAE Train Loss: 0.07487304508686066 | MAE Test Loss: 0.1806420087814331 \n",
            "OrderedDict({'weights': tensor([0.3263]), 'bias': tensor([0.4520])})\n",
            "Epoch: 7190 | MAE Train Loss: 0.07483813911676407 | MAE Test Loss: 0.1805318295955658 \n",
            "OrderedDict({'weights': tensor([0.3265]), 'bias': tensor([0.4519])})\n",
            "Epoch: 7200 | MAE Train Loss: 0.07480324059724808 | MAE Test Loss: 0.18042173981666565 \n",
            "OrderedDict({'weights': tensor([0.3266]), 'bias': tensor([0.4519])})\n",
            "Epoch: 7210 | MAE Train Loss: 0.07476833462715149 | MAE Test Loss: 0.18031157553195953 \n",
            "OrderedDict({'weights': tensor([0.3268]), 'bias': tensor([0.4518])})\n",
            "Epoch: 7220 | MAE Train Loss: 0.0747334286570549 | MAE Test Loss: 0.1802014410495758 \n",
            "OrderedDict({'weights': tensor([0.3270]), 'bias': tensor([0.4518])})\n",
            "Epoch: 7230 | MAE Train Loss: 0.07469852268695831 | MAE Test Loss: 0.18009129166603088 \n",
            "OrderedDict({'weights': tensor([0.3272]), 'bias': tensor([0.4517])})\n",
            "Epoch: 7240 | MAE Train Loss: 0.07466361671686172 | MAE Test Loss: 0.17998118698596954 \n",
            "OrderedDict({'weights': tensor([0.3274]), 'bias': tensor([0.4517])})\n",
            "Epoch: 7250 | MAE Train Loss: 0.07462871074676514 | MAE Test Loss: 0.17987105250358582 \n",
            "OrderedDict({'weights': tensor([0.3275]), 'bias': tensor([0.4516])})\n",
            "Epoch: 7260 | MAE Train Loss: 0.07459380477666855 | MAE Test Loss: 0.1797608882188797 \n",
            "OrderedDict({'weights': tensor([0.3277]), 'bias': tensor([0.4516])})\n",
            "Epoch: 7270 | MAE Train Loss: 0.07455890625715256 | MAE Test Loss: 0.17965075373649597 \n",
            "OrderedDict({'weights': tensor([0.3279]), 'bias': tensor([0.4515])})\n",
            "Epoch: 7280 | MAE Train Loss: 0.07452400028705597 | MAE Test Loss: 0.17954063415527344 \n",
            "OrderedDict({'weights': tensor([0.3281]), 'bias': tensor([0.4515])})\n",
            "Epoch: 7290 | MAE Train Loss: 0.07448909431695938 | MAE Test Loss: 0.17943045496940613 \n",
            "OrderedDict({'weights': tensor([0.3283]), 'bias': tensor([0.4514])})\n",
            "Epoch: 7300 | MAE Train Loss: 0.07445420324802399 | MAE Test Loss: 0.17932036519050598 \n",
            "OrderedDict({'weights': tensor([0.3284]), 'bias': tensor([0.4514])})\n",
            "Epoch: 7310 | MAE Train Loss: 0.0744192972779274 | MAE Test Loss: 0.17921020090579987 \n",
            "OrderedDict({'weights': tensor([0.3286]), 'bias': tensor([0.4513])})\n",
            "Epoch: 7320 | MAE Train Loss: 0.07438438385725021 | MAE Test Loss: 0.17910006642341614 \n",
            "OrderedDict({'weights': tensor([0.3288]), 'bias': tensor([0.4513])})\n",
            "Epoch: 7330 | MAE Train Loss: 0.07434947788715363 | MAE Test Loss: 0.17898991703987122 \n",
            "OrderedDict({'weights': tensor([0.3290]), 'bias': tensor([0.4512])})\n",
            "Epoch: 7340 | MAE Train Loss: 0.07431457191705704 | MAE Test Loss: 0.17887981235980988 \n",
            "OrderedDict({'weights': tensor([0.3292]), 'bias': tensor([0.4512])})\n",
            "Epoch: 7350 | MAE Train Loss: 0.07427966594696045 | MAE Test Loss: 0.17876967787742615 \n",
            "OrderedDict({'weights': tensor([0.3293]), 'bias': tensor([0.4511])})\n",
            "Epoch: 7360 | MAE Train Loss: 0.07424476742744446 | MAE Test Loss: 0.17865951359272003 \n",
            "OrderedDict({'weights': tensor([0.3295]), 'bias': tensor([0.4511])})\n",
            "Epoch: 7370 | MAE Train Loss: 0.07420985400676727 | MAE Test Loss: 0.1785493791103363 \n",
            "OrderedDict({'weights': tensor([0.3297]), 'bias': tensor([0.4510])})\n",
            "Epoch: 7380 | MAE Train Loss: 0.07417495548725128 | MAE Test Loss: 0.17843925952911377 \n",
            "OrderedDict({'weights': tensor([0.3299]), 'bias': tensor([0.4510])})\n",
            "Epoch: 7390 | MAE Train Loss: 0.0741400495171547 | MAE Test Loss: 0.17832908034324646 \n",
            "OrderedDict({'weights': tensor([0.3301]), 'bias': tensor([0.4509])})\n",
            "Epoch: 7400 | MAE Train Loss: 0.0741051509976387 | MAE Test Loss: 0.1782189905643463 \n",
            "OrderedDict({'weights': tensor([0.3302]), 'bias': tensor([0.4509])})\n",
            "Epoch: 7410 | MAE Train Loss: 0.07407024502754211 | MAE Test Loss: 0.1781088262796402 \n",
            "OrderedDict({'weights': tensor([0.3304]), 'bias': tensor([0.4508])})\n",
            "Epoch: 7420 | MAE Train Loss: 0.07403533160686493 | MAE Test Loss: 0.17799869179725647 \n",
            "OrderedDict({'weights': tensor([0.3306]), 'bias': tensor([0.4508])})\n",
            "Epoch: 7430 | MAE Train Loss: 0.07400043308734894 | MAE Test Loss: 0.17788854241371155 \n",
            "OrderedDict({'weights': tensor([0.3308]), 'bias': tensor([0.4507])})\n",
            "Epoch: 7440 | MAE Train Loss: 0.07396552711725235 | MAE Test Loss: 0.1777784377336502 \n",
            "OrderedDict({'weights': tensor([0.3310]), 'bias': tensor([0.4507])})\n",
            "Epoch: 7450 | MAE Train Loss: 0.07393062114715576 | MAE Test Loss: 0.17766830325126648 \n",
            "OrderedDict({'weights': tensor([0.3311]), 'bias': tensor([0.4506])})\n",
            "Epoch: 7460 | MAE Train Loss: 0.07389571517705917 | MAE Test Loss: 0.17755813896656036 \n",
            "OrderedDict({'weights': tensor([0.3313]), 'bias': tensor([0.4506])})\n",
            "Epoch: 7470 | MAE Train Loss: 0.07386080920696259 | MAE Test Loss: 0.17744800448417664 \n",
            "OrderedDict({'weights': tensor([0.3315]), 'bias': tensor([0.4505])})\n",
            "Epoch: 7480 | MAE Train Loss: 0.0738259106874466 | MAE Test Loss: 0.1773378849029541 \n",
            "OrderedDict({'weights': tensor([0.3317]), 'bias': tensor([0.4505])})\n",
            "Epoch: 7490 | MAE Train Loss: 0.07379100471735 | MAE Test Loss: 0.1772277057170868 \n",
            "OrderedDict({'weights': tensor([0.3319]), 'bias': tensor([0.4504])})\n",
            "Epoch: 7500 | MAE Train Loss: 0.07375610619783401 | MAE Test Loss: 0.17711761593818665 \n",
            "OrderedDict({'weights': tensor([0.3320]), 'bias': tensor([0.4504])})\n",
            "Epoch: 7510 | MAE Train Loss: 0.07372120767831802 | MAE Test Loss: 0.17700745165348053 \n",
            "OrderedDict({'weights': tensor([0.3322]), 'bias': tensor([0.4503])})\n",
            "Epoch: 7520 | MAE Train Loss: 0.07368628680706024 | MAE Test Loss: 0.1768973171710968 \n",
            "OrderedDict({'weights': tensor([0.3324]), 'bias': tensor([0.4503])})\n",
            "Epoch: 7530 | MAE Train Loss: 0.07365138828754425 | MAE Test Loss: 0.17678716778755188 \n",
            "OrderedDict({'weights': tensor([0.3326]), 'bias': tensor([0.4502])})\n",
            "Epoch: 7540 | MAE Train Loss: 0.07361648231744766 | MAE Test Loss: 0.17667706310749054 \n",
            "OrderedDict({'weights': tensor([0.3328]), 'bias': tensor([0.4502])})\n",
            "Epoch: 7550 | MAE Train Loss: 0.07358157634735107 | MAE Test Loss: 0.1765669286251068 \n",
            "OrderedDict({'weights': tensor([0.3329]), 'bias': tensor([0.4501])})\n",
            "Epoch: 7560 | MAE Train Loss: 0.07354667782783508 | MAE Test Loss: 0.1764567643404007 \n",
            "OrderedDict({'weights': tensor([0.3331]), 'bias': tensor([0.4501])})\n",
            "Epoch: 7570 | MAE Train Loss: 0.0735117644071579 | MAE Test Loss: 0.17634662985801697 \n",
            "OrderedDict({'weights': tensor([0.3333]), 'bias': tensor([0.4500])})\n",
            "Epoch: 7580 | MAE Train Loss: 0.0734768658876419 | MAE Test Loss: 0.17623651027679443 \n",
            "OrderedDict({'weights': tensor([0.3335]), 'bias': tensor([0.4500])})\n",
            "Epoch: 7590 | MAE Train Loss: 0.07344195991754532 | MAE Test Loss: 0.17612633109092712 \n",
            "OrderedDict({'weights': tensor([0.3337]), 'bias': tensor([0.4499])})\n",
            "Epoch: 7600 | MAE Train Loss: 0.07340706139802933 | MAE Test Loss: 0.17601624131202698 \n",
            "OrderedDict({'weights': tensor([0.3338]), 'bias': tensor([0.4499])})\n",
            "Epoch: 7610 | MAE Train Loss: 0.07337215542793274 | MAE Test Loss: 0.17590607702732086 \n",
            "OrderedDict({'weights': tensor([0.3340]), 'bias': tensor([0.4498])})\n",
            "Epoch: 7620 | MAE Train Loss: 0.07333724200725555 | MAE Test Loss: 0.17579594254493713 \n",
            "OrderedDict({'weights': tensor([0.3342]), 'bias': tensor([0.4498])})\n",
            "Epoch: 7630 | MAE Train Loss: 0.07330234348773956 | MAE Test Loss: 0.1756857931613922 \n",
            "OrderedDict({'weights': tensor([0.3344]), 'bias': tensor([0.4497])})\n",
            "Epoch: 7640 | MAE Train Loss: 0.07326743751764297 | MAE Test Loss: 0.17557568848133087 \n",
            "OrderedDict({'weights': tensor([0.3346]), 'bias': tensor([0.4497])})\n",
            "Epoch: 7650 | MAE Train Loss: 0.07323253154754639 | MAE Test Loss: 0.17546555399894714 \n",
            "OrderedDict({'weights': tensor([0.3347]), 'bias': tensor([0.4496])})\n",
            "Epoch: 7660 | MAE Train Loss: 0.0731976255774498 | MAE Test Loss: 0.17535538971424103 \n",
            "OrderedDict({'weights': tensor([0.3349]), 'bias': tensor([0.4496])})\n",
            "Epoch: 7670 | MAE Train Loss: 0.07316271960735321 | MAE Test Loss: 0.1752452552318573 \n",
            "OrderedDict({'weights': tensor([0.3351]), 'bias': tensor([0.4495])})\n",
            "Epoch: 7680 | MAE Train Loss: 0.07312782108783722 | MAE Test Loss: 0.17513513565063477 \n",
            "OrderedDict({'weights': tensor([0.3353]), 'bias': tensor([0.4495])})\n",
            "Epoch: 7690 | MAE Train Loss: 0.07309291511774063 | MAE Test Loss: 0.17502495646476746 \n",
            "OrderedDict({'weights': tensor([0.3355]), 'bias': tensor([0.4494])})\n",
            "Epoch: 7700 | MAE Train Loss: 0.07305801659822464 | MAE Test Loss: 0.1749148666858673 \n",
            "OrderedDict({'weights': tensor([0.3356]), 'bias': tensor([0.4494])})\n",
            "Epoch: 7710 | MAE Train Loss: 0.07302311807870865 | MAE Test Loss: 0.1748047024011612 \n",
            "OrderedDict({'weights': tensor([0.3358]), 'bias': tensor([0.4493])})\n",
            "Epoch: 7720 | MAE Train Loss: 0.07298819720745087 | MAE Test Loss: 0.17469456791877747 \n",
            "OrderedDict({'weights': tensor([0.3360]), 'bias': tensor([0.4493])})\n",
            "Epoch: 7730 | MAE Train Loss: 0.07295329868793488 | MAE Test Loss: 0.17458441853523254 \n",
            "OrderedDict({'weights': tensor([0.3362]), 'bias': tensor([0.4492])})\n",
            "Epoch: 7740 | MAE Train Loss: 0.07291839271783829 | MAE Test Loss: 0.1744743138551712 \n",
            "OrderedDict({'weights': tensor([0.3364]), 'bias': tensor([0.4492])})\n",
            "Epoch: 7750 | MAE Train Loss: 0.0728834867477417 | MAE Test Loss: 0.17436417937278748 \n",
            "OrderedDict({'weights': tensor([0.3365]), 'bias': tensor([0.4491])})\n",
            "Epoch: 7760 | MAE Train Loss: 0.07284858822822571 | MAE Test Loss: 0.17425401508808136 \n",
            "OrderedDict({'weights': tensor([0.3367]), 'bias': tensor([0.4491])})\n",
            "Epoch: 7770 | MAE Train Loss: 0.07281367480754852 | MAE Test Loss: 0.17414388060569763 \n",
            "OrderedDict({'weights': tensor([0.3369]), 'bias': tensor([0.4490])})\n",
            "Epoch: 7780 | MAE Train Loss: 0.07277877628803253 | MAE Test Loss: 0.1740337610244751 \n",
            "OrderedDict({'weights': tensor([0.3371]), 'bias': tensor([0.4490])})\n",
            "Epoch: 7790 | MAE Train Loss: 0.07274387031793594 | MAE Test Loss: 0.1739235818386078 \n",
            "OrderedDict({'weights': tensor([0.3373]), 'bias': tensor([0.4489])})\n",
            "Epoch: 7800 | MAE Train Loss: 0.07270897179841995 | MAE Test Loss: 0.17381349205970764 \n",
            "OrderedDict({'weights': tensor([0.3374]), 'bias': tensor([0.4489])})\n",
            "Epoch: 7810 | MAE Train Loss: 0.07267406582832336 | MAE Test Loss: 0.17370332777500153 \n",
            "OrderedDict({'weights': tensor([0.3376]), 'bias': tensor([0.4488])})\n",
            "Epoch: 7820 | MAE Train Loss: 0.07263915240764618 | MAE Test Loss: 0.1735931932926178 \n",
            "OrderedDict({'weights': tensor([0.3378]), 'bias': tensor([0.4488])})\n",
            "Epoch: 7830 | MAE Train Loss: 0.07260425388813019 | MAE Test Loss: 0.17348304390907288 \n",
            "OrderedDict({'weights': tensor([0.3380]), 'bias': tensor([0.4487])})\n",
            "Epoch: 7840 | MAE Train Loss: 0.0725693553686142 | MAE Test Loss: 0.17337293922901154 \n",
            "OrderedDict({'weights': tensor([0.3382]), 'bias': tensor([0.4487])})\n",
            "Epoch: 7850 | MAE Train Loss: 0.07253444194793701 | MAE Test Loss: 0.1732628047466278 \n",
            "OrderedDict({'weights': tensor([0.3383]), 'bias': tensor([0.4486])})\n",
            "Epoch: 7860 | MAE Train Loss: 0.07249953597784042 | MAE Test Loss: 0.1731526404619217 \n",
            "OrderedDict({'weights': tensor([0.3385]), 'bias': tensor([0.4486])})\n",
            "Epoch: 7870 | MAE Train Loss: 0.07246463000774384 | MAE Test Loss: 0.17304250597953796 \n",
            "OrderedDict({'weights': tensor([0.3387]), 'bias': tensor([0.4485])})\n",
            "Epoch: 7880 | MAE Train Loss: 0.07242973148822784 | MAE Test Loss: 0.17293238639831543 \n",
            "OrderedDict({'weights': tensor([0.3389]), 'bias': tensor([0.4485])})\n",
            "Epoch: 7890 | MAE Train Loss: 0.07239482551813126 | MAE Test Loss: 0.17282220721244812 \n",
            "OrderedDict({'weights': tensor([0.3391]), 'bias': tensor([0.4484])})\n",
            "Epoch: 7900 | MAE Train Loss: 0.07235992699861526 | MAE Test Loss: 0.17271211743354797 \n",
            "OrderedDict({'weights': tensor([0.3392]), 'bias': tensor([0.4484])})\n",
            "Epoch: 7910 | MAE Train Loss: 0.07232502847909927 | MAE Test Loss: 0.17260195314884186 \n",
            "OrderedDict({'weights': tensor([0.3394]), 'bias': tensor([0.4483])})\n",
            "Epoch: 7920 | MAE Train Loss: 0.07229010760784149 | MAE Test Loss: 0.17249181866645813 \n",
            "OrderedDict({'weights': tensor([0.3396]), 'bias': tensor([0.4483])})\n",
            "Epoch: 7930 | MAE Train Loss: 0.0722552090883255 | MAE Test Loss: 0.1723816692829132 \n",
            "OrderedDict({'weights': tensor([0.3398]), 'bias': tensor([0.4482])})\n",
            "Epoch: 7940 | MAE Train Loss: 0.07222030311822891 | MAE Test Loss: 0.17227156460285187 \n",
            "OrderedDict({'weights': tensor([0.3400]), 'bias': tensor([0.4482])})\n",
            "Epoch: 7950 | MAE Train Loss: 0.07218539714813232 | MAE Test Loss: 0.17216143012046814 \n",
            "OrderedDict({'weights': tensor([0.3401]), 'bias': tensor([0.4481])})\n",
            "Epoch: 7960 | MAE Train Loss: 0.07215049862861633 | MAE Test Loss: 0.17205126583576202 \n",
            "OrderedDict({'weights': tensor([0.3403]), 'bias': tensor([0.4481])})\n",
            "Epoch: 7970 | MAE Train Loss: 0.07211558520793915 | MAE Test Loss: 0.1719411313533783 \n",
            "OrderedDict({'weights': tensor([0.3405]), 'bias': tensor([0.4480])})\n",
            "Epoch: 7980 | MAE Train Loss: 0.07208068668842316 | MAE Test Loss: 0.17183101177215576 \n",
            "OrderedDict({'weights': tensor([0.3407]), 'bias': tensor([0.4480])})\n",
            "Epoch: 7990 | MAE Train Loss: 0.07204578071832657 | MAE Test Loss: 0.17172083258628845 \n",
            "OrderedDict({'weights': tensor([0.3409]), 'bias': tensor([0.4479])})\n",
            "Epoch: 8000 | MAE Train Loss: 0.07201088219881058 | MAE Test Loss: 0.17161071300506592 \n",
            "OrderedDict({'weights': tensor([0.3410]), 'bias': tensor([0.4479])})\n",
            "Epoch: 8010 | MAE Train Loss: 0.07197597622871399 | MAE Test Loss: 0.1715005785226822 \n",
            "OrderedDict({'weights': tensor([0.3412]), 'bias': tensor([0.4478])})\n",
            "Epoch: 8020 | MAE Train Loss: 0.0719410628080368 | MAE Test Loss: 0.17139045894145966 \n",
            "OrderedDict({'weights': tensor([0.3414]), 'bias': tensor([0.4478])})\n",
            "Epoch: 8030 | MAE Train Loss: 0.07190616428852081 | MAE Test Loss: 0.17128029465675354 \n",
            "OrderedDict({'weights': tensor([0.3416]), 'bias': tensor([0.4477])})\n",
            "Epoch: 8040 | MAE Train Loss: 0.07187126576900482 | MAE Test Loss: 0.1711701601743698 \n",
            "OrderedDict({'weights': tensor([0.3418]), 'bias': tensor([0.4477])})\n",
            "Epoch: 8050 | MAE Train Loss: 0.07183635234832764 | MAE Test Loss: 0.17106004059314728 \n",
            "OrderedDict({'weights': tensor([0.3419]), 'bias': tensor([0.4476])})\n",
            "Epoch: 8060 | MAE Train Loss: 0.07180144637823105 | MAE Test Loss: 0.17094989120960236 \n",
            "OrderedDict({'weights': tensor([0.3421]), 'bias': tensor([0.4476])})\n",
            "Epoch: 8070 | MAE Train Loss: 0.07176654040813446 | MAE Test Loss: 0.17083974182605743 \n",
            "OrderedDict({'weights': tensor([0.3423]), 'bias': tensor([0.4475])})\n",
            "Epoch: 8080 | MAE Train Loss: 0.07173164188861847 | MAE Test Loss: 0.1707296371459961 \n",
            "OrderedDict({'weights': tensor([0.3425]), 'bias': tensor([0.4475])})\n",
            "Epoch: 8090 | MAE Train Loss: 0.07169673591852188 | MAE Test Loss: 0.17061945796012878 \n",
            "OrderedDict({'weights': tensor([0.3427]), 'bias': tensor([0.4474])})\n",
            "Epoch: 8100 | MAE Train Loss: 0.07166183739900589 | MAE Test Loss: 0.17050936818122864 \n",
            "OrderedDict({'weights': tensor([0.3428]), 'bias': tensor([0.4474])})\n",
            "Epoch: 8110 | MAE Train Loss: 0.0716269388794899 | MAE Test Loss: 0.17039920389652252 \n",
            "OrderedDict({'weights': tensor([0.3430]), 'bias': tensor([0.4473])})\n",
            "Epoch: 8120 | MAE Train Loss: 0.07159201800823212 | MAE Test Loss: 0.1702890843153 \n",
            "OrderedDict({'weights': tensor([0.3432]), 'bias': tensor([0.4473])})\n",
            "Epoch: 8130 | MAE Train Loss: 0.07155711948871613 | MAE Test Loss: 0.17017892003059387 \n",
            "OrderedDict({'weights': tensor([0.3434]), 'bias': tensor([0.4472])})\n",
            "Epoch: 8140 | MAE Train Loss: 0.07152221351861954 | MAE Test Loss: 0.17006878554821014 \n",
            "OrderedDict({'weights': tensor([0.3436]), 'bias': tensor([0.4472])})\n",
            "Epoch: 8150 | MAE Train Loss: 0.07148730754852295 | MAE Test Loss: 0.1699586659669876 \n",
            "OrderedDict({'weights': tensor([0.3437]), 'bias': tensor([0.4471])})\n",
            "Epoch: 8160 | MAE Train Loss: 0.07145240902900696 | MAE Test Loss: 0.1698485165834427 \n",
            "OrderedDict({'weights': tensor([0.3439]), 'bias': tensor([0.4471])})\n",
            "Epoch: 8170 | MAE Train Loss: 0.07141749560832977 | MAE Test Loss: 0.16973836719989777 \n",
            "OrderedDict({'weights': tensor([0.3441]), 'bias': tensor([0.4470])})\n",
            "Epoch: 8180 | MAE Train Loss: 0.07138259708881378 | MAE Test Loss: 0.16962826251983643 \n",
            "OrderedDict({'weights': tensor([0.3443]), 'bias': tensor([0.4470])})\n",
            "Epoch: 8190 | MAE Train Loss: 0.0713476911187172 | MAE Test Loss: 0.16951808333396912 \n",
            "OrderedDict({'weights': tensor([0.3445]), 'bias': tensor([0.4469])})\n",
            "Epoch: 8200 | MAE Train Loss: 0.0713127925992012 | MAE Test Loss: 0.16940799355506897 \n",
            "OrderedDict({'weights': tensor([0.3446]), 'bias': tensor([0.4469])})\n",
            "Epoch: 8210 | MAE Train Loss: 0.07127788662910461 | MAE Test Loss: 0.16929782927036285 \n",
            "OrderedDict({'weights': tensor([0.3448]), 'bias': tensor([0.4468])})\n",
            "Epoch: 8220 | MAE Train Loss: 0.07124297320842743 | MAE Test Loss: 0.16918770968914032 \n",
            "OrderedDict({'weights': tensor([0.3450]), 'bias': tensor([0.4468])})\n",
            "Epoch: 8230 | MAE Train Loss: 0.07120807468891144 | MAE Test Loss: 0.1690775454044342 \n",
            "OrderedDict({'weights': tensor([0.3452]), 'bias': tensor([0.4467])})\n",
            "Epoch: 8240 | MAE Train Loss: 0.07117317616939545 | MAE Test Loss: 0.16896741092205048 \n",
            "OrderedDict({'weights': tensor([0.3454]), 'bias': tensor([0.4467])})\n",
            "Epoch: 8250 | MAE Train Loss: 0.07113826274871826 | MAE Test Loss: 0.16885729134082794 \n",
            "OrderedDict({'weights': tensor([0.3455]), 'bias': tensor([0.4466])})\n",
            "Epoch: 8260 | MAE Train Loss: 0.07110335677862167 | MAE Test Loss: 0.16874714195728302 \n",
            "OrderedDict({'weights': tensor([0.3457]), 'bias': tensor([0.4466])})\n",
            "Epoch: 8270 | MAE Train Loss: 0.07106845080852509 | MAE Test Loss: 0.1686369925737381 \n",
            "OrderedDict({'weights': tensor([0.3459]), 'bias': tensor([0.4465])})\n",
            "Epoch: 8280 | MAE Train Loss: 0.0710335522890091 | MAE Test Loss: 0.16852688789367676 \n",
            "OrderedDict({'weights': tensor([0.3461]), 'bias': tensor([0.4465])})\n",
            "Epoch: 8290 | MAE Train Loss: 0.0709986463189125 | MAE Test Loss: 0.16841670870780945 \n",
            "OrderedDict({'weights': tensor([0.3463]), 'bias': tensor([0.4464])})\n",
            "Epoch: 8300 | MAE Train Loss: 0.07096374779939651 | MAE Test Loss: 0.1683066189289093 \n",
            "OrderedDict({'weights': tensor([0.3464]), 'bias': tensor([0.4464])})\n",
            "Epoch: 8310 | MAE Train Loss: 0.07092884927988052 | MAE Test Loss: 0.16819645464420319 \n",
            "OrderedDict({'weights': tensor([0.3466]), 'bias': tensor([0.4463])})\n",
            "Epoch: 8320 | MAE Train Loss: 0.07089392840862274 | MAE Test Loss: 0.16808633506298065 \n",
            "OrderedDict({'weights': tensor([0.3468]), 'bias': tensor([0.4463])})\n",
            "Epoch: 8330 | MAE Train Loss: 0.07085902988910675 | MAE Test Loss: 0.16797617077827454 \n",
            "OrderedDict({'weights': tensor([0.3470]), 'bias': tensor([0.4462])})\n",
            "Epoch: 8340 | MAE Train Loss: 0.07082412391901016 | MAE Test Loss: 0.1678660362958908 \n",
            "OrderedDict({'weights': tensor([0.3472]), 'bias': tensor([0.4462])})\n",
            "Epoch: 8350 | MAE Train Loss: 0.07078922539949417 | MAE Test Loss: 0.16775591671466827 \n",
            "OrderedDict({'weights': tensor([0.3473]), 'bias': tensor([0.4461])})\n",
            "Epoch: 8360 | MAE Train Loss: 0.07075431942939758 | MAE Test Loss: 0.16764576733112335 \n",
            "OrderedDict({'weights': tensor([0.3475]), 'bias': tensor([0.4461])})\n",
            "Epoch: 8370 | MAE Train Loss: 0.0707194060087204 | MAE Test Loss: 0.16753561794757843 \n",
            "OrderedDict({'weights': tensor([0.3477]), 'bias': tensor([0.4460])})\n",
            "Epoch: 8380 | MAE Train Loss: 0.0706845074892044 | MAE Test Loss: 0.1674255132675171 \n",
            "OrderedDict({'weights': tensor([0.3479]), 'bias': tensor([0.4460])})\n",
            "Epoch: 8390 | MAE Train Loss: 0.07064960151910782 | MAE Test Loss: 0.16731533408164978 \n",
            "OrderedDict({'weights': tensor([0.3481]), 'bias': tensor([0.4459])})\n",
            "Epoch: 8400 | MAE Train Loss: 0.07061470299959183 | MAE Test Loss: 0.16720524430274963 \n",
            "OrderedDict({'weights': tensor([0.3482]), 'bias': tensor([0.4459])})\n",
            "Epoch: 8410 | MAE Train Loss: 0.07057979702949524 | MAE Test Loss: 0.16709508001804352 \n",
            "OrderedDict({'weights': tensor([0.3484]), 'bias': tensor([0.4458])})\n",
            "Epoch: 8420 | MAE Train Loss: 0.07054488360881805 | MAE Test Loss: 0.16698496043682098 \n",
            "OrderedDict({'weights': tensor([0.3486]), 'bias': tensor([0.4458])})\n",
            "Epoch: 8430 | MAE Train Loss: 0.07050998508930206 | MAE Test Loss: 0.16687479615211487 \n",
            "OrderedDict({'weights': tensor([0.3488]), 'bias': tensor([0.4457])})\n",
            "Epoch: 8440 | MAE Train Loss: 0.07047508656978607 | MAE Test Loss: 0.16676466166973114 \n",
            "OrderedDict({'weights': tensor([0.3490]), 'bias': tensor([0.4457])})\n",
            "Epoch: 8450 | MAE Train Loss: 0.07044018059968948 | MAE Test Loss: 0.1666545420885086 \n",
            "OrderedDict({'weights': tensor([0.3491]), 'bias': tensor([0.4456])})\n",
            "Epoch: 8460 | MAE Train Loss: 0.0704052671790123 | MAE Test Loss: 0.16654439270496368 \n",
            "OrderedDict({'weights': tensor([0.3493]), 'bias': tensor([0.4456])})\n",
            "Epoch: 8470 | MAE Train Loss: 0.07037036120891571 | MAE Test Loss: 0.16643424332141876 \n",
            "OrderedDict({'weights': tensor([0.3495]), 'bias': tensor([0.4455])})\n",
            "Epoch: 8480 | MAE Train Loss: 0.07033546268939972 | MAE Test Loss: 0.16632413864135742 \n",
            "OrderedDict({'weights': tensor([0.3497]), 'bias': tensor([0.4455])})\n",
            "Epoch: 8490 | MAE Train Loss: 0.07030055671930313 | MAE Test Loss: 0.1662139594554901 \n",
            "OrderedDict({'weights': tensor([0.3499]), 'bias': tensor([0.4454])})\n",
            "Epoch: 8500 | MAE Train Loss: 0.07026565819978714 | MAE Test Loss: 0.16610386967658997 \n",
            "OrderedDict({'weights': tensor([0.3500]), 'bias': tensor([0.4454])})\n",
            "Epoch: 8510 | MAE Train Loss: 0.07023075968027115 | MAE Test Loss: 0.16599370539188385 \n",
            "OrderedDict({'weights': tensor([0.3502]), 'bias': tensor([0.4453])})\n",
            "Epoch: 8520 | MAE Train Loss: 0.07019583880901337 | MAE Test Loss: 0.16588358581066132 \n",
            "OrderedDict({'weights': tensor([0.3504]), 'bias': tensor([0.4453])})\n",
            "Epoch: 8530 | MAE Train Loss: 0.07016094028949738 | MAE Test Loss: 0.1657734215259552 \n",
            "OrderedDict({'weights': tensor([0.3506]), 'bias': tensor([0.4452])})\n",
            "Epoch: 8540 | MAE Train Loss: 0.07012603431940079 | MAE Test Loss: 0.16566328704357147 \n",
            "OrderedDict({'weights': tensor([0.3508]), 'bias': tensor([0.4452])})\n",
            "Epoch: 8550 | MAE Train Loss: 0.0700911357998848 | MAE Test Loss: 0.16555316746234894 \n",
            "OrderedDict({'weights': tensor([0.3509]), 'bias': tensor([0.4451])})\n",
            "Epoch: 8560 | MAE Train Loss: 0.07005622982978821 | MAE Test Loss: 0.16544301807880402 \n",
            "OrderedDict({'weights': tensor([0.3511]), 'bias': tensor([0.4451])})\n",
            "Epoch: 8570 | MAE Train Loss: 0.07002131640911102 | MAE Test Loss: 0.1653328686952591 \n",
            "OrderedDict({'weights': tensor([0.3513]), 'bias': tensor([0.4450])})\n",
            "Epoch: 8580 | MAE Train Loss: 0.06998641788959503 | MAE Test Loss: 0.16522276401519775 \n",
            "OrderedDict({'weights': tensor([0.3515]), 'bias': tensor([0.4450])})\n",
            "Epoch: 8590 | MAE Train Loss: 0.06995151191949844 | MAE Test Loss: 0.16511258482933044 \n",
            "OrderedDict({'weights': tensor([0.3517]), 'bias': tensor([0.4449])})\n",
            "Epoch: 8600 | MAE Train Loss: 0.06991661339998245 | MAE Test Loss: 0.1650024950504303 \n",
            "OrderedDict({'weights': tensor([0.3518]), 'bias': tensor([0.4449])})\n",
            "Epoch: 8610 | MAE Train Loss: 0.06988170742988586 | MAE Test Loss: 0.16489233076572418 \n",
            "OrderedDict({'weights': tensor([0.3520]), 'bias': tensor([0.4448])})\n",
            "Epoch: 8620 | MAE Train Loss: 0.06984679400920868 | MAE Test Loss: 0.16478221118450165 \n",
            "OrderedDict({'weights': tensor([0.3522]), 'bias': tensor([0.4448])})\n",
            "Epoch: 8630 | MAE Train Loss: 0.06981189548969269 | MAE Test Loss: 0.16467204689979553 \n",
            "OrderedDict({'weights': tensor([0.3524]), 'bias': tensor([0.4447])})\n",
            "Epoch: 8640 | MAE Train Loss: 0.0697769969701767 | MAE Test Loss: 0.1645619124174118 \n",
            "OrderedDict({'weights': tensor([0.3526]), 'bias': tensor([0.4447])})\n",
            "Epoch: 8650 | MAE Train Loss: 0.06974209100008011 | MAE Test Loss: 0.16445179283618927 \n",
            "OrderedDict({'weights': tensor([0.3527]), 'bias': tensor([0.4446])})\n",
            "Epoch: 8660 | MAE Train Loss: 0.06970717757940292 | MAE Test Loss: 0.16434164345264435 \n",
            "OrderedDict({'weights': tensor([0.3529]), 'bias': tensor([0.4446])})\n",
            "Epoch: 8670 | MAE Train Loss: 0.06967227160930634 | MAE Test Loss: 0.16423149406909943 \n",
            "OrderedDict({'weights': tensor([0.3531]), 'bias': tensor([0.4445])})\n",
            "Epoch: 8680 | MAE Train Loss: 0.06963737308979034 | MAE Test Loss: 0.16412138938903809 \n",
            "OrderedDict({'weights': tensor([0.3533]), 'bias': tensor([0.4445])})\n",
            "Epoch: 8690 | MAE Train Loss: 0.06960246711969376 | MAE Test Loss: 0.16401121020317078 \n",
            "OrderedDict({'weights': tensor([0.3535]), 'bias': tensor([0.4444])})\n",
            "Epoch: 8700 | MAE Train Loss: 0.06956756860017776 | MAE Test Loss: 0.16390112042427063 \n",
            "OrderedDict({'weights': tensor([0.3536]), 'bias': tensor([0.4444])})\n",
            "Epoch: 8710 | MAE Train Loss: 0.06953267008066177 | MAE Test Loss: 0.16379095613956451 \n",
            "OrderedDict({'weights': tensor([0.3538]), 'bias': tensor([0.4443])})\n",
            "Epoch: 8720 | MAE Train Loss: 0.06949774920940399 | MAE Test Loss: 0.16368083655834198 \n",
            "OrderedDict({'weights': tensor([0.3540]), 'bias': tensor([0.4443])})\n",
            "Epoch: 8730 | MAE Train Loss: 0.069462850689888 | MAE Test Loss: 0.16357067227363586 \n",
            "OrderedDict({'weights': tensor([0.3542]), 'bias': tensor([0.4442])})\n",
            "Epoch: 8740 | MAE Train Loss: 0.06942794471979141 | MAE Test Loss: 0.16346053779125214 \n",
            "OrderedDict({'weights': tensor([0.3544]), 'bias': tensor([0.4442])})\n",
            "Epoch: 8750 | MAE Train Loss: 0.06939304620027542 | MAE Test Loss: 0.1633504182100296 \n",
            "OrderedDict({'weights': tensor([0.3545]), 'bias': tensor([0.4441])})\n",
            "Epoch: 8760 | MAE Train Loss: 0.06935814023017883 | MAE Test Loss: 0.16324026882648468 \n",
            "OrderedDict({'weights': tensor([0.3547]), 'bias': tensor([0.4441])})\n",
            "Epoch: 8770 | MAE Train Loss: 0.06932322680950165 | MAE Test Loss: 0.16313011944293976 \n",
            "OrderedDict({'weights': tensor([0.3549]), 'bias': tensor([0.4440])})\n",
            "Epoch: 8780 | MAE Train Loss: 0.06928832828998566 | MAE Test Loss: 0.16302001476287842 \n",
            "OrderedDict({'weights': tensor([0.3551]), 'bias': tensor([0.4440])})\n",
            "Epoch: 8790 | MAE Train Loss: 0.06925342231988907 | MAE Test Loss: 0.1629098355770111 \n",
            "OrderedDict({'weights': tensor([0.3553]), 'bias': tensor([0.4439])})\n",
            "Epoch: 8800 | MAE Train Loss: 0.06921852380037308 | MAE Test Loss: 0.16279974579811096 \n",
            "OrderedDict({'weights': tensor([0.3554]), 'bias': tensor([0.4439])})\n",
            "Epoch: 8810 | MAE Train Loss: 0.06918361783027649 | MAE Test Loss: 0.16268958151340485 \n",
            "OrderedDict({'weights': tensor([0.3556]), 'bias': tensor([0.4438])})\n",
            "Epoch: 8820 | MAE Train Loss: 0.0691487044095993 | MAE Test Loss: 0.1625794619321823 \n",
            "OrderedDict({'weights': tensor([0.3558]), 'bias': tensor([0.4438])})\n",
            "Epoch: 8830 | MAE Train Loss: 0.06911380589008331 | MAE Test Loss: 0.1624692976474762 \n",
            "OrderedDict({'weights': tensor([0.3560]), 'bias': tensor([0.4437])})\n",
            "Epoch: 8840 | MAE Train Loss: 0.06907890737056732 | MAE Test Loss: 0.16235916316509247 \n",
            "OrderedDict({'weights': tensor([0.3562]), 'bias': tensor([0.4437])})\n",
            "Epoch: 8850 | MAE Train Loss: 0.06904400140047073 | MAE Test Loss: 0.16224904358386993 \n",
            "OrderedDict({'weights': tensor([0.3563]), 'bias': tensor([0.4436])})\n",
            "Epoch: 8860 | MAE Train Loss: 0.06900908797979355 | MAE Test Loss: 0.162138894200325 \n",
            "OrderedDict({'weights': tensor([0.3565]), 'bias': tensor([0.4436])})\n",
            "Epoch: 8870 | MAE Train Loss: 0.06897418200969696 | MAE Test Loss: 0.1620287448167801 \n",
            "OrderedDict({'weights': tensor([0.3567]), 'bias': tensor([0.4435])})\n",
            "Epoch: 8880 | MAE Train Loss: 0.06893928349018097 | MAE Test Loss: 0.16191864013671875 \n",
            "OrderedDict({'weights': tensor([0.3569]), 'bias': tensor([0.4435])})\n",
            "Epoch: 8890 | MAE Train Loss: 0.06890437752008438 | MAE Test Loss: 0.16180846095085144 \n",
            "OrderedDict({'weights': tensor([0.3571]), 'bias': tensor([0.4434])})\n",
            "Epoch: 8900 | MAE Train Loss: 0.06886947900056839 | MAE Test Loss: 0.1616983711719513 \n",
            "OrderedDict({'weights': tensor([0.3572]), 'bias': tensor([0.4434])})\n",
            "Epoch: 8910 | MAE Train Loss: 0.0688345804810524 | MAE Test Loss: 0.16158820688724518 \n",
            "OrderedDict({'weights': tensor([0.3574]), 'bias': tensor([0.4433])})\n",
            "Epoch: 8920 | MAE Train Loss: 0.06879965960979462 | MAE Test Loss: 0.16147808730602264 \n",
            "OrderedDict({'weights': tensor([0.3576]), 'bias': tensor([0.4433])})\n",
            "Epoch: 8930 | MAE Train Loss: 0.06876476109027863 | MAE Test Loss: 0.16136792302131653 \n",
            "OrderedDict({'weights': tensor([0.3578]), 'bias': tensor([0.4432])})\n",
            "Epoch: 8940 | MAE Train Loss: 0.06872985512018204 | MAE Test Loss: 0.1612577885389328 \n",
            "OrderedDict({'weights': tensor([0.3580]), 'bias': tensor([0.4432])})\n",
            "Epoch: 8950 | MAE Train Loss: 0.06869495660066605 | MAE Test Loss: 0.16114766895771027 \n",
            "OrderedDict({'weights': tensor([0.3581]), 'bias': tensor([0.4431])})\n",
            "Epoch: 8960 | MAE Train Loss: 0.06866005063056946 | MAE Test Loss: 0.16103751957416534 \n",
            "OrderedDict({'weights': tensor([0.3583]), 'bias': tensor([0.4431])})\n",
            "Epoch: 8970 | MAE Train Loss: 0.06862513720989227 | MAE Test Loss: 0.16092737019062042 \n",
            "OrderedDict({'weights': tensor([0.3585]), 'bias': tensor([0.4430])})\n",
            "Epoch: 8980 | MAE Train Loss: 0.06859023869037628 | MAE Test Loss: 0.16081726551055908 \n",
            "OrderedDict({'weights': tensor([0.3587]), 'bias': tensor([0.4430])})\n",
            "Epoch: 8990 | MAE Train Loss: 0.0685553327202797 | MAE Test Loss: 0.16070708632469177 \n",
            "OrderedDict({'weights': tensor([0.3589]), 'bias': tensor([0.4429])})\n",
            "Epoch: 9000 | MAE Train Loss: 0.0685204342007637 | MAE Test Loss: 0.16059699654579163 \n",
            "OrderedDict({'weights': tensor([0.3590]), 'bias': tensor([0.4429])})\n",
            "Epoch: 9010 | MAE Train Loss: 0.06848552823066711 | MAE Test Loss: 0.1604868322610855 \n",
            "OrderedDict({'weights': tensor([0.3592]), 'bias': tensor([0.4428])})\n",
            "Epoch: 9020 | MAE Train Loss: 0.06845061480998993 | MAE Test Loss: 0.16037671267986298 \n",
            "OrderedDict({'weights': tensor([0.3594]), 'bias': tensor([0.4428])})\n",
            "Epoch: 9030 | MAE Train Loss: 0.06841571629047394 | MAE Test Loss: 0.16026654839515686 \n",
            "OrderedDict({'weights': tensor([0.3596]), 'bias': tensor([0.4427])})\n",
            "Epoch: 9040 | MAE Train Loss: 0.06838081777095795 | MAE Test Loss: 0.16015641391277313 \n",
            "OrderedDict({'weights': tensor([0.3598]), 'bias': tensor([0.4427])})\n",
            "Epoch: 9050 | MAE Train Loss: 0.06834591180086136 | MAE Test Loss: 0.1600462943315506 \n",
            "OrderedDict({'weights': tensor([0.3599]), 'bias': tensor([0.4426])})\n",
            "Epoch: 9060 | MAE Train Loss: 0.06831099838018417 | MAE Test Loss: 0.15993614494800568 \n",
            "OrderedDict({'weights': tensor([0.3601]), 'bias': tensor([0.4426])})\n",
            "Epoch: 9070 | MAE Train Loss: 0.06827609241008759 | MAE Test Loss: 0.15982599556446075 \n",
            "OrderedDict({'weights': tensor([0.3603]), 'bias': tensor([0.4425])})\n",
            "Epoch: 9080 | MAE Train Loss: 0.0682411938905716 | MAE Test Loss: 0.15971589088439941 \n",
            "OrderedDict({'weights': tensor([0.3605]), 'bias': tensor([0.4425])})\n",
            "Epoch: 9090 | MAE Train Loss: 0.068206287920475 | MAE Test Loss: 0.1596057116985321 \n",
            "OrderedDict({'weights': tensor([0.3607]), 'bias': tensor([0.4424])})\n",
            "Epoch: 9100 | MAE Train Loss: 0.06817138940095901 | MAE Test Loss: 0.15949562191963196 \n",
            "OrderedDict({'weights': tensor([0.3608]), 'bias': tensor([0.4424])})\n",
            "Epoch: 9110 | MAE Train Loss: 0.06813649088144302 | MAE Test Loss: 0.15938545763492584 \n",
            "OrderedDict({'weights': tensor([0.3610]), 'bias': tensor([0.4423])})\n",
            "Epoch: 9120 | MAE Train Loss: 0.06810157001018524 | MAE Test Loss: 0.1592753380537033 \n",
            "OrderedDict({'weights': tensor([0.3612]), 'bias': tensor([0.4423])})\n",
            "Epoch: 9130 | MAE Train Loss: 0.06806667149066925 | MAE Test Loss: 0.1591651737689972 \n",
            "OrderedDict({'weights': tensor([0.3614]), 'bias': tensor([0.4422])})\n",
            "Epoch: 9140 | MAE Train Loss: 0.06803202629089355 | MAE Test Loss: 0.15907564759254456 \n",
            "OrderedDict({'weights': tensor([0.3615]), 'bias': tensor([0.4421])})\n",
            "Epoch: 9150 | MAE Train Loss: 0.06799772381782532 | MAE Test Loss: 0.1589929312467575 \n",
            "OrderedDict({'weights': tensor([0.3617]), 'bias': tensor([0.4421])})\n",
            "Epoch: 9160 | MAE Train Loss: 0.06796333938837051 | MAE Test Loss: 0.15891025960445404 \n",
            "OrderedDict({'weights': tensor([0.3619]), 'bias': tensor([0.4420])})\n",
            "Epoch: 9170 | MAE Train Loss: 0.0679289922118187 | MAE Test Loss: 0.15883103013038635 \n",
            "OrderedDict({'weights': tensor([0.3621]), 'bias': tensor([0.4419])})\n",
            "Epoch: 9180 | MAE Train Loss: 0.0678945928812027 | MAE Test Loss: 0.1587483435869217 \n",
            "OrderedDict({'weights': tensor([0.3622]), 'bias': tensor([0.4419])})\n",
            "Epoch: 9190 | MAE Train Loss: 0.06786025315523148 | MAE Test Loss: 0.1586725264787674 \n",
            "OrderedDict({'weights': tensor([0.3624]), 'bias': tensor([0.4418])})\n",
            "Epoch: 9200 | MAE Train Loss: 0.06782589852809906 | MAE Test Loss: 0.15858986973762512 \n",
            "OrderedDict({'weights': tensor([0.3626]), 'bias': tensor([0.4417])})\n",
            "Epoch: 9210 | MAE Train Loss: 0.06779150664806366 | MAE Test Loss: 0.15850713849067688 \n",
            "OrderedDict({'weights': tensor([0.3627]), 'bias': tensor([0.4416])})\n",
            "Epoch: 9220 | MAE Train Loss: 0.06775716692209244 | MAE Test Loss: 0.15843133628368378 \n",
            "OrderedDict({'weights': tensor([0.3629]), 'bias': tensor([0.4416])})\n",
            "Epoch: 9230 | MAE Train Loss: 0.06772283464670181 | MAE Test Loss: 0.15834864974021912 \n",
            "OrderedDict({'weights': tensor([0.3631]), 'bias': tensor([0.4415])})\n",
            "Epoch: 9240 | MAE Train Loss: 0.06768842041492462 | MAE Test Loss: 0.15826594829559326 \n",
            "OrderedDict({'weights': tensor([0.3633]), 'bias': tensor([0.4414])})\n",
            "Epoch: 9250 | MAE Train Loss: 0.067654088139534 | MAE Test Loss: 0.15819016098976135 \n",
            "OrderedDict({'weights': tensor([0.3634]), 'bias': tensor([0.4414])})\n",
            "Epoch: 9260 | MAE Train Loss: 0.0676197037100792 | MAE Test Loss: 0.15811088681221008 \n",
            "OrderedDict({'weights': tensor([0.3636]), 'bias': tensor([0.4413])})\n",
            "Epoch: 9270 | MAE Train Loss: 0.06758533418178558 | MAE Test Loss: 0.15802475810050964 \n",
            "OrderedDict({'weights': tensor([0.3638]), 'bias': tensor([0.4412])})\n",
            "Epoch: 9280 | MAE Train Loss: 0.06755100935697556 | MAE Test Loss: 0.15794894099235535 \n",
            "OrderedDict({'weights': tensor([0.3639]), 'bias': tensor([0.4411])})\n",
            "Epoch: 9290 | MAE Train Loss: 0.06751665472984314 | MAE Test Loss: 0.15786626935005188 \n",
            "OrderedDict({'weights': tensor([0.3641]), 'bias': tensor([0.4411])})\n",
            "Epoch: 9300 | MAE Train Loss: 0.06748224794864655 | MAE Test Loss: 0.1577835977077484 \n",
            "OrderedDict({'weights': tensor([0.3643]), 'bias': tensor([0.4410])})\n",
            "Epoch: 9310 | MAE Train Loss: 0.06744790822267532 | MAE Test Loss: 0.15770435333251953 \n",
            "OrderedDict({'weights': tensor([0.3645]), 'bias': tensor([0.4409])})\n",
            "Epoch: 9320 | MAE Train Loss: 0.06741353869438171 | MAE Test Loss: 0.15762850642204285 \n",
            "OrderedDict({'weights': tensor([0.3646]), 'bias': tensor([0.4409])})\n",
            "Epoch: 9330 | MAE Train Loss: 0.06737922132015228 | MAE Test Loss: 0.15754583477973938 \n",
            "OrderedDict({'weights': tensor([0.3648]), 'bias': tensor([0.4408])})\n",
            "Epoch: 9340 | MAE Train Loss: 0.06734482198953629 | MAE Test Loss: 0.15746314823627472 \n",
            "OrderedDict({'weights': tensor([0.3650]), 'bias': tensor([0.4407])})\n",
            "Epoch: 9350 | MAE Train Loss: 0.06731047481298447 | MAE Test Loss: 0.15738730132579803 \n",
            "OrderedDict({'weights': tensor([0.3651]), 'bias': tensor([0.4406])})\n",
            "Epoch: 9360 | MAE Train Loss: 0.06727613508701324 | MAE Test Loss: 0.15730464458465576 \n",
            "OrderedDict({'weights': tensor([0.3653]), 'bias': tensor([0.4406])})\n",
            "Epoch: 9370 | MAE Train Loss: 0.06724173575639725 | MAE Test Loss: 0.1572219431400299 \n",
            "OrderedDict({'weights': tensor([0.3655]), 'bias': tensor([0.4405])})\n",
            "Epoch: 9380 | MAE Train Loss: 0.06720738112926483 | MAE Test Loss: 0.1571461260318756 \n",
            "OrderedDict({'weights': tensor([0.3657]), 'bias': tensor([0.4404])})\n",
            "Epoch: 9390 | MAE Train Loss: 0.0671730563044548 | MAE Test Loss: 0.15706345438957214 \n",
            "OrderedDict({'weights': tensor([0.3658]), 'bias': tensor([0.4404])})\n",
            "Epoch: 9400 | MAE Train Loss: 0.0671386867761612 | MAE Test Loss: 0.15698421001434326 \n",
            "OrderedDict({'weights': tensor([0.3660]), 'bias': tensor([0.4403])})\n",
            "Epoch: 9410 | MAE Train Loss: 0.06710430979728699 | MAE Test Loss: 0.1569015234708786 \n",
            "OrderedDict({'weights': tensor([0.3662]), 'bias': tensor([0.4402])})\n",
            "Epoch: 9420 | MAE Train Loss: 0.06706991046667099 | MAE Test Loss: 0.1568256914615631 \n",
            "OrderedDict({'weights': tensor([0.3663]), 'bias': tensor([0.4401])})\n",
            "Epoch: 9430 | MAE Train Loss: 0.06703560799360275 | MAE Test Loss: 0.15674300491809845 \n",
            "OrderedDict({'weights': tensor([0.3665]), 'bias': tensor([0.4401])})\n",
            "Epoch: 9440 | MAE Train Loss: 0.06700122356414795 | MAE Test Loss: 0.1566603183746338 \n",
            "OrderedDict({'weights': tensor([0.3667]), 'bias': tensor([0.4400])})\n",
            "Epoch: 9450 | MAE Train Loss: 0.06696684658527374 | MAE Test Loss: 0.1565845012664795 \n",
            "OrderedDict({'weights': tensor([0.3668]), 'bias': tensor([0.4399])})\n",
            "Epoch: 9460 | MAE Train Loss: 0.06693252176046371 | MAE Test Loss: 0.15650181472301483 \n",
            "OrderedDict({'weights': tensor([0.3670]), 'bias': tensor([0.4399])})\n",
            "Epoch: 9470 | MAE Train Loss: 0.06689812988042831 | MAE Test Loss: 0.15641912817955017 \n",
            "OrderedDict({'weights': tensor([0.3672]), 'bias': tensor([0.4398])})\n",
            "Epoch: 9480 | MAE Train Loss: 0.0668637603521347 | MAE Test Loss: 0.15634331107139587 \n",
            "OrderedDict({'weights': tensor([0.3674]), 'bias': tensor([0.4397])})\n",
            "Epoch: 9490 | MAE Train Loss: 0.0668293908238411 | MAE Test Loss: 0.15625721216201782 \n",
            "OrderedDict({'weights': tensor([0.3675]), 'bias': tensor([0.4396])})\n",
            "Epoch: 9500 | MAE Train Loss: 0.06679506599903107 | MAE Test Loss: 0.15618140995502472 \n",
            "OrderedDict({'weights': tensor([0.3677]), 'bias': tensor([0.4396])})\n",
            "Epoch: 9510 | MAE Train Loss: 0.06676067411899567 | MAE Test Loss: 0.15610215067863464 \n",
            "OrderedDict({'weights': tensor([0.3679]), 'bias': tensor([0.4395])})\n",
            "Epoch: 9520 | MAE Train Loss: 0.06672636419534683 | MAE Test Loss: 0.15601946413516998 \n",
            "OrderedDict({'weights': tensor([0.3680]), 'bias': tensor([0.4394])})\n",
            "Epoch: 9530 | MAE Train Loss: 0.06669196486473083 | MAE Test Loss: 0.15593676269054413 \n",
            "OrderedDict({'weights': tensor([0.3682]), 'bias': tensor([0.4394])})\n",
            "Epoch: 9540 | MAE Train Loss: 0.06665760278701782 | MAE Test Loss: 0.15586097538471222 \n",
            "OrderedDict({'weights': tensor([0.3684]), 'bias': tensor([0.4393])})\n",
            "Epoch: 9550 | MAE Train Loss: 0.06662321090698242 | MAE Test Loss: 0.15577486157417297 \n",
            "OrderedDict({'weights': tensor([0.3686]), 'bias': tensor([0.4392])})\n",
            "Epoch: 9560 | MAE Train Loss: 0.06658890098333359 | MAE Test Loss: 0.1556990146636963 \n",
            "OrderedDict({'weights': tensor([0.3687]), 'bias': tensor([0.4391])})\n",
            "Epoch: 9570 | MAE Train Loss: 0.06655453145503998 | MAE Test Loss: 0.15561632812023163 \n",
            "OrderedDict({'weights': tensor([0.3689]), 'bias': tensor([0.4391])})\n",
            "Epoch: 9580 | MAE Train Loss: 0.06652013212442398 | MAE Test Loss: 0.15553364157676697 \n",
            "OrderedDict({'weights': tensor([0.3691]), 'bias': tensor([0.4390])})\n",
            "Epoch: 9590 | MAE Train Loss: 0.06648582220077515 | MAE Test Loss: 0.15545782446861267 \n",
            "OrderedDict({'weights': tensor([0.3692]), 'bias': tensor([0.4389])})\n",
            "Epoch: 9600 | MAE Train Loss: 0.06645144522190094 | MAE Test Loss: 0.1553751528263092 \n",
            "OrderedDict({'weights': tensor([0.3694]), 'bias': tensor([0.4388])})\n",
            "Epoch: 9610 | MAE Train Loss: 0.06641705334186554 | MAE Test Loss: 0.1552993357181549 \n",
            "OrderedDict({'weights': tensor([0.3696]), 'bias': tensor([0.4388])})\n",
            "Epoch: 9620 | MAE Train Loss: 0.0663827508687973 | MAE Test Loss: 0.15521661937236786 \n",
            "OrderedDict({'weights': tensor([0.3698]), 'bias': tensor([0.4387])})\n",
            "Epoch: 9630 | MAE Train Loss: 0.0663483589887619 | MAE Test Loss: 0.1551339477300644 \n",
            "OrderedDict({'weights': tensor([0.3699]), 'bias': tensor([0.4386])})\n",
            "Epoch: 9640 | MAE Train Loss: 0.06631401926279068 | MAE Test Loss: 0.1550547182559967 \n",
            "OrderedDict({'weights': tensor([0.3701]), 'bias': tensor([0.4386])})\n",
            "Epoch: 9650 | MAE Train Loss: 0.06627961993217468 | MAE Test Loss: 0.15497203171253204 \n",
            "OrderedDict({'weights': tensor([0.3703]), 'bias': tensor([0.4385])})\n",
            "Epoch: 9660 | MAE Train Loss: 0.06624528020620346 | MAE Test Loss: 0.15489621460437775 \n",
            "OrderedDict({'weights': tensor([0.3704]), 'bias': tensor([0.4384])})\n",
            "Epoch: 9670 | MAE Train Loss: 0.06621092557907104 | MAE Test Loss: 0.15481355786323547 \n",
            "OrderedDict({'weights': tensor([0.3706]), 'bias': tensor([0.4383])})\n",
            "Epoch: 9680 | MAE Train Loss: 0.06617653369903564 | MAE Test Loss: 0.15473082661628723 \n",
            "OrderedDict({'weights': tensor([0.3708]), 'bias': tensor([0.4383])})\n",
            "Epoch: 9690 | MAE Train Loss: 0.06614218652248383 | MAE Test Loss: 0.15465502440929413 \n",
            "OrderedDict({'weights': tensor([0.3710]), 'bias': tensor([0.4382])})\n",
            "Epoch: 9700 | MAE Train Loss: 0.0661078542470932 | MAE Test Loss: 0.15457233786582947 \n",
            "OrderedDict({'weights': tensor([0.3711]), 'bias': tensor([0.4381])})\n",
            "Epoch: 9710 | MAE Train Loss: 0.06607344001531601 | MAE Test Loss: 0.1544896364212036 \n",
            "OrderedDict({'weights': tensor([0.3713]), 'bias': tensor([0.4381])})\n",
            "Epoch: 9720 | MAE Train Loss: 0.06603912264108658 | MAE Test Loss: 0.1544138491153717 \n",
            "OrderedDict({'weights': tensor([0.3715]), 'bias': tensor([0.4380])})\n",
            "Epoch: 9730 | MAE Train Loss: 0.06600473076105118 | MAE Test Loss: 0.15433457493782043 \n",
            "OrderedDict({'weights': tensor([0.3716]), 'bias': tensor([0.4379])})\n",
            "Epoch: 9740 | MAE Train Loss: 0.06597035378217697 | MAE Test Loss: 0.15424844622612 \n",
            "OrderedDict({'weights': tensor([0.3718]), 'bias': tensor([0.4378])})\n",
            "Epoch: 9750 | MAE Train Loss: 0.06593603640794754 | MAE Test Loss: 0.1541726291179657 \n",
            "OrderedDict({'weights': tensor([0.3720]), 'bias': tensor([0.4378])})\n",
            "Epoch: 9760 | MAE Train Loss: 0.06590168178081512 | MAE Test Loss: 0.15408995747566223 \n",
            "OrderedDict({'weights': tensor([0.3721]), 'bias': tensor([0.4377])})\n",
            "Epoch: 9770 | MAE Train Loss: 0.06586727499961853 | MAE Test Loss: 0.15400728583335876 \n",
            "OrderedDict({'weights': tensor([0.3723]), 'bias': tensor([0.4376])})\n",
            "Epoch: 9780 | MAE Train Loss: 0.06583292782306671 | MAE Test Loss: 0.15392804145812988 \n",
            "OrderedDict({'weights': tensor([0.3725]), 'bias': tensor([0.4376])})\n",
            "Epoch: 9790 | MAE Train Loss: 0.0657985657453537 | MAE Test Loss: 0.1538521945476532 \n",
            "OrderedDict({'weights': tensor([0.3727]), 'bias': tensor([0.4375])})\n",
            "Epoch: 9800 | MAE Train Loss: 0.06576424837112427 | MAE Test Loss: 0.15376952290534973 \n",
            "OrderedDict({'weights': tensor([0.3728]), 'bias': tensor([0.4374])})\n",
            "Epoch: 9810 | MAE Train Loss: 0.06572984158992767 | MAE Test Loss: 0.15368683636188507 \n",
            "OrderedDict({'weights': tensor([0.3730]), 'bias': tensor([0.4373])})\n",
            "Epoch: 9820 | MAE Train Loss: 0.06569548696279526 | MAE Test Loss: 0.1536109894514084 \n",
            "OrderedDict({'weights': tensor([0.3732]), 'bias': tensor([0.4373])})\n",
            "Epoch: 9830 | MAE Train Loss: 0.06566116213798523 | MAE Test Loss: 0.1535283327102661 \n",
            "OrderedDict({'weights': tensor([0.3733]), 'bias': tensor([0.4372])})\n",
            "Epoch: 9840 | MAE Train Loss: 0.06562675535678864 | MAE Test Loss: 0.15344563126564026 \n",
            "OrderedDict({'weights': tensor([0.3735]), 'bias': tensor([0.4371])})\n",
            "Epoch: 9850 | MAE Train Loss: 0.06559240818023682 | MAE Test Loss: 0.15336981415748596 \n",
            "OrderedDict({'weights': tensor([0.3737]), 'bias': tensor([0.4370])})\n",
            "Epoch: 9860 | MAE Train Loss: 0.06555808335542679 | MAE Test Loss: 0.1532871425151825 \n",
            "OrderedDict({'weights': tensor([0.3739]), 'bias': tensor([0.4370])})\n",
            "Epoch: 9870 | MAE Train Loss: 0.06552372127771378 | MAE Test Loss: 0.1532078981399536 \n",
            "OrderedDict({'weights': tensor([0.3740]), 'bias': tensor([0.4369])})\n",
            "Epoch: 9880 | MAE Train Loss: 0.06548933684825897 | MAE Test Loss: 0.15312521159648895 \n",
            "OrderedDict({'weights': tensor([0.3742]), 'bias': tensor([0.4368])})\n",
            "Epoch: 9890 | MAE Train Loss: 0.06545493751764297 | MAE Test Loss: 0.15304937958717346 \n",
            "OrderedDict({'weights': tensor([0.3744]), 'bias': tensor([0.4368])})\n",
            "Epoch: 9900 | MAE Train Loss: 0.06542063504457474 | MAE Test Loss: 0.1529666930437088 \n",
            "OrderedDict({'weights': tensor([0.3745]), 'bias': tensor([0.4367])})\n",
            "Epoch: 9910 | MAE Train Loss: 0.06538624316453934 | MAE Test Loss: 0.15288400650024414 \n",
            "OrderedDict({'weights': tensor([0.3747]), 'bias': tensor([0.4366])})\n",
            "Epoch: 9920 | MAE Train Loss: 0.06535186618566513 | MAE Test Loss: 0.15280818939208984 \n",
            "OrderedDict({'weights': tensor([0.3749]), 'bias': tensor([0.4365])})\n",
            "Epoch: 9930 | MAE Train Loss: 0.0653175488114357 | MAE Test Loss: 0.15272550284862518 \n",
            "OrderedDict({'weights': tensor([0.3751]), 'bias': tensor([0.4365])})\n",
            "Epoch: 9940 | MAE Train Loss: 0.0652831643819809 | MAE Test Loss: 0.15264281630516052 \n",
            "OrderedDict({'weights': tensor([0.3752]), 'bias': tensor([0.4364])})\n",
            "Epoch: 9950 | MAE Train Loss: 0.06524877995252609 | MAE Test Loss: 0.15256699919700623 \n",
            "OrderedDict({'weights': tensor([0.3754]), 'bias': tensor([0.4363])})\n",
            "Epoch: 9960 | MAE Train Loss: 0.06521441042423248 | MAE Test Loss: 0.15248090028762817 \n",
            "OrderedDict({'weights': tensor([0.3756]), 'bias': tensor([0.4363])})\n",
            "Epoch: 9970 | MAE Train Loss: 0.06518009305000305 | MAE Test Loss: 0.15240509808063507 \n",
            "OrderedDict({'weights': tensor([0.3757]), 'bias': tensor([0.4362])})\n",
            "Epoch: 9980 | MAE Train Loss: 0.06514570116996765 | MAE Test Loss: 0.152325838804245 \n",
            "OrderedDict({'weights': tensor([0.3759]), 'bias': tensor([0.4361])})\n",
            "Epoch: 9990 | MAE Train Loss: 0.06511138379573822 | MAE Test Loss: 0.15224315226078033 \n",
            "OrderedDict({'weights': tensor([0.3761]), 'bias': tensor([0.4360])})\n",
            "Epoch: 10000 | MAE Train Loss: 0.06507699191570282 | MAE Test Loss: 0.15216045081615448 \n",
            "OrderedDict({'weights': tensor([0.3763]), 'bias': tensor([0.4360])})\n",
            "Epoch: 10010 | MAE Train Loss: 0.06504262983798981 | MAE Test Loss: 0.15208466351032257 \n",
            "OrderedDict({'weights': tensor([0.3764]), 'bias': tensor([0.4359])})\n",
            "Epoch: 10020 | MAE Train Loss: 0.0650082379579544 | MAE Test Loss: 0.15199854969978333 \n",
            "OrderedDict({'weights': tensor([0.3766]), 'bias': tensor([0.4358])})\n",
            "Epoch: 10030 | MAE Train Loss: 0.06497392803430557 | MAE Test Loss: 0.15192270278930664 \n",
            "OrderedDict({'weights': tensor([0.3768]), 'bias': tensor([0.4358])})\n",
            "Epoch: 10040 | MAE Train Loss: 0.06493955850601196 | MAE Test Loss: 0.15184001624584198 \n",
            "OrderedDict({'weights': tensor([0.3769]), 'bias': tensor([0.4357])})\n",
            "Epoch: 10050 | MAE Train Loss: 0.06490515172481537 | MAE Test Loss: 0.15175732970237732 \n",
            "OrderedDict({'weights': tensor([0.3771]), 'bias': tensor([0.4356])})\n",
            "Epoch: 10060 | MAE Train Loss: 0.06487084925174713 | MAE Test Loss: 0.15168151259422302 \n",
            "OrderedDict({'weights': tensor([0.3773]), 'bias': tensor([0.4355])})\n",
            "Epoch: 10070 | MAE Train Loss: 0.06483646482229233 | MAE Test Loss: 0.15159884095191956 \n",
            "OrderedDict({'weights': tensor([0.3774]), 'bias': tensor([0.4355])})\n",
            "Epoch: 10080 | MAE Train Loss: 0.06480206549167633 | MAE Test Loss: 0.15152302384376526 \n",
            "OrderedDict({'weights': tensor([0.3776]), 'bias': tensor([0.4354])})\n",
            "Epoch: 10090 | MAE Train Loss: 0.06476777046918869 | MAE Test Loss: 0.1514403074979782 \n",
            "OrderedDict({'weights': tensor([0.3778]), 'bias': tensor([0.4353])})\n",
            "Epoch: 10100 | MAE Train Loss: 0.06473338603973389 | MAE Test Loss: 0.15135763585567474 \n",
            "OrderedDict({'weights': tensor([0.3780]), 'bias': tensor([0.4353])})\n",
            "Epoch: 10110 | MAE Train Loss: 0.06469903886318207 | MAE Test Loss: 0.15127840638160706 \n",
            "OrderedDict({'weights': tensor([0.3781]), 'bias': tensor([0.4352])})\n",
            "Epoch: 10120 | MAE Train Loss: 0.06466464698314667 | MAE Test Loss: 0.1511957198381424 \n",
            "OrderedDict({'weights': tensor([0.3783]), 'bias': tensor([0.4351])})\n",
            "Epoch: 10130 | MAE Train Loss: 0.06463030725717545 | MAE Test Loss: 0.1511199027299881 \n",
            "OrderedDict({'weights': tensor([0.3785]), 'bias': tensor([0.4350])})\n",
            "Epoch: 10140 | MAE Train Loss: 0.06459595263004303 | MAE Test Loss: 0.15103724598884583 \n",
            "OrderedDict({'weights': tensor([0.3786]), 'bias': tensor([0.4350])})\n",
            "Epoch: 10150 | MAE Train Loss: 0.06456156075000763 | MAE Test Loss: 0.15095451474189758 \n",
            "OrderedDict({'weights': tensor([0.3788]), 'bias': tensor([0.4349])})\n",
            "Epoch: 10160 | MAE Train Loss: 0.06452721357345581 | MAE Test Loss: 0.15087871253490448 \n",
            "OrderedDict({'weights': tensor([0.3790]), 'bias': tensor([0.4348])})\n",
            "Epoch: 10170 | MAE Train Loss: 0.06449288129806519 | MAE Test Loss: 0.15079602599143982 \n",
            "OrderedDict({'weights': tensor([0.3792]), 'bias': tensor([0.4348])})\n",
            "Epoch: 10180 | MAE Train Loss: 0.064458467066288 | MAE Test Loss: 0.15071332454681396 \n",
            "OrderedDict({'weights': tensor([0.3793]), 'bias': tensor([0.4347])})\n",
            "Epoch: 10190 | MAE Train Loss: 0.06442414224147797 | MAE Test Loss: 0.15063753724098206 \n",
            "OrderedDict({'weights': tensor([0.3795]), 'bias': tensor([0.4346])})\n",
            "Epoch: 10200 | MAE Train Loss: 0.06438975036144257 | MAE Test Loss: 0.1505582630634308 \n",
            "OrderedDict({'weights': tensor([0.3797]), 'bias': tensor([0.4345])})\n",
            "Epoch: 10210 | MAE Train Loss: 0.06435538083314896 | MAE Test Loss: 0.15047213435173035 \n",
            "OrderedDict({'weights': tensor([0.3798]), 'bias': tensor([0.4345])})\n",
            "Epoch: 10220 | MAE Train Loss: 0.06432105600833893 | MAE Test Loss: 0.15039631724357605 \n",
            "OrderedDict({'weights': tensor([0.3800]), 'bias': tensor([0.4344])})\n",
            "Epoch: 10230 | MAE Train Loss: 0.06428670883178711 | MAE Test Loss: 0.15031364560127258 \n",
            "OrderedDict({'weights': tensor([0.3802]), 'bias': tensor([0.4343])})\n",
            "Epoch: 10240 | MAE Train Loss: 0.06425230205059052 | MAE Test Loss: 0.15023097395896912 \n",
            "OrderedDict({'weights': tensor([0.3804]), 'bias': tensor([0.4343])})\n",
            "Epoch: 10250 | MAE Train Loss: 0.0642179548740387 | MAE Test Loss: 0.15015172958374023 \n",
            "OrderedDict({'weights': tensor([0.3805]), 'bias': tensor([0.4342])})\n",
            "Epoch: 10260 | MAE Train Loss: 0.06418358534574509 | MAE Test Loss: 0.15007588267326355 \n",
            "OrderedDict({'weights': tensor([0.3807]), 'bias': tensor([0.4341])})\n",
            "Epoch: 10270 | MAE Train Loss: 0.06414927542209625 | MAE Test Loss: 0.14999321103096008 \n",
            "OrderedDict({'weights': tensor([0.3809]), 'bias': tensor([0.4340])})\n",
            "Epoch: 10280 | MAE Train Loss: 0.06411486864089966 | MAE Test Loss: 0.14991052448749542 \n",
            "OrderedDict({'weights': tensor([0.3810]), 'bias': tensor([0.4340])})\n",
            "Epoch: 10290 | MAE Train Loss: 0.06408051401376724 | MAE Test Loss: 0.14983467757701874 \n",
            "OrderedDict({'weights': tensor([0.3812]), 'bias': tensor([0.4339])})\n",
            "Epoch: 10300 | MAE Train Loss: 0.06404618918895721 | MAE Test Loss: 0.14975202083587646 \n",
            "OrderedDict({'weights': tensor([0.3814]), 'bias': tensor([0.4338])})\n",
            "Epoch: 10310 | MAE Train Loss: 0.06401178240776062 | MAE Test Loss: 0.1496693193912506 \n",
            "OrderedDict({'weights': tensor([0.3816]), 'bias': tensor([0.4338])})\n",
            "Epoch: 10320 | MAE Train Loss: 0.0639774352312088 | MAE Test Loss: 0.1495935022830963 \n",
            "OrderedDict({'weights': tensor([0.3817]), 'bias': tensor([0.4337])})\n",
            "Epoch: 10330 | MAE Train Loss: 0.06394310295581818 | MAE Test Loss: 0.14951083064079285 \n",
            "OrderedDict({'weights': tensor([0.3819]), 'bias': tensor([0.4336])})\n",
            "Epoch: 10340 | MAE Train Loss: 0.06390874087810516 | MAE Test Loss: 0.14943158626556396 \n",
            "OrderedDict({'weights': tensor([0.3821]), 'bias': tensor([0.4335])})\n",
            "Epoch: 10350 | MAE Train Loss: 0.06387435644865036 | MAE Test Loss: 0.1493488997220993 \n",
            "OrderedDict({'weights': tensor([0.3822]), 'bias': tensor([0.4335])})\n",
            "Epoch: 10360 | MAE Train Loss: 0.06383997201919556 | MAE Test Loss: 0.1492730677127838 \n",
            "OrderedDict({'weights': tensor([0.3824]), 'bias': tensor([0.4334])})\n",
            "Epoch: 10370 | MAE Train Loss: 0.06380565464496613 | MAE Test Loss: 0.14919038116931915 \n",
            "OrderedDict({'weights': tensor([0.3826]), 'bias': tensor([0.4333])})\n",
            "Epoch: 10380 | MAE Train Loss: 0.06377127021551132 | MAE Test Loss: 0.1491076946258545 \n",
            "OrderedDict({'weights': tensor([0.3827]), 'bias': tensor([0.4332])})\n",
            "Epoch: 10390 | MAE Train Loss: 0.06373688578605652 | MAE Test Loss: 0.1490318775177002 \n",
            "OrderedDict({'weights': tensor([0.3829]), 'bias': tensor([0.4332])})\n",
            "Epoch: 10400 | MAE Train Loss: 0.06370256841182709 | MAE Test Loss: 0.14894919097423553 \n",
            "OrderedDict({'weights': tensor([0.3831]), 'bias': tensor([0.4331])})\n",
            "Epoch: 10410 | MAE Train Loss: 0.06366818398237228 | MAE Test Loss: 0.14886650443077087 \n",
            "OrderedDict({'weights': tensor([0.3833]), 'bias': tensor([0.4330])})\n",
            "Epoch: 10420 | MAE Train Loss: 0.06363380700349808 | MAE Test Loss: 0.14879068732261658 \n",
            "OrderedDict({'weights': tensor([0.3834]), 'bias': tensor([0.4330])})\n",
            "Epoch: 10430 | MAE Train Loss: 0.06359943747520447 | MAE Test Loss: 0.14870458841323853 \n",
            "OrderedDict({'weights': tensor([0.3836]), 'bias': tensor([0.4329])})\n",
            "Epoch: 10440 | MAE Train Loss: 0.06356512010097504 | MAE Test Loss: 0.14862878620624542 \n",
            "OrderedDict({'weights': tensor([0.3838]), 'bias': tensor([0.4328])})\n",
            "Epoch: 10450 | MAE Train Loss: 0.06353072822093964 | MAE Test Loss: 0.14854952692985535 \n",
            "OrderedDict({'weights': tensor([0.3839]), 'bias': tensor([0.4327])})\n",
            "Epoch: 10460 | MAE Train Loss: 0.0634964108467102 | MAE Test Loss: 0.14846684038639069 \n",
            "OrderedDict({'weights': tensor([0.3841]), 'bias': tensor([0.4327])})\n",
            "Epoch: 10470 | MAE Train Loss: 0.0634620189666748 | MAE Test Loss: 0.14838413894176483 \n",
            "OrderedDict({'weights': tensor([0.3843]), 'bias': tensor([0.4326])})\n",
            "Epoch: 10480 | MAE Train Loss: 0.0634276494383812 | MAE Test Loss: 0.14830835163593292 \n",
            "OrderedDict({'weights': tensor([0.3845]), 'bias': tensor([0.4325])})\n",
            "Epoch: 10490 | MAE Train Loss: 0.0633932575583458 | MAE Test Loss: 0.14822223782539368 \n",
            "OrderedDict({'weights': tensor([0.3846]), 'bias': tensor([0.4325])})\n",
            "Epoch: 10500 | MAE Train Loss: 0.06335894763469696 | MAE Test Loss: 0.148146390914917 \n",
            "OrderedDict({'weights': tensor([0.3848]), 'bias': tensor([0.4324])})\n",
            "Epoch: 10510 | MAE Train Loss: 0.06332458555698395 | MAE Test Loss: 0.14806370437145233 \n",
            "OrderedDict({'weights': tensor([0.3850]), 'bias': tensor([0.4323])})\n",
            "Epoch: 10520 | MAE Train Loss: 0.06329017877578735 | MAE Test Loss: 0.14798101782798767 \n",
            "OrderedDict({'weights': tensor([0.3851]), 'bias': tensor([0.4322])})\n",
            "Epoch: 10530 | MAE Train Loss: 0.06325586885213852 | MAE Test Loss: 0.14790520071983337 \n",
            "OrderedDict({'weights': tensor([0.3853]), 'bias': tensor([0.4322])})\n",
            "Epoch: 10540 | MAE Train Loss: 0.06322149187326431 | MAE Test Loss: 0.1478225290775299 \n",
            "OrderedDict({'weights': tensor([0.3855]), 'bias': tensor([0.4321])})\n",
            "Epoch: 10550 | MAE Train Loss: 0.06318709254264832 | MAE Test Loss: 0.1477467119693756 \n",
            "OrderedDict({'weights': tensor([0.3857]), 'bias': tensor([0.4320])})\n",
            "Epoch: 10560 | MAE Train Loss: 0.06315279752016068 | MAE Test Loss: 0.14766399562358856 \n",
            "OrderedDict({'weights': tensor([0.3858]), 'bias': tensor([0.4320])})\n",
            "Epoch: 10570 | MAE Train Loss: 0.06311841309070587 | MAE Test Loss: 0.1475813239812851 \n",
            "OrderedDict({'weights': tensor([0.3860]), 'bias': tensor([0.4319])})\n",
            "Epoch: 10580 | MAE Train Loss: 0.06308406591415405 | MAE Test Loss: 0.1475020945072174 \n",
            "OrderedDict({'weights': tensor([0.3862]), 'bias': tensor([0.4318])})\n",
            "Epoch: 10590 | MAE Train Loss: 0.06304966658353806 | MAE Test Loss: 0.14741940796375275 \n",
            "OrderedDict({'weights': tensor([0.3863]), 'bias': tensor([0.4317])})\n",
            "Epoch: 10600 | MAE Train Loss: 0.06301532685756683 | MAE Test Loss: 0.14734359085559845 \n",
            "OrderedDict({'weights': tensor([0.3865]), 'bias': tensor([0.4317])})\n",
            "Epoch: 10610 | MAE Train Loss: 0.06298097223043442 | MAE Test Loss: 0.14726093411445618 \n",
            "OrderedDict({'weights': tensor([0.3867]), 'bias': tensor([0.4316])})\n",
            "Epoch: 10620 | MAE Train Loss: 0.06294658035039902 | MAE Test Loss: 0.14717820286750793 \n",
            "OrderedDict({'weights': tensor([0.3869]), 'bias': tensor([0.4315])})\n",
            "Epoch: 10630 | MAE Train Loss: 0.0629122406244278 | MAE Test Loss: 0.14710240066051483 \n",
            "OrderedDict({'weights': tensor([0.3870]), 'bias': tensor([0.4314])})\n",
            "Epoch: 10640 | MAE Train Loss: 0.06287790834903717 | MAE Test Loss: 0.14701971411705017 \n",
            "OrderedDict({'weights': tensor([0.3872]), 'bias': tensor([0.4314])})\n",
            "Epoch: 10650 | MAE Train Loss: 0.06284348666667938 | MAE Test Loss: 0.14693701267242432 \n",
            "OrderedDict({'weights': tensor([0.3874]), 'bias': tensor([0.4313])})\n",
            "Epoch: 10660 | MAE Train Loss: 0.06280916929244995 | MAE Test Loss: 0.1468612253665924 \n",
            "OrderedDict({'weights': tensor([0.3875]), 'bias': tensor([0.4312])})\n",
            "Epoch: 10670 | MAE Train Loss: 0.06277477741241455 | MAE Test Loss: 0.14678195118904114 \n",
            "OrderedDict({'weights': tensor([0.3877]), 'bias': tensor([0.4312])})\n",
            "Epoch: 10680 | MAE Train Loss: 0.06274040043354034 | MAE Test Loss: 0.1466958224773407 \n",
            "OrderedDict({'weights': tensor([0.3879]), 'bias': tensor([0.4311])})\n",
            "Epoch: 10690 | MAE Train Loss: 0.06270608305931091 | MAE Test Loss: 0.1466200053691864 \n",
            "OrderedDict({'weights': tensor([0.3880]), 'bias': tensor([0.4310])})\n",
            "Epoch: 10700 | MAE Train Loss: 0.0626717358827591 | MAE Test Loss: 0.14653733372688293 \n",
            "OrderedDict({'weights': tensor([0.3882]), 'bias': tensor([0.4309])})\n",
            "Epoch: 10710 | MAE Train Loss: 0.0626373216509819 | MAE Test Loss: 0.14645466208457947 \n",
            "OrderedDict({'weights': tensor([0.3884]), 'bias': tensor([0.4309])})\n",
            "Epoch: 10720 | MAE Train Loss: 0.06260298192501068 | MAE Test Loss: 0.1463753879070282 \n",
            "OrderedDict({'weights': tensor([0.3886]), 'bias': tensor([0.4308])})\n",
            "Epoch: 10730 | MAE Train Loss: 0.06256861239671707 | MAE Test Loss: 0.1462995707988739 \n",
            "OrderedDict({'weights': tensor([0.3887]), 'bias': tensor([0.4307])})\n",
            "Epoch: 10740 | MAE Train Loss: 0.06253429502248764 | MAE Test Loss: 0.14621689915657043 \n",
            "OrderedDict({'weights': tensor([0.3889]), 'bias': tensor([0.4307])})\n",
            "Epoch: 10750 | MAE Train Loss: 0.062499891966581345 | MAE Test Loss: 0.14613421261310577 \n",
            "OrderedDict({'weights': tensor([0.3891]), 'bias': tensor([0.4306])})\n",
            "Epoch: 10760 | MAE Train Loss: 0.06246553733944893 | MAE Test Loss: 0.1460583657026291 \n",
            "OrderedDict({'weights': tensor([0.3892]), 'bias': tensor([0.4305])})\n",
            "Epoch: 10770 | MAE Train Loss: 0.0624312087893486 | MAE Test Loss: 0.14597570896148682 \n",
            "OrderedDict({'weights': tensor([0.3894]), 'bias': tensor([0.4304])})\n",
            "Epoch: 10780 | MAE Train Loss: 0.062396805733442307 | MAE Test Loss: 0.14589300751686096 \n",
            "OrderedDict({'weights': tensor([0.3896]), 'bias': tensor([0.4304])})\n",
            "Epoch: 10790 | MAE Train Loss: 0.062362462282180786 | MAE Test Loss: 0.14581719040870667 \n",
            "OrderedDict({'weights': tensor([0.3898]), 'bias': tensor([0.4303])})\n",
            "Epoch: 10800 | MAE Train Loss: 0.06232813000679016 | MAE Test Loss: 0.1457345187664032 \n",
            "OrderedDict({'weights': tensor([0.3899]), 'bias': tensor([0.4302])})\n",
            "Epoch: 10810 | MAE Train Loss: 0.06229376792907715 | MAE Test Loss: 0.14565527439117432 \n",
            "OrderedDict({'weights': tensor([0.3901]), 'bias': tensor([0.4302])})\n",
            "Epoch: 10820 | MAE Train Loss: 0.062259383499622345 | MAE Test Loss: 0.14557258784770966 \n",
            "OrderedDict({'weights': tensor([0.3903]), 'bias': tensor([0.4301])})\n",
            "Epoch: 10830 | MAE Train Loss: 0.06222499534487724 | MAE Test Loss: 0.14549677073955536 \n",
            "OrderedDict({'weights': tensor([0.3904]), 'bias': tensor([0.4300])})\n",
            "Epoch: 10840 | MAE Train Loss: 0.06219068169593811 | MAE Test Loss: 0.1454140692949295 \n",
            "OrderedDict({'weights': tensor([0.3906]), 'bias': tensor([0.4299])})\n",
            "Epoch: 10850 | MAE Train Loss: 0.06215629726648331 | MAE Test Loss: 0.14533138275146484 \n",
            "OrderedDict({'weights': tensor([0.3908]), 'bias': tensor([0.4299])})\n",
            "Epoch: 10860 | MAE Train Loss: 0.062121909111738205 | MAE Test Loss: 0.14525556564331055 \n",
            "OrderedDict({'weights': tensor([0.3910]), 'bias': tensor([0.4298])})\n",
            "Epoch: 10870 | MAE Train Loss: 0.06208759546279907 | MAE Test Loss: 0.1451728790998459 \n",
            "OrderedDict({'weights': tensor([0.3911]), 'bias': tensor([0.4297])})\n",
            "Epoch: 10880 | MAE Train Loss: 0.06205321103334427 | MAE Test Loss: 0.14509019255638123 \n",
            "OrderedDict({'weights': tensor([0.3913]), 'bias': tensor([0.4297])})\n",
            "Epoch: 10890 | MAE Train Loss: 0.062018830329179764 | MAE Test Loss: 0.14501437544822693 \n",
            "OrderedDict({'weights': tensor([0.3915]), 'bias': tensor([0.4296])})\n",
            "Epoch: 10900 | MAE Train Loss: 0.061984460800886154 | MAE Test Loss: 0.14492827653884888 \n",
            "OrderedDict({'weights': tensor([0.3916]), 'bias': tensor([0.4295])})\n",
            "Epoch: 10910 | MAE Train Loss: 0.061950139701366425 | MAE Test Loss: 0.14485245943069458 \n",
            "OrderedDict({'weights': tensor([0.3918]), 'bias': tensor([0.4294])})\n",
            "Epoch: 10920 | MAE Train Loss: 0.061915747821331024 | MAE Test Loss: 0.1447732150554657 \n",
            "OrderedDict({'weights': tensor([0.3920]), 'bias': tensor([0.4294])})\n",
            "Epoch: 10930 | MAE Train Loss: 0.06188143417239189 | MAE Test Loss: 0.14469052851200104 \n",
            "OrderedDict({'weights': tensor([0.3921]), 'bias': tensor([0.4293])})\n",
            "Epoch: 10940 | MAE Train Loss: 0.06184704229235649 | MAE Test Loss: 0.14460782706737518 \n",
            "OrderedDict({'weights': tensor([0.3923]), 'bias': tensor([0.4292])})\n",
            "Epoch: 10950 | MAE Train Loss: 0.06181267648935318 | MAE Test Loss: 0.14453203976154327 \n",
            "OrderedDict({'weights': tensor([0.3925]), 'bias': tensor([0.4292])})\n",
            "Epoch: 10960 | MAE Train Loss: 0.06177828833460808 | MAE Test Loss: 0.14444592595100403 \n",
            "OrderedDict({'weights': tensor([0.3927]), 'bias': tensor([0.4291])})\n",
            "Epoch: 10970 | MAE Train Loss: 0.061743974685668945 | MAE Test Loss: 0.14437007904052734 \n",
            "OrderedDict({'weights': tensor([0.3928]), 'bias': tensor([0.4290])})\n",
            "Epoch: 10980 | MAE Train Loss: 0.061709605157375336 | MAE Test Loss: 0.14428739249706268 \n",
            "OrderedDict({'weights': tensor([0.3930]), 'bias': tensor([0.4289])})\n",
            "Epoch: 10990 | MAE Train Loss: 0.06167520210146904 | MAE Test Loss: 0.14420470595359802 \n",
            "OrderedDict({'weights': tensor([0.3932]), 'bias': tensor([0.4289])})\n",
            "Epoch: 11000 | MAE Train Loss: 0.061640895903110504 | MAE Test Loss: 0.14412888884544373 \n",
            "OrderedDict({'weights': tensor([0.3933]), 'bias': tensor([0.4288])})\n",
            "Epoch: 11010 | MAE Train Loss: 0.061606515198946 | MAE Test Loss: 0.14404621720314026 \n",
            "OrderedDict({'weights': tensor([0.3935]), 'bias': tensor([0.4287])})\n",
            "Epoch: 11020 | MAE Train Loss: 0.06157211586833 | MAE Test Loss: 0.14397040009498596 \n",
            "OrderedDict({'weights': tensor([0.3937]), 'bias': tensor([0.4286])})\n",
            "Epoch: 11030 | MAE Train Loss: 0.06153782084584236 | MAE Test Loss: 0.1438876837491989 \n",
            "OrderedDict({'weights': tensor([0.3939]), 'bias': tensor([0.4286])})\n",
            "Epoch: 11040 | MAE Train Loss: 0.06150343269109726 | MAE Test Loss: 0.14380502700805664 \n",
            "OrderedDict({'weights': tensor([0.3940]), 'bias': tensor([0.4285])})\n",
            "Epoch: 11050 | MAE Train Loss: 0.06146908923983574 | MAE Test Loss: 0.14372578263282776 \n",
            "OrderedDict({'weights': tensor([0.3942]), 'bias': tensor([0.4284])})\n",
            "Epoch: 11060 | MAE Train Loss: 0.06143469363451004 | MAE Test Loss: 0.1436430960893631 \n",
            "OrderedDict({'weights': tensor([0.3944]), 'bias': tensor([0.4284])})\n",
            "Epoch: 11070 | MAE Train Loss: 0.06140035390853882 | MAE Test Loss: 0.1435672491788864 \n",
            "OrderedDict({'weights': tensor([0.3945]), 'bias': tensor([0.4283])})\n",
            "Epoch: 11080 | MAE Train Loss: 0.0613659992814064 | MAE Test Loss: 0.14348459243774414 \n",
            "OrderedDict({'weights': tensor([0.3947]), 'bias': tensor([0.4282])})\n",
            "Epoch: 11090 | MAE Train Loss: 0.061331607401371 | MAE Test Loss: 0.14340190589427948 \n",
            "OrderedDict({'weights': tensor([0.3949]), 'bias': tensor([0.4282])})\n",
            "Epoch: 11100 | MAE Train Loss: 0.06129726022481918 | MAE Test Loss: 0.14332608878612518 \n",
            "OrderedDict({'weights': tensor([0.3951]), 'bias': tensor([0.4281])})\n",
            "Epoch: 11110 | MAE Train Loss: 0.06126292794942856 | MAE Test Loss: 0.14324340224266052 \n",
            "OrderedDict({'weights': tensor([0.3952]), 'bias': tensor([0.4280])})\n",
            "Epoch: 11120 | MAE Train Loss: 0.06122851371765137 | MAE Test Loss: 0.14316070079803467 \n",
            "OrderedDict({'weights': tensor([0.3954]), 'bias': tensor([0.4279])})\n",
            "Epoch: 11130 | MAE Train Loss: 0.06119419261813164 | MAE Test Loss: 0.14308491349220276 \n",
            "OrderedDict({'weights': tensor([0.3956]), 'bias': tensor([0.4279])})\n",
            "Epoch: 11140 | MAE Train Loss: 0.06115980073809624 | MAE Test Loss: 0.1430056393146515 \n",
            "OrderedDict({'weights': tensor([0.3957]), 'bias': tensor([0.4278])})\n",
            "Epoch: 11150 | MAE Train Loss: 0.06112542748451233 | MAE Test Loss: 0.14291951060295105 \n",
            "OrderedDict({'weights': tensor([0.3959]), 'bias': tensor([0.4277])})\n",
            "Epoch: 11160 | MAE Train Loss: 0.0610911063849926 | MAE Test Loss: 0.14284369349479675 \n",
            "OrderedDict({'weights': tensor([0.3961]), 'bias': tensor([0.4276])})\n",
            "Epoch: 11170 | MAE Train Loss: 0.061056751757860184 | MAE Test Loss: 0.1427610218524933 \n",
            "OrderedDict({'weights': tensor([0.3963]), 'bias': tensor([0.4276])})\n",
            "Epoch: 11180 | MAE Train Loss: 0.06102234870195389 | MAE Test Loss: 0.14267835021018982 \n",
            "OrderedDict({'weights': tensor([0.3964]), 'bias': tensor([0.4275])})\n",
            "Epoch: 11190 | MAE Train Loss: 0.06098800152540207 | MAE Test Loss: 0.14259907603263855 \n",
            "OrderedDict({'weights': tensor([0.3966]), 'bias': tensor([0.4274])})\n",
            "Epoch: 11200 | MAE Train Loss: 0.06095363572239876 | MAE Test Loss: 0.14252325892448425 \n",
            "OrderedDict({'weights': tensor([0.3968]), 'bias': tensor([0.4274])})\n",
            "Epoch: 11210 | MAE Train Loss: 0.060919322073459625 | MAE Test Loss: 0.1424405872821808 \n",
            "OrderedDict({'weights': tensor([0.3969]), 'bias': tensor([0.4273])})\n",
            "Epoch: 11220 | MAE Train Loss: 0.06088491529226303 | MAE Test Loss: 0.14235790073871613 \n",
            "OrderedDict({'weights': tensor([0.3971]), 'bias': tensor([0.4272])})\n",
            "Epoch: 11230 | MAE Train Loss: 0.060850560665130615 | MAE Test Loss: 0.14228205382823944 \n",
            "OrderedDict({'weights': tensor([0.3973]), 'bias': tensor([0.4271])})\n",
            "Epoch: 11240 | MAE Train Loss: 0.06081623584032059 | MAE Test Loss: 0.14219939708709717 \n",
            "OrderedDict({'weights': tensor([0.3974]), 'bias': tensor([0.4271])})\n",
            "Epoch: 11250 | MAE Train Loss: 0.06078182905912399 | MAE Test Loss: 0.1421166956424713 \n",
            "OrderedDict({'weights': tensor([0.3976]), 'bias': tensor([0.4270])})\n",
            "Epoch: 11260 | MAE Train Loss: 0.06074748560786247 | MAE Test Loss: 0.14204087853431702 \n",
            "OrderedDict({'weights': tensor([0.3978]), 'bias': tensor([0.4269])})\n",
            "Epoch: 11270 | MAE Train Loss: 0.06071315333247185 | MAE Test Loss: 0.14195820689201355 \n",
            "OrderedDict({'weights': tensor([0.3980]), 'bias': tensor([0.4269])})\n",
            "Epoch: 11280 | MAE Train Loss: 0.060678791254758835 | MAE Test Loss: 0.14187896251678467 \n",
            "OrderedDict({'weights': tensor([0.3981]), 'bias': tensor([0.4268])})\n",
            "Epoch: 11290 | MAE Train Loss: 0.06064440682530403 | MAE Test Loss: 0.14179627597332 \n",
            "OrderedDict({'weights': tensor([0.3983]), 'bias': tensor([0.4267])})\n",
            "Epoch: 11300 | MAE Train Loss: 0.060610007494688034 | MAE Test Loss: 0.1417204588651657 \n",
            "OrderedDict({'weights': tensor([0.3985]), 'bias': tensor([0.4266])})\n",
            "Epoch: 11310 | MAE Train Loss: 0.0605757050216198 | MAE Test Loss: 0.14163775742053986 \n",
            "OrderedDict({'weights': tensor([0.3986]), 'bias': tensor([0.4266])})\n",
            "Epoch: 11320 | MAE Train Loss: 0.06054132059216499 | MAE Test Loss: 0.1415550708770752 \n",
            "OrderedDict({'weights': tensor([0.3988]), 'bias': tensor([0.4265])})\n",
            "Epoch: 11330 | MAE Train Loss: 0.06050693988800049 | MAE Test Loss: 0.1414792537689209 \n",
            "OrderedDict({'weights': tensor([0.3990]), 'bias': tensor([0.4264])})\n",
            "Epoch: 11340 | MAE Train Loss: 0.06047261878848076 | MAE Test Loss: 0.14139656722545624 \n",
            "OrderedDict({'weights': tensor([0.3992]), 'bias': tensor([0.4264])})\n",
            "Epoch: 11350 | MAE Train Loss: 0.060438234359025955 | MAE Test Loss: 0.14131388068199158 \n",
            "OrderedDict({'weights': tensor([0.3993]), 'bias': tensor([0.4263])})\n",
            "Epoch: 11360 | MAE Train Loss: 0.06040385365486145 | MAE Test Loss: 0.14123806357383728 \n",
            "OrderedDict({'weights': tensor([0.3995]), 'bias': tensor([0.4262])})\n",
            "Epoch: 11370 | MAE Train Loss: 0.06036948412656784 | MAE Test Loss: 0.14115196466445923 \n",
            "OrderedDict({'weights': tensor([0.3997]), 'bias': tensor([0.4261])})\n",
            "Epoch: 11380 | MAE Train Loss: 0.06033516675233841 | MAE Test Loss: 0.14107614755630493 \n",
            "OrderedDict({'weights': tensor([0.3998]), 'bias': tensor([0.4261])})\n",
            "Epoch: 11390 | MAE Train Loss: 0.06030077487230301 | MAE Test Loss: 0.14099690318107605 \n",
            "OrderedDict({'weights': tensor([0.4000]), 'bias': tensor([0.4260])})\n",
            "Epoch: 11400 | MAE Train Loss: 0.06026645749807358 | MAE Test Loss: 0.1409142166376114 \n",
            "OrderedDict({'weights': tensor([0.4002]), 'bias': tensor([0.4259])})\n",
            "Epoch: 11410 | MAE Train Loss: 0.06023206561803818 | MAE Test Loss: 0.14083151519298553 \n",
            "OrderedDict({'weights': tensor([0.4004]), 'bias': tensor([0.4259])})\n",
            "Epoch: 11420 | MAE Train Loss: 0.060197699815034866 | MAE Test Loss: 0.14075572788715363 \n",
            "OrderedDict({'weights': tensor([0.4005]), 'bias': tensor([0.4258])})\n",
            "Epoch: 11430 | MAE Train Loss: 0.060163311660289764 | MAE Test Loss: 0.14066961407661438 \n",
            "OrderedDict({'weights': tensor([0.4007]), 'bias': tensor([0.4257])})\n",
            "Epoch: 11440 | MAE Train Loss: 0.06012899801135063 | MAE Test Loss: 0.1405937671661377 \n",
            "OrderedDict({'weights': tensor([0.4009]), 'bias': tensor([0.4256])})\n",
            "Epoch: 11450 | MAE Train Loss: 0.06009463220834732 | MAE Test Loss: 0.14051108062267303 \n",
            "OrderedDict({'weights': tensor([0.4010]), 'bias': tensor([0.4256])})\n",
            "Epoch: 11460 | MAE Train Loss: 0.060060225427150726 | MAE Test Loss: 0.14042839407920837 \n",
            "OrderedDict({'weights': tensor([0.4012]), 'bias': tensor([0.4255])})\n",
            "Epoch: 11470 | MAE Train Loss: 0.06002591922879219 | MAE Test Loss: 0.14035257697105408 \n",
            "OrderedDict({'weights': tensor([0.4014]), 'bias': tensor([0.4254])})\n",
            "Epoch: 11480 | MAE Train Loss: 0.059991538524627686 | MAE Test Loss: 0.1402699053287506 \n",
            "OrderedDict({'weights': tensor([0.4016]), 'bias': tensor([0.4253])})\n",
            "Epoch: 11490 | MAE Train Loss: 0.05995713919401169 | MAE Test Loss: 0.1401940882205963 \n",
            "OrderedDict({'weights': tensor([0.4017]), 'bias': tensor([0.4253])})\n",
            "Epoch: 11500 | MAE Train Loss: 0.05992284417152405 | MAE Test Loss: 0.14011137187480927 \n",
            "OrderedDict({'weights': tensor([0.4019]), 'bias': tensor([0.4252])})\n",
            "Epoch: 11510 | MAE Train Loss: 0.059888459742069244 | MAE Test Loss: 0.140028715133667 \n",
            "OrderedDict({'weights': tensor([0.4021]), 'bias': tensor([0.4251])})\n",
            "Epoch: 11520 | MAE Train Loss: 0.059854112565517426 | MAE Test Loss: 0.1399494707584381 \n",
            "OrderedDict({'weights': tensor([0.4022]), 'bias': tensor([0.4251])})\n",
            "Epoch: 11530 | MAE Train Loss: 0.05981971696019173 | MAE Test Loss: 0.13986678421497345 \n",
            "OrderedDict({'weights': tensor([0.4024]), 'bias': tensor([0.4250])})\n",
            "Epoch: 11540 | MAE Train Loss: 0.059785377234220505 | MAE Test Loss: 0.13979093730449677 \n",
            "OrderedDict({'weights': tensor([0.4026]), 'bias': tensor([0.4249])})\n",
            "Epoch: 11550 | MAE Train Loss: 0.05975102260708809 | MAE Test Loss: 0.1397082805633545 \n",
            "OrderedDict({'weights': tensor([0.4027]), 'bias': tensor([0.4248])})\n",
            "Epoch: 11560 | MAE Train Loss: 0.05971663072705269 | MAE Test Loss: 0.13962559401988983 \n",
            "OrderedDict({'weights': tensor([0.4029]), 'bias': tensor([0.4248])})\n",
            "Epoch: 11570 | MAE Train Loss: 0.05968228727579117 | MAE Test Loss: 0.13954977691173553 \n",
            "OrderedDict({'weights': tensor([0.4031]), 'bias': tensor([0.4247])})\n",
            "Epoch: 11580 | MAE Train Loss: 0.05964795500040054 | MAE Test Loss: 0.13946709036827087 \n",
            "OrderedDict({'weights': tensor([0.4033]), 'bias': tensor([0.4246])})\n",
            "Epoch: 11590 | MAE Train Loss: 0.059613537043333054 | MAE Test Loss: 0.13938438892364502 \n",
            "OrderedDict({'weights': tensor([0.4034]), 'bias': tensor([0.4246])})\n",
            "Epoch: 11600 | MAE Train Loss: 0.059579215943813324 | MAE Test Loss: 0.1393086016178131 \n",
            "OrderedDict({'weights': tensor([0.4036]), 'bias': tensor([0.4245])})\n",
            "Epoch: 11610 | MAE Train Loss: 0.059544824063777924 | MAE Test Loss: 0.13922932744026184 \n",
            "OrderedDict({'weights': tensor([0.4038]), 'bias': tensor([0.4244])})\n",
            "Epoch: 11620 | MAE Train Loss: 0.059510450810194016 | MAE Test Loss: 0.1391431987285614 \n",
            "OrderedDict({'weights': tensor([0.4039]), 'bias': tensor([0.4243])})\n",
            "Epoch: 11630 | MAE Train Loss: 0.059476129710674286 | MAE Test Loss: 0.1390673816204071 \n",
            "OrderedDict({'weights': tensor([0.4041]), 'bias': tensor([0.4243])})\n",
            "Epoch: 11640 | MAE Train Loss: 0.05944177508354187 | MAE Test Loss: 0.13898470997810364 \n",
            "OrderedDict({'weights': tensor([0.4043]), 'bias': tensor([0.4242])})\n",
            "Epoch: 11650 | MAE Train Loss: 0.059407372027635574 | MAE Test Loss: 0.13890203833580017 \n",
            "OrderedDict({'weights': tensor([0.4045]), 'bias': tensor([0.4241])})\n",
            "Epoch: 11660 | MAE Train Loss: 0.059373028576374054 | MAE Test Loss: 0.1388227641582489 \n",
            "OrderedDict({'weights': tensor([0.4046]), 'bias': tensor([0.4241])})\n",
            "Epoch: 11670 | MAE Train Loss: 0.059338659048080444 | MAE Test Loss: 0.1387469470500946 \n",
            "OrderedDict({'weights': tensor([0.4048]), 'bias': tensor([0.4240])})\n",
            "Epoch: 11680 | MAE Train Loss: 0.05930434539914131 | MAE Test Loss: 0.13866427540779114 \n",
            "OrderedDict({'weights': tensor([0.4050]), 'bias': tensor([0.4239])})\n",
            "Epoch: 11690 | MAE Train Loss: 0.059269942343235016 | MAE Test Loss: 0.13858158886432648 \n",
            "OrderedDict({'weights': tensor([0.4051]), 'bias': tensor([0.4238])})\n",
            "Epoch: 11700 | MAE Train Loss: 0.0592355839908123 | MAE Test Loss: 0.1385057419538498 \n",
            "OrderedDict({'weights': tensor([0.4053]), 'bias': tensor([0.4238])})\n",
            "Epoch: 11710 | MAE Train Loss: 0.059201259166002274 | MAE Test Loss: 0.13842308521270752 \n",
            "OrderedDict({'weights': tensor([0.4055]), 'bias': tensor([0.4237])})\n",
            "Epoch: 11720 | MAE Train Loss: 0.05916685611009598 | MAE Test Loss: 0.13834038376808167 \n",
            "OrderedDict({'weights': tensor([0.4057]), 'bias': tensor([0.4236])})\n",
            "Epoch: 11730 | MAE Train Loss: 0.05913250893354416 | MAE Test Loss: 0.13826456665992737 \n",
            "OrderedDict({'weights': tensor([0.4058]), 'bias': tensor([0.4236])})\n",
            "Epoch: 11740 | MAE Train Loss: 0.059098176658153534 | MAE Test Loss: 0.1381818950176239 \n",
            "OrderedDict({'weights': tensor([0.4060]), 'bias': tensor([0.4235])})\n",
            "Epoch: 11750 | MAE Train Loss: 0.05906381458044052 | MAE Test Loss: 0.13810265064239502 \n",
            "OrderedDict({'weights': tensor([0.4062]), 'bias': tensor([0.4234])})\n",
            "Epoch: 11760 | MAE Train Loss: 0.05902943015098572 | MAE Test Loss: 0.13801996409893036 \n",
            "OrderedDict({'weights': tensor([0.4063]), 'bias': tensor([0.4233])})\n",
            "Epoch: 11770 | MAE Train Loss: 0.05899503082036972 | MAE Test Loss: 0.13794414699077606 \n",
            "OrderedDict({'weights': tensor([0.4065]), 'bias': tensor([0.4233])})\n",
            "Epoch: 11780 | MAE Train Loss: 0.05896072834730148 | MAE Test Loss: 0.1378614455461502 \n",
            "OrderedDict({'weights': tensor([0.4067]), 'bias': tensor([0.4232])})\n",
            "Epoch: 11790 | MAE Train Loss: 0.05892634391784668 | MAE Test Loss: 0.13777875900268555 \n",
            "OrderedDict({'weights': tensor([0.4069]), 'bias': tensor([0.4231])})\n",
            "Epoch: 11800 | MAE Train Loss: 0.058891963213682175 | MAE Test Loss: 0.13770294189453125 \n",
            "OrderedDict({'weights': tensor([0.4070]), 'bias': tensor([0.4230])})\n",
            "Epoch: 11810 | MAE Train Loss: 0.058857642114162445 | MAE Test Loss: 0.1376202553510666 \n",
            "OrderedDict({'weights': tensor([0.4072]), 'bias': tensor([0.4230])})\n",
            "Epoch: 11820 | MAE Train Loss: 0.05882325768470764 | MAE Test Loss: 0.13753756880760193 \n",
            "OrderedDict({'weights': tensor([0.4074]), 'bias': tensor([0.4229])})\n",
            "Epoch: 11830 | MAE Train Loss: 0.05878887698054314 | MAE Test Loss: 0.13746175169944763 \n",
            "OrderedDict({'weights': tensor([0.4075]), 'bias': tensor([0.4228])})\n",
            "Epoch: 11840 | MAE Train Loss: 0.058754511177539825 | MAE Test Loss: 0.13737565279006958 \n",
            "OrderedDict({'weights': tensor([0.4077]), 'bias': tensor([0.4228])})\n",
            "Epoch: 11850 | MAE Train Loss: 0.058720190078020096 | MAE Test Loss: 0.13729983568191528 \n",
            "OrderedDict({'weights': tensor([0.4079]), 'bias': tensor([0.4227])})\n",
            "Epoch: 11860 | MAE Train Loss: 0.058685798197984695 | MAE Test Loss: 0.1372205913066864 \n",
            "OrderedDict({'weights': tensor([0.4080]), 'bias': tensor([0.4226])})\n",
            "Epoch: 11870 | MAE Train Loss: 0.05865148454904556 | MAE Test Loss: 0.13713790476322174 \n",
            "OrderedDict({'weights': tensor([0.4082]), 'bias': tensor([0.4225])})\n",
            "Epoch: 11880 | MAE Train Loss: 0.05861709266901016 | MAE Test Loss: 0.1370552033185959 \n",
            "OrderedDict({'weights': tensor([0.4084]), 'bias': tensor([0.4225])})\n",
            "Epoch: 11890 | MAE Train Loss: 0.058582715690135956 | MAE Test Loss: 0.13697941601276398 \n",
            "OrderedDict({'weights': tensor([0.4086]), 'bias': tensor([0.4224])})\n",
            "Epoch: 11900 | MAE Train Loss: 0.05854833871126175 | MAE Test Loss: 0.13689330220222473 \n",
            "OrderedDict({'weights': tensor([0.4087]), 'bias': tensor([0.4223])})\n",
            "Epoch: 11910 | MAE Train Loss: 0.05851402133703232 | MAE Test Loss: 0.13681745529174805 \n",
            "OrderedDict({'weights': tensor([0.4089]), 'bias': tensor([0.4223])})\n",
            "Epoch: 11920 | MAE Train Loss: 0.05847965553402901 | MAE Test Loss: 0.1367347687482834 \n",
            "OrderedDict({'weights': tensor([0.4091]), 'bias': tensor([0.4222])})\n",
            "Epoch: 11930 | MAE Train Loss: 0.05844525247812271 | MAE Test Loss: 0.13665208220481873 \n",
            "OrderedDict({'weights': tensor([0.4092]), 'bias': tensor([0.4221])})\n",
            "Epoch: 11940 | MAE Train Loss: 0.05841094255447388 | MAE Test Loss: 0.13657626509666443 \n",
            "OrderedDict({'weights': tensor([0.4094]), 'bias': tensor([0.4220])})\n",
            "Epoch: 11950 | MAE Train Loss: 0.05837656930088997 | MAE Test Loss: 0.13649359345436096 \n",
            "OrderedDict({'weights': tensor([0.4096]), 'bias': tensor([0.4220])})\n",
            "Epoch: 11960 | MAE Train Loss: 0.05834216624498367 | MAE Test Loss: 0.13641777634620667 \n",
            "OrderedDict({'weights': tensor([0.4098]), 'bias': tensor([0.4219])})\n",
            "Epoch: 11970 | MAE Train Loss: 0.058307867497205734 | MAE Test Loss: 0.13633506000041962 \n",
            "OrderedDict({'weights': tensor([0.4099]), 'bias': tensor([0.4218])})\n",
            "Epoch: 11980 | MAE Train Loss: 0.05827348306775093 | MAE Test Loss: 0.13625240325927734 \n",
            "OrderedDict({'weights': tensor([0.4101]), 'bias': tensor([0.4218])})\n",
            "Epoch: 11990 | MAE Train Loss: 0.05823913961648941 | MAE Test Loss: 0.13617315888404846 \n",
            "OrderedDict({'weights': tensor([0.4103]), 'bias': tensor([0.4217])})\n",
            "Epoch: 12000 | MAE Train Loss: 0.05820474028587341 | MAE Test Loss: 0.1360904723405838 \n",
            "OrderedDict({'weights': tensor([0.4104]), 'bias': tensor([0.4216])})\n",
            "Epoch: 12010 | MAE Train Loss: 0.05817040055990219 | MAE Test Loss: 0.13601462543010712 \n",
            "OrderedDict({'weights': tensor([0.4106]), 'bias': tensor([0.4215])})\n",
            "Epoch: 12020 | MAE Train Loss: 0.058136045932769775 | MAE Test Loss: 0.13593196868896484 \n",
            "OrderedDict({'weights': tensor([0.4108]), 'bias': tensor([0.4215])})\n",
            "Epoch: 12030 | MAE Train Loss: 0.05810164660215378 | MAE Test Loss: 0.13584928214550018 \n",
            "OrderedDict({'weights': tensor([0.4110]), 'bias': tensor([0.4214])})\n",
            "Epoch: 12040 | MAE Train Loss: 0.058067310601472855 | MAE Test Loss: 0.1357734650373459 \n",
            "OrderedDict({'weights': tensor([0.4111]), 'bias': tensor([0.4213])})\n",
            "Epoch: 12050 | MAE Train Loss: 0.05803297832608223 | MAE Test Loss: 0.13569077849388123 \n",
            "OrderedDict({'weights': tensor([0.4113]), 'bias': tensor([0.4213])})\n",
            "Epoch: 12060 | MAE Train Loss: 0.05799856036901474 | MAE Test Loss: 0.13560807704925537 \n",
            "OrderedDict({'weights': tensor([0.4115]), 'bias': tensor([0.4212])})\n",
            "Epoch: 12070 | MAE Train Loss: 0.05796424299478531 | MAE Test Loss: 0.13553228974342346 \n",
            "OrderedDict({'weights': tensor([0.4116]), 'bias': tensor([0.4211])})\n",
            "Epoch: 12080 | MAE Train Loss: 0.05792985111474991 | MAE Test Loss: 0.1354530155658722 \n",
            "OrderedDict({'weights': tensor([0.4118]), 'bias': tensor([0.4210])})\n",
            "Epoch: 12090 | MAE Train Loss: 0.0578954741358757 | MAE Test Loss: 0.13536688685417175 \n",
            "OrderedDict({'weights': tensor([0.4120]), 'bias': tensor([0.4210])})\n",
            "Epoch: 12100 | MAE Train Loss: 0.05786115676164627 | MAE Test Loss: 0.13529106974601746 \n",
            "OrderedDict({'weights': tensor([0.4122]), 'bias': tensor([0.4209])})\n",
            "Epoch: 12110 | MAE Train Loss: 0.057826798409223557 | MAE Test Loss: 0.135208398103714 \n",
            "OrderedDict({'weights': tensor([0.4123]), 'bias': tensor([0.4208])})\n",
            "Epoch: 12120 | MAE Train Loss: 0.05779239535331726 | MAE Test Loss: 0.13512572646141052 \n",
            "OrderedDict({'weights': tensor([0.4125]), 'bias': tensor([0.4208])})\n",
            "Epoch: 12130 | MAE Train Loss: 0.05775805190205574 | MAE Test Loss: 0.13504645228385925 \n",
            "OrderedDict({'weights': tensor([0.4127]), 'bias': tensor([0.4207])})\n",
            "Epoch: 12140 | MAE Train Loss: 0.05772368237376213 | MAE Test Loss: 0.13497063517570496 \n",
            "OrderedDict({'weights': tensor([0.4128]), 'bias': tensor([0.4206])})\n",
            "Epoch: 12150 | MAE Train Loss: 0.057689368724823 | MAE Test Loss: 0.1348879635334015 \n",
            "OrderedDict({'weights': tensor([0.4130]), 'bias': tensor([0.4205])})\n",
            "Epoch: 12160 | MAE Train Loss: 0.0576549656689167 | MAE Test Loss: 0.13480527698993683 \n",
            "OrderedDict({'weights': tensor([0.4132]), 'bias': tensor([0.4205])})\n",
            "Epoch: 12170 | MAE Train Loss: 0.05762060731649399 | MAE Test Loss: 0.13472943007946014 \n",
            "OrderedDict({'weights': tensor([0.4133]), 'bias': tensor([0.4204])})\n",
            "Epoch: 12180 | MAE Train Loss: 0.05758628249168396 | MAE Test Loss: 0.13464677333831787 \n",
            "OrderedDict({'weights': tensor([0.4135]), 'bias': tensor([0.4203])})\n",
            "Epoch: 12190 | MAE Train Loss: 0.057551879435777664 | MAE Test Loss: 0.13456407189369202 \n",
            "OrderedDict({'weights': tensor([0.4137]), 'bias': tensor([0.4203])})\n",
            "Epoch: 12200 | MAE Train Loss: 0.057517535984516144 | MAE Test Loss: 0.13448825478553772 \n",
            "OrderedDict({'weights': tensor([0.4139]), 'bias': tensor([0.4202])})\n",
            "Epoch: 12210 | MAE Train Loss: 0.05748320370912552 | MAE Test Loss: 0.13440558314323425 \n",
            "OrderedDict({'weights': tensor([0.4140]), 'bias': tensor([0.4201])})\n",
            "Epoch: 12220 | MAE Train Loss: 0.057448841631412506 | MAE Test Loss: 0.13432633876800537 \n",
            "OrderedDict({'weights': tensor([0.4142]), 'bias': tensor([0.4200])})\n",
            "Epoch: 12230 | MAE Train Loss: 0.057414453476667404 | MAE Test Loss: 0.1342436522245407 \n",
            "OrderedDict({'weights': tensor([0.4144]), 'bias': tensor([0.4200])})\n",
            "Epoch: 12240 | MAE Train Loss: 0.057380057871341705 | MAE Test Loss: 0.1341678351163864 \n",
            "OrderedDict({'weights': tensor([0.4145]), 'bias': tensor([0.4199])})\n",
            "Epoch: 12250 | MAE Train Loss: 0.05734575539827347 | MAE Test Loss: 0.13408513367176056 \n",
            "OrderedDict({'weights': tensor([0.4147]), 'bias': tensor([0.4198])})\n",
            "Epoch: 12260 | MAE Train Loss: 0.057311367243528366 | MAE Test Loss: 0.1340024471282959 \n",
            "OrderedDict({'weights': tensor([0.4149]), 'bias': tensor([0.4197])})\n",
            "Epoch: 12270 | MAE Train Loss: 0.05727698653936386 | MAE Test Loss: 0.1339266300201416 \n",
            "OrderedDict({'weights': tensor([0.4151]), 'bias': tensor([0.4197])})\n",
            "Epoch: 12280 | MAE Train Loss: 0.05724266916513443 | MAE Test Loss: 0.13384394347667694 \n",
            "OrderedDict({'weights': tensor([0.4152]), 'bias': tensor([0.4196])})\n",
            "Epoch: 12290 | MAE Train Loss: 0.05720828101038933 | MAE Test Loss: 0.13376125693321228 \n",
            "OrderedDict({'weights': tensor([0.4154]), 'bias': tensor([0.4195])})\n",
            "Epoch: 12300 | MAE Train Loss: 0.05717390030622482 | MAE Test Loss: 0.13368543982505798 \n",
            "OrderedDict({'weights': tensor([0.4156]), 'bias': tensor([0.4195])})\n",
            "Epoch: 12310 | MAE Train Loss: 0.05713953450322151 | MAE Test Loss: 0.13359934091567993 \n",
            "OrderedDict({'weights': tensor([0.4157]), 'bias': tensor([0.4194])})\n",
            "Epoch: 12320 | MAE Train Loss: 0.05710521340370178 | MAE Test Loss: 0.13352352380752563 \n",
            "OrderedDict({'weights': tensor([0.4159]), 'bias': tensor([0.4193])})\n",
            "Epoch: 12330 | MAE Train Loss: 0.05707082897424698 | MAE Test Loss: 0.13344427943229675 \n",
            "OrderedDict({'weights': tensor([0.4161]), 'bias': tensor([0.4192])})\n",
            "Epoch: 12340 | MAE Train Loss: 0.05703651160001755 | MAE Test Loss: 0.1333615928888321 \n",
            "OrderedDict({'weights': tensor([0.4163]), 'bias': tensor([0.4192])})\n",
            "Epoch: 12350 | MAE Train Loss: 0.05700210854411125 | MAE Test Loss: 0.13327889144420624 \n",
            "OrderedDict({'weights': tensor([0.4164]), 'bias': tensor([0.4191])})\n",
            "Epoch: 12360 | MAE Train Loss: 0.05696774274110794 | MAE Test Loss: 0.13320310413837433 \n",
            "OrderedDict({'weights': tensor([0.4166]), 'bias': tensor([0.4190])})\n",
            "Epoch: 12370 | MAE Train Loss: 0.056933362036943436 | MAE Test Loss: 0.13311699032783508 \n",
            "OrderedDict({'weights': tensor([0.4168]), 'bias': tensor([0.4190])})\n",
            "Epoch: 12380 | MAE Train Loss: 0.0568990483880043 | MAE Test Loss: 0.1330411434173584 \n",
            "OrderedDict({'weights': tensor([0.4169]), 'bias': tensor([0.4189])})\n",
            "Epoch: 12390 | MAE Train Loss: 0.05686467885971069 | MAE Test Loss: 0.13295845687389374 \n",
            "OrderedDict({'weights': tensor([0.4171]), 'bias': tensor([0.4188])})\n",
            "Epoch: 12400 | MAE Train Loss: 0.0568302758038044 | MAE Test Loss: 0.13287577033042908 \n",
            "OrderedDict({'weights': tensor([0.4173]), 'bias': tensor([0.4187])})\n",
            "Epoch: 12410 | MAE Train Loss: 0.05679596588015556 | MAE Test Loss: 0.13279995322227478 \n",
            "OrderedDict({'weights': tensor([0.4174]), 'bias': tensor([0.4187])})\n",
            "Epoch: 12420 | MAE Train Loss: 0.056761592626571655 | MAE Test Loss: 0.1327172815799713 \n",
            "OrderedDict({'weights': tensor([0.4176]), 'bias': tensor([0.4186])})\n",
            "Epoch: 12430 | MAE Train Loss: 0.05672718957066536 | MAE Test Loss: 0.13264146447181702 \n",
            "OrderedDict({'weights': tensor([0.4178]), 'bias': tensor([0.4185])})\n",
            "Epoch: 12440 | MAE Train Loss: 0.05669288709759712 | MAE Test Loss: 0.13255874812602997 \n",
            "OrderedDict({'weights': tensor([0.4180]), 'bias': tensor([0.4185])})\n",
            "Epoch: 12450 | MAE Train Loss: 0.05665850639343262 | MAE Test Loss: 0.1324760913848877 \n",
            "OrderedDict({'weights': tensor([0.4181]), 'bias': tensor([0.4184])})\n",
            "Epoch: 12460 | MAE Train Loss: 0.0566241629421711 | MAE Test Loss: 0.1323968470096588 \n",
            "OrderedDict({'weights': tensor([0.4183]), 'bias': tensor([0.4183])})\n",
            "Epoch: 12470 | MAE Train Loss: 0.0565897636115551 | MAE Test Loss: 0.13231416046619415 \n",
            "OrderedDict({'weights': tensor([0.4185]), 'bias': tensor([0.4182])})\n",
            "Epoch: 12480 | MAE Train Loss: 0.056555427610874176 | MAE Test Loss: 0.13223831355571747 \n",
            "OrderedDict({'weights': tensor([0.4186]), 'bias': tensor([0.4182])})\n",
            "Epoch: 12490 | MAE Train Loss: 0.05652106925845146 | MAE Test Loss: 0.1321556568145752 \n",
            "OrderedDict({'weights': tensor([0.4188]), 'bias': tensor([0.4181])})\n",
            "Epoch: 12500 | MAE Train Loss: 0.05648667365312576 | MAE Test Loss: 0.13207297027111053 \n",
            "OrderedDict({'weights': tensor([0.4190]), 'bias': tensor([0.4180])})\n",
            "Epoch: 12510 | MAE Train Loss: 0.05645233392715454 | MAE Test Loss: 0.13199715316295624 \n",
            "OrderedDict({'weights': tensor([0.4192]), 'bias': tensor([0.4180])})\n",
            "Epoch: 12520 | MAE Train Loss: 0.056418001651763916 | MAE Test Loss: 0.13191446661949158 \n",
            "OrderedDict({'weights': tensor([0.4193]), 'bias': tensor([0.4179])})\n",
            "Epoch: 12530 | MAE Train Loss: 0.056383587419986725 | MAE Test Loss: 0.13183176517486572 \n",
            "OrderedDict({'weights': tensor([0.4195]), 'bias': tensor([0.4178])})\n",
            "Epoch: 12540 | MAE Train Loss: 0.056349266320466995 | MAE Test Loss: 0.1317559778690338 \n",
            "OrderedDict({'weights': tensor([0.4197]), 'bias': tensor([0.4177])})\n",
            "Epoch: 12550 | MAE Train Loss: 0.056314874440431595 | MAE Test Loss: 0.13167670369148254 \n",
            "OrderedDict({'weights': tensor([0.4198]), 'bias': tensor([0.4177])})\n",
            "Epoch: 12560 | MAE Train Loss: 0.05628050118684769 | MAE Test Loss: 0.1315905749797821 \n",
            "OrderedDict({'weights': tensor([0.4200]), 'bias': tensor([0.4176])})\n",
            "Epoch: 12570 | MAE Train Loss: 0.056246183812618256 | MAE Test Loss: 0.1315147578716278 \n",
            "OrderedDict({'weights': tensor([0.4202]), 'bias': tensor([0.4175])})\n",
            "Epoch: 12580 | MAE Train Loss: 0.05621182173490524 | MAE Test Loss: 0.13143208622932434 \n",
            "OrderedDict({'weights': tensor([0.4204]), 'bias': tensor([0.4175])})\n",
            "Epoch: 12590 | MAE Train Loss: 0.05617741495370865 | MAE Test Loss: 0.13134941458702087 \n",
            "OrderedDict({'weights': tensor([0.4205]), 'bias': tensor([0.4174])})\n",
            "Epoch: 12600 | MAE Train Loss: 0.05614307522773743 | MAE Test Loss: 0.1312701404094696 \n",
            "OrderedDict({'weights': tensor([0.4207]), 'bias': tensor([0.4173])})\n",
            "Epoch: 12610 | MAE Train Loss: 0.05610870569944382 | MAE Test Loss: 0.1311943233013153 \n",
            "OrderedDict({'weights': tensor([0.4209]), 'bias': tensor([0.4172])})\n",
            "Epoch: 12620 | MAE Train Loss: 0.056074392050504684 | MAE Test Loss: 0.13111165165901184 \n",
            "OrderedDict({'weights': tensor([0.4210]), 'bias': tensor([0.4172])})\n",
            "Epoch: 12630 | MAE Train Loss: 0.05603998899459839 | MAE Test Loss: 0.13102896511554718 \n",
            "OrderedDict({'weights': tensor([0.4212]), 'bias': tensor([0.4171])})\n",
            "Epoch: 12640 | MAE Train Loss: 0.05600563436746597 | MAE Test Loss: 0.1309531182050705 \n",
            "OrderedDict({'weights': tensor([0.4214]), 'bias': tensor([0.4170])})\n",
            "Epoch: 12650 | MAE Train Loss: 0.05597130209207535 | MAE Test Loss: 0.13087046146392822 \n",
            "OrderedDict({'weights': tensor([0.4216]), 'bias': tensor([0.4169])})\n",
            "Epoch: 12660 | MAE Train Loss: 0.05593690276145935 | MAE Test Loss: 0.13078776001930237 \n",
            "OrderedDict({'weights': tensor([0.4217]), 'bias': tensor([0.4169])})\n",
            "Epoch: 12670 | MAE Train Loss: 0.05590255931019783 | MAE Test Loss: 0.13071194291114807 \n",
            "OrderedDict({'weights': tensor([0.4219]), 'bias': tensor([0.4168])})\n",
            "Epoch: 12680 | MAE Train Loss: 0.05586821958422661 | MAE Test Loss: 0.1306292712688446 \n",
            "OrderedDict({'weights': tensor([0.4221]), 'bias': tensor([0.4167])})\n",
            "Epoch: 12690 | MAE Train Loss: 0.05583386495709419 | MAE Test Loss: 0.13055002689361572 \n",
            "OrderedDict({'weights': tensor([0.4222]), 'bias': tensor([0.4167])})\n",
            "Epoch: 12700 | MAE Train Loss: 0.05579947307705879 | MAE Test Loss: 0.13046734035015106 \n",
            "OrderedDict({'weights': tensor([0.4224]), 'bias': tensor([0.4166])})\n",
            "Epoch: 12710 | MAE Train Loss: 0.05576508492231369 | MAE Test Loss: 0.13039152324199677 \n",
            "OrderedDict({'weights': tensor([0.4226]), 'bias': tensor([0.4165])})\n",
            "Epoch: 12720 | MAE Train Loss: 0.055730778723955154 | MAE Test Loss: 0.1303088217973709 \n",
            "OrderedDict({'weights': tensor([0.4227]), 'bias': tensor([0.4164])})\n",
            "Epoch: 12730 | MAE Train Loss: 0.05569639056921005 | MAE Test Loss: 0.13022613525390625 \n",
            "OrderedDict({'weights': tensor([0.4229]), 'bias': tensor([0.4164])})\n",
            "Epoch: 12740 | MAE Train Loss: 0.055662013590335846 | MAE Test Loss: 0.13015031814575195 \n",
            "OrderedDict({'weights': tensor([0.4231]), 'bias': tensor([0.4163])})\n",
            "Epoch: 12750 | MAE Train Loss: 0.055627692490816116 | MAE Test Loss: 0.1300676316022873 \n",
            "OrderedDict({'weights': tensor([0.4233]), 'bias': tensor([0.4162])})\n",
            "Epoch: 12760 | MAE Train Loss: 0.055593304336071014 | MAE Test Loss: 0.12998494505882263 \n",
            "OrderedDict({'weights': tensor([0.4234]), 'bias': tensor([0.4162])})\n",
            "Epoch: 12770 | MAE Train Loss: 0.05555892735719681 | MAE Test Loss: 0.12990912795066833 \n",
            "OrderedDict({'weights': tensor([0.4236]), 'bias': tensor([0.4161])})\n",
            "Epoch: 12780 | MAE Train Loss: 0.0555245578289032 | MAE Test Loss: 0.12982302904129028 \n",
            "OrderedDict({'weights': tensor([0.4238]), 'bias': tensor([0.4160])})\n",
            "Epoch: 12790 | MAE Train Loss: 0.05549023300409317 | MAE Test Loss: 0.129747211933136 \n",
            "OrderedDict({'weights': tensor([0.4239]), 'bias': tensor([0.4159])})\n",
            "Epoch: 12800 | MAE Train Loss: 0.055455852299928665 | MAE Test Loss: 0.1296679675579071 \n",
            "OrderedDict({'weights': tensor([0.4241]), 'bias': tensor([0.4159])})\n",
            "Epoch: 12810 | MAE Train Loss: 0.05542153865098953 | MAE Test Loss: 0.12958528101444244 \n",
            "OrderedDict({'weights': tensor([0.4243]), 'bias': tensor([0.4158])})\n",
            "Epoch: 12820 | MAE Train Loss: 0.05538713186979294 | MAE Test Loss: 0.1295025795698166 \n",
            "OrderedDict({'weights': tensor([0.4245]), 'bias': tensor([0.4157])})\n",
            "Epoch: 12830 | MAE Train Loss: 0.05535276606678963 | MAE Test Loss: 0.12942679226398468 \n",
            "OrderedDict({'weights': tensor([0.4246]), 'bias': tensor([0.4157])})\n",
            "Epoch: 12840 | MAE Train Loss: 0.05531838536262512 | MAE Test Loss: 0.12934067845344543 \n",
            "OrderedDict({'weights': tensor([0.4248]), 'bias': tensor([0.4156])})\n",
            "Epoch: 12850 | MAE Train Loss: 0.05528407171368599 | MAE Test Loss: 0.12926483154296875 \n",
            "OrderedDict({'weights': tensor([0.4250]), 'bias': tensor([0.4155])})\n",
            "Epoch: 12860 | MAE Train Loss: 0.05524970218539238 | MAE Test Loss: 0.1291821449995041 \n",
            "OrderedDict({'weights': tensor([0.4251]), 'bias': tensor([0.4154])})\n",
            "Epoch: 12870 | MAE Train Loss: 0.055215299129486084 | MAE Test Loss: 0.12909945845603943 \n",
            "OrderedDict({'weights': tensor([0.4253]), 'bias': tensor([0.4154])})\n",
            "Epoch: 12880 | MAE Train Loss: 0.05518098920583725 | MAE Test Loss: 0.12902364134788513 \n",
            "OrderedDict({'weights': tensor([0.4255]), 'bias': tensor([0.4153])})\n",
            "Epoch: 12890 | MAE Train Loss: 0.05514661595225334 | MAE Test Loss: 0.12894096970558167 \n",
            "OrderedDict({'weights': tensor([0.4257]), 'bias': tensor([0.4152])})\n",
            "Epoch: 12900 | MAE Train Loss: 0.055112212896347046 | MAE Test Loss: 0.12886515259742737 \n",
            "OrderedDict({'weights': tensor([0.4258]), 'bias': tensor([0.4151])})\n",
            "Epoch: 12910 | MAE Train Loss: 0.05507791042327881 | MAE Test Loss: 0.12878243625164032 \n",
            "OrderedDict({'weights': tensor([0.4260]), 'bias': tensor([0.4151])})\n",
            "Epoch: 12920 | MAE Train Loss: 0.055043529719114304 | MAE Test Loss: 0.12869977951049805 \n",
            "OrderedDict({'weights': tensor([0.4262]), 'bias': tensor([0.4150])})\n",
            "Epoch: 12930 | MAE Train Loss: 0.05500918626785278 | MAE Test Loss: 0.12862053513526917 \n",
            "OrderedDict({'weights': tensor([0.4263]), 'bias': tensor([0.4149])})\n",
            "Epoch: 12940 | MAE Train Loss: 0.054974786937236786 | MAE Test Loss: 0.1285378485918045 \n",
            "OrderedDict({'weights': tensor([0.4265]), 'bias': tensor([0.4149])})\n",
            "Epoch: 12950 | MAE Train Loss: 0.05494045093655586 | MAE Test Loss: 0.12846200168132782 \n",
            "OrderedDict({'weights': tensor([0.4267]), 'bias': tensor([0.4148])})\n",
            "Epoch: 12960 | MAE Train Loss: 0.05490609258413315 | MAE Test Loss: 0.12837934494018555 \n",
            "OrderedDict({'weights': tensor([0.4269]), 'bias': tensor([0.4147])})\n",
            "Epoch: 12970 | MAE Train Loss: 0.05487169697880745 | MAE Test Loss: 0.1282966583967209 \n",
            "OrderedDict({'weights': tensor([0.4270]), 'bias': tensor([0.4147])})\n",
            "Epoch: 12980 | MAE Train Loss: 0.05483735725283623 | MAE Test Loss: 0.1282208412885666 \n",
            "OrderedDict({'weights': tensor([0.4272]), 'bias': tensor([0.4146])})\n",
            "Epoch: 12990 | MAE Train Loss: 0.0548030249774456 | MAE Test Loss: 0.12813815474510193 \n",
            "OrderedDict({'weights': tensor([0.4274]), 'bias': tensor([0.4145])})\n",
            "Epoch: 13000 | MAE Train Loss: 0.05476861074566841 | MAE Test Loss: 0.12805545330047607 \n",
            "OrderedDict({'weights': tensor([0.4275]), 'bias': tensor([0.4144])})\n",
            "Epoch: 13010 | MAE Train Loss: 0.05473428964614868 | MAE Test Loss: 0.12797966599464417 \n",
            "OrderedDict({'weights': tensor([0.4277]), 'bias': tensor([0.4144])})\n",
            "Epoch: 13020 | MAE Train Loss: 0.05469989776611328 | MAE Test Loss: 0.1279003918170929 \n",
            "OrderedDict({'weights': tensor([0.4279]), 'bias': tensor([0.4143])})\n",
            "Epoch: 13030 | MAE Train Loss: 0.05466552451252937 | MAE Test Loss: 0.12781426310539246 \n",
            "OrderedDict({'weights': tensor([0.4281]), 'bias': tensor([0.4142])})\n",
            "Epoch: 13040 | MAE Train Loss: 0.05463121086359024 | MAE Test Loss: 0.12773844599723816 \n",
            "OrderedDict({'weights': tensor([0.4282]), 'bias': tensor([0.4141])})\n",
            "Epoch: 13050 | MAE Train Loss: 0.05459684878587723 | MAE Test Loss: 0.1276557743549347 \n",
            "OrderedDict({'weights': tensor([0.4284]), 'bias': tensor([0.4141])})\n",
            "Epoch: 13060 | MAE Train Loss: 0.054562438279390335 | MAE Test Loss: 0.12757310271263123 \n",
            "OrderedDict({'weights': tensor([0.4286]), 'bias': tensor([0.4140])})\n",
            "Epoch: 13070 | MAE Train Loss: 0.05452809855341911 | MAE Test Loss: 0.12749382853507996 \n",
            "OrderedDict({'weights': tensor([0.4287]), 'bias': tensor([0.4139])})\n",
            "Epoch: 13080 | MAE Train Loss: 0.0544937327504158 | MAE Test Loss: 0.12741801142692566 \n",
            "OrderedDict({'weights': tensor([0.4289]), 'bias': tensor([0.4139])})\n",
            "Epoch: 13090 | MAE Train Loss: 0.05445941537618637 | MAE Test Loss: 0.1273353397846222 \n",
            "OrderedDict({'weights': tensor([0.4291]), 'bias': tensor([0.4138])})\n",
            "Epoch: 13100 | MAE Train Loss: 0.054425012320280075 | MAE Test Loss: 0.12725265324115753 \n",
            "OrderedDict({'weights': tensor([0.4292]), 'bias': tensor([0.4137])})\n",
            "Epoch: 13110 | MAE Train Loss: 0.05439066141843796 | MAE Test Loss: 0.12717683613300323 \n",
            "OrderedDict({'weights': tensor([0.4294]), 'bias': tensor([0.4136])})\n",
            "Epoch: 13120 | MAE Train Loss: 0.054356325417757034 | MAE Test Loss: 0.12709414958953857 \n",
            "OrderedDict({'weights': tensor([0.4296]), 'bias': tensor([0.4136])})\n",
            "Epoch: 13130 | MAE Train Loss: 0.05432192608714104 | MAE Test Loss: 0.12701144814491272 \n",
            "OrderedDict({'weights': tensor([0.4298]), 'bias': tensor([0.4135])})\n",
            "Epoch: 13140 | MAE Train Loss: 0.05428758263587952 | MAE Test Loss: 0.12693564593791962 \n",
            "OrderedDict({'weights': tensor([0.4299]), 'bias': tensor([0.4134])})\n",
            "Epoch: 13150 | MAE Train Loss: 0.05425325036048889 | MAE Test Loss: 0.12685295939445496 \n",
            "OrderedDict({'weights': tensor([0.4301]), 'bias': tensor([0.4134])})\n",
            "Epoch: 13160 | MAE Train Loss: 0.05421888828277588 | MAE Test Loss: 0.12677371501922607 \n",
            "OrderedDict({'weights': tensor([0.4303]), 'bias': tensor([0.4133])})\n",
            "Epoch: 13170 | MAE Train Loss: 0.05418449640274048 | MAE Test Loss: 0.12669101357460022 \n",
            "OrderedDict({'weights': tensor([0.4304]), 'bias': tensor([0.4132])})\n",
            "Epoch: 13180 | MAE Train Loss: 0.054150111973285675 | MAE Test Loss: 0.12661519646644592 \n",
            "OrderedDict({'weights': tensor([0.4306]), 'bias': tensor([0.4131])})\n",
            "Epoch: 13190 | MAE Train Loss: 0.05411580204963684 | MAE Test Loss: 0.12653250992298126 \n",
            "OrderedDict({'weights': tensor([0.4308]), 'bias': tensor([0.4131])})\n",
            "Epoch: 13200 | MAE Train Loss: 0.05408141762018204 | MAE Test Loss: 0.1264498233795166 \n",
            "OrderedDict({'weights': tensor([0.4310]), 'bias': tensor([0.4130])})\n",
            "Epoch: 13210 | MAE Train Loss: 0.05404703691601753 | MAE Test Loss: 0.1263740062713623 \n",
            "OrderedDict({'weights': tensor([0.4311]), 'bias': tensor([0.4129])})\n",
            "Epoch: 13220 | MAE Train Loss: 0.0540127158164978 | MAE Test Loss: 0.12629131972789764 \n",
            "OrderedDict({'weights': tensor([0.4313]), 'bias': tensor([0.4129])})\n",
            "Epoch: 13230 | MAE Train Loss: 0.053978331387043 | MAE Test Loss: 0.12620863318443298 \n",
            "OrderedDict({'weights': tensor([0.4315]), 'bias': tensor([0.4128])})\n",
            "Epoch: 13240 | MAE Train Loss: 0.053943950682878494 | MAE Test Loss: 0.1261328160762787 \n",
            "OrderedDict({'weights': tensor([0.4316]), 'bias': tensor([0.4127])})\n",
            "Epoch: 13250 | MAE Train Loss: 0.053909581154584885 | MAE Test Loss: 0.12604671716690063 \n",
            "OrderedDict({'weights': tensor([0.4318]), 'bias': tensor([0.4126])})\n",
            "Epoch: 13260 | MAE Train Loss: 0.05387525632977486 | MAE Test Loss: 0.12597090005874634 \n",
            "OrderedDict({'weights': tensor([0.4320]), 'bias': tensor([0.4126])})\n",
            "Epoch: 13270 | MAE Train Loss: 0.05384087562561035 | MAE Test Loss: 0.12589165568351746 \n",
            "OrderedDict({'weights': tensor([0.4322]), 'bias': tensor([0.4125])})\n",
            "Epoch: 13280 | MAE Train Loss: 0.05380656197667122 | MAE Test Loss: 0.1258089691400528 \n",
            "OrderedDict({'weights': tensor([0.4323]), 'bias': tensor([0.4124])})\n",
            "Epoch: 13290 | MAE Train Loss: 0.05377215892076492 | MAE Test Loss: 0.12572626769542694 \n",
            "OrderedDict({'weights': tensor([0.4325]), 'bias': tensor([0.4124])})\n",
            "Epoch: 13300 | MAE Train Loss: 0.053737789392471313 | MAE Test Loss: 0.12565048038959503 \n",
            "OrderedDict({'weights': tensor([0.4327]), 'bias': tensor([0.4123])})\n",
            "Epoch: 13310 | MAE Train Loss: 0.05370340868830681 | MAE Test Loss: 0.1255643665790558 \n",
            "OrderedDict({'weights': tensor([0.4328]), 'bias': tensor([0.4122])})\n",
            "Epoch: 13320 | MAE Train Loss: 0.05366910248994827 | MAE Test Loss: 0.1254885196685791 \n",
            "OrderedDict({'weights': tensor([0.4330]), 'bias': tensor([0.4121])})\n",
            "Epoch: 13330 | MAE Train Loss: 0.053634725511074066 | MAE Test Loss: 0.12540583312511444 \n",
            "OrderedDict({'weights': tensor([0.4332]), 'bias': tensor([0.4121])})\n",
            "Epoch: 13340 | MAE Train Loss: 0.05360032245516777 | MAE Test Loss: 0.12532314658164978 \n",
            "OrderedDict({'weights': tensor([0.4333]), 'bias': tensor([0.4120])})\n",
            "Epoch: 13350 | MAE Train Loss: 0.053566016256809235 | MAE Test Loss: 0.12524732947349548 \n",
            "OrderedDict({'weights': tensor([0.4335]), 'bias': tensor([0.4119])})\n",
            "Epoch: 13360 | MAE Train Loss: 0.053531646728515625 | MAE Test Loss: 0.12516465783119202 \n",
            "OrderedDict({'weights': tensor([0.4337]), 'bias': tensor([0.4119])})\n",
            "Epoch: 13370 | MAE Train Loss: 0.05349723622202873 | MAE Test Loss: 0.12508884072303772 \n",
            "OrderedDict({'weights': tensor([0.4339]), 'bias': tensor([0.4118])})\n",
            "Epoch: 13380 | MAE Train Loss: 0.053462933748960495 | MAE Test Loss: 0.12500612437725067 \n",
            "OrderedDict({'weights': tensor([0.4340]), 'bias': tensor([0.4117])})\n",
            "Epoch: 13390 | MAE Train Loss: 0.05342855304479599 | MAE Test Loss: 0.1249234676361084 \n",
            "OrderedDict({'weights': tensor([0.4342]), 'bias': tensor([0.4116])})\n",
            "Epoch: 13400 | MAE Train Loss: 0.05339420959353447 | MAE Test Loss: 0.12484421581029892 \n",
            "OrderedDict({'weights': tensor([0.4344]), 'bias': tensor([0.4116])})\n",
            "Epoch: 13410 | MAE Train Loss: 0.05335981398820877 | MAE Test Loss: 0.12476153671741486 \n",
            "OrderedDict({'weights': tensor([0.4345]), 'bias': tensor([0.4115])})\n",
            "Epoch: 13420 | MAE Train Loss: 0.05332547426223755 | MAE Test Loss: 0.12468568980693817 \n",
            "OrderedDict({'weights': tensor([0.4347]), 'bias': tensor([0.4114])})\n",
            "Epoch: 13430 | MAE Train Loss: 0.05329111963510513 | MAE Test Loss: 0.1246030330657959 \n",
            "OrderedDict({'weights': tensor([0.4349]), 'bias': tensor([0.4113])})\n",
            "Epoch: 13440 | MAE Train Loss: 0.053256720304489136 | MAE Test Loss: 0.12452032417058945 \n",
            "OrderedDict({'weights': tensor([0.4351]), 'bias': tensor([0.4113])})\n",
            "Epoch: 13450 | MAE Train Loss: 0.053222380578517914 | MAE Test Loss: 0.12444452941417694 \n",
            "OrderedDict({'weights': tensor([0.4352]), 'bias': tensor([0.4112])})\n",
            "Epoch: 13460 | MAE Train Loss: 0.05318804830312729 | MAE Test Loss: 0.12436182796955109 \n",
            "OrderedDict({'weights': tensor([0.4354]), 'bias': tensor([0.4111])})\n",
            "Epoch: 13470 | MAE Train Loss: 0.0531536340713501 | MAE Test Loss: 0.12427914142608643 \n",
            "OrderedDict({'weights': tensor([0.4356]), 'bias': tensor([0.4111])})\n",
            "Epoch: 13480 | MAE Train Loss: 0.05311930924654007 | MAE Test Loss: 0.12420334666967392 \n",
            "OrderedDict({'weights': tensor([0.4357]), 'bias': tensor([0.4110])})\n",
            "Epoch: 13490 | MAE Train Loss: 0.05308492109179497 | MAE Test Loss: 0.12412407249212265 \n",
            "OrderedDict({'weights': tensor([0.4359]), 'bias': tensor([0.4109])})\n",
            "Epoch: 13500 | MAE Train Loss: 0.05305054783821106 | MAE Test Loss: 0.1240379586815834 \n",
            "OrderedDict({'weights': tensor([0.4361]), 'bias': tensor([0.4108])})\n",
            "Epoch: 13510 | MAE Train Loss: 0.05301623418927193 | MAE Test Loss: 0.12396214157342911 \n",
            "OrderedDict({'weights': tensor([0.4363]), 'bias': tensor([0.4108])})\n",
            "Epoch: 13520 | MAE Train Loss: 0.052981872111558914 | MAE Test Loss: 0.12387945502996445 \n",
            "OrderedDict({'weights': tensor([0.4364]), 'bias': tensor([0.4107])})\n",
            "Epoch: 13530 | MAE Train Loss: 0.05294746160507202 | MAE Test Loss: 0.12379679828882217 \n",
            "OrderedDict({'weights': tensor([0.4366]), 'bias': tensor([0.4106])})\n",
            "Epoch: 13540 | MAE Train Loss: 0.0529131218791008 | MAE Test Loss: 0.1237175241112709 \n",
            "OrderedDict({'weights': tensor([0.4368]), 'bias': tensor([0.4106])})\n",
            "Epoch: 13550 | MAE Train Loss: 0.05287875607609749 | MAE Test Loss: 0.12364170700311661 \n",
            "OrderedDict({'weights': tensor([0.4369]), 'bias': tensor([0.4105])})\n",
            "Epoch: 13560 | MAE Train Loss: 0.052844442427158356 | MAE Test Loss: 0.12355902045965195 \n",
            "OrderedDict({'weights': tensor([0.4371]), 'bias': tensor([0.4104])})\n",
            "Epoch: 13570 | MAE Train Loss: 0.05281003564596176 | MAE Test Loss: 0.12347634136676788 \n",
            "OrderedDict({'weights': tensor([0.4373]), 'bias': tensor([0.4103])})\n",
            "Epoch: 13580 | MAE Train Loss: 0.05277568846940994 | MAE Test Loss: 0.12340052425861359 \n",
            "OrderedDict({'weights': tensor([0.4375]), 'bias': tensor([0.4103])})\n",
            "Epoch: 13590 | MAE Train Loss: 0.05274134874343872 | MAE Test Loss: 0.12331783771514893 \n",
            "OrderedDict({'weights': tensor([0.4376]), 'bias': tensor([0.4102])})\n",
            "Epoch: 13600 | MAE Train Loss: 0.05270694941282272 | MAE Test Loss: 0.12323512881994247 \n",
            "OrderedDict({'weights': tensor([0.4378]), 'bias': tensor([0.4101])})\n",
            "Epoch: 13610 | MAE Train Loss: 0.0526726059615612 | MAE Test Loss: 0.12315933406352997 \n",
            "OrderedDict({'weights': tensor([0.4380]), 'bias': tensor([0.4101])})\n",
            "Epoch: 13620 | MAE Train Loss: 0.05263827368617058 | MAE Test Loss: 0.1230766549706459 \n",
            "OrderedDict({'weights': tensor([0.4381]), 'bias': tensor([0.4100])})\n",
            "Epoch: 13630 | MAE Train Loss: 0.052603911608457565 | MAE Test Loss: 0.12299740314483643 \n",
            "OrderedDict({'weights': tensor([0.4383]), 'bias': tensor([0.4099])})\n",
            "Epoch: 13640 | MAE Train Loss: 0.052569519728422165 | MAE Test Loss: 0.12291469424962997 \n",
            "OrderedDict({'weights': tensor([0.4385]), 'bias': tensor([0.4098])})\n",
            "Epoch: 13650 | MAE Train Loss: 0.05253513529896736 | MAE Test Loss: 0.12283887714147568 \n",
            "OrderedDict({'weights': tensor([0.4386]), 'bias': tensor([0.4098])})\n",
            "Epoch: 13660 | MAE Train Loss: 0.05250082537531853 | MAE Test Loss: 0.12275619804859161 \n",
            "OrderedDict({'weights': tensor([0.4388]), 'bias': tensor([0.4097])})\n",
            "Epoch: 13670 | MAE Train Loss: 0.052466440945863724 | MAE Test Loss: 0.12267351150512695 \n",
            "OrderedDict({'weights': tensor([0.4390]), 'bias': tensor([0.4096])})\n",
            "Epoch: 13680 | MAE Train Loss: 0.05243206024169922 | MAE Test Loss: 0.12259769439697266 \n",
            "OrderedDict({'weights': tensor([0.4392]), 'bias': tensor([0.4095])})\n",
            "Epoch: 13690 | MAE Train Loss: 0.05239773914217949 | MAE Test Loss: 0.122515007853508 \n",
            "OrderedDict({'weights': tensor([0.4393]), 'bias': tensor([0.4095])})\n",
            "Epoch: 13700 | MAE Train Loss: 0.052363354712724686 | MAE Test Loss: 0.12243232876062393 \n",
            "OrderedDict({'weights': tensor([0.4395]), 'bias': tensor([0.4094])})\n",
            "Epoch: 13710 | MAE Train Loss: 0.05232897400856018 | MAE Test Loss: 0.12235651165246964 \n",
            "OrderedDict({'weights': tensor([0.4397]), 'bias': tensor([0.4093])})\n",
            "Epoch: 13720 | MAE Train Loss: 0.05229460448026657 | MAE Test Loss: 0.12227040529251099 \n",
            "OrderedDict({'weights': tensor([0.4398]), 'bias': tensor([0.4093])})\n",
            "Epoch: 13730 | MAE Train Loss: 0.05226027965545654 | MAE Test Loss: 0.12219458818435669 \n",
            "OrderedDict({'weights': tensor([0.4400]), 'bias': tensor([0.4092])})\n",
            "Epoch: 13740 | MAE Train Loss: 0.05222589895129204 | MAE Test Loss: 0.1221153512597084 \n",
            "OrderedDict({'weights': tensor([0.4402]), 'bias': tensor([0.4091])})\n",
            "Epoch: 13750 | MAE Train Loss: 0.052191585302352905 | MAE Test Loss: 0.12203265726566315 \n",
            "OrderedDict({'weights': tensor([0.4404]), 'bias': tensor([0.4090])})\n",
            "Epoch: 13760 | MAE Train Loss: 0.05215718224644661 | MAE Test Loss: 0.12194995582103729 \n",
            "OrderedDict({'weights': tensor([0.4405]), 'bias': tensor([0.4090])})\n",
            "Epoch: 13770 | MAE Train Loss: 0.0521228089928627 | MAE Test Loss: 0.12187416851520538 \n",
            "OrderedDict({'weights': tensor([0.4407]), 'bias': tensor([0.4089])})\n",
            "Epoch: 13780 | MAE Train Loss: 0.052088432013988495 | MAE Test Loss: 0.12178804725408554 \n",
            "OrderedDict({'weights': tensor([0.4409]), 'bias': tensor([0.4088])})\n",
            "Epoch: 13790 | MAE Train Loss: 0.05205412581562996 | MAE Test Loss: 0.12171220779418945 \n",
            "OrderedDict({'weights': tensor([0.4410]), 'bias': tensor([0.4088])})\n",
            "Epoch: 13800 | MAE Train Loss: 0.05201975256204605 | MAE Test Loss: 0.12162952125072479 \n",
            "OrderedDict({'weights': tensor([0.4412]), 'bias': tensor([0.4087])})\n",
            "Epoch: 13810 | MAE Train Loss: 0.05198534578084946 | MAE Test Loss: 0.12154684215784073 \n",
            "OrderedDict({'weights': tensor([0.4414]), 'bias': tensor([0.4086])})\n",
            "Epoch: 13820 | MAE Train Loss: 0.05195103958249092 | MAE Test Loss: 0.12147101014852524 \n",
            "OrderedDict({'weights': tensor([0.4416]), 'bias': tensor([0.4085])})\n",
            "Epoch: 13830 | MAE Train Loss: 0.05191667005419731 | MAE Test Loss: 0.12138833850622177 \n",
            "OrderedDict({'weights': tensor([0.4417]), 'bias': tensor([0.4085])})\n",
            "Epoch: 13840 | MAE Train Loss: 0.05188225954771042 | MAE Test Loss: 0.12131252139806747 \n",
            "OrderedDict({'weights': tensor([0.4419]), 'bias': tensor([0.4084])})\n",
            "Epoch: 13850 | MAE Train Loss: 0.05184795707464218 | MAE Test Loss: 0.12122981250286102 \n",
            "OrderedDict({'weights': tensor([0.4421]), 'bias': tensor([0.4083])})\n",
            "Epoch: 13860 | MAE Train Loss: 0.051813580095767975 | MAE Test Loss: 0.12114715576171875 \n",
            "OrderedDict({'weights': tensor([0.4422]), 'bias': tensor([0.4083])})\n",
            "Epoch: 13870 | MAE Train Loss: 0.051779232919216156 | MAE Test Loss: 0.12106790393590927 \n",
            "OrderedDict({'weights': tensor([0.4424]), 'bias': tensor([0.4082])})\n",
            "Epoch: 13880 | MAE Train Loss: 0.05174483731389046 | MAE Test Loss: 0.12098522484302521 \n",
            "OrderedDict({'weights': tensor([0.4426]), 'bias': tensor([0.4081])})\n",
            "Epoch: 13890 | MAE Train Loss: 0.051710497587919235 | MAE Test Loss: 0.12090937793254852 \n",
            "OrderedDict({'weights': tensor([0.4428]), 'bias': tensor([0.4080])})\n",
            "Epoch: 13900 | MAE Train Loss: 0.05167614296078682 | MAE Test Loss: 0.12082672119140625 \n",
            "OrderedDict({'weights': tensor([0.4429]), 'bias': tensor([0.4080])})\n",
            "Epoch: 13910 | MAE Train Loss: 0.05164174363017082 | MAE Test Loss: 0.1207440122961998 \n",
            "OrderedDict({'weights': tensor([0.4431]), 'bias': tensor([0.4079])})\n",
            "Epoch: 13920 | MAE Train Loss: 0.0516074113547802 | MAE Test Loss: 0.12066821753978729 \n",
            "OrderedDict({'weights': tensor([0.4433]), 'bias': tensor([0.4078])})\n",
            "Epoch: 13930 | MAE Train Loss: 0.051573075354099274 | MAE Test Loss: 0.12058551609516144 \n",
            "OrderedDict({'weights': tensor([0.4434]), 'bias': tensor([0.4078])})\n",
            "Epoch: 13940 | MAE Train Loss: 0.051538657397031784 | MAE Test Loss: 0.12050282955169678 \n",
            "OrderedDict({'weights': tensor([0.4436]), 'bias': tensor([0.4077])})\n",
            "Epoch: 13950 | MAE Train Loss: 0.051504332572221756 | MAE Test Loss: 0.12042703479528427 \n",
            "OrderedDict({'weights': tensor([0.4438]), 'bias': tensor([0.4076])})\n",
            "Epoch: 13960 | MAE Train Loss: 0.051469944417476654 | MAE Test Loss: 0.120347760617733 \n",
            "OrderedDict({'weights': tensor([0.4439]), 'bias': tensor([0.4075])})\n",
            "Epoch: 13970 | MAE Train Loss: 0.051435571163892746 | MAE Test Loss: 0.12026164680719376 \n",
            "OrderedDict({'weights': tensor([0.4441]), 'bias': tensor([0.4075])})\n",
            "Epoch: 13980 | MAE Train Loss: 0.05140125751495361 | MAE Test Loss: 0.12018582969903946 \n",
            "OrderedDict({'weights': tensor([0.4443]), 'bias': tensor([0.4074])})\n",
            "Epoch: 13990 | MAE Train Loss: 0.0513668954372406 | MAE Test Loss: 0.1201031431555748 \n",
            "OrderedDict({'weights': tensor([0.4445]), 'bias': tensor([0.4073])})\n",
            "Epoch: 14000 | MAE Train Loss: 0.05133248493075371 | MAE Test Loss: 0.12002048641443253 \n",
            "OrderedDict({'weights': tensor([0.4446]), 'bias': tensor([0.4073])})\n",
            "Epoch: 14010 | MAE Train Loss: 0.051298148930072784 | MAE Test Loss: 0.11994121223688126 \n",
            "OrderedDict({'weights': tensor([0.4448]), 'bias': tensor([0.4072])})\n",
            "Epoch: 14020 | MAE Train Loss: 0.051263779401779175 | MAE Test Loss: 0.11986539512872696 \n",
            "OrderedDict({'weights': tensor([0.4450]), 'bias': tensor([0.4071])})\n",
            "Epoch: 14030 | MAE Train Loss: 0.05122946575284004 | MAE Test Loss: 0.1197827085852623 \n",
            "OrderedDict({'weights': tensor([0.4451]), 'bias': tensor([0.4070])})\n",
            "Epoch: 14040 | MAE Train Loss: 0.051195062696933746 | MAE Test Loss: 0.11970002949237823 \n",
            "OrderedDict({'weights': tensor([0.4453]), 'bias': tensor([0.4070])})\n",
            "Epoch: 14050 | MAE Train Loss: 0.05116071179509163 | MAE Test Loss: 0.11962421238422394 \n",
            "OrderedDict({'weights': tensor([0.4455]), 'bias': tensor([0.4069])})\n",
            "Epoch: 14060 | MAE Train Loss: 0.05112637206912041 | MAE Test Loss: 0.11954152584075928 \n",
            "OrderedDict({'weights': tensor([0.4457]), 'bias': tensor([0.4068])})\n",
            "Epoch: 14070 | MAE Train Loss: 0.05109197646379471 | MAE Test Loss: 0.11945881694555283 \n",
            "OrderedDict({'weights': tensor([0.4458]), 'bias': tensor([0.4068])})\n",
            "Epoch: 14080 | MAE Train Loss: 0.05105762928724289 | MAE Test Loss: 0.11938302218914032 \n",
            "OrderedDict({'weights': tensor([0.4460]), 'bias': tensor([0.4067])})\n",
            "Epoch: 14090 | MAE Train Loss: 0.051023297011852264 | MAE Test Loss: 0.11930034309625626 \n",
            "OrderedDict({'weights': tensor([0.4462]), 'bias': tensor([0.4066])})\n",
            "Epoch: 14100 | MAE Train Loss: 0.05098893493413925 | MAE Test Loss: 0.11922109127044678 \n",
            "OrderedDict({'weights': tensor([0.4463]), 'bias': tensor([0.4065])})\n",
            "Epoch: 14110 | MAE Train Loss: 0.05095454305410385 | MAE Test Loss: 0.11913838237524033 \n",
            "OrderedDict({'weights': tensor([0.4465]), 'bias': tensor([0.4065])})\n",
            "Epoch: 14120 | MAE Train Loss: 0.05092015862464905 | MAE Test Loss: 0.11906256526708603 \n",
            "OrderedDict({'weights': tensor([0.4467]), 'bias': tensor([0.4064])})\n",
            "Epoch: 14130 | MAE Train Loss: 0.050885848701000214 | MAE Test Loss: 0.11897988617420197 \n",
            "OrderedDict({'weights': tensor([0.4469]), 'bias': tensor([0.4063])})\n",
            "Epoch: 14140 | MAE Train Loss: 0.05085146427154541 | MAE Test Loss: 0.1188971996307373 \n",
            "OrderedDict({'weights': tensor([0.4470]), 'bias': tensor([0.4063])})\n",
            "Epoch: 14150 | MAE Train Loss: 0.050817083567380905 | MAE Test Loss: 0.11882138252258301 \n",
            "OrderedDict({'weights': tensor([0.4472]), 'bias': tensor([0.4062])})\n",
            "Epoch: 14160 | MAE Train Loss: 0.050782762467861176 | MAE Test Loss: 0.11873869597911835 \n",
            "OrderedDict({'weights': tensor([0.4474]), 'bias': tensor([0.4061])})\n",
            "Epoch: 14170 | MAE Train Loss: 0.05074837803840637 | MAE Test Loss: 0.11865601688623428 \n",
            "OrderedDict({'weights': tensor([0.4475]), 'bias': tensor([0.4060])})\n",
            "Epoch: 14180 | MAE Train Loss: 0.05071399733424187 | MAE Test Loss: 0.11858019977807999 \n",
            "OrderedDict({'weights': tensor([0.4477]), 'bias': tensor([0.4060])})\n",
            "Epoch: 14190 | MAE Train Loss: 0.050679631531238556 | MAE Test Loss: 0.11849409341812134 \n",
            "OrderedDict({'weights': tensor([0.4479]), 'bias': tensor([0.4059])})\n",
            "Epoch: 14200 | MAE Train Loss: 0.05064530298113823 | MAE Test Loss: 0.11841827630996704 \n",
            "OrderedDict({'weights': tensor([0.4480]), 'bias': tensor([0.4058])})\n",
            "Epoch: 14210 | MAE Train Loss: 0.050610922276973724 | MAE Test Loss: 0.11833903938531876 \n",
            "OrderedDict({'weights': tensor([0.4482]), 'bias': tensor([0.4057])})\n",
            "Epoch: 14220 | MAE Train Loss: 0.05057660862803459 | MAE Test Loss: 0.1182563453912735 \n",
            "OrderedDict({'weights': tensor([0.4484]), 'bias': tensor([0.4057])})\n",
            "Epoch: 14230 | MAE Train Loss: 0.050542205572128296 | MAE Test Loss: 0.11817364394664764 \n",
            "OrderedDict({'weights': tensor([0.4486]), 'bias': tensor([0.4056])})\n",
            "Epoch: 14240 | MAE Train Loss: 0.05050783231854439 | MAE Test Loss: 0.11809785664081573 \n",
            "OrderedDict({'weights': tensor([0.4487]), 'bias': tensor([0.4055])})\n",
            "Epoch: 14250 | MAE Train Loss: 0.05047345906496048 | MAE Test Loss: 0.11801173537969589 \n",
            "OrderedDict({'weights': tensor([0.4489]), 'bias': tensor([0.4055])})\n",
            "Epoch: 14260 | MAE Train Loss: 0.050439149141311646 | MAE Test Loss: 0.1179358959197998 \n",
            "OrderedDict({'weights': tensor([0.4491]), 'bias': tensor([0.4054])})\n",
            "Epoch: 14270 | MAE Train Loss: 0.05040477588772774 | MAE Test Loss: 0.11785320937633514 \n",
            "OrderedDict({'weights': tensor([0.4492]), 'bias': tensor([0.4053])})\n",
            "Epoch: 14280 | MAE Train Loss: 0.05037037283182144 | MAE Test Loss: 0.11777053028345108 \n",
            "OrderedDict({'weights': tensor([0.4494]), 'bias': tensor([0.4052])})\n",
            "Epoch: 14290 | MAE Train Loss: 0.05033606290817261 | MAE Test Loss: 0.11769469827413559 \n",
            "OrderedDict({'weights': tensor([0.4496]), 'bias': tensor([0.4052])})\n",
            "Epoch: 14300 | MAE Train Loss: 0.050301693379879 | MAE Test Loss: 0.11761202663183212 \n",
            "OrderedDict({'weights': tensor([0.4498]), 'bias': tensor([0.4051])})\n",
            "Epoch: 14310 | MAE Train Loss: 0.050267286598682404 | MAE Test Loss: 0.11753620952367783 \n",
            "OrderedDict({'weights': tensor([0.4499]), 'bias': tensor([0.4050])})\n",
            "Epoch: 14320 | MAE Train Loss: 0.050232984125614166 | MAE Test Loss: 0.11745350062847137 \n",
            "OrderedDict({'weights': tensor([0.4501]), 'bias': tensor([0.4050])})\n",
            "Epoch: 14330 | MAE Train Loss: 0.05019860342144966 | MAE Test Loss: 0.1173708438873291 \n",
            "OrderedDict({'weights': tensor([0.4503]), 'bias': tensor([0.4049])})\n",
            "Epoch: 14340 | MAE Train Loss: 0.05016425997018814 | MAE Test Loss: 0.11729159206151962 \n",
            "OrderedDict({'weights': tensor([0.4504]), 'bias': tensor([0.4048])})\n",
            "Epoch: 14350 | MAE Train Loss: 0.050129860639572144 | MAE Test Loss: 0.11720891296863556 \n",
            "OrderedDict({'weights': tensor([0.4506]), 'bias': tensor([0.4047])})\n",
            "Epoch: 14360 | MAE Train Loss: 0.05009552091360092 | MAE Test Loss: 0.11713306605815887 \n",
            "OrderedDict({'weights': tensor([0.4508]), 'bias': tensor([0.4047])})\n",
            "Epoch: 14370 | MAE Train Loss: 0.050061166286468506 | MAE Test Loss: 0.1170504093170166 \n",
            "OrderedDict({'weights': tensor([0.4510]), 'bias': tensor([0.4046])})\n",
            "Epoch: 14380 | MAE Train Loss: 0.05002676695585251 | MAE Test Loss: 0.11696770042181015 \n",
            "OrderedDict({'weights': tensor([0.4511]), 'bias': tensor([0.4045])})\n",
            "Epoch: 14390 | MAE Train Loss: 0.049992434680461884 | MAE Test Loss: 0.11689190566539764 \n",
            "OrderedDict({'weights': tensor([0.4513]), 'bias': tensor([0.4045])})\n",
            "Epoch: 14400 | MAE Train Loss: 0.04995809867978096 | MAE Test Loss: 0.11680920422077179 \n",
            "OrderedDict({'weights': tensor([0.4515]), 'bias': tensor([0.4044])})\n",
            "Epoch: 14410 | MAE Train Loss: 0.04992368072271347 | MAE Test Loss: 0.11672651767730713 \n",
            "OrderedDict({'weights': tensor([0.4516]), 'bias': tensor([0.4043])})\n",
            "Epoch: 14420 | MAE Train Loss: 0.04988935589790344 | MAE Test Loss: 0.11665072292089462 \n",
            "OrderedDict({'weights': tensor([0.4518]), 'bias': tensor([0.4042])})\n",
            "Epoch: 14430 | MAE Train Loss: 0.04985497146844864 | MAE Test Loss: 0.11657144874334335 \n",
            "OrderedDict({'weights': tensor([0.4520]), 'bias': tensor([0.4042])})\n",
            "Epoch: 14440 | MAE Train Loss: 0.04982059821486473 | MAE Test Loss: 0.11648533493280411 \n",
            "OrderedDict({'weights': tensor([0.4522]), 'bias': tensor([0.4041])})\n",
            "Epoch: 14450 | MAE Train Loss: 0.049786277115345 | MAE Test Loss: 0.11640951782464981 \n",
            "OrderedDict({'weights': tensor([0.4523]), 'bias': tensor([0.4040])})\n",
            "Epoch: 14460 | MAE Train Loss: 0.04975191876292229 | MAE Test Loss: 0.11632683128118515 \n",
            "OrderedDict({'weights': tensor([0.4525]), 'bias': tensor([0.4040])})\n",
            "Epoch: 14470 | MAE Train Loss: 0.049717508256435394 | MAE Test Loss: 0.11624417454004288 \n",
            "OrderedDict({'weights': tensor([0.4527]), 'bias': tensor([0.4039])})\n",
            "Epoch: 14480 | MAE Train Loss: 0.04968317225575447 | MAE Test Loss: 0.11616490036249161 \n",
            "OrderedDict({'weights': tensor([0.4528]), 'bias': tensor([0.4038])})\n",
            "Epoch: 14490 | MAE Train Loss: 0.04964879900217056 | MAE Test Loss: 0.11608908325433731 \n",
            "OrderedDict({'weights': tensor([0.4530]), 'bias': tensor([0.4037])})\n",
            "Epoch: 14500 | MAE Train Loss: 0.04961448907852173 | MAE Test Loss: 0.11600639671087265 \n",
            "OrderedDict({'weights': tensor([0.4532]), 'bias': tensor([0.4037])})\n",
            "Epoch: 14510 | MAE Train Loss: 0.04958008602261543 | MAE Test Loss: 0.11592371761798859 \n",
            "OrderedDict({'weights': tensor([0.4534]), 'bias': tensor([0.4036])})\n",
            "Epoch: 14520 | MAE Train Loss: 0.04954573139548302 | MAE Test Loss: 0.11584790050983429 \n",
            "OrderedDict({'weights': tensor([0.4535]), 'bias': tensor([0.4035])})\n",
            "Epoch: 14530 | MAE Train Loss: 0.04951139912009239 | MAE Test Loss: 0.11576521396636963 \n",
            "OrderedDict({'weights': tensor([0.4537]), 'bias': tensor([0.4034])})\n",
            "Epoch: 14540 | MAE Train Loss: 0.049476999789476395 | MAE Test Loss: 0.11568250507116318 \n",
            "OrderedDict({'weights': tensor([0.4539]), 'bias': tensor([0.4034])})\n",
            "Epoch: 14550 | MAE Train Loss: 0.049442656338214874 | MAE Test Loss: 0.11560671031475067 \n",
            "OrderedDict({'weights': tensor([0.4540]), 'bias': tensor([0.4033])})\n",
            "Epoch: 14560 | MAE Train Loss: 0.04940832406282425 | MAE Test Loss: 0.11552403122186661 \n",
            "OrderedDict({'weights': tensor([0.4542]), 'bias': tensor([0.4032])})\n",
            "Epoch: 14570 | MAE Train Loss: 0.04937396198511124 | MAE Test Loss: 0.11544477939605713 \n",
            "OrderedDict({'weights': tensor([0.4544]), 'bias': tensor([0.4032])})\n",
            "Epoch: 14580 | MAE Train Loss: 0.049339570105075836 | MAE Test Loss: 0.11536207050085068 \n",
            "OrderedDict({'weights': tensor([0.4545]), 'bias': tensor([0.4031])})\n",
            "Epoch: 14590 | MAE Train Loss: 0.049305181950330734 | MAE Test Loss: 0.11528625339269638 \n",
            "OrderedDict({'weights': tensor([0.4547]), 'bias': tensor([0.4030])})\n",
            "Epoch: 14600 | MAE Train Loss: 0.0492708757519722 | MAE Test Loss: 0.11520357429981232 \n",
            "OrderedDict({'weights': tensor([0.4549]), 'bias': tensor([0.4029])})\n",
            "Epoch: 14610 | MAE Train Loss: 0.0492364875972271 | MAE Test Loss: 0.11512088775634766 \n",
            "OrderedDict({'weights': tensor([0.4551]), 'bias': tensor([0.4029])})\n",
            "Epoch: 14620 | MAE Train Loss: 0.04920210689306259 | MAE Test Loss: 0.11504507064819336 \n",
            "OrderedDict({'weights': tensor([0.4552]), 'bias': tensor([0.4028])})\n",
            "Epoch: 14630 | MAE Train Loss: 0.04916778951883316 | MAE Test Loss: 0.1149623841047287 \n",
            "OrderedDict({'weights': tensor([0.4554]), 'bias': tensor([0.4027])})\n",
            "Epoch: 14640 | MAE Train Loss: 0.04913339763879776 | MAE Test Loss: 0.11487970501184464 \n",
            "OrderedDict({'weights': tensor([0.4556]), 'bias': tensor([0.4027])})\n",
            "Epoch: 14650 | MAE Train Loss: 0.04909902438521385 | MAE Test Loss: 0.11480388790369034 \n",
            "OrderedDict({'weights': tensor([0.4557]), 'bias': tensor([0.4026])})\n",
            "Epoch: 14660 | MAE Train Loss: 0.04906465485692024 | MAE Test Loss: 0.11471778154373169 \n",
            "OrderedDict({'weights': tensor([0.4559]), 'bias': tensor([0.4025])})\n",
            "Epoch: 14670 | MAE Train Loss: 0.049030326306819916 | MAE Test Loss: 0.11464196443557739 \n",
            "OrderedDict({'weights': tensor([0.4561]), 'bias': tensor([0.4024])})\n",
            "Epoch: 14680 | MAE Train Loss: 0.04899594932794571 | MAE Test Loss: 0.11456272751092911 \n",
            "OrderedDict({'weights': tensor([0.4563]), 'bias': tensor([0.4024])})\n",
            "Epoch: 14690 | MAE Train Loss: 0.04896163195371628 | MAE Test Loss: 0.11448003351688385 \n",
            "OrderedDict({'weights': tensor([0.4564]), 'bias': tensor([0.4023])})\n",
            "Epoch: 14700 | MAE Train Loss: 0.04892722889780998 | MAE Test Loss: 0.114397332072258 \n",
            "OrderedDict({'weights': tensor([0.4566]), 'bias': tensor([0.4022])})\n",
            "Epoch: 14710 | MAE Train Loss: 0.048892855644226074 | MAE Test Loss: 0.11432154476642609 \n",
            "OrderedDict({'weights': tensor([0.4568]), 'bias': tensor([0.4022])})\n",
            "Epoch: 14720 | MAE Train Loss: 0.048858482390642166 | MAE Test Loss: 0.11423542350530624 \n",
            "OrderedDict({'weights': tensor([0.4569]), 'bias': tensor([0.4021])})\n",
            "Epoch: 14730 | MAE Train Loss: 0.04882417246699333 | MAE Test Loss: 0.11415958404541016 \n",
            "OrderedDict({'weights': tensor([0.4571]), 'bias': tensor([0.4020])})\n",
            "Epoch: 14740 | MAE Train Loss: 0.048789799213409424 | MAE Test Loss: 0.1140768975019455 \n",
            "OrderedDict({'weights': tensor([0.4573]), 'bias': tensor([0.4019])})\n",
            "Epoch: 14750 | MAE Train Loss: 0.04875539615750313 | MAE Test Loss: 0.11399421840906143 \n",
            "OrderedDict({'weights': tensor([0.4575]), 'bias': tensor([0.4019])})\n",
            "Epoch: 14760 | MAE Train Loss: 0.048721086233854294 | MAE Test Loss: 0.11391838639974594 \n",
            "OrderedDict({'weights': tensor([0.4576]), 'bias': tensor([0.4018])})\n",
            "Epoch: 14770 | MAE Train Loss: 0.04868672043085098 | MAE Test Loss: 0.11383571475744247 \n",
            "OrderedDict({'weights': tensor([0.4578]), 'bias': tensor([0.4017])})\n",
            "Epoch: 14780 | MAE Train Loss: 0.04865230992436409 | MAE Test Loss: 0.11375989764928818 \n",
            "OrderedDict({'weights': tensor([0.4580]), 'bias': tensor([0.4017])})\n",
            "Epoch: 14790 | MAE Train Loss: 0.04861801117658615 | MAE Test Loss: 0.11367718875408173 \n",
            "OrderedDict({'weights': tensor([0.4581]), 'bias': tensor([0.4016])})\n",
            "Epoch: 14800 | MAE Train Loss: 0.048583630472421646 | MAE Test Loss: 0.11359453201293945 \n",
            "OrderedDict({'weights': tensor([0.4583]), 'bias': tensor([0.4015])})\n",
            "Epoch: 14810 | MAE Train Loss: 0.04854928329586983 | MAE Test Loss: 0.11351528018712997 \n",
            "OrderedDict({'weights': tensor([0.4585]), 'bias': tensor([0.4014])})\n",
            "Epoch: 14820 | MAE Train Loss: 0.04851488023996353 | MAE Test Loss: 0.11343258619308472 \n",
            "OrderedDict({'weights': tensor([0.4587]), 'bias': tensor([0.4014])})\n",
            "Epoch: 14830 | MAE Train Loss: 0.048480547964572906 | MAE Test Loss: 0.11335675418376923 \n",
            "OrderedDict({'weights': tensor([0.4588]), 'bias': tensor([0.4013])})\n",
            "Epoch: 14840 | MAE Train Loss: 0.04844618961215019 | MAE Test Loss: 0.11327409744262695 \n",
            "OrderedDict({'weights': tensor([0.4590]), 'bias': tensor([0.4012])})\n",
            "Epoch: 14850 | MAE Train Loss: 0.04841179400682449 | MAE Test Loss: 0.1131913885474205 \n",
            "OrderedDict({'weights': tensor([0.4592]), 'bias': tensor([0.4012])})\n",
            "Epoch: 14860 | MAE Train Loss: 0.04837745800614357 | MAE Test Loss: 0.113115593791008 \n",
            "OrderedDict({'weights': tensor([0.4593]), 'bias': tensor([0.4011])})\n",
            "Epoch: 14870 | MAE Train Loss: 0.048343122005462646 | MAE Test Loss: 0.11303289234638214 \n",
            "OrderedDict({'weights': tensor([0.4595]), 'bias': tensor([0.4010])})\n",
            "Epoch: 14880 | MAE Train Loss: 0.048308707773685455 | MAE Test Loss: 0.11295020580291748 \n",
            "OrderedDict({'weights': tensor([0.4597]), 'bias': tensor([0.4009])})\n",
            "Epoch: 14890 | MAE Train Loss: 0.04827437922358513 | MAE Test Loss: 0.11287441104650497 \n",
            "OrderedDict({'weights': tensor([0.4598]), 'bias': tensor([0.4009])})\n",
            "Epoch: 14900 | MAE Train Loss: 0.048239998519420624 | MAE Test Loss: 0.1127951368689537 \n",
            "OrderedDict({'weights': tensor([0.4600]), 'bias': tensor([0.4008])})\n",
            "Epoch: 14910 | MAE Train Loss: 0.04820562154054642 | MAE Test Loss: 0.11270902305841446 \n",
            "OrderedDict({'weights': tensor([0.4602]), 'bias': tensor([0.4007])})\n",
            "Epoch: 14920 | MAE Train Loss: 0.048171304166316986 | MAE Test Loss: 0.11263320595026016 \n",
            "OrderedDict({'weights': tensor([0.4604]), 'bias': tensor([0.4006])})\n",
            "Epoch: 14930 | MAE Train Loss: 0.04813694208860397 | MAE Test Loss: 0.1125505194067955 \n",
            "OrderedDict({'weights': tensor([0.4605]), 'bias': tensor([0.4006])})\n",
            "Epoch: 14940 | MAE Train Loss: 0.04810253530740738 | MAE Test Loss: 0.11246786266565323 \n",
            "OrderedDict({'weights': tensor([0.4607]), 'bias': tensor([0.4005])})\n",
            "Epoch: 14950 | MAE Train Loss: 0.04806819558143616 | MAE Test Loss: 0.11238858848810196 \n",
            "OrderedDict({'weights': tensor([0.4609]), 'bias': tensor([0.4004])})\n",
            "Epoch: 14960 | MAE Train Loss: 0.04803382605314255 | MAE Test Loss: 0.11231277137994766 \n",
            "OrderedDict({'weights': tensor([0.4610]), 'bias': tensor([0.4004])})\n",
            "Epoch: 14970 | MAE Train Loss: 0.047999512404203415 | MAE Test Loss: 0.112230084836483 \n",
            "OrderedDict({'weights': tensor([0.4612]), 'bias': tensor([0.4003])})\n",
            "Epoch: 14980 | MAE Train Loss: 0.04796510934829712 | MAE Test Loss: 0.11214740574359894 \n",
            "OrderedDict({'weights': tensor([0.4614]), 'bias': tensor([0.4002])})\n",
            "Epoch: 14990 | MAE Train Loss: 0.0479307547211647 | MAE Test Loss: 0.11207157373428345 \n",
            "OrderedDict({'weights': tensor([0.4616]), 'bias': tensor([0.4001])})\n",
            "Epoch: 15000 | MAE Train Loss: 0.04789642244577408 | MAE Test Loss: 0.11198890209197998 \n",
            "OrderedDict({'weights': tensor([0.4617]), 'bias': tensor([0.4001])})\n",
            "Epoch: 15010 | MAE Train Loss: 0.04786202311515808 | MAE Test Loss: 0.11190620809793472 \n",
            "OrderedDict({'weights': tensor([0.4619]), 'bias': tensor([0.4000])})\n",
            "Epoch: 15020 | MAE Train Loss: 0.04782767966389656 | MAE Test Loss: 0.11183039098978043 \n",
            "OrderedDict({'weights': tensor([0.4621]), 'bias': tensor([0.3999])})\n",
            "Epoch: 15030 | MAE Train Loss: 0.04779333993792534 | MAE Test Loss: 0.11174771934747696 \n",
            "OrderedDict({'weights': tensor([0.4622]), 'bias': tensor([0.3999])})\n",
            "Epoch: 15040 | MAE Train Loss: 0.04775898531079292 | MAE Test Loss: 0.11166846752166748 \n",
            "OrderedDict({'weights': tensor([0.4624]), 'bias': tensor([0.3998])})\n",
            "Epoch: 15050 | MAE Train Loss: 0.04772459343075752 | MAE Test Loss: 0.11158575862646103 \n",
            "OrderedDict({'weights': tensor([0.4626]), 'bias': tensor([0.3997])})\n",
            "Epoch: 15060 | MAE Train Loss: 0.04769020527601242 | MAE Test Loss: 0.11150995641946793 \n",
            "OrderedDict({'weights': tensor([0.4628]), 'bias': tensor([0.3996])})\n",
            "Epoch: 15070 | MAE Train Loss: 0.047655899077653885 | MAE Test Loss: 0.11142726242542267 \n",
            "OrderedDict({'weights': tensor([0.4629]), 'bias': tensor([0.3996])})\n",
            "Epoch: 15080 | MAE Train Loss: 0.04762151092290878 | MAE Test Loss: 0.11134457588195801 \n",
            "OrderedDict({'weights': tensor([0.4631]), 'bias': tensor([0.3995])})\n",
            "Epoch: 15090 | MAE Train Loss: 0.047587133944034576 | MAE Test Loss: 0.11126875877380371 \n",
            "OrderedDict({'weights': tensor([0.4633]), 'bias': tensor([0.3994])})\n",
            "Epoch: 15100 | MAE Train Loss: 0.04755281284451485 | MAE Test Loss: 0.11118607223033905 \n",
            "OrderedDict({'weights': tensor([0.4634]), 'bias': tensor([0.3994])})\n",
            "Epoch: 15110 | MAE Train Loss: 0.047518424689769745 | MAE Test Loss: 0.11110339313745499 \n",
            "OrderedDict({'weights': tensor([0.4636]), 'bias': tensor([0.3993])})\n",
            "Epoch: 15120 | MAE Train Loss: 0.04748404771089554 | MAE Test Loss: 0.11102757602930069 \n",
            "OrderedDict({'weights': tensor([0.4638]), 'bias': tensor([0.3992])})\n",
            "Epoch: 15130 | MAE Train Loss: 0.04744967818260193 | MAE Test Loss: 0.11094146966934204 \n",
            "OrderedDict({'weights': tensor([0.4639]), 'bias': tensor([0.3991])})\n",
            "Epoch: 15140 | MAE Train Loss: 0.0474153533577919 | MAE Test Loss: 0.11086565256118774 \n",
            "OrderedDict({'weights': tensor([0.4641]), 'bias': tensor([0.3991])})\n",
            "Epoch: 15150 | MAE Train Loss: 0.047380972653627396 | MAE Test Loss: 0.11078640073537827 \n",
            "OrderedDict({'weights': tensor([0.4643]), 'bias': tensor([0.3990])})\n",
            "Epoch: 15160 | MAE Train Loss: 0.047346655279397964 | MAE Test Loss: 0.11070370674133301 \n",
            "OrderedDict({'weights': tensor([0.4645]), 'bias': tensor([0.3989])})\n",
            "Epoch: 15170 | MAE Train Loss: 0.04731225222349167 | MAE Test Loss: 0.11062102019786835 \n",
            "OrderedDict({'weights': tensor([0.4646]), 'bias': tensor([0.3989])})\n",
            "Epoch: 15180 | MAE Train Loss: 0.04727787896990776 | MAE Test Loss: 0.11054523289203644 \n",
            "OrderedDict({'weights': tensor([0.4648]), 'bias': tensor([0.3988])})\n",
            "Epoch: 15190 | MAE Train Loss: 0.04724350571632385 | MAE Test Loss: 0.1104591116309166 \n",
            "OrderedDict({'weights': tensor([0.4650]), 'bias': tensor([0.3987])})\n",
            "Epoch: 15200 | MAE Train Loss: 0.04720919579267502 | MAE Test Loss: 0.11038327217102051 \n",
            "OrderedDict({'weights': tensor([0.4651]), 'bias': tensor([0.3986])})\n",
            "Epoch: 15210 | MAE Train Loss: 0.04717482253909111 | MAE Test Loss: 0.11030058562755585 \n",
            "OrderedDict({'weights': tensor([0.4653]), 'bias': tensor([0.3986])})\n",
            "Epoch: 15220 | MAE Train Loss: 0.047140419483184814 | MAE Test Loss: 0.11021790653467178 \n",
            "OrderedDict({'weights': tensor([0.4655]), 'bias': tensor([0.3985])})\n",
            "Epoch: 15230 | MAE Train Loss: 0.04710610955953598 | MAE Test Loss: 0.11014208942651749 \n",
            "OrderedDict({'weights': tensor([0.4657]), 'bias': tensor([0.3984])})\n",
            "Epoch: 15240 | MAE Train Loss: 0.04707174375653267 | MAE Test Loss: 0.11005940288305283 \n",
            "OrderedDict({'weights': tensor([0.4658]), 'bias': tensor([0.3984])})\n",
            "Epoch: 15250 | MAE Train Loss: 0.047037333250045776 | MAE Test Loss: 0.10998358577489853 \n",
            "OrderedDict({'weights': tensor([0.4660]), 'bias': tensor([0.3983])})\n",
            "Epoch: 15260 | MAE Train Loss: 0.04700303450226784 | MAE Test Loss: 0.10990089178085327 \n",
            "OrderedDict({'weights': tensor([0.4662]), 'bias': tensor([0.3982])})\n",
            "Epoch: 15270 | MAE Train Loss: 0.04696865379810333 | MAE Test Loss: 0.1098182201385498 \n",
            "OrderedDict({'weights': tensor([0.4663]), 'bias': tensor([0.3981])})\n",
            "Epoch: 15280 | MAE Train Loss: 0.046934306621551514 | MAE Test Loss: 0.10973896831274033 \n",
            "OrderedDict({'weights': tensor([0.4665]), 'bias': tensor([0.3981])})\n",
            "Epoch: 15290 | MAE Train Loss: 0.046899907290935516 | MAE Test Loss: 0.10965628921985626 \n",
            "OrderedDict({'weights': tensor([0.4667]), 'bias': tensor([0.3980])})\n",
            "Epoch: 15300 | MAE Train Loss: 0.046865563839673996 | MAE Test Loss: 0.10958044230937958 \n",
            "OrderedDict({'weights': tensor([0.4669]), 'bias': tensor([0.3979])})\n",
            "Epoch: 15310 | MAE Train Loss: 0.04683121293783188 | MAE Test Loss: 0.1094977855682373 \n",
            "OrderedDict({'weights': tensor([0.4670]), 'bias': tensor([0.3978])})\n",
            "Epoch: 15320 | MAE Train Loss: 0.04679681733250618 | MAE Test Loss: 0.10941509157419205 \n",
            "OrderedDict({'weights': tensor([0.4672]), 'bias': tensor([0.3978])})\n",
            "Epoch: 15330 | MAE Train Loss: 0.04676248878240585 | MAE Test Loss: 0.10933927446603775 \n",
            "OrderedDict({'weights': tensor([0.4674]), 'bias': tensor([0.3977])})\n",
            "Epoch: 15340 | MAE Train Loss: 0.04672814533114433 | MAE Test Loss: 0.10925658047199249 \n",
            "OrderedDict({'weights': tensor([0.4675]), 'bias': tensor([0.3976])})\n",
            "Epoch: 15350 | MAE Train Loss: 0.04669373109936714 | MAE Test Loss: 0.10917389392852783 \n",
            "OrderedDict({'weights': tensor([0.4677]), 'bias': tensor([0.3976])})\n",
            "Epoch: 15360 | MAE Train Loss: 0.046659402549266815 | MAE Test Loss: 0.10909809917211533 \n",
            "OrderedDict({'weights': tensor([0.4679]), 'bias': tensor([0.3975])})\n",
            "Epoch: 15370 | MAE Train Loss: 0.04662502184510231 | MAE Test Loss: 0.10901882499456406 \n",
            "OrderedDict({'weights': tensor([0.4681]), 'bias': tensor([0.3974])})\n",
            "Epoch: 15380 | MAE Train Loss: 0.0465906485915184 | MAE Test Loss: 0.10893271118402481 \n",
            "OrderedDict({'weights': tensor([0.4682]), 'bias': tensor([0.3973])})\n",
            "Epoch: 15390 | MAE Train Loss: 0.04655632749199867 | MAE Test Loss: 0.10885689407587051 \n",
            "OrderedDict({'weights': tensor([0.4684]), 'bias': tensor([0.3973])})\n",
            "Epoch: 15400 | MAE Train Loss: 0.04652196913957596 | MAE Test Loss: 0.10877420753240585 \n",
            "OrderedDict({'weights': tensor([0.4686]), 'bias': tensor([0.3972])})\n",
            "Epoch: 15410 | MAE Train Loss: 0.046487558633089066 | MAE Test Loss: 0.10869153589010239 \n",
            "OrderedDict({'weights': tensor([0.4687]), 'bias': tensor([0.3971])})\n",
            "Epoch: 15420 | MAE Train Loss: 0.046453218907117844 | MAE Test Loss: 0.10861227661371231 \n",
            "OrderedDict({'weights': tensor([0.4689]), 'bias': tensor([0.3971])})\n",
            "Epoch: 15430 | MAE Train Loss: 0.046418849378824234 | MAE Test Loss: 0.10853645950555801 \n",
            "OrderedDict({'weights': tensor([0.4691]), 'bias': tensor([0.3970])})\n",
            "Epoch: 15440 | MAE Train Loss: 0.0463845357298851 | MAE Test Loss: 0.10845377296209335 \n",
            "OrderedDict({'weights': tensor([0.4692]), 'bias': tensor([0.3969])})\n",
            "Epoch: 15450 | MAE Train Loss: 0.046350132673978806 | MAE Test Loss: 0.10837109386920929 \n",
            "OrderedDict({'weights': tensor([0.4694]), 'bias': tensor([0.3968])})\n",
            "Epoch: 15460 | MAE Train Loss: 0.04631578177213669 | MAE Test Loss: 0.1082952618598938 \n",
            "OrderedDict({'weights': tensor([0.4696]), 'bias': tensor([0.3968])})\n",
            "Epoch: 15470 | MAE Train Loss: 0.04628144949674606 | MAE Test Loss: 0.10821259021759033 \n",
            "OrderedDict({'weights': tensor([0.4698]), 'bias': tensor([0.3967])})\n",
            "Epoch: 15480 | MAE Train Loss: 0.04624704644083977 | MAE Test Loss: 0.10812989622354507 \n",
            "OrderedDict({'weights': tensor([0.4699]), 'bias': tensor([0.3966])})\n",
            "Epoch: 15490 | MAE Train Loss: 0.04621270298957825 | MAE Test Loss: 0.10805407911539078 \n",
            "OrderedDict({'weights': tensor([0.4701]), 'bias': tensor([0.3966])})\n",
            "Epoch: 15500 | MAE Train Loss: 0.046178363263607025 | MAE Test Loss: 0.10797140747308731 \n",
            "OrderedDict({'weights': tensor([0.4703]), 'bias': tensor([0.3965])})\n",
            "Epoch: 15510 | MAE Train Loss: 0.04614400863647461 | MAE Test Loss: 0.10789215564727783 \n",
            "OrderedDict({'weights': tensor([0.4704]), 'bias': tensor([0.3964])})\n",
            "Epoch: 15520 | MAE Train Loss: 0.04610961675643921 | MAE Test Loss: 0.10780944675207138 \n",
            "OrderedDict({'weights': tensor([0.4706]), 'bias': tensor([0.3963])})\n",
            "Epoch: 15530 | MAE Train Loss: 0.046075232326984406 | MAE Test Loss: 0.10773364454507828 \n",
            "OrderedDict({'weights': tensor([0.4708]), 'bias': tensor([0.3963])})\n",
            "Epoch: 15540 | MAE Train Loss: 0.04604092240333557 | MAE Test Loss: 0.10765095055103302 \n",
            "OrderedDict({'weights': tensor([0.4710]), 'bias': tensor([0.3962])})\n",
            "Epoch: 15550 | MAE Train Loss: 0.04600653052330017 | MAE Test Loss: 0.10756826400756836 \n",
            "OrderedDict({'weights': tensor([0.4711]), 'bias': tensor([0.3961])})\n",
            "Epoch: 15560 | MAE Train Loss: 0.04597215726971626 | MAE Test Loss: 0.10749244689941406 \n",
            "OrderedDict({'weights': tensor([0.4713]), 'bias': tensor([0.3961])})\n",
            "Epoch: 15570 | MAE Train Loss: 0.04593783617019653 | MAE Test Loss: 0.1074097603559494 \n",
            "OrderedDict({'weights': tensor([0.4715]), 'bias': tensor([0.3960])})\n",
            "Epoch: 15580 | MAE Train Loss: 0.04590344801545143 | MAE Test Loss: 0.10732708126306534 \n",
            "OrderedDict({'weights': tensor([0.4716]), 'bias': tensor([0.3959])})\n",
            "Epoch: 15590 | MAE Train Loss: 0.04586907476186752 | MAE Test Loss: 0.10725126415491104 \n",
            "OrderedDict({'weights': tensor([0.4718]), 'bias': tensor([0.3958])})\n",
            "Epoch: 15600 | MAE Train Loss: 0.045834701508283615 | MAE Test Loss: 0.10716515779495239 \n",
            "OrderedDict({'weights': tensor([0.4720]), 'bias': tensor([0.3958])})\n",
            "Epoch: 15610 | MAE Train Loss: 0.04580037668347359 | MAE Test Loss: 0.1070893406867981 \n",
            "OrderedDict({'weights': tensor([0.4722]), 'bias': tensor([0.3957])})\n",
            "Epoch: 15620 | MAE Train Loss: 0.04576599597930908 | MAE Test Loss: 0.10701008886098862 \n",
            "OrderedDict({'weights': tensor([0.4723]), 'bias': tensor([0.3956])})\n",
            "Epoch: 15630 | MAE Train Loss: 0.04573167860507965 | MAE Test Loss: 0.10692739486694336 \n",
            "OrderedDict({'weights': tensor([0.4725]), 'bias': tensor([0.3956])})\n",
            "Epoch: 15640 | MAE Train Loss: 0.045697279274463654 | MAE Test Loss: 0.1068447083234787 \n",
            "OrderedDict({'weights': tensor([0.4727]), 'bias': tensor([0.3955])})\n",
            "Epoch: 15650 | MAE Train Loss: 0.04566290229558945 | MAE Test Loss: 0.10676892101764679 \n",
            "OrderedDict({'weights': tensor([0.4728]), 'bias': tensor([0.3954])})\n",
            "Epoch: 15660 | MAE Train Loss: 0.04562852904200554 | MAE Test Loss: 0.10668279975652695 \n",
            "OrderedDict({'weights': tensor([0.4730]), 'bias': tensor([0.3953])})\n",
            "Epoch: 15670 | MAE Train Loss: 0.045594222843647 | MAE Test Loss: 0.10660696029663086 \n",
            "OrderedDict({'weights': tensor([0.4732]), 'bias': tensor([0.3953])})\n",
            "Epoch: 15680 | MAE Train Loss: 0.0455598458647728 | MAE Test Loss: 0.1065242737531662 \n",
            "OrderedDict({'weights': tensor([0.4734]), 'bias': tensor([0.3952])})\n",
            "Epoch: 15690 | MAE Train Loss: 0.0455254428088665 | MAE Test Loss: 0.10644159466028214 \n",
            "OrderedDict({'weights': tensor([0.4735]), 'bias': tensor([0.3951])})\n",
            "Epoch: 15700 | MAE Train Loss: 0.045491136610507965 | MAE Test Loss: 0.10636577755212784 \n",
            "OrderedDict({'weights': tensor([0.4737]), 'bias': tensor([0.3950])})\n",
            "Epoch: 15710 | MAE Train Loss: 0.045456767082214355 | MAE Test Loss: 0.10628309100866318 \n",
            "OrderedDict({'weights': tensor([0.4739]), 'bias': tensor([0.3950])})\n",
            "Epoch: 15720 | MAE Train Loss: 0.04542236402630806 | MAE Test Loss: 0.10620727390050888 \n",
            "OrderedDict({'weights': tensor([0.4740]), 'bias': tensor([0.3949])})\n",
            "Epoch: 15730 | MAE Train Loss: 0.045388057827949524 | MAE Test Loss: 0.10612457990646362 \n",
            "OrderedDict({'weights': tensor([0.4742]), 'bias': tensor([0.3948])})\n",
            "Epoch: 15740 | MAE Train Loss: 0.04535367712378502 | MAE Test Loss: 0.10604190826416016 \n",
            "OrderedDict({'weights': tensor([0.4744]), 'bias': tensor([0.3948])})\n",
            "Epoch: 15750 | MAE Train Loss: 0.0453193299472332 | MAE Test Loss: 0.10596265643835068 \n",
            "OrderedDict({'weights': tensor([0.4745]), 'bias': tensor([0.3947])})\n",
            "Epoch: 15760 | MAE Train Loss: 0.0452849306166172 | MAE Test Loss: 0.10587997734546661 \n",
            "OrderedDict({'weights': tensor([0.4747]), 'bias': tensor([0.3946])})\n",
            "Epoch: 15770 | MAE Train Loss: 0.04525058716535568 | MAE Test Loss: 0.10580413043498993 \n",
            "OrderedDict({'weights': tensor([0.4749]), 'bias': tensor([0.3945])})\n",
            "Epoch: 15780 | MAE Train Loss: 0.045216239988803864 | MAE Test Loss: 0.10572147369384766 \n",
            "OrderedDict({'weights': tensor([0.4751]), 'bias': tensor([0.3945])})\n",
            "Epoch: 15790 | MAE Train Loss: 0.045181840658187866 | MAE Test Loss: 0.1056387796998024 \n",
            "OrderedDict({'weights': tensor([0.4752]), 'bias': tensor([0.3944])})\n",
            "Epoch: 15800 | MAE Train Loss: 0.04514751210808754 | MAE Test Loss: 0.1055629625916481 \n",
            "OrderedDict({'weights': tensor([0.4754]), 'bias': tensor([0.3943])})\n",
            "Epoch: 15810 | MAE Train Loss: 0.04511316865682602 | MAE Test Loss: 0.10548026859760284 \n",
            "OrderedDict({'weights': tensor([0.4756]), 'bias': tensor([0.3943])})\n",
            "Epoch: 15820 | MAE Train Loss: 0.04507875442504883 | MAE Test Loss: 0.10539758205413818 \n",
            "OrderedDict({'weights': tensor([0.4757]), 'bias': tensor([0.3942])})\n",
            "Epoch: 15830 | MAE Train Loss: 0.0450444296002388 | MAE Test Loss: 0.10532178729772568 \n",
            "OrderedDict({'weights': tensor([0.4759]), 'bias': tensor([0.3941])})\n",
            "Epoch: 15840 | MAE Train Loss: 0.045010045170784 | MAE Test Loss: 0.10524251312017441 \n",
            "OrderedDict({'weights': tensor([0.4761]), 'bias': tensor([0.3940])})\n",
            "Epoch: 15850 | MAE Train Loss: 0.04497567191720009 | MAE Test Loss: 0.10515639930963516 \n",
            "OrderedDict({'weights': tensor([0.4763]), 'bias': tensor([0.3940])})\n",
            "Epoch: 15860 | MAE Train Loss: 0.04494135081768036 | MAE Test Loss: 0.10508058220148087 \n",
            "OrderedDict({'weights': tensor([0.4764]), 'bias': tensor([0.3939])})\n",
            "Epoch: 15870 | MAE Train Loss: 0.044906992465257645 | MAE Test Loss: 0.1049978956580162 \n",
            "OrderedDict({'weights': tensor([0.4766]), 'bias': tensor([0.3938])})\n",
            "Epoch: 15880 | MAE Train Loss: 0.04487258195877075 | MAE Test Loss: 0.10491522401571274 \n",
            "OrderedDict({'weights': tensor([0.4768]), 'bias': tensor([0.3938])})\n",
            "Epoch: 15890 | MAE Train Loss: 0.04483824223279953 | MAE Test Loss: 0.10483596473932266 \n",
            "OrderedDict({'weights': tensor([0.4769]), 'bias': tensor([0.3937])})\n",
            "Epoch: 15900 | MAE Train Loss: 0.04480387270450592 | MAE Test Loss: 0.10476014763116837 \n",
            "OrderedDict({'weights': tensor([0.4771]), 'bias': tensor([0.3936])})\n",
            "Epoch: 15910 | MAE Train Loss: 0.044769562780857086 | MAE Test Loss: 0.1046774610877037 \n",
            "OrderedDict({'weights': tensor([0.4773]), 'bias': tensor([0.3935])})\n",
            "Epoch: 15920 | MAE Train Loss: 0.04473515599966049 | MAE Test Loss: 0.10459478199481964 \n",
            "OrderedDict({'weights': tensor([0.4775]), 'bias': tensor([0.3935])})\n",
            "Epoch: 15930 | MAE Train Loss: 0.044700805097818375 | MAE Test Loss: 0.10451894998550415 \n",
            "OrderedDict({'weights': tensor([0.4776]), 'bias': tensor([0.3934])})\n",
            "Epoch: 15940 | MAE Train Loss: 0.04466647282242775 | MAE Test Loss: 0.10443627834320068 \n",
            "OrderedDict({'weights': tensor([0.4778]), 'bias': tensor([0.3933])})\n",
            "Epoch: 15950 | MAE Train Loss: 0.044632069766521454 | MAE Test Loss: 0.10435358434915543 \n",
            "OrderedDict({'weights': tensor([0.4780]), 'bias': tensor([0.3933])})\n",
            "Epoch: 15960 | MAE Train Loss: 0.044597726315259933 | MAE Test Loss: 0.10427776724100113 \n",
            "OrderedDict({'weights': tensor([0.4781]), 'bias': tensor([0.3932])})\n",
            "Epoch: 15970 | MAE Train Loss: 0.04456339031457901 | MAE Test Loss: 0.10419509559869766 \n",
            "OrderedDict({'weights': tensor([0.4783]), 'bias': tensor([0.3931])})\n",
            "Epoch: 15980 | MAE Train Loss: 0.044529031962156296 | MAE Test Loss: 0.10411584377288818 \n",
            "OrderedDict({'weights': tensor([0.4785]), 'bias': tensor([0.3930])})\n",
            "Epoch: 15990 | MAE Train Loss: 0.044494640082120895 | MAE Test Loss: 0.10403313487768173 \n",
            "OrderedDict({'weights': tensor([0.4787]), 'bias': tensor([0.3930])})\n",
            "Epoch: 16000 | MAE Train Loss: 0.04446025565266609 | MAE Test Loss: 0.10395733267068863 \n",
            "OrderedDict({'weights': tensor([0.4788]), 'bias': tensor([0.3929])})\n",
            "Epoch: 16010 | MAE Train Loss: 0.04442594572901726 | MAE Test Loss: 0.10387463867664337 \n",
            "OrderedDict({'weights': tensor([0.4790]), 'bias': tensor([0.3928])})\n",
            "Epoch: 16020 | MAE Train Loss: 0.04439155384898186 | MAE Test Loss: 0.10379195213317871 \n",
            "OrderedDict({'weights': tensor([0.4792]), 'bias': tensor([0.3928])})\n",
            "Epoch: 16030 | MAE Train Loss: 0.04435718059539795 | MAE Test Loss: 0.10371613502502441 \n",
            "OrderedDict({'weights': tensor([0.4793]), 'bias': tensor([0.3927])})\n",
            "Epoch: 16040 | MAE Train Loss: 0.04432285949587822 | MAE Test Loss: 0.10363344848155975 \n",
            "OrderedDict({'weights': tensor([0.4795]), 'bias': tensor([0.3926])})\n",
            "Epoch: 16050 | MAE Train Loss: 0.04428847134113312 | MAE Test Loss: 0.10355076938867569 \n",
            "OrderedDict({'weights': tensor([0.4797]), 'bias': tensor([0.3925])})\n",
            "Epoch: 16060 | MAE Train Loss: 0.04425409808754921 | MAE Test Loss: 0.10347495228052139 \n",
            "OrderedDict({'weights': tensor([0.4798]), 'bias': tensor([0.3925])})\n",
            "Epoch: 16070 | MAE Train Loss: 0.0442197248339653 | MAE Test Loss: 0.10338884592056274 \n",
            "OrderedDict({'weights': tensor([0.4800]), 'bias': tensor([0.3924])})\n",
            "Epoch: 16080 | MAE Train Loss: 0.04418540000915527 | MAE Test Loss: 0.10331302881240845 \n",
            "OrderedDict({'weights': tensor([0.4802]), 'bias': tensor([0.3923])})\n",
            "Epoch: 16090 | MAE Train Loss: 0.04415101930499077 | MAE Test Loss: 0.10323377698659897 \n",
            "OrderedDict({'weights': tensor([0.4804]), 'bias': tensor([0.3922])})\n",
            "Epoch: 16100 | MAE Train Loss: 0.04411670193076134 | MAE Test Loss: 0.10315108299255371 \n",
            "OrderedDict({'weights': tensor([0.4805]), 'bias': tensor([0.3922])})\n",
            "Epoch: 16110 | MAE Train Loss: 0.04408230260014534 | MAE Test Loss: 0.10306839644908905 \n",
            "OrderedDict({'weights': tensor([0.4807]), 'bias': tensor([0.3921])})\n",
            "Epoch: 16120 | MAE Train Loss: 0.04404792934656143 | MAE Test Loss: 0.10299260914325714 \n",
            "OrderedDict({'weights': tensor([0.4809]), 'bias': tensor([0.3920])})\n",
            "Epoch: 16130 | MAE Train Loss: 0.044013552367687225 | MAE Test Loss: 0.1029064878821373 \n",
            "OrderedDict({'weights': tensor([0.4810]), 'bias': tensor([0.3920])})\n",
            "Epoch: 16140 | MAE Train Loss: 0.04397924616932869 | MAE Test Loss: 0.10283064842224121 \n",
            "OrderedDict({'weights': tensor([0.4812]), 'bias': tensor([0.3919])})\n",
            "Epoch: 16150 | MAE Train Loss: 0.04394487291574478 | MAE Test Loss: 0.10274796187877655 \n",
            "OrderedDict({'weights': tensor([0.4814]), 'bias': tensor([0.3918])})\n",
            "Epoch: 16160 | MAE Train Loss: 0.04391046613454819 | MAE Test Loss: 0.10266528278589249 \n",
            "OrderedDict({'weights': tensor([0.4816]), 'bias': tensor([0.3917])})\n",
            "Epoch: 16170 | MAE Train Loss: 0.04387615993618965 | MAE Test Loss: 0.10258946567773819 \n",
            "OrderedDict({'weights': tensor([0.4817]), 'bias': tensor([0.3917])})\n",
            "Epoch: 16180 | MAE Train Loss: 0.04384179040789604 | MAE Test Loss: 0.10250677913427353 \n",
            "OrderedDict({'weights': tensor([0.4819]), 'bias': tensor([0.3916])})\n",
            "Epoch: 16190 | MAE Train Loss: 0.043807387351989746 | MAE Test Loss: 0.10243096202611923 \n",
            "OrderedDict({'weights': tensor([0.4821]), 'bias': tensor([0.3915])})\n",
            "Epoch: 16200 | MAE Train Loss: 0.04377308115363121 | MAE Test Loss: 0.10234826803207397 \n",
            "OrderedDict({'weights': tensor([0.4822]), 'bias': tensor([0.3915])})\n",
            "Epoch: 16210 | MAE Train Loss: 0.043738700449466705 | MAE Test Loss: 0.10226559638977051 \n",
            "OrderedDict({'weights': tensor([0.4824]), 'bias': tensor([0.3914])})\n",
            "Epoch: 16220 | MAE Train Loss: 0.043704353272914886 | MAE Test Loss: 0.10218634456396103 \n",
            "OrderedDict({'weights': tensor([0.4826]), 'bias': tensor([0.3913])})\n",
            "Epoch: 16230 | MAE Train Loss: 0.04366995394229889 | MAE Test Loss: 0.10210366547107697 \n",
            "OrderedDict({'weights': tensor([0.4828]), 'bias': tensor([0.3912])})\n",
            "Epoch: 16240 | MAE Train Loss: 0.04363561421632767 | MAE Test Loss: 0.10202781856060028 \n",
            "OrderedDict({'weights': tensor([0.4829]), 'bias': tensor([0.3912])})\n",
            "Epoch: 16250 | MAE Train Loss: 0.04360126331448555 | MAE Test Loss: 0.10194516181945801 \n",
            "OrderedDict({'weights': tensor([0.4831]), 'bias': tensor([0.3911])})\n",
            "Epoch: 16260 | MAE Train Loss: 0.04356686398386955 | MAE Test Loss: 0.10186246782541275 \n",
            "OrderedDict({'weights': tensor([0.4833]), 'bias': tensor([0.3910])})\n",
            "Epoch: 16270 | MAE Train Loss: 0.043532535433769226 | MAE Test Loss: 0.10178665071725845 \n",
            "OrderedDict({'weights': tensor([0.4834]), 'bias': tensor([0.3910])})\n",
            "Epoch: 16280 | MAE Train Loss: 0.043498195707798004 | MAE Test Loss: 0.1017039567232132 \n",
            "OrderedDict({'weights': tensor([0.4836]), 'bias': tensor([0.3909])})\n",
            "Epoch: 16290 | MAE Train Loss: 0.043463777750730515 | MAE Test Loss: 0.10162127017974854 \n",
            "OrderedDict({'weights': tensor([0.4838]), 'bias': tensor([0.3908])})\n",
            "Epoch: 16300 | MAE Train Loss: 0.043429452925920486 | MAE Test Loss: 0.10154547542333603 \n",
            "OrderedDict({'weights': tensor([0.4839]), 'bias': tensor([0.3907])})\n",
            "Epoch: 16310 | MAE Train Loss: 0.04339506849646568 | MAE Test Loss: 0.10146620124578476 \n",
            "OrderedDict({'weights': tensor([0.4841]), 'bias': tensor([0.3907])})\n",
            "Epoch: 16320 | MAE Train Loss: 0.043360695242881775 | MAE Test Loss: 0.10138008743524551 \n",
            "OrderedDict({'weights': tensor([0.4843]), 'bias': tensor([0.3906])})\n",
            "Epoch: 16330 | MAE Train Loss: 0.043326374143362045 | MAE Test Loss: 0.10130427032709122 \n",
            "OrderedDict({'weights': tensor([0.4845]), 'bias': tensor([0.3905])})\n",
            "Epoch: 16340 | MAE Train Loss: 0.04329201579093933 | MAE Test Loss: 0.10122158378362656 \n",
            "OrderedDict({'weights': tensor([0.4846]), 'bias': tensor([0.3905])})\n",
            "Epoch: 16350 | MAE Train Loss: 0.04325760528445244 | MAE Test Loss: 0.10113891214132309 \n",
            "OrderedDict({'weights': tensor([0.4848]), 'bias': tensor([0.3904])})\n",
            "Epoch: 16360 | MAE Train Loss: 0.043223269283771515 | MAE Test Loss: 0.10105965286493301 \n",
            "OrderedDict({'weights': tensor([0.4850]), 'bias': tensor([0.3903])})\n",
            "Epoch: 16370 | MAE Train Loss: 0.04318889603018761 | MAE Test Loss: 0.10098383575677872 \n",
            "OrderedDict({'weights': tensor([0.4851]), 'bias': tensor([0.3902])})\n",
            "Epoch: 16380 | MAE Train Loss: 0.04315458610653877 | MAE Test Loss: 0.10090114921331406 \n",
            "OrderedDict({'weights': tensor([0.4853]), 'bias': tensor([0.3902])})\n",
            "Epoch: 16390 | MAE Train Loss: 0.04312018305063248 | MAE Test Loss: 0.10081847012042999 \n",
            "OrderedDict({'weights': tensor([0.4855]), 'bias': tensor([0.3901])})\n",
            "Epoch: 16400 | MAE Train Loss: 0.04308582842350006 | MAE Test Loss: 0.1007426381111145 \n",
            "OrderedDict({'weights': tensor([0.4857]), 'bias': tensor([0.3900])})\n",
            "Epoch: 16410 | MAE Train Loss: 0.043051499873399734 | MAE Test Loss: 0.10065996646881104 \n",
            "OrderedDict({'weights': tensor([0.4858]), 'bias': tensor([0.3900])})\n",
            "Epoch: 16420 | MAE Train Loss: 0.04301709681749344 | MAE Test Loss: 0.10057727247476578 \n",
            "OrderedDict({'weights': tensor([0.4860]), 'bias': tensor([0.3899])})\n",
            "Epoch: 16430 | MAE Train Loss: 0.04298274964094162 | MAE Test Loss: 0.10050145536661148 \n",
            "OrderedDict({'weights': tensor([0.4862]), 'bias': tensor([0.3898])})\n",
            "Epoch: 16440 | MAE Train Loss: 0.042948413640260696 | MAE Test Loss: 0.10041878372430801 \n",
            "OrderedDict({'weights': tensor([0.4863]), 'bias': tensor([0.3897])})\n",
            "Epoch: 16450 | MAE Train Loss: 0.04291405528783798 | MAE Test Loss: 0.10033953189849854 \n",
            "OrderedDict({'weights': tensor([0.4865]), 'bias': tensor([0.3897])})\n",
            "Epoch: 16460 | MAE Train Loss: 0.04287966340780258 | MAE Test Loss: 0.10025682300329208 \n",
            "OrderedDict({'weights': tensor([0.4867]), 'bias': tensor([0.3896])})\n",
            "Epoch: 16470 | MAE Train Loss: 0.04284527897834778 | MAE Test Loss: 0.10018102079629898 \n",
            "OrderedDict({'weights': tensor([0.4869]), 'bias': tensor([0.3895])})\n",
            "Epoch: 16480 | MAE Train Loss: 0.042810969054698944 | MAE Test Loss: 0.10009832680225372 \n",
            "OrderedDict({'weights': tensor([0.4870]), 'bias': tensor([0.3894])})\n",
            "Epoch: 16490 | MAE Train Loss: 0.042776577174663544 | MAE Test Loss: 0.10001564025878906 \n",
            "OrderedDict({'weights': tensor([0.4872]), 'bias': tensor([0.3894])})\n",
            "Epoch: 16500 | MAE Train Loss: 0.042742203921079636 | MAE Test Loss: 0.09993983060121536 \n",
            "OrderedDict({'weights': tensor([0.4874]), 'bias': tensor([0.3893])})\n",
            "Epoch: 16510 | MAE Train Loss: 0.042707882821559906 | MAE Test Loss: 0.0998571440577507 \n",
            "OrderedDict({'weights': tensor([0.4875]), 'bias': tensor([0.3892])})\n",
            "Epoch: 16520 | MAE Train Loss: 0.042673494666814804 | MAE Test Loss: 0.09977445751428604 \n",
            "OrderedDict({'weights': tensor([0.4877]), 'bias': tensor([0.3892])})\n",
            "Epoch: 16530 | MAE Train Loss: 0.042639121413230896 | MAE Test Loss: 0.09969864785671234 \n",
            "OrderedDict({'weights': tensor([0.4879]), 'bias': tensor([0.3891])})\n",
            "Epoch: 16540 | MAE Train Loss: 0.042604751884937286 | MAE Test Loss: 0.0996125340461731 \n",
            "OrderedDict({'weights': tensor([0.4881]), 'bias': tensor([0.3890])})\n",
            "Epoch: 16550 | MAE Train Loss: 0.04257042333483696 | MAE Test Loss: 0.0995367169380188 \n",
            "OrderedDict({'weights': tensor([0.4882]), 'bias': tensor([0.3889])})\n",
            "Epoch: 16560 | MAE Train Loss: 0.042536042630672455 | MAE Test Loss: 0.09945746511220932 \n",
            "OrderedDict({'weights': tensor([0.4884]), 'bias': tensor([0.3889])})\n",
            "Epoch: 16570 | MAE Train Loss: 0.042501725256443024 | MAE Test Loss: 0.09937477856874466 \n",
            "OrderedDict({'weights': tensor([0.4886]), 'bias': tensor([0.3888])})\n",
            "Epoch: 16580 | MAE Train Loss: 0.042467325925827026 | MAE Test Loss: 0.09929209202528 \n",
            "OrderedDict({'weights': tensor([0.4887]), 'bias': tensor([0.3887])})\n",
            "Epoch: 16590 | MAE Train Loss: 0.04243295267224312 | MAE Test Loss: 0.0992162898182869 \n",
            "OrderedDict({'weights': tensor([0.4889]), 'bias': tensor([0.3887])})\n",
            "Epoch: 16600 | MAE Train Loss: 0.04239857941865921 | MAE Test Loss: 0.09913016855716705 \n",
            "OrderedDict({'weights': tensor([0.4891]), 'bias': tensor([0.3886])})\n",
            "Epoch: 16610 | MAE Train Loss: 0.042364269495010376 | MAE Test Loss: 0.09905433654785156 \n",
            "OrderedDict({'weights': tensor([0.4892]), 'bias': tensor([0.3885])})\n",
            "Epoch: 16620 | MAE Train Loss: 0.04232989624142647 | MAE Test Loss: 0.0989716500043869 \n",
            "OrderedDict({'weights': tensor([0.4894]), 'bias': tensor([0.3884])})\n",
            "Epoch: 16630 | MAE Train Loss: 0.04229549318552017 | MAE Test Loss: 0.09888897091150284 \n",
            "OrderedDict({'weights': tensor([0.4896]), 'bias': tensor([0.3884])})\n",
            "Epoch: 16640 | MAE Train Loss: 0.04226118326187134 | MAE Test Loss: 0.09881314635276794 \n",
            "OrderedDict({'weights': tensor([0.4898]), 'bias': tensor([0.3883])})\n",
            "Epoch: 16650 | MAE Train Loss: 0.04222681373357773 | MAE Test Loss: 0.09873045980930328 \n",
            "OrderedDict({'weights': tensor([0.4899]), 'bias': tensor([0.3882])})\n",
            "Epoch: 16660 | MAE Train Loss: 0.04219241067767143 | MAE Test Loss: 0.09865464270114899 \n",
            "OrderedDict({'weights': tensor([0.4901]), 'bias': tensor([0.3882])})\n",
            "Epoch: 16670 | MAE Train Loss: 0.0421581044793129 | MAE Test Loss: 0.09857195615768433 \n",
            "OrderedDict({'weights': tensor([0.4903]), 'bias': tensor([0.3881])})\n",
            "Epoch: 16680 | MAE Train Loss: 0.04212372750043869 | MAE Test Loss: 0.09848928451538086 \n",
            "OrderedDict({'weights': tensor([0.4904]), 'bias': tensor([0.3880])})\n",
            "Epoch: 16690 | MAE Train Loss: 0.04208938032388687 | MAE Test Loss: 0.09841003268957138 \n",
            "OrderedDict({'weights': tensor([0.4906]), 'bias': tensor([0.3879])})\n",
            "Epoch: 16700 | MAE Train Loss: 0.042054977267980576 | MAE Test Loss: 0.09832734614610672 \n",
            "OrderedDict({'weights': tensor([0.4908]), 'bias': tensor([0.3879])})\n",
            "Epoch: 16710 | MAE Train Loss: 0.042020637542009354 | MAE Test Loss: 0.09825151413679123 \n",
            "OrderedDict({'weights': tensor([0.4910]), 'bias': tensor([0.3878])})\n",
            "Epoch: 16720 | MAE Train Loss: 0.041986286640167236 | MAE Test Loss: 0.09816885739564896 \n",
            "OrderedDict({'weights': tensor([0.4911]), 'bias': tensor([0.3877])})\n",
            "Epoch: 16730 | MAE Train Loss: 0.04195188730955124 | MAE Test Loss: 0.0980861559510231 \n",
            "OrderedDict({'weights': tensor([0.4913]), 'bias': tensor([0.3877])})\n",
            "Epoch: 16740 | MAE Train Loss: 0.04191755875945091 | MAE Test Loss: 0.0980103388428688 \n",
            "OrderedDict({'weights': tensor([0.4915]), 'bias': tensor([0.3876])})\n",
            "Epoch: 16750 | MAE Train Loss: 0.04188321903347969 | MAE Test Loss: 0.09792764484882355 \n",
            "OrderedDict({'weights': tensor([0.4916]), 'bias': tensor([0.3875])})\n",
            "Epoch: 16760 | MAE Train Loss: 0.0418488010764122 | MAE Test Loss: 0.09784496575593948 \n",
            "OrderedDict({'weights': tensor([0.4918]), 'bias': tensor([0.3874])})\n",
            "Epoch: 16770 | MAE Train Loss: 0.04181447625160217 | MAE Test Loss: 0.09776915609836578 \n",
            "OrderedDict({'weights': tensor([0.4920]), 'bias': tensor([0.3874])})\n",
            "Epoch: 16780 | MAE Train Loss: 0.04178009182214737 | MAE Test Loss: 0.09768989682197571 \n",
            "OrderedDict({'weights': tensor([0.4922]), 'bias': tensor([0.3873])})\n",
            "Epoch: 16790 | MAE Train Loss: 0.04174571856856346 | MAE Test Loss: 0.09760378301143646 \n",
            "OrderedDict({'weights': tensor([0.4923]), 'bias': tensor([0.3872])})\n",
            "Epoch: 16800 | MAE Train Loss: 0.04171139746904373 | MAE Test Loss: 0.09752795100212097 \n",
            "OrderedDict({'weights': tensor([0.4925]), 'bias': tensor([0.3871])})\n",
            "Epoch: 16810 | MAE Train Loss: 0.04167703911662102 | MAE Test Loss: 0.09744527190923691 \n",
            "OrderedDict({'weights': tensor([0.4927]), 'bias': tensor([0.3871])})\n",
            "Epoch: 16820 | MAE Train Loss: 0.041642628610134125 | MAE Test Loss: 0.09736260026693344 \n",
            "OrderedDict({'weights': tensor([0.4928]), 'bias': tensor([0.3870])})\n",
            "Epoch: 16830 | MAE Train Loss: 0.0416082926094532 | MAE Test Loss: 0.09728334844112396 \n",
            "OrderedDict({'weights': tensor([0.4930]), 'bias': tensor([0.3869])})\n",
            "Epoch: 16840 | MAE Train Loss: 0.04157391935586929 | MAE Test Loss: 0.09720752388238907 \n",
            "OrderedDict({'weights': tensor([0.4932]), 'bias': tensor([0.3869])})\n",
            "Epoch: 16850 | MAE Train Loss: 0.04153960943222046 | MAE Test Loss: 0.09712483733892441 \n",
            "OrderedDict({'weights': tensor([0.4934]), 'bias': tensor([0.3868])})\n",
            "Epoch: 16860 | MAE Train Loss: 0.04150520637631416 | MAE Test Loss: 0.09704215079545975 \n",
            "OrderedDict({'weights': tensor([0.4935]), 'bias': tensor([0.3867])})\n",
            "Epoch: 16870 | MAE Train Loss: 0.04147085174918175 | MAE Test Loss: 0.09696632623672485 \n",
            "OrderedDict({'weights': tensor([0.4937]), 'bias': tensor([0.3866])})\n",
            "Epoch: 16880 | MAE Train Loss: 0.04143652319908142 | MAE Test Loss: 0.09688365459442139 \n",
            "OrderedDict({'weights': tensor([0.4939]), 'bias': tensor([0.3866])})\n",
            "Epoch: 16890 | MAE Train Loss: 0.041402120143175125 | MAE Test Loss: 0.09680096060037613 \n",
            "OrderedDict({'weights': tensor([0.4940]), 'bias': tensor([0.3865])})\n",
            "Epoch: 16900 | MAE Train Loss: 0.041367776691913605 | MAE Test Loss: 0.09672514349222183 \n",
            "OrderedDict({'weights': tensor([0.4942]), 'bias': tensor([0.3864])})\n",
            "Epoch: 16910 | MAE Train Loss: 0.04133343696594238 | MAE Test Loss: 0.09664246439933777 \n",
            "OrderedDict({'weights': tensor([0.4944]), 'bias': tensor([0.3864])})\n",
            "Epoch: 16920 | MAE Train Loss: 0.04129908233880997 | MAE Test Loss: 0.09656321257352829 \n",
            "OrderedDict({'weights': tensor([0.4945]), 'bias': tensor([0.3863])})\n",
            "Epoch: 16930 | MAE Train Loss: 0.04126469045877457 | MAE Test Loss: 0.09648051857948303 \n",
            "OrderedDict({'weights': tensor([0.4947]), 'bias': tensor([0.3862])})\n",
            "Epoch: 16940 | MAE Train Loss: 0.041230302304029465 | MAE Test Loss: 0.09640470892190933 \n",
            "OrderedDict({'weights': tensor([0.4949]), 'bias': tensor([0.3861])})\n",
            "Epoch: 16950 | MAE Train Loss: 0.04119599610567093 | MAE Test Loss: 0.09632201492786407 \n",
            "OrderedDict({'weights': tensor([0.4951]), 'bias': tensor([0.3861])})\n",
            "Epoch: 16960 | MAE Train Loss: 0.04116160422563553 | MAE Test Loss: 0.09623933583498001 \n",
            "OrderedDict({'weights': tensor([0.4952]), 'bias': tensor([0.3860])})\n",
            "Epoch: 16970 | MAE Train Loss: 0.04112722724676132 | MAE Test Loss: 0.09616351872682571 \n",
            "OrderedDict({'weights': tensor([0.4954]), 'bias': tensor([0.3859])})\n",
            "Epoch: 16980 | MAE Train Loss: 0.04109290987253189 | MAE Test Loss: 0.09608083218336105 \n",
            "OrderedDict({'weights': tensor([0.4956]), 'bias': tensor([0.3859])})\n",
            "Epoch: 16990 | MAE Train Loss: 0.04105851799249649 | MAE Test Loss: 0.09599814563989639 \n",
            "OrderedDict({'weights': tensor([0.4957]), 'bias': tensor([0.3858])})\n",
            "Epoch: 17000 | MAE Train Loss: 0.04102414473891258 | MAE Test Loss: 0.09592233598232269 \n",
            "OrderedDict({'weights': tensor([0.4959]), 'bias': tensor([0.3857])})\n",
            "Epoch: 17010 | MAE Train Loss: 0.04098977521061897 | MAE Test Loss: 0.09583622217178345 \n",
            "OrderedDict({'weights': tensor([0.4961]), 'bias': tensor([0.3856])})\n",
            "Epoch: 17020 | MAE Train Loss: 0.040955446660518646 | MAE Test Loss: 0.09576040506362915 \n",
            "OrderedDict({'weights': tensor([0.4963]), 'bias': tensor([0.3856])})\n",
            "Epoch: 17030 | MAE Train Loss: 0.04092106968164444 | MAE Test Loss: 0.09568115323781967 \n",
            "OrderedDict({'weights': tensor([0.4964]), 'bias': tensor([0.3855])})\n",
            "Epoch: 17040 | MAE Train Loss: 0.04088675230741501 | MAE Test Loss: 0.09559846669435501 \n",
            "OrderedDict({'weights': tensor([0.4966]), 'bias': tensor([0.3854])})\n",
            "Epoch: 17050 | MAE Train Loss: 0.04085234925150871 | MAE Test Loss: 0.09551578015089035 \n",
            "OrderedDict({'weights': tensor([0.4968]), 'bias': tensor([0.3854])})\n",
            "Epoch: 17060 | MAE Train Loss: 0.040817975997924805 | MAE Test Loss: 0.09543997794389725 \n",
            "OrderedDict({'weights': tensor([0.4969]), 'bias': tensor([0.3853])})\n",
            "Epoch: 17070 | MAE Train Loss: 0.0407836027443409 | MAE Test Loss: 0.0953538566827774 \n",
            "OrderedDict({'weights': tensor([0.4971]), 'bias': tensor([0.3852])})\n",
            "Epoch: 17080 | MAE Train Loss: 0.04074929282069206 | MAE Test Loss: 0.09527802467346191 \n",
            "OrderedDict({'weights': tensor([0.4973]), 'bias': tensor([0.3851])})\n",
            "Epoch: 17090 | MAE Train Loss: 0.040714919567108154 | MAE Test Loss: 0.09519533812999725 \n",
            "OrderedDict({'weights': tensor([0.4975]), 'bias': tensor([0.3851])})\n",
            "Epoch: 17100 | MAE Train Loss: 0.04068051651120186 | MAE Test Loss: 0.09511265903711319 \n",
            "OrderedDict({'weights': tensor([0.4976]), 'bias': tensor([0.3850])})\n",
            "Epoch: 17110 | MAE Train Loss: 0.040646206587553024 | MAE Test Loss: 0.0950368344783783 \n",
            "OrderedDict({'weights': tensor([0.4978]), 'bias': tensor([0.3849])})\n",
            "Epoch: 17120 | MAE Train Loss: 0.04061184078454971 | MAE Test Loss: 0.09495414793491364 \n",
            "OrderedDict({'weights': tensor([0.4980]), 'bias': tensor([0.3849])})\n",
            "Epoch: 17130 | MAE Train Loss: 0.04057743400335312 | MAE Test Loss: 0.09487833082675934 \n",
            "OrderedDict({'weights': tensor([0.4981]), 'bias': tensor([0.3848])})\n",
            "Epoch: 17140 | MAE Train Loss: 0.04054313153028488 | MAE Test Loss: 0.09479564428329468 \n",
            "OrderedDict({'weights': tensor([0.4983]), 'bias': tensor([0.3847])})\n",
            "Epoch: 17150 | MAE Train Loss: 0.04050875082612038 | MAE Test Loss: 0.09471297264099121 \n",
            "OrderedDict({'weights': tensor([0.4985]), 'bias': tensor([0.3846])})\n",
            "Epoch: 17160 | MAE Train Loss: 0.04047440364956856 | MAE Test Loss: 0.09463372081518173 \n",
            "OrderedDict({'weights': tensor([0.4987]), 'bias': tensor([0.3846])})\n",
            "Epoch: 17170 | MAE Train Loss: 0.04044000059366226 | MAE Test Loss: 0.09455103427171707 \n",
            "OrderedDict({'weights': tensor([0.4988]), 'bias': tensor([0.3845])})\n",
            "Epoch: 17180 | MAE Train Loss: 0.04040566086769104 | MAE Test Loss: 0.09447520226240158 \n",
            "OrderedDict({'weights': tensor([0.4990]), 'bias': tensor([0.3844])})\n",
            "Epoch: 17190 | MAE Train Loss: 0.04037130996584892 | MAE Test Loss: 0.09439254552125931 \n",
            "OrderedDict({'weights': tensor([0.4992]), 'bias': tensor([0.3844])})\n",
            "Epoch: 17200 | MAE Train Loss: 0.040336914360523224 | MAE Test Loss: 0.09430984407663345 \n",
            "OrderedDict({'weights': tensor([0.4993]), 'bias': tensor([0.3843])})\n",
            "Epoch: 17210 | MAE Train Loss: 0.0403025820851326 | MAE Test Loss: 0.09423402696847916 \n",
            "OrderedDict({'weights': tensor([0.4995]), 'bias': tensor([0.3842])})\n",
            "Epoch: 17220 | MAE Train Loss: 0.04026824235916138 | MAE Test Loss: 0.0941513329744339 \n",
            "OrderedDict({'weights': tensor([0.4997]), 'bias': tensor([0.3841])})\n",
            "Epoch: 17230 | MAE Train Loss: 0.040233828127384186 | MAE Test Loss: 0.09406865388154984 \n",
            "OrderedDict({'weights': tensor([0.4998]), 'bias': tensor([0.3841])})\n",
            "Epoch: 17240 | MAE Train Loss: 0.04019949957728386 | MAE Test Loss: 0.09399284422397614 \n",
            "OrderedDict({'weights': tensor([0.5000]), 'bias': tensor([0.3840])})\n",
            "Epoch: 17250 | MAE Train Loss: 0.040165118873119354 | MAE Test Loss: 0.09391360729932785 \n",
            "OrderedDict({'weights': tensor([0.5002]), 'bias': tensor([0.3839])})\n",
            "Epoch: 17260 | MAE Train Loss: 0.04013075679540634 | MAE Test Loss: 0.0938275158405304 \n",
            "OrderedDict({'weights': tensor([0.5004]), 'bias': tensor([0.3838])})\n",
            "Epoch: 17270 | MAE Train Loss: 0.040096431970596313 | MAE Test Loss: 0.0937517061829567 \n",
            "OrderedDict({'weights': tensor([0.5005]), 'bias': tensor([0.3838])})\n",
            "Epoch: 17280 | MAE Train Loss: 0.0400620736181736 | MAE Test Loss: 0.09366901218891144 \n",
            "OrderedDict({'weights': tensor([0.5007]), 'bias': tensor([0.3837])})\n",
            "Epoch: 17290 | MAE Train Loss: 0.0400276705622673 | MAE Test Loss: 0.09358632564544678 \n",
            "OrderedDict({'weights': tensor([0.5009]), 'bias': tensor([0.3836])})\n",
            "Epoch: 17300 | MAE Train Loss: 0.03999333083629608 | MAE Test Loss: 0.09350710362195969 \n",
            "OrderedDict({'weights': tensor([0.5010]), 'bias': tensor([0.3836])})\n",
            "Epoch: 17310 | MAE Train Loss: 0.03995897248387337 | MAE Test Loss: 0.0934312641620636 \n",
            "OrderedDict({'weights': tensor([0.5012]), 'bias': tensor([0.3835])})\n",
            "Epoch: 17320 | MAE Train Loss: 0.03992459923028946 | MAE Test Loss: 0.09334520995616913 \n",
            "OrderedDict({'weights': tensor([0.5014]), 'bias': tensor([0.3834])})\n",
            "Epoch: 17330 | MAE Train Loss: 0.03989028558135033 | MAE Test Loss: 0.09326937794685364 \n",
            "OrderedDict({'weights': tensor([0.5016]), 'bias': tensor([0.3833])})\n",
            "Epoch: 17340 | MAE Train Loss: 0.03985590860247612 | MAE Test Loss: 0.09318669885396957 \n",
            "OrderedDict({'weights': tensor([0.5017]), 'bias': tensor([0.3833])})\n",
            "Epoch: 17350 | MAE Train Loss: 0.039821501821279526 | MAE Test Loss: 0.09310746937990189 \n",
            "OrderedDict({'weights': tensor([0.5019]), 'bias': tensor([0.3832])})\n",
            "Epoch: 17360 | MAE Train Loss: 0.0397871658205986 | MAE Test Loss: 0.09302478283643723 \n",
            "OrderedDict({'weights': tensor([0.5021]), 'bias': tensor([0.3831])})\n",
            "Epoch: 17370 | MAE Train Loss: 0.03975283354520798 | MAE Test Loss: 0.09294556081295013 \n",
            "OrderedDict({'weights': tensor([0.5022]), 'bias': tensor([0.3831])})\n",
            "Epoch: 17380 | MAE Train Loss: 0.03971843048930168 | MAE Test Loss: 0.09286974370479584 \n",
            "OrderedDict({'weights': tensor([0.5024]), 'bias': tensor([0.3830])})\n",
            "Epoch: 17390 | MAE Train Loss: 0.03968413546681404 | MAE Test Loss: 0.09278705716133118 \n",
            "OrderedDict({'weights': tensor([0.5026]), 'bias': tensor([0.3829])})\n",
            "Epoch: 17400 | MAE Train Loss: 0.03964974731206894 | MAE Test Loss: 0.09270438551902771 \n",
            "OrderedDict({'weights': tensor([0.5028]), 'bias': tensor([0.3828])})\n",
            "Epoch: 17410 | MAE Train Loss: 0.039615415036678314 | MAE Test Loss: 0.09262514114379883 \n",
            "OrderedDict({'weights': tensor([0.5029]), 'bias': tensor([0.3828])})\n",
            "Epoch: 17420 | MAE Train Loss: 0.0395810641348362 | MAE Test Loss: 0.09254591912031174 \n",
            "OrderedDict({'weights': tensor([0.5031]), 'bias': tensor([0.3827])})\n",
            "Epoch: 17430 | MAE Train Loss: 0.03954667970538139 | MAE Test Loss: 0.09246324002742767 \n",
            "OrderedDict({'weights': tensor([0.5033]), 'bias': tensor([0.3826])})\n",
            "Epoch: 17440 | MAE Train Loss: 0.03951228782534599 | MAE Test Loss: 0.09238742291927338 \n",
            "OrderedDict({'weights': tensor([0.5034]), 'bias': tensor([0.3826])})\n",
            "Epoch: 17450 | MAE Train Loss: 0.03947798162698746 | MAE Test Loss: 0.09230474382638931 \n",
            "OrderedDict({'weights': tensor([0.5036]), 'bias': tensor([0.3825])})\n",
            "Epoch: 17460 | MAE Train Loss: 0.03944360092282295 | MAE Test Loss: 0.09222551435232162 \n",
            "OrderedDict({'weights': tensor([0.5038]), 'bias': tensor([0.3824])})\n",
            "Epoch: 17470 | MAE Train Loss: 0.039409246295690536 | MAE Test Loss: 0.09214281290769577 \n",
            "OrderedDict({'weights': tensor([0.5040]), 'bias': tensor([0.3823])})\n",
            "Epoch: 17480 | MAE Train Loss: 0.03937489911913872 | MAE Test Loss: 0.09206359833478928 \n",
            "OrderedDict({'weights': tensor([0.5041]), 'bias': tensor([0.3823])})\n",
            "Epoch: 17490 | MAE Train Loss: 0.039340510964393616 | MAE Test Loss: 0.09198091179132462 \n",
            "OrderedDict({'weights': tensor([0.5043]), 'bias': tensor([0.3822])})\n",
            "Epoch: 17500 | MAE Train Loss: 0.03930613771080971 | MAE Test Loss: 0.09190510213375092 \n",
            "OrderedDict({'weights': tensor([0.5045]), 'bias': tensor([0.3821])})\n",
            "Epoch: 17510 | MAE Train Loss: 0.039271771907806396 | MAE Test Loss: 0.09181901067495346 \n",
            "OrderedDict({'weights': tensor([0.5046]), 'bias': tensor([0.3821])})\n",
            "Epoch: 17520 | MAE Train Loss: 0.03923744708299637 | MAE Test Loss: 0.09174320101737976 \n",
            "OrderedDict({'weights': tensor([0.5048]), 'bias': tensor([0.3820])})\n",
            "Epoch: 17530 | MAE Train Loss: 0.03920306637883186 | MAE Test Loss: 0.09166395664215088 \n",
            "OrderedDict({'weights': tensor([0.5050]), 'bias': tensor([0.3819])})\n",
            "Epoch: 17540 | MAE Train Loss: 0.03916875272989273 | MAE Test Loss: 0.09158127009868622 \n",
            "OrderedDict({'weights': tensor([0.5051]), 'bias': tensor([0.3818])})\n",
            "Epoch: 17550 | MAE Train Loss: 0.039134349673986435 | MAE Test Loss: 0.09149859845638275 \n",
            "OrderedDict({'weights': tensor([0.5053]), 'bias': tensor([0.3818])})\n",
            "Epoch: 17560 | MAE Train Loss: 0.039099980145692825 | MAE Test Loss: 0.09142276644706726 \n",
            "OrderedDict({'weights': tensor([0.5055]), 'bias': tensor([0.3817])})\n",
            "Epoch: 17570 | MAE Train Loss: 0.039065610617399216 | MAE Test Loss: 0.0913366749882698 \n",
            "OrderedDict({'weights': tensor([0.5057]), 'bias': tensor([0.3816])})\n",
            "Epoch: 17580 | MAE Train Loss: 0.03903127834200859 | MAE Test Loss: 0.09125746786594391 \n",
            "OrderedDict({'weights': tensor([0.5058]), 'bias': tensor([0.3816])})\n",
            "Epoch: 17590 | MAE Train Loss: 0.03899691253900528 | MAE Test Loss: 0.09118162840604782 \n",
            "OrderedDict({'weights': tensor([0.5060]), 'bias': tensor([0.3815])})\n",
            "Epoch: 17600 | MAE Train Loss: 0.03896259516477585 | MAE Test Loss: 0.09109897166490555 \n",
            "OrderedDict({'weights': tensor([0.5062]), 'bias': tensor([0.3814])})\n",
            "Epoch: 17610 | MAE Train Loss: 0.03892819210886955 | MAE Test Loss: 0.09101627767086029 \n",
            "OrderedDict({'weights': tensor([0.5063]), 'bias': tensor([0.3813])})\n",
            "Epoch: 17620 | MAE Train Loss: 0.03889385610818863 | MAE Test Loss: 0.0909370556473732 \n",
            "OrderedDict({'weights': tensor([0.5065]), 'bias': tensor([0.3813])})\n",
            "Epoch: 17630 | MAE Train Loss: 0.03885945677757263 | MAE Test Loss: 0.09085782617330551 \n",
            "OrderedDict({'weights': tensor([0.5067]), 'bias': tensor([0.3812])})\n",
            "Epoch: 17640 | MAE Train Loss: 0.03882511332631111 | MAE Test Loss: 0.09077514708042145 \n",
            "OrderedDict({'weights': tensor([0.5069]), 'bias': tensor([0.3811])})\n",
            "Epoch: 17650 | MAE Train Loss: 0.0387907549738884 | MAE Test Loss: 0.09069932997226715 \n",
            "OrderedDict({'weights': tensor([0.5070]), 'bias': tensor([0.3810])})\n",
            "Epoch: 17660 | MAE Train Loss: 0.03875643387436867 | MAE Test Loss: 0.0906166359782219 \n",
            "OrderedDict({'weights': tensor([0.5072]), 'bias': tensor([0.3810])})\n",
            "Epoch: 17670 | MAE Train Loss: 0.03872207552194595 | MAE Test Loss: 0.0905374139547348 \n",
            "OrderedDict({'weights': tensor([0.5074]), 'bias': tensor([0.3809])})\n",
            "Epoch: 17680 | MAE Train Loss: 0.03868768736720085 | MAE Test Loss: 0.09045473486185074 \n",
            "OrderedDict({'weights': tensor([0.5075]), 'bias': tensor([0.3808])})\n",
            "Epoch: 17690 | MAE Train Loss: 0.038653355091810226 | MAE Test Loss: 0.09037549048662186 \n",
            "OrderedDict({'weights': tensor([0.5077]), 'bias': tensor([0.3808])})\n",
            "Epoch: 17700 | MAE Train Loss: 0.038618944585323334 | MAE Test Loss: 0.09029281139373779 \n",
            "OrderedDict({'weights': tensor([0.5079]), 'bias': tensor([0.3807])})\n",
            "Epoch: 17710 | MAE Train Loss: 0.03858460858464241 | MAE Test Loss: 0.09021700173616409 \n",
            "OrderedDict({'weights': tensor([0.5081]), 'bias': tensor([0.3806])})\n",
            "Epoch: 17720 | MAE Train Loss: 0.038550276309251785 | MAE Test Loss: 0.09013429284095764 \n",
            "OrderedDict({'weights': tensor([0.5082]), 'bias': tensor([0.3805])})\n",
            "Epoch: 17730 | MAE Train Loss: 0.038515932857990265 | MAE Test Loss: 0.09005509316921234 \n",
            "OrderedDict({'weights': tensor([0.5084]), 'bias': tensor([0.3805])})\n",
            "Epoch: 17740 | MAE Train Loss: 0.038481540977954865 | MAE Test Loss: 0.08997587114572525 \n",
            "OrderedDict({'weights': tensor([0.5086]), 'bias': tensor([0.3804])})\n",
            "Epoch: 17750 | MAE Train Loss: 0.03844720125198364 | MAE Test Loss: 0.08989317715167999 \n",
            "OrderedDict({'weights': tensor([0.5087]), 'bias': tensor([0.3803])})\n",
            "Epoch: 17760 | MAE Train Loss: 0.03841278702020645 | MAE Test Loss: 0.08981049805879593 \n",
            "OrderedDict({'weights': tensor([0.5089]), 'bias': tensor([0.3803])})\n",
            "Epoch: 17770 | MAE Train Loss: 0.038378458470106125 | MAE Test Loss: 0.08973468840122223 \n",
            "OrderedDict({'weights': tensor([0.5091]), 'bias': tensor([0.3802])})\n",
            "Epoch: 17780 | MAE Train Loss: 0.03834407776594162 | MAE Test Loss: 0.08965545147657394 \n",
            "OrderedDict({'weights': tensor([0.5092]), 'bias': tensor([0.3801])})\n",
            "Epoch: 17790 | MAE Train Loss: 0.03830971568822861 | MAE Test Loss: 0.08956936001777649 \n",
            "OrderedDict({'weights': tensor([0.5094]), 'bias': tensor([0.3800])})\n",
            "Epoch: 17800 | MAE Train Loss: 0.03827539086341858 | MAE Test Loss: 0.08949355036020279 \n",
            "OrderedDict({'weights': tensor([0.5096]), 'bias': tensor([0.3800])})\n",
            "Epoch: 17810 | MAE Train Loss: 0.038241032510995865 | MAE Test Loss: 0.08941085636615753 \n",
            "OrderedDict({'weights': tensor([0.5098]), 'bias': tensor([0.3799])})\n",
            "Epoch: 17820 | MAE Train Loss: 0.03820662945508957 | MAE Test Loss: 0.08932816982269287 \n",
            "OrderedDict({'weights': tensor([0.5099]), 'bias': tensor([0.3798])})\n",
            "Epoch: 17830 | MAE Train Loss: 0.03817228972911835 | MAE Test Loss: 0.08924894779920578 \n",
            "OrderedDict({'weights': tensor([0.5101]), 'bias': tensor([0.3798])})\n",
            "Epoch: 17840 | MAE Train Loss: 0.03813793137669563 | MAE Test Loss: 0.08917310833930969 \n",
            "OrderedDict({'weights': tensor([0.5103]), 'bias': tensor([0.3797])})\n",
            "Epoch: 17850 | MAE Train Loss: 0.038103558123111725 | MAE Test Loss: 0.08908705413341522 \n",
            "OrderedDict({'weights': tensor([0.5104]), 'bias': tensor([0.3796])})\n",
            "Epoch: 17860 | MAE Train Loss: 0.03806924447417259 | MAE Test Loss: 0.08901122957468033 \n",
            "OrderedDict({'weights': tensor([0.5106]), 'bias': tensor([0.3795])})\n",
            "Epoch: 17870 | MAE Train Loss: 0.038034867495298386 | MAE Test Loss: 0.08892853558063507 \n",
            "OrderedDict({'weights': tensor([0.5108]), 'bias': tensor([0.3795])})\n",
            "Epoch: 17880 | MAE Train Loss: 0.03800046071410179 | MAE Test Loss: 0.08884931355714798 \n",
            "OrderedDict({'weights': tensor([0.5110]), 'bias': tensor([0.3794])})\n",
            "Epoch: 17890 | MAE Train Loss: 0.03796612471342087 | MAE Test Loss: 0.08876662701368332 \n",
            "OrderedDict({'weights': tensor([0.5111]), 'bias': tensor([0.3793])})\n",
            "Epoch: 17900 | MAE Train Loss: 0.03793179243803024 | MAE Test Loss: 0.08868740499019623 \n",
            "OrderedDict({'weights': tensor([0.5113]), 'bias': tensor([0.3793])})\n",
            "Epoch: 17910 | MAE Train Loss: 0.03789738938212395 | MAE Test Loss: 0.08861158043146133 \n",
            "OrderedDict({'weights': tensor([0.5115]), 'bias': tensor([0.3792])})\n",
            "Epoch: 17920 | MAE Train Loss: 0.03786309435963631 | MAE Test Loss: 0.08852890133857727 \n",
            "OrderedDict({'weights': tensor([0.5116]), 'bias': tensor([0.3791])})\n",
            "Epoch: 17930 | MAE Train Loss: 0.037828706204891205 | MAE Test Loss: 0.0884462296962738 \n",
            "OrderedDict({'weights': tensor([0.5118]), 'bias': tensor([0.3790])})\n",
            "Epoch: 17940 | MAE Train Loss: 0.03779437392950058 | MAE Test Loss: 0.08836699277162552 \n",
            "OrderedDict({'weights': tensor([0.5120]), 'bias': tensor([0.3790])})\n",
            "Epoch: 17950 | MAE Train Loss: 0.03776002302765846 | MAE Test Loss: 0.08828776329755783 \n",
            "OrderedDict({'weights': tensor([0.5122]), 'bias': tensor([0.3789])})\n",
            "Epoch: 17960 | MAE Train Loss: 0.03772563859820366 | MAE Test Loss: 0.08820508420467377 \n",
            "OrderedDict({'weights': tensor([0.5123]), 'bias': tensor([0.3788])})\n",
            "Epoch: 17970 | MAE Train Loss: 0.03769124671816826 | MAE Test Loss: 0.08812926709651947 \n",
            "OrderedDict({'weights': tensor([0.5125]), 'bias': tensor([0.3787])})\n",
            "Epoch: 17980 | MAE Train Loss: 0.03765694051980972 | MAE Test Loss: 0.0880465880036354 \n",
            "OrderedDict({'weights': tensor([0.5127]), 'bias': tensor([0.3787])})\n",
            "Epoch: 17990 | MAE Train Loss: 0.03762255236506462 | MAE Test Loss: 0.08796735107898712 \n",
            "OrderedDict({'weights': tensor([0.5128]), 'bias': tensor([0.3786])})\n",
            "Epoch: 18000 | MAE Train Loss: 0.0375882051885128 | MAE Test Loss: 0.08788465708494186 \n",
            "OrderedDict({'weights': tensor([0.5130]), 'bias': tensor([0.3785])})\n",
            "Epoch: 18010 | MAE Train Loss: 0.03755385801196098 | MAE Test Loss: 0.08780544251203537 \n",
            "OrderedDict({'weights': tensor([0.5132]), 'bias': tensor([0.3785])})\n",
            "Epoch: 18020 | MAE Train Loss: 0.03751946985721588 | MAE Test Loss: 0.0877227634191513 \n",
            "OrderedDict({'weights': tensor([0.5134]), 'bias': tensor([0.3784])})\n",
            "Epoch: 18030 | MAE Train Loss: 0.03748509660363197 | MAE Test Loss: 0.08764694631099701 \n",
            "OrderedDict({'weights': tensor([0.5135]), 'bias': tensor([0.3783])})\n",
            "Epoch: 18040 | MAE Train Loss: 0.03745073080062866 | MAE Test Loss: 0.08756085485219955 \n",
            "OrderedDict({'weights': tensor([0.5137]), 'bias': tensor([0.3782])})\n",
            "Epoch: 18050 | MAE Train Loss: 0.037416405975818634 | MAE Test Loss: 0.08748504519462585 \n",
            "OrderedDict({'weights': tensor([0.5139]), 'bias': tensor([0.3782])})\n",
            "Epoch: 18060 | MAE Train Loss: 0.03738202527165413 | MAE Test Loss: 0.08740580826997757 \n",
            "OrderedDict({'weights': tensor([0.5140]), 'bias': tensor([0.3781])})\n",
            "Epoch: 18070 | MAE Train Loss: 0.037347711622714996 | MAE Test Loss: 0.08732311427593231 \n",
            "OrderedDict({'weights': tensor([0.5142]), 'bias': tensor([0.3780])})\n",
            "Epoch: 18080 | MAE Train Loss: 0.0373133085668087 | MAE Test Loss: 0.08724044263362885 \n",
            "OrderedDict({'weights': tensor([0.5144]), 'bias': tensor([0.3780])})\n",
            "Epoch: 18090 | MAE Train Loss: 0.03727893903851509 | MAE Test Loss: 0.08716461062431335 \n",
            "OrderedDict({'weights': tensor([0.5145]), 'bias': tensor([0.3779])})\n",
            "Epoch: 18100 | MAE Train Loss: 0.03724456951022148 | MAE Test Loss: 0.0870785266160965 \n",
            "OrderedDict({'weights': tensor([0.5147]), 'bias': tensor([0.3778])})\n",
            "Epoch: 18110 | MAE Train Loss: 0.037210237234830856 | MAE Test Loss: 0.08699931204319 \n",
            "OrderedDict({'weights': tensor([0.5149]), 'bias': tensor([0.3777])})\n",
            "Epoch: 18120 | MAE Train Loss: 0.037175871431827545 | MAE Test Loss: 0.08692347258329391 \n",
            "OrderedDict({'weights': tensor([0.5151]), 'bias': tensor([0.3777])})\n",
            "Epoch: 18130 | MAE Train Loss: 0.037141554057598114 | MAE Test Loss: 0.08684081584215164 \n",
            "OrderedDict({'weights': tensor([0.5152]), 'bias': tensor([0.3776])})\n",
            "Epoch: 18140 | MAE Train Loss: 0.03710715100169182 | MAE Test Loss: 0.08675812184810638 \n",
            "OrderedDict({'weights': tensor([0.5154]), 'bias': tensor([0.3775])})\n",
            "Epoch: 18150 | MAE Train Loss: 0.037072815001010895 | MAE Test Loss: 0.0866788923740387 \n",
            "OrderedDict({'weights': tensor([0.5156]), 'bias': tensor([0.3775])})\n",
            "Epoch: 18160 | MAE Train Loss: 0.0370384156703949 | MAE Test Loss: 0.0865996703505516 \n",
            "OrderedDict({'weights': tensor([0.5157]), 'bias': tensor([0.3774])})\n",
            "Epoch: 18170 | MAE Train Loss: 0.03700407221913338 | MAE Test Loss: 0.08651699125766754 \n",
            "OrderedDict({'weights': tensor([0.5159]), 'bias': tensor([0.3773])})\n",
            "Epoch: 18180 | MAE Train Loss: 0.03696971386671066 | MAE Test Loss: 0.08644117414951324 \n",
            "OrderedDict({'weights': tensor([0.5161]), 'bias': tensor([0.3772])})\n",
            "Epoch: 18190 | MAE Train Loss: 0.03693539276719093 | MAE Test Loss: 0.08635848760604858 \n",
            "OrderedDict({'weights': tensor([0.5163]), 'bias': tensor([0.3772])})\n",
            "Epoch: 18200 | MAE Train Loss: 0.03690103441476822 | MAE Test Loss: 0.0862792581319809 \n",
            "OrderedDict({'weights': tensor([0.5164]), 'bias': tensor([0.3771])})\n",
            "Epoch: 18210 | MAE Train Loss: 0.03686664626002312 | MAE Test Loss: 0.08619657903909683 \n",
            "OrderedDict({'weights': tensor([0.5166]), 'bias': tensor([0.3770])})\n",
            "Epoch: 18220 | MAE Train Loss: 0.03683231398463249 | MAE Test Loss: 0.08611734211444855 \n",
            "OrderedDict({'weights': tensor([0.5168]), 'bias': tensor([0.3770])})\n",
            "Epoch: 18230 | MAE Train Loss: 0.0367979034781456 | MAE Test Loss: 0.08603464812040329 \n",
            "OrderedDict({'weights': tensor([0.5169]), 'bias': tensor([0.3769])})\n",
            "Epoch: 18240 | MAE Train Loss: 0.036763567477464676 | MAE Test Loss: 0.08595884591341019 \n",
            "OrderedDict({'weights': tensor([0.5171]), 'bias': tensor([0.3768])})\n",
            "Epoch: 18250 | MAE Train Loss: 0.03672923520207405 | MAE Test Loss: 0.08587613701820374 \n",
            "OrderedDict({'weights': tensor([0.5173]), 'bias': tensor([0.3767])})\n",
            "Epoch: 18260 | MAE Train Loss: 0.03669489175081253 | MAE Test Loss: 0.08579693734645844 \n",
            "OrderedDict({'weights': tensor([0.5175]), 'bias': tensor([0.3767])})\n",
            "Epoch: 18270 | MAE Train Loss: 0.03666049987077713 | MAE Test Loss: 0.08571770787239075 \n",
            "OrderedDict({'weights': tensor([0.5176]), 'bias': tensor([0.3766])})\n",
            "Epoch: 18280 | MAE Train Loss: 0.03662616014480591 | MAE Test Loss: 0.08563502132892609 \n",
            "OrderedDict({'weights': tensor([0.5178]), 'bias': tensor([0.3765])})\n",
            "Epoch: 18290 | MAE Train Loss: 0.03659174591302872 | MAE Test Loss: 0.08555234223604202 \n",
            "OrderedDict({'weights': tensor([0.5180]), 'bias': tensor([0.3765])})\n",
            "Epoch: 18300 | MAE Train Loss: 0.03655741736292839 | MAE Test Loss: 0.08547653257846832 \n",
            "OrderedDict({'weights': tensor([0.5181]), 'bias': tensor([0.3764])})\n",
            "Epoch: 18310 | MAE Train Loss: 0.036523036658763885 | MAE Test Loss: 0.08539730310440063 \n",
            "OrderedDict({'weights': tensor([0.5183]), 'bias': tensor([0.3763])})\n",
            "Epoch: 18320 | MAE Train Loss: 0.03648867458105087 | MAE Test Loss: 0.08531120419502258 \n",
            "OrderedDict({'weights': tensor([0.5185]), 'bias': tensor([0.3762])})\n",
            "Epoch: 18330 | MAE Train Loss: 0.036454349756240845 | MAE Test Loss: 0.08523539453744888 \n",
            "OrderedDict({'weights': tensor([0.5187]), 'bias': tensor([0.3762])})\n",
            "Epoch: 18340 | MAE Train Loss: 0.03641999140381813 | MAE Test Loss: 0.08515270054340363 \n",
            "OrderedDict({'weights': tensor([0.5188]), 'bias': tensor([0.3761])})\n",
            "Epoch: 18350 | MAE Train Loss: 0.036385588347911835 | MAE Test Loss: 0.08507002145051956 \n",
            "OrderedDict({'weights': tensor([0.5190]), 'bias': tensor([0.3760])})\n",
            "Epoch: 18360 | MAE Train Loss: 0.03635124862194061 | MAE Test Loss: 0.08499079197645187 \n",
            "OrderedDict({'weights': tensor([0.5192]), 'bias': tensor([0.3760])})\n",
            "Epoch: 18370 | MAE Train Loss: 0.0363168902695179 | MAE Test Loss: 0.08491495251655579 \n",
            "OrderedDict({'weights': tensor([0.5193]), 'bias': tensor([0.3759])})\n",
            "Epoch: 18380 | MAE Train Loss: 0.03628251701593399 | MAE Test Loss: 0.08482889831066132 \n",
            "OrderedDict({'weights': tensor([0.5195]), 'bias': tensor([0.3758])})\n",
            "Epoch: 18390 | MAE Train Loss: 0.03624820336699486 | MAE Test Loss: 0.08475307375192642 \n",
            "OrderedDict({'weights': tensor([0.5197]), 'bias': tensor([0.3757])})\n",
            "Epoch: 18400 | MAE Train Loss: 0.03621382638812065 | MAE Test Loss: 0.08467037975788116 \n",
            "OrderedDict({'weights': tensor([0.5198]), 'bias': tensor([0.3757])})\n",
            "Epoch: 18410 | MAE Train Loss: 0.03617941960692406 | MAE Test Loss: 0.08459115773439407 \n",
            "OrderedDict({'weights': tensor([0.5200]), 'bias': tensor([0.3756])})\n",
            "Epoch: 18420 | MAE Train Loss: 0.036145083606243134 | MAE Test Loss: 0.08450847119092941 \n",
            "OrderedDict({'weights': tensor([0.5202]), 'bias': tensor([0.3755])})\n",
            "Epoch: 18430 | MAE Train Loss: 0.03611075133085251 | MAE Test Loss: 0.08442924916744232 \n",
            "OrderedDict({'weights': tensor([0.5204]), 'bias': tensor([0.3754])})\n",
            "Epoch: 18440 | MAE Train Loss: 0.03607634827494621 | MAE Test Loss: 0.08435342460870743 \n",
            "OrderedDict({'weights': tensor([0.5205]), 'bias': tensor([0.3754])})\n",
            "Epoch: 18450 | MAE Train Loss: 0.03604205325245857 | MAE Test Loss: 0.08427074551582336 \n",
            "OrderedDict({'weights': tensor([0.5207]), 'bias': tensor([0.3753])})\n",
            "Epoch: 18460 | MAE Train Loss: 0.03600766509771347 | MAE Test Loss: 0.0841880664229393 \n",
            "OrderedDict({'weights': tensor([0.5209]), 'bias': tensor([0.3752])})\n",
            "Epoch: 18470 | MAE Train Loss: 0.035973332822322845 | MAE Test Loss: 0.08410883694887161 \n",
            "OrderedDict({'weights': tensor([0.5210]), 'bias': tensor([0.3752])})\n",
            "Epoch: 18480 | MAE Train Loss: 0.03593898192048073 | MAE Test Loss: 0.08402960747480392 \n",
            "OrderedDict({'weights': tensor([0.5212]), 'bias': tensor([0.3751])})\n",
            "Epoch: 18490 | MAE Train Loss: 0.035904597491025925 | MAE Test Loss: 0.08394692838191986 \n",
            "OrderedDict({'weights': tensor([0.5214]), 'bias': tensor([0.3750])})\n",
            "Epoch: 18500 | MAE Train Loss: 0.035870205610990524 | MAE Test Loss: 0.08387111127376556 \n",
            "OrderedDict({'weights': tensor([0.5216]), 'bias': tensor([0.3749])})\n",
            "Epoch: 18510 | MAE Train Loss: 0.03583589941263199 | MAE Test Loss: 0.0837884396314621 \n",
            "OrderedDict({'weights': tensor([0.5217]), 'bias': tensor([0.3749])})\n",
            "Epoch: 18520 | MAE Train Loss: 0.03580151125788689 | MAE Test Loss: 0.08370919525623322 \n",
            "OrderedDict({'weights': tensor([0.5219]), 'bias': tensor([0.3748])})\n",
            "Epoch: 18530 | MAE Train Loss: 0.03576716408133507 | MAE Test Loss: 0.08362649381160736 \n",
            "OrderedDict({'weights': tensor([0.5221]), 'bias': tensor([0.3747])})\n",
            "Epoch: 18540 | MAE Train Loss: 0.03573281690478325 | MAE Test Loss: 0.08354729413986206 \n",
            "OrderedDict({'weights': tensor([0.5222]), 'bias': tensor([0.3747])})\n",
            "Epoch: 18550 | MAE Train Loss: 0.03569842875003815 | MAE Test Loss: 0.0834646001458168 \n",
            "OrderedDict({'weights': tensor([0.5224]), 'bias': tensor([0.3746])})\n",
            "Epoch: 18560 | MAE Train Loss: 0.03566405549645424 | MAE Test Loss: 0.0833887979388237 \n",
            "OrderedDict({'weights': tensor([0.5226]), 'bias': tensor([0.3745])})\n",
            "Epoch: 18570 | MAE Train Loss: 0.03562968969345093 | MAE Test Loss: 0.08330269902944565 \n",
            "OrderedDict({'weights': tensor([0.5228]), 'bias': tensor([0.3744])})\n",
            "Epoch: 18580 | MAE Train Loss: 0.0355953648686409 | MAE Test Loss: 0.08322688192129135 \n",
            "OrderedDict({'weights': tensor([0.5229]), 'bias': tensor([0.3744])})\n",
            "Epoch: 18590 | MAE Train Loss: 0.035560984164476395 | MAE Test Loss: 0.08314765244722366 \n",
            "OrderedDict({'weights': tensor([0.5231]), 'bias': tensor([0.3743])})\n",
            "Epoch: 18600 | MAE Train Loss: 0.03552667051553726 | MAE Test Loss: 0.0830649584531784 \n",
            "OrderedDict({'weights': tensor([0.5233]), 'bias': tensor([0.3742])})\n",
            "Epoch: 18610 | MAE Train Loss: 0.035492267459630966 | MAE Test Loss: 0.08298228681087494 \n",
            "OrderedDict({'weights': tensor([0.5234]), 'bias': tensor([0.3742])})\n",
            "Epoch: 18620 | MAE Train Loss: 0.03545789793133736 | MAE Test Loss: 0.08290645480155945 \n",
            "OrderedDict({'weights': tensor([0.5236]), 'bias': tensor([0.3741])})\n",
            "Epoch: 18630 | MAE Train Loss: 0.03542352840304375 | MAE Test Loss: 0.08282037079334259 \n",
            "OrderedDict({'weights': tensor([0.5238]), 'bias': tensor([0.3740])})\n",
            "Epoch: 18640 | MAE Train Loss: 0.03538919612765312 | MAE Test Loss: 0.0827411562204361 \n",
            "OrderedDict({'weights': tensor([0.5240]), 'bias': tensor([0.3739])})\n",
            "Epoch: 18650 | MAE Train Loss: 0.03535483032464981 | MAE Test Loss: 0.08266530930995941 \n",
            "OrderedDict({'weights': tensor([0.5241]), 'bias': tensor([0.3739])})\n",
            "Epoch: 18660 | MAE Train Loss: 0.03532051295042038 | MAE Test Loss: 0.08258266001939774 \n",
            "OrderedDict({'weights': tensor([0.5243]), 'bias': tensor([0.3738])})\n",
            "Epoch: 18670 | MAE Train Loss: 0.035286109894514084 | MAE Test Loss: 0.08249997347593307 \n",
            "OrderedDict({'weights': tensor([0.5245]), 'bias': tensor([0.3737])})\n",
            "Epoch: 18680 | MAE Train Loss: 0.03525177389383316 | MAE Test Loss: 0.08242073655128479 \n",
            "OrderedDict({'weights': tensor([0.5246]), 'bias': tensor([0.3737])})\n",
            "Epoch: 18690 | MAE Train Loss: 0.03521737456321716 | MAE Test Loss: 0.0823415145277977 \n",
            "OrderedDict({'weights': tensor([0.5248]), 'bias': tensor([0.3736])})\n",
            "Epoch: 18700 | MAE Train Loss: 0.03518303111195564 | MAE Test Loss: 0.08225883543491364 \n",
            "OrderedDict({'weights': tensor([0.5250]), 'bias': tensor([0.3735])})\n",
            "Epoch: 18710 | MAE Train Loss: 0.03514867275953293 | MAE Test Loss: 0.08218301832675934 \n",
            "OrderedDict({'weights': tensor([0.5251]), 'bias': tensor([0.3734])})\n",
            "Epoch: 18720 | MAE Train Loss: 0.0351143516600132 | MAE Test Loss: 0.08210033178329468 \n",
            "OrderedDict({'weights': tensor([0.5253]), 'bias': tensor([0.3734])})\n",
            "Epoch: 18730 | MAE Train Loss: 0.035079993307590485 | MAE Test Loss: 0.08202110230922699 \n",
            "OrderedDict({'weights': tensor([0.5255]), 'bias': tensor([0.3733])})\n",
            "Epoch: 18740 | MAE Train Loss: 0.03504560515284538 | MAE Test Loss: 0.08193843066692352 \n",
            "OrderedDict({'weights': tensor([0.5257]), 'bias': tensor([0.3732])})\n",
            "Epoch: 18750 | MAE Train Loss: 0.03501127287745476 | MAE Test Loss: 0.08185918629169464 \n",
            "OrderedDict({'weights': tensor([0.5258]), 'bias': tensor([0.3732])})\n",
            "Epoch: 18760 | MAE Train Loss: 0.034976862370967865 | MAE Test Loss: 0.08177649229764938 \n",
            "OrderedDict({'weights': tensor([0.5260]), 'bias': tensor([0.3731])})\n",
            "Epoch: 18770 | MAE Train Loss: 0.03494252637028694 | MAE Test Loss: 0.08170069009065628 \n",
            "OrderedDict({'weights': tensor([0.5262]), 'bias': tensor([0.3730])})\n",
            "Epoch: 18780 | MAE Train Loss: 0.034908194094896317 | MAE Test Loss: 0.08161798119544983 \n",
            "OrderedDict({'weights': tensor([0.5263]), 'bias': tensor([0.3729])})\n",
            "Epoch: 18790 | MAE Train Loss: 0.034873850643634796 | MAE Test Loss: 0.08153878897428513 \n",
            "OrderedDict({'weights': tensor([0.5265]), 'bias': tensor([0.3729])})\n",
            "Epoch: 18800 | MAE Train Loss: 0.034839458763599396 | MAE Test Loss: 0.08145955204963684 \n",
            "OrderedDict({'weights': tensor([0.5267]), 'bias': tensor([0.3728])})\n",
            "Epoch: 18810 | MAE Train Loss: 0.034805119037628174 | MAE Test Loss: 0.08137686550617218 \n",
            "OrderedDict({'weights': tensor([0.5269]), 'bias': tensor([0.3727])})\n",
            "Epoch: 18820 | MAE Train Loss: 0.03477070480585098 | MAE Test Loss: 0.08129418641328812 \n",
            "OrderedDict({'weights': tensor([0.5270]), 'bias': tensor([0.3726])})\n",
            "Epoch: 18830 | MAE Train Loss: 0.034736376255750656 | MAE Test Loss: 0.08121837675571442 \n",
            "OrderedDict({'weights': tensor([0.5272]), 'bias': tensor([0.3726])})\n",
            "Epoch: 18840 | MAE Train Loss: 0.03470199555158615 | MAE Test Loss: 0.08113914728164673 \n",
            "OrderedDict({'weights': tensor([0.5274]), 'bias': tensor([0.3725])})\n",
            "Epoch: 18850 | MAE Train Loss: 0.03466763347387314 | MAE Test Loss: 0.08105304837226868 \n",
            "OrderedDict({'weights': tensor([0.5275]), 'bias': tensor([0.3724])})\n",
            "Epoch: 18860 | MAE Train Loss: 0.03463331237435341 | MAE Test Loss: 0.08097724616527557 \n",
            "OrderedDict({'weights': tensor([0.5277]), 'bias': tensor([0.3724])})\n",
            "Epoch: 18870 | MAE Train Loss: 0.034598954021930695 | MAE Test Loss: 0.08089454472064972 \n",
            "OrderedDict({'weights': tensor([0.5279]), 'bias': tensor([0.3723])})\n",
            "Epoch: 18880 | MAE Train Loss: 0.0345645472407341 | MAE Test Loss: 0.08081186562776566 \n",
            "OrderedDict({'weights': tensor([0.5281]), 'bias': tensor([0.3722])})\n",
            "Epoch: 18890 | MAE Train Loss: 0.03453020751476288 | MAE Test Loss: 0.08073263615369797 \n",
            "OrderedDict({'weights': tensor([0.5282]), 'bias': tensor([0.3721])})\n",
            "Epoch: 18900 | MAE Train Loss: 0.034495849162340164 | MAE Test Loss: 0.08065679669380188 \n",
            "OrderedDict({'weights': tensor([0.5284]), 'bias': tensor([0.3721])})\n",
            "Epoch: 18910 | MAE Train Loss: 0.034461475908756256 | MAE Test Loss: 0.08057074248790741 \n",
            "OrderedDict({'weights': tensor([0.5286]), 'bias': tensor([0.3720])})\n",
            "Epoch: 18920 | MAE Train Loss: 0.034427158534526825 | MAE Test Loss: 0.08049491792917252 \n",
            "OrderedDict({'weights': tensor([0.5287]), 'bias': tensor([0.3719])})\n",
            "Epoch: 18930 | MAE Train Loss: 0.03439278528094292 | MAE Test Loss: 0.08041222393512726 \n",
            "OrderedDict({'weights': tensor([0.5289]), 'bias': tensor([0.3719])})\n",
            "Epoch: 18940 | MAE Train Loss: 0.03435837849974632 | MAE Test Loss: 0.08033300191164017 \n",
            "OrderedDict({'weights': tensor([0.5291]), 'bias': tensor([0.3718])})\n",
            "Epoch: 18950 | MAE Train Loss: 0.0343240424990654 | MAE Test Loss: 0.0802503228187561 \n",
            "OrderedDict({'weights': tensor([0.5293]), 'bias': tensor([0.3717])})\n",
            "Epoch: 18960 | MAE Train Loss: 0.034289710223674774 | MAE Test Loss: 0.08017109334468842 \n",
            "OrderedDict({'weights': tensor([0.5294]), 'bias': tensor([0.3716])})\n",
            "Epoch: 18970 | MAE Train Loss: 0.03425530716776848 | MAE Test Loss: 0.08009526878595352 \n",
            "OrderedDict({'weights': tensor([0.5296]), 'bias': tensor([0.3716])})\n",
            "Epoch: 18980 | MAE Train Loss: 0.03422101214528084 | MAE Test Loss: 0.08001258969306946 \n",
            "OrderedDict({'weights': tensor([0.5298]), 'bias': tensor([0.3715])})\n",
            "Epoch: 18990 | MAE Train Loss: 0.034186623990535736 | MAE Test Loss: 0.0799299106001854 \n",
            "OrderedDict({'weights': tensor([0.5299]), 'bias': tensor([0.3714])})\n",
            "Epoch: 19000 | MAE Train Loss: 0.03415229171514511 | MAE Test Loss: 0.0798506811261177 \n",
            "OrderedDict({'weights': tensor([0.5301]), 'bias': tensor([0.3714])})\n",
            "Epoch: 19010 | MAE Train Loss: 0.034117940813302994 | MAE Test Loss: 0.07977145165205002 \n",
            "OrderedDict({'weights': tensor([0.5303]), 'bias': tensor([0.3713])})\n",
            "Epoch: 19020 | MAE Train Loss: 0.03408355638384819 | MAE Test Loss: 0.07968877255916595 \n",
            "OrderedDict({'weights': tensor([0.5304]), 'bias': tensor([0.3712])})\n",
            "Epoch: 19030 | MAE Train Loss: 0.03404916450381279 | MAE Test Loss: 0.07961295545101166 \n",
            "OrderedDict({'weights': tensor([0.5306]), 'bias': tensor([0.3711])})\n",
            "Epoch: 19040 | MAE Train Loss: 0.034014858305454254 | MAE Test Loss: 0.07953028380870819 \n",
            "OrderedDict({'weights': tensor([0.5308]), 'bias': tensor([0.3711])})\n",
            "Epoch: 19050 | MAE Train Loss: 0.03398047015070915 | MAE Test Loss: 0.07945103943347931 \n",
            "OrderedDict({'weights': tensor([0.5310]), 'bias': tensor([0.3710])})\n",
            "Epoch: 19060 | MAE Train Loss: 0.03394612297415733 | MAE Test Loss: 0.07936833798885345 \n",
            "OrderedDict({'weights': tensor([0.5311]), 'bias': tensor([0.3709])})\n",
            "Epoch: 19070 | MAE Train Loss: 0.033911775797605515 | MAE Test Loss: 0.07928913831710815 \n",
            "OrderedDict({'weights': tensor([0.5313]), 'bias': tensor([0.3709])})\n",
            "Epoch: 19080 | MAE Train Loss: 0.03387738764286041 | MAE Test Loss: 0.0792064443230629 \n",
            "OrderedDict({'weights': tensor([0.5315]), 'bias': tensor([0.3708])})\n",
            "Epoch: 19090 | MAE Train Loss: 0.033843014389276505 | MAE Test Loss: 0.0791306421160698 \n",
            "OrderedDict({'weights': tensor([0.5316]), 'bias': tensor([0.3707])})\n",
            "Epoch: 19100 | MAE Train Loss: 0.03380864858627319 | MAE Test Loss: 0.07904454320669174 \n",
            "OrderedDict({'weights': tensor([0.5318]), 'bias': tensor([0.3706])})\n",
            "Epoch: 19110 | MAE Train Loss: 0.033774323761463165 | MAE Test Loss: 0.07896872609853745 \n",
            "OrderedDict({'weights': tensor([0.5320]), 'bias': tensor([0.3706])})\n",
            "Epoch: 19120 | MAE Train Loss: 0.03373994305729866 | MAE Test Loss: 0.07888950407505035 \n",
            "OrderedDict({'weights': tensor([0.5322]), 'bias': tensor([0.3705])})\n",
            "Epoch: 19130 | MAE Train Loss: 0.03370562940835953 | MAE Test Loss: 0.0788068026304245 \n",
            "OrderedDict({'weights': tensor([0.5323]), 'bias': tensor([0.3704])})\n",
            "Epoch: 19140 | MAE Train Loss: 0.03367122635245323 | MAE Test Loss: 0.07872413098812103 \n",
            "OrderedDict({'weights': tensor([0.5325]), 'bias': tensor([0.3704])})\n",
            "Epoch: 19150 | MAE Train Loss: 0.03363685682415962 | MAE Test Loss: 0.07864829897880554 \n",
            "OrderedDict({'weights': tensor([0.5327]), 'bias': tensor([0.3703])})\n",
            "Epoch: 19160 | MAE Train Loss: 0.03360248729586601 | MAE Test Loss: 0.07856221497058868 \n",
            "OrderedDict({'weights': tensor([0.5328]), 'bias': tensor([0.3702])})\n",
            "Epoch: 19170 | MAE Train Loss: 0.03356815502047539 | MAE Test Loss: 0.07848299294710159 \n",
            "OrderedDict({'weights': tensor([0.5330]), 'bias': tensor([0.3701])})\n",
            "Epoch: 19180 | MAE Train Loss: 0.033533789217472076 | MAE Test Loss: 0.0784071534872055 \n",
            "OrderedDict({'weights': tensor([0.5332]), 'bias': tensor([0.3701])})\n",
            "Epoch: 19190 | MAE Train Loss: 0.033499471843242645 | MAE Test Loss: 0.07832450419664383 \n",
            "OrderedDict({'weights': tensor([0.5334]), 'bias': tensor([0.3700])})\n",
            "Epoch: 19200 | MAE Train Loss: 0.03346506878733635 | MAE Test Loss: 0.07824181765317917 \n",
            "OrderedDict({'weights': tensor([0.5335]), 'bias': tensor([0.3699])})\n",
            "Epoch: 19210 | MAE Train Loss: 0.033430732786655426 | MAE Test Loss: 0.07816258072853088 \n",
            "OrderedDict({'weights': tensor([0.5337]), 'bias': tensor([0.3698])})\n",
            "Epoch: 19220 | MAE Train Loss: 0.03339633345603943 | MAE Test Loss: 0.07808335870504379 \n",
            "OrderedDict({'weights': tensor([0.5339]), 'bias': tensor([0.3698])})\n",
            "Epoch: 19230 | MAE Train Loss: 0.03336199000477791 | MAE Test Loss: 0.07800067961215973 \n",
            "OrderedDict({'weights': tensor([0.5340]), 'bias': tensor([0.3697])})\n",
            "Epoch: 19240 | MAE Train Loss: 0.033327631652355194 | MAE Test Loss: 0.07792486250400543 \n",
            "OrderedDict({'weights': tensor([0.5342]), 'bias': tensor([0.3696])})\n",
            "Epoch: 19250 | MAE Train Loss: 0.033293310552835464 | MAE Test Loss: 0.07784216850996017 \n",
            "OrderedDict({'weights': tensor([0.5344]), 'bias': tensor([0.3696])})\n",
            "Epoch: 19260 | MAE Train Loss: 0.03325895220041275 | MAE Test Loss: 0.07776294648647308 \n",
            "OrderedDict({'weights': tensor([0.5345]), 'bias': tensor([0.3695])})\n",
            "Epoch: 19270 | MAE Train Loss: 0.03322456404566765 | MAE Test Loss: 0.07768027484416962 \n",
            "OrderedDict({'weights': tensor([0.5347]), 'bias': tensor([0.3694])})\n",
            "Epoch: 19280 | MAE Train Loss: 0.03319023177027702 | MAE Test Loss: 0.07760103046894073 \n",
            "OrderedDict({'weights': tensor([0.5349]), 'bias': tensor([0.3693])})\n",
            "Epoch: 19290 | MAE Train Loss: 0.03315582126379013 | MAE Test Loss: 0.07751833647489548 \n",
            "OrderedDict({'weights': tensor([0.5351]), 'bias': tensor([0.3693])})\n",
            "Epoch: 19300 | MAE Train Loss: 0.033121488988399506 | MAE Test Loss: 0.07744253426790237 \n",
            "OrderedDict({'weights': tensor([0.5352]), 'bias': tensor([0.3692])})\n",
            "Epoch: 19310 | MAE Train Loss: 0.03308715298771858 | MAE Test Loss: 0.07735982537269592 \n",
            "OrderedDict({'weights': tensor([0.5354]), 'bias': tensor([0.3691])})\n",
            "Epoch: 19320 | MAE Train Loss: 0.03305280953645706 | MAE Test Loss: 0.07728063315153122 \n",
            "OrderedDict({'weights': tensor([0.5356]), 'bias': tensor([0.3691])})\n",
            "Epoch: 19330 | MAE Train Loss: 0.03301841765642166 | MAE Test Loss: 0.07720139622688293 \n",
            "OrderedDict({'weights': tensor([0.5357]), 'bias': tensor([0.3690])})\n",
            "Epoch: 19340 | MAE Train Loss: 0.03298407793045044 | MAE Test Loss: 0.07711870223283768 \n",
            "OrderedDict({'weights': tensor([0.5359]), 'bias': tensor([0.3689])})\n",
            "Epoch: 19350 | MAE Train Loss: 0.03294966369867325 | MAE Test Loss: 0.07703603059053421 \n",
            "OrderedDict({'weights': tensor([0.5361]), 'bias': tensor([0.3688])})\n",
            "Epoch: 19360 | MAE Train Loss: 0.03291533514857292 | MAE Test Loss: 0.07696022093296051 \n",
            "OrderedDict({'weights': tensor([0.5363]), 'bias': tensor([0.3688])})\n",
            "Epoch: 19370 | MAE Train Loss: 0.03288095444440842 | MAE Test Loss: 0.07688098400831223 \n",
            "OrderedDict({'weights': tensor([0.5364]), 'bias': tensor([0.3687])})\n",
            "Epoch: 19380 | MAE Train Loss: 0.032846592366695404 | MAE Test Loss: 0.07679489254951477 \n",
            "OrderedDict({'weights': tensor([0.5366]), 'bias': tensor([0.3686])})\n",
            "Epoch: 19390 | MAE Train Loss: 0.032812267541885376 | MAE Test Loss: 0.07671909034252167 \n",
            "OrderedDict({'weights': tensor([0.5368]), 'bias': tensor([0.3686])})\n",
            "Epoch: 19400 | MAE Train Loss: 0.03277791291475296 | MAE Test Loss: 0.07663638889789581 \n",
            "OrderedDict({'weights': tensor([0.5369]), 'bias': tensor([0.3685])})\n",
            "Epoch: 19410 | MAE Train Loss: 0.032743506133556366 | MAE Test Loss: 0.07655371725559235 \n",
            "OrderedDict({'weights': tensor([0.5371]), 'bias': tensor([0.3684])})\n",
            "Epoch: 19420 | MAE Train Loss: 0.032709166407585144 | MAE Test Loss: 0.07647447288036346 \n",
            "OrderedDict({'weights': tensor([0.5373]), 'bias': tensor([0.3683])})\n",
            "Epoch: 19430 | MAE Train Loss: 0.03267481178045273 | MAE Test Loss: 0.07639864087104797 \n",
            "OrderedDict({'weights': tensor([0.5375]), 'bias': tensor([0.3683])})\n",
            "Epoch: 19440 | MAE Train Loss: 0.03264043480157852 | MAE Test Loss: 0.0763125866651535 \n",
            "OrderedDict({'weights': tensor([0.5376]), 'bias': tensor([0.3682])})\n",
            "Epoch: 19450 | MAE Train Loss: 0.03260611742734909 | MAE Test Loss: 0.0762367695569992 \n",
            "OrderedDict({'weights': tensor([0.5378]), 'bias': tensor([0.3681])})\n",
            "Epoch: 19460 | MAE Train Loss: 0.03257174417376518 | MAE Test Loss: 0.07615406811237335 \n",
            "OrderedDict({'weights': tensor([0.5380]), 'bias': tensor([0.3681])})\n",
            "Epoch: 19470 | MAE Train Loss: 0.03253733739256859 | MAE Test Loss: 0.07607484608888626 \n",
            "OrderedDict({'weights': tensor([0.5381]), 'bias': tensor([0.3680])})\n",
            "Epoch: 19480 | MAE Train Loss: 0.032503001391887665 | MAE Test Loss: 0.0759921669960022 \n",
            "OrderedDict({'weights': tensor([0.5383]), 'bias': tensor([0.3679])})\n",
            "Epoch: 19490 | MAE Train Loss: 0.03246866911649704 | MAE Test Loss: 0.07591293752193451 \n",
            "OrderedDict({'weights': tensor([0.5385]), 'bias': tensor([0.3678])})\n",
            "Epoch: 19500 | MAE Train Loss: 0.032434266060590744 | MAE Test Loss: 0.07583711296319962 \n",
            "OrderedDict({'weights': tensor([0.5387]), 'bias': tensor([0.3678])})\n",
            "Epoch: 19510 | MAE Train Loss: 0.032399967312812805 | MAE Test Loss: 0.07575443387031555 \n",
            "OrderedDict({'weights': tensor([0.5388]), 'bias': tensor([0.3677])})\n",
            "Epoch: 19520 | MAE Train Loss: 0.032365582883358 | MAE Test Loss: 0.07567175477743149 \n",
            "OrderedDict({'weights': tensor([0.5390]), 'bias': tensor([0.3676])})\n",
            "Epoch: 19530 | MAE Train Loss: 0.03233125060796738 | MAE Test Loss: 0.0755925327539444 \n",
            "OrderedDict({'weights': tensor([0.5392]), 'bias': tensor([0.3676])})\n",
            "Epoch: 19540 | MAE Train Loss: 0.03229689970612526 | MAE Test Loss: 0.07551328837871552 \n",
            "OrderedDict({'weights': tensor([0.5393]), 'bias': tensor([0.3675])})\n",
            "Epoch: 19550 | MAE Train Loss: 0.032262515276670456 | MAE Test Loss: 0.07543061673641205 \n",
            "OrderedDict({'weights': tensor([0.5395]), 'bias': tensor([0.3674])})\n",
            "Epoch: 19560 | MAE Train Loss: 0.032228123396635056 | MAE Test Loss: 0.07535479962825775 \n",
            "OrderedDict({'weights': tensor([0.5397]), 'bias': tensor([0.3673])})\n",
            "Epoch: 19570 | MAE Train Loss: 0.03219381719827652 | MAE Test Loss: 0.07527212798595428 \n",
            "OrderedDict({'weights': tensor([0.5398]), 'bias': tensor([0.3673])})\n",
            "Epoch: 19580 | MAE Train Loss: 0.032159436494112015 | MAE Test Loss: 0.0751928836107254 \n",
            "OrderedDict({'weights': tensor([0.5400]), 'bias': tensor([0.3672])})\n",
            "Epoch: 19590 | MAE Train Loss: 0.0321250818669796 | MAE Test Loss: 0.07511018216609955 \n",
            "OrderedDict({'weights': tensor([0.5402]), 'bias': tensor([0.3671])})\n",
            "Epoch: 19600 | MAE Train Loss: 0.03209073841571808 | MAE Test Loss: 0.07503098249435425 \n",
            "OrderedDict({'weights': tensor([0.5404]), 'bias': tensor([0.3670])})\n",
            "Epoch: 19610 | MAE Train Loss: 0.03205634653568268 | MAE Test Loss: 0.07494829595088959 \n",
            "OrderedDict({'weights': tensor([0.5405]), 'bias': tensor([0.3670])})\n",
            "Epoch: 19620 | MAE Train Loss: 0.03202196955680847 | MAE Test Loss: 0.07487247884273529 \n",
            "OrderedDict({'weights': tensor([0.5407]), 'bias': tensor([0.3669])})\n",
            "Epoch: 19630 | MAE Train Loss: 0.03198760747909546 | MAE Test Loss: 0.07478638738393784 \n",
            "OrderedDict({'weights': tensor([0.5409]), 'bias': tensor([0.3668])})\n",
            "Epoch: 19640 | MAE Train Loss: 0.03195328265428543 | MAE Test Loss: 0.07471057027578354 \n",
            "OrderedDict({'weights': tensor([0.5410]), 'bias': tensor([0.3668])})\n",
            "Epoch: 19650 | MAE Train Loss: 0.031918901950120926 | MAE Test Loss: 0.07463134825229645 \n",
            "OrderedDict({'weights': tensor([0.5412]), 'bias': tensor([0.3667])})\n",
            "Epoch: 19660 | MAE Train Loss: 0.03188458830118179 | MAE Test Loss: 0.0745486468076706 \n",
            "OrderedDict({'weights': tensor([0.5414]), 'bias': tensor([0.3666])})\n",
            "Epoch: 19670 | MAE Train Loss: 0.0318501852452755 | MAE Test Loss: 0.07446597516536713 \n",
            "OrderedDict({'weights': tensor([0.5416]), 'bias': tensor([0.3665])})\n",
            "Epoch: 19680 | MAE Train Loss: 0.03181581571698189 | MAE Test Loss: 0.07439014315605164 \n",
            "OrderedDict({'weights': tensor([0.5417]), 'bias': tensor([0.3665])})\n",
            "Epoch: 19690 | MAE Train Loss: 0.03178144991397858 | MAE Test Loss: 0.07430405914783478 \n",
            "OrderedDict({'weights': tensor([0.5419]), 'bias': tensor([0.3664])})\n",
            "Epoch: 19700 | MAE Train Loss: 0.03174711391329765 | MAE Test Loss: 0.07422483712434769 \n",
            "OrderedDict({'weights': tensor([0.5421]), 'bias': tensor([0.3663])})\n",
            "Epoch: 19710 | MAE Train Loss: 0.03171274811029434 | MAE Test Loss: 0.0741489976644516 \n",
            "OrderedDict({'weights': tensor([0.5422]), 'bias': tensor([0.3663])})\n",
            "Epoch: 19720 | MAE Train Loss: 0.03167842701077461 | MAE Test Loss: 0.07406634837388992 \n",
            "OrderedDict({'weights': tensor([0.5424]), 'bias': tensor([0.3662])})\n",
            "Epoch: 19730 | MAE Train Loss: 0.031644027680158615 | MAE Test Loss: 0.07398366183042526 \n",
            "OrderedDict({'weights': tensor([0.5426]), 'bias': tensor([0.3661])})\n",
            "Epoch: 19740 | MAE Train Loss: 0.03160969167947769 | MAE Test Loss: 0.07390442490577698 \n",
            "OrderedDict({'weights': tensor([0.5428]), 'bias': tensor([0.3660])})\n",
            "Epoch: 19750 | MAE Train Loss: 0.031575292348861694 | MAE Test Loss: 0.07382520288228989 \n",
            "OrderedDict({'weights': tensor([0.5429]), 'bias': tensor([0.3660])})\n",
            "Epoch: 19760 | MAE Train Loss: 0.031540948897600174 | MAE Test Loss: 0.07374252378940582 \n",
            "OrderedDict({'weights': tensor([0.5431]), 'bias': tensor([0.3659])})\n",
            "Epoch: 19770 | MAE Train Loss: 0.03150659427046776 | MAE Test Loss: 0.07366670668125153 \n",
            "OrderedDict({'weights': tensor([0.5433]), 'bias': tensor([0.3658])})\n",
            "Epoch: 19780 | MAE Train Loss: 0.03147226944565773 | MAE Test Loss: 0.07358401268720627 \n",
            "OrderedDict({'weights': tensor([0.5434]), 'bias': tensor([0.3658])})\n",
            "Epoch: 19790 | MAE Train Loss: 0.031437914818525314 | MAE Test Loss: 0.07350479066371918 \n",
            "OrderedDict({'weights': tensor([0.5436]), 'bias': tensor([0.3657])})\n",
            "Epoch: 19800 | MAE Train Loss: 0.031403522938489914 | MAE Test Loss: 0.07342211902141571 \n",
            "OrderedDict({'weights': tensor([0.5438]), 'bias': tensor([0.3656])})\n",
            "Epoch: 19810 | MAE Train Loss: 0.03136919438838959 | MAE Test Loss: 0.07334287464618683 \n",
            "OrderedDict({'weights': tensor([0.5440]), 'bias': tensor([0.3655])})\n",
            "Epoch: 19820 | MAE Train Loss: 0.03133478760719299 | MAE Test Loss: 0.07326018065214157 \n",
            "OrderedDict({'weights': tensor([0.5441]), 'bias': tensor([0.3655])})\n",
            "Epoch: 19830 | MAE Train Loss: 0.03130044788122177 | MAE Test Loss: 0.07318437844514847 \n",
            "OrderedDict({'weights': tensor([0.5443]), 'bias': tensor([0.3654])})\n",
            "Epoch: 19840 | MAE Train Loss: 0.03126611188054085 | MAE Test Loss: 0.07310166954994202 \n",
            "OrderedDict({'weights': tensor([0.5445]), 'bias': tensor([0.3653])})\n",
            "Epoch: 19850 | MAE Train Loss: 0.031231766566634178 | MAE Test Loss: 0.07302247732877731 \n",
            "OrderedDict({'weights': tensor([0.5446]), 'bias': tensor([0.3653])})\n",
            "Epoch: 19860 | MAE Train Loss: 0.031197374686598778 | MAE Test Loss: 0.07294324040412903 \n",
            "OrderedDict({'weights': tensor([0.5448]), 'bias': tensor([0.3652])})\n",
            "Epoch: 19870 | MAE Train Loss: 0.031163036823272705 | MAE Test Loss: 0.07286054641008377 \n",
            "OrderedDict({'weights': tensor([0.5450]), 'bias': tensor([0.3651])})\n",
            "Epoch: 19880 | MAE Train Loss: 0.031128620728850365 | MAE Test Loss: 0.0727778822183609 \n",
            "OrderedDict({'weights': tensor([0.5451]), 'bias': tensor([0.3650])})\n",
            "Epoch: 19890 | MAE Train Loss: 0.031094294041395187 | MAE Test Loss: 0.0727020651102066 \n",
            "OrderedDict({'weights': tensor([0.5453]), 'bias': tensor([0.3650])})\n",
            "Epoch: 19900 | MAE Train Loss: 0.03105991519987583 | MAE Test Loss: 0.07262282818555832 \n",
            "OrderedDict({'weights': tensor([0.5455]), 'bias': tensor([0.3649])})\n",
            "Epoch: 19910 | MAE Train Loss: 0.03102554939687252 | MAE Test Loss: 0.07253673672676086 \n",
            "OrderedDict({'weights': tensor([0.5457]), 'bias': tensor([0.3648])})\n",
            "Epoch: 19920 | MAE Train Loss: 0.03099122643470764 | MAE Test Loss: 0.07246093451976776 \n",
            "OrderedDict({'weights': tensor([0.5458]), 'bias': tensor([0.3647])})\n",
            "Epoch: 19930 | MAE Train Loss: 0.030956869944930077 | MAE Test Loss: 0.0723782330751419 \n",
            "OrderedDict({'weights': tensor([0.5460]), 'bias': tensor([0.3647])})\n",
            "Epoch: 19940 | MAE Train Loss: 0.030922463163733482 | MAE Test Loss: 0.07229555398225784 \n",
            "OrderedDict({'weights': tensor([0.5462]), 'bias': tensor([0.3646])})\n",
            "Epoch: 19950 | MAE Train Loss: 0.03088812530040741 | MAE Test Loss: 0.07221631705760956 \n",
            "OrderedDict({'weights': tensor([0.5463]), 'bias': tensor([0.3645])})\n",
            "Epoch: 19960 | MAE Train Loss: 0.030853768810629845 | MAE Test Loss: 0.07214048504829407 \n",
            "OrderedDict({'weights': tensor([0.5465]), 'bias': tensor([0.3645])})\n",
            "Epoch: 19970 | MAE Train Loss: 0.030819395557045937 | MAE Test Loss: 0.0720544308423996 \n",
            "OrderedDict({'weights': tensor([0.5467]), 'bias': tensor([0.3644])})\n",
            "Epoch: 19980 | MAE Train Loss: 0.030785078182816505 | MAE Test Loss: 0.0719786137342453 \n",
            "OrderedDict({'weights': tensor([0.5469]), 'bias': tensor([0.3643])})\n",
            "Epoch: 19990 | MAE Train Loss: 0.030750703066587448 | MAE Test Loss: 0.07189591228961945 \n",
            "OrderedDict({'weights': tensor([0.5470]), 'bias': tensor([0.3642])})\n",
            "Epoch: 20000 | MAE Train Loss: 0.030716296285390854 | MAE Test Loss: 0.07181669771671295 \n",
            "OrderedDict({'weights': tensor([0.5472]), 'bias': tensor([0.3642])})\n",
            "Epoch: 20010 | MAE Train Loss: 0.03068196214735508 | MAE Test Loss: 0.07173401117324829 \n",
            "OrderedDict({'weights': tensor([0.5474]), 'bias': tensor([0.3641])})\n",
            "Epoch: 20020 | MAE Train Loss: 0.030647629871964455 | MAE Test Loss: 0.0716547816991806 \n",
            "OrderedDict({'weights': tensor([0.5475]), 'bias': tensor([0.3640])})\n",
            "Epoch: 20030 | MAE Train Loss: 0.03061322495341301 | MAE Test Loss: 0.0715789645910263 \n",
            "OrderedDict({'weights': tensor([0.5477]), 'bias': tensor([0.3640])})\n",
            "Epoch: 20040 | MAE Train Loss: 0.03057892620563507 | MAE Test Loss: 0.07149627804756165 \n",
            "OrderedDict({'weights': tensor([0.5479]), 'bias': tensor([0.3639])})\n",
            "Epoch: 20050 | MAE Train Loss: 0.030544545501470566 | MAE Test Loss: 0.07141359895467758 \n",
            "OrderedDict({'weights': tensor([0.5481]), 'bias': tensor([0.3638])})\n",
            "Epoch: 20060 | MAE Train Loss: 0.030510207638144493 | MAE Test Loss: 0.0713343694806099 \n",
            "OrderedDict({'weights': tensor([0.5482]), 'bias': tensor([0.3637])})\n",
            "Epoch: 20070 | MAE Train Loss: 0.030475858598947525 | MAE Test Loss: 0.07125513255596161 \n",
            "OrderedDict({'weights': tensor([0.5484]), 'bias': tensor([0.3637])})\n",
            "Epoch: 20080 | MAE Train Loss: 0.03044147416949272 | MAE Test Loss: 0.07117246091365814 \n",
            "OrderedDict({'weights': tensor([0.5486]), 'bias': tensor([0.3636])})\n",
            "Epoch: 20090 | MAE Train Loss: 0.030407080426812172 | MAE Test Loss: 0.07109664380550385 \n",
            "OrderedDict({'weights': tensor([0.5487]), 'bias': tensor([0.3635])})\n",
            "Epoch: 20100 | MAE Train Loss: 0.030372777953743935 | MAE Test Loss: 0.07101397216320038 \n",
            "OrderedDict({'weights': tensor([0.5489]), 'bias': tensor([0.3635])})\n",
            "Epoch: 20110 | MAE Train Loss: 0.03033839538693428 | MAE Test Loss: 0.0709347277879715 \n",
            "OrderedDict({'weights': tensor([0.5491]), 'bias': tensor([0.3634])})\n",
            "Epoch: 20120 | MAE Train Loss: 0.030304040759801865 | MAE Test Loss: 0.07085202634334564 \n",
            "OrderedDict({'weights': tensor([0.5493]), 'bias': tensor([0.3633])})\n",
            "Epoch: 20130 | MAE Train Loss: 0.030269697308540344 | MAE Test Loss: 0.07077282667160034 \n",
            "OrderedDict({'weights': tensor([0.5494]), 'bias': tensor([0.3632])})\n",
            "Epoch: 20140 | MAE Train Loss: 0.030235309153795242 | MAE Test Loss: 0.07069014012813568 \n",
            "OrderedDict({'weights': tensor([0.5496]), 'bias': tensor([0.3632])})\n",
            "Epoch: 20150 | MAE Train Loss: 0.030200928449630737 | MAE Test Loss: 0.07061432301998138 \n",
            "OrderedDict({'weights': tensor([0.5498]), 'bias': tensor([0.3631])})\n",
            "Epoch: 20160 | MAE Train Loss: 0.030166566371917725 | MAE Test Loss: 0.07052823901176453 \n",
            "OrderedDict({'weights': tensor([0.5499]), 'bias': tensor([0.3630])})\n",
            "Epoch: 20170 | MAE Train Loss: 0.030132239684462547 | MAE Test Loss: 0.07045241445302963 \n",
            "OrderedDict({'weights': tensor([0.5501]), 'bias': tensor([0.3630])})\n",
            "Epoch: 20180 | MAE Train Loss: 0.030097857117652893 | MAE Test Loss: 0.07037318497896194 \n",
            "OrderedDict({'weights': tensor([0.5503]), 'bias': tensor([0.3629])})\n",
            "Epoch: 20190 | MAE Train Loss: 0.030063549056649208 | MAE Test Loss: 0.07029049098491669 \n",
            "OrderedDict({'weights': tensor([0.5504]), 'bias': tensor([0.3628])})\n",
            "Epoch: 20200 | MAE Train Loss: 0.030029144138097763 | MAE Test Loss: 0.07020781934261322 \n",
            "OrderedDict({'weights': tensor([0.5506]), 'bias': tensor([0.3627])})\n",
            "Epoch: 20210 | MAE Train Loss: 0.029994774609804153 | MAE Test Loss: 0.07013198733329773 \n",
            "OrderedDict({'weights': tensor([0.5508]), 'bias': tensor([0.3627])})\n",
            "Epoch: 20220 | MAE Train Loss: 0.029960408806800842 | MAE Test Loss: 0.07004590332508087 \n",
            "OrderedDict({'weights': tensor([0.5510]), 'bias': tensor([0.3626])})\n",
            "Epoch: 20230 | MAE Train Loss: 0.02992607280611992 | MAE Test Loss: 0.06996668130159378 \n",
            "OrderedDict({'weights': tensor([0.5511]), 'bias': tensor([0.3625])})\n",
            "Epoch: 20240 | MAE Train Loss: 0.029891708865761757 | MAE Test Loss: 0.06989084184169769 \n",
            "OrderedDict({'weights': tensor([0.5513]), 'bias': tensor([0.3625])})\n",
            "Epoch: 20250 | MAE Train Loss: 0.029857385903596878 | MAE Test Loss: 0.06980818510055542 \n",
            "OrderedDict({'weights': tensor([0.5515]), 'bias': tensor([0.3624])})\n",
            "Epoch: 20260 | MAE Train Loss: 0.02982298657298088 | MAE Test Loss: 0.06972550600767136 \n",
            "OrderedDict({'weights': tensor([0.5516]), 'bias': tensor([0.3623])})\n",
            "Epoch: 20270 | MAE Train Loss: 0.029788648709654808 | MAE Test Loss: 0.06964626908302307 \n",
            "OrderedDict({'weights': tensor([0.5518]), 'bias': tensor([0.3622])})\n",
            "Epoch: 20280 | MAE Train Loss: 0.02975425124168396 | MAE Test Loss: 0.06956705451011658 \n",
            "OrderedDict({'weights': tensor([0.5520]), 'bias': tensor([0.3622])})\n",
            "Epoch: 20290 | MAE Train Loss: 0.02971990779042244 | MAE Test Loss: 0.06948436796665192 \n",
            "OrderedDict({'weights': tensor([0.5522]), 'bias': tensor([0.3621])})\n",
            "Epoch: 20300 | MAE Train Loss: 0.029685553163290024 | MAE Test Loss: 0.06940855085849762 \n",
            "OrderedDict({'weights': tensor([0.5523]), 'bias': tensor([0.3620])})\n",
            "Epoch: 20310 | MAE Train Loss: 0.029651228338479996 | MAE Test Loss: 0.06932585686445236 \n",
            "OrderedDict({'weights': tensor([0.5525]), 'bias': tensor([0.3620])})\n",
            "Epoch: 20320 | MAE Train Loss: 0.02961687371134758 | MAE Test Loss: 0.06924663484096527 \n",
            "OrderedDict({'weights': tensor([0.5527]), 'bias': tensor([0.3619])})\n",
            "Epoch: 20330 | MAE Train Loss: 0.02958248183131218 | MAE Test Loss: 0.0691639631986618 \n",
            "OrderedDict({'weights': tensor([0.5528]), 'bias': tensor([0.3618])})\n",
            "Epoch: 20340 | MAE Train Loss: 0.029548153281211853 | MAE Test Loss: 0.06908471882343292 \n",
            "OrderedDict({'weights': tensor([0.5530]), 'bias': tensor([0.3617])})\n",
            "Epoch: 20350 | MAE Train Loss: 0.02951374650001526 | MAE Test Loss: 0.06900202482938766 \n",
            "OrderedDict({'weights': tensor([0.5532]), 'bias': tensor([0.3617])})\n",
            "Epoch: 20360 | MAE Train Loss: 0.029479404911398888 | MAE Test Loss: 0.06892622262239456 \n",
            "OrderedDict({'weights': tensor([0.5534]), 'bias': tensor([0.3616])})\n",
            "Epoch: 20370 | MAE Train Loss: 0.029445070773363113 | MAE Test Loss: 0.06884351372718811 \n",
            "OrderedDict({'weights': tensor([0.5535]), 'bias': tensor([0.3615])})\n",
            "Epoch: 20380 | MAE Train Loss: 0.029410725459456444 | MAE Test Loss: 0.06876432150602341 \n",
            "OrderedDict({'weights': tensor([0.5537]), 'bias': tensor([0.3614])})\n",
            "Epoch: 20390 | MAE Train Loss: 0.029376333579421043 | MAE Test Loss: 0.06868508458137512 \n",
            "OrderedDict({'weights': tensor([0.5539]), 'bias': tensor([0.3614])})\n",
            "Epoch: 20400 | MAE Train Loss: 0.02934199571609497 | MAE Test Loss: 0.06860239058732986 \n",
            "OrderedDict({'weights': tensor([0.5540]), 'bias': tensor([0.3613])})\n",
            "Epoch: 20410 | MAE Train Loss: 0.02930757962167263 | MAE Test Loss: 0.068519726395607 \n",
            "OrderedDict({'weights': tensor([0.5542]), 'bias': tensor([0.3612])})\n",
            "Epoch: 20420 | MAE Train Loss: 0.029273252934217453 | MAE Test Loss: 0.0684439092874527 \n",
            "OrderedDict({'weights': tensor([0.5544]), 'bias': tensor([0.3612])})\n",
            "Epoch: 20430 | MAE Train Loss: 0.029238874092698097 | MAE Test Loss: 0.06836467236280441 \n",
            "OrderedDict({'weights': tensor([0.5545]), 'bias': tensor([0.3611])})\n",
            "Epoch: 20440 | MAE Train Loss: 0.029204508289694786 | MAE Test Loss: 0.06827858090400696 \n",
            "OrderedDict({'weights': tensor([0.5547]), 'bias': tensor([0.3610])})\n",
            "Epoch: 20450 | MAE Train Loss: 0.029170189052820206 | MAE Test Loss: 0.06820277869701385 \n",
            "OrderedDict({'weights': tensor([0.5549]), 'bias': tensor([0.3609])})\n",
            "Epoch: 20460 | MAE Train Loss: 0.029135828837752342 | MAE Test Loss: 0.068120077252388 \n",
            "OrderedDict({'weights': tensor([0.5551]), 'bias': tensor([0.3609])})\n",
            "Epoch: 20470 | MAE Train Loss: 0.029101422056555748 | MAE Test Loss: 0.06803739815950394 \n",
            "OrderedDict({'weights': tensor([0.5552]), 'bias': tensor([0.3608])})\n",
            "Epoch: 20480 | MAE Train Loss: 0.029067084193229675 | MAE Test Loss: 0.06795816123485565 \n",
            "OrderedDict({'weights': tensor([0.5554]), 'bias': tensor([0.3607])})\n",
            "Epoch: 20490 | MAE Train Loss: 0.02903272770345211 | MAE Test Loss: 0.06788232922554016 \n",
            "OrderedDict({'weights': tensor([0.5556]), 'bias': tensor([0.3607])})\n",
            "Epoch: 20500 | MAE Train Loss: 0.028998354449868202 | MAE Test Loss: 0.06779627501964569 \n",
            "OrderedDict({'weights': tensor([0.5557]), 'bias': tensor([0.3606])})\n",
            "Epoch: 20510 | MAE Train Loss: 0.02896403707563877 | MAE Test Loss: 0.0677204579114914 \n",
            "OrderedDict({'weights': tensor([0.5559]), 'bias': tensor([0.3605])})\n",
            "Epoch: 20520 | MAE Train Loss: 0.028929661959409714 | MAE Test Loss: 0.06763775646686554 \n",
            "OrderedDict({'weights': tensor([0.5561]), 'bias': tensor([0.3604])})\n",
            "Epoch: 20530 | MAE Train Loss: 0.02889525517821312 | MAE Test Loss: 0.06755854189395905 \n",
            "OrderedDict({'weights': tensor([0.5563]), 'bias': tensor([0.3604])})\n",
            "Epoch: 20540 | MAE Train Loss: 0.028860921040177345 | MAE Test Loss: 0.06747585535049438 \n",
            "OrderedDict({'weights': tensor([0.5564]), 'bias': tensor([0.3603])})\n",
            "Epoch: 20550 | MAE Train Loss: 0.02882658876478672 | MAE Test Loss: 0.0673966184258461 \n",
            "OrderedDict({'weights': tensor([0.5566]), 'bias': tensor([0.3602])})\n",
            "Epoch: 20560 | MAE Train Loss: 0.028792183846235275 | MAE Test Loss: 0.0673208087682724 \n",
            "OrderedDict({'weights': tensor([0.5568]), 'bias': tensor([0.3602])})\n",
            "Epoch: 20570 | MAE Train Loss: 0.028757885098457336 | MAE Test Loss: 0.06723812222480774 \n",
            "OrderedDict({'weights': tensor([0.5569]), 'bias': tensor([0.3601])})\n",
            "Epoch: 20580 | MAE Train Loss: 0.02872350439429283 | MAE Test Loss: 0.06715544313192368 \n",
            "OrderedDict({'weights': tensor([0.5571]), 'bias': tensor([0.3600])})\n",
            "Epoch: 20590 | MAE Train Loss: 0.02868916653096676 | MAE Test Loss: 0.06707621365785599 \n",
            "OrderedDict({'weights': tensor([0.5573]), 'bias': tensor([0.3599])})\n",
            "Epoch: 20600 | MAE Train Loss: 0.02865481749176979 | MAE Test Loss: 0.0669969767332077 \n",
            "OrderedDict({'weights': tensor([0.5575]), 'bias': tensor([0.3599])})\n",
            "Epoch: 20610 | MAE Train Loss: 0.028620433062314987 | MAE Test Loss: 0.06691430509090424 \n",
            "OrderedDict({'weights': tensor([0.5576]), 'bias': tensor([0.3598])})\n",
            "Epoch: 20620 | MAE Train Loss: 0.028586039319634438 | MAE Test Loss: 0.06683848798274994 \n",
            "OrderedDict({'weights': tensor([0.5578]), 'bias': tensor([0.3597])})\n",
            "Epoch: 20630 | MAE Train Loss: 0.0285517368465662 | MAE Test Loss: 0.06675581634044647 \n",
            "OrderedDict({'weights': tensor([0.5580]), 'bias': tensor([0.3597])})\n",
            "Epoch: 20640 | MAE Train Loss: 0.028517354279756546 | MAE Test Loss: 0.06667657196521759 \n",
            "OrderedDict({'weights': tensor([0.5581]), 'bias': tensor([0.3596])})\n",
            "Epoch: 20650 | MAE Train Loss: 0.02848299965262413 | MAE Test Loss: 0.06659387052059174 \n",
            "OrderedDict({'weights': tensor([0.5583]), 'bias': tensor([0.3595])})\n",
            "Epoch: 20660 | MAE Train Loss: 0.02844865620136261 | MAE Test Loss: 0.06651467084884644 \n",
            "OrderedDict({'weights': tensor([0.5585]), 'bias': tensor([0.3594])})\n",
            "Epoch: 20670 | MAE Train Loss: 0.028414268046617508 | MAE Test Loss: 0.06643198430538177 \n",
            "OrderedDict({'weights': tensor([0.5587]), 'bias': tensor([0.3594])})\n",
            "Epoch: 20680 | MAE Train Loss: 0.028379887342453003 | MAE Test Loss: 0.06635616719722748 \n",
            "OrderedDict({'weights': tensor([0.5588]), 'bias': tensor([0.3593])})\n",
            "Epoch: 20690 | MAE Train Loss: 0.02834552526473999 | MAE Test Loss: 0.06627007573843002 \n",
            "OrderedDict({'weights': tensor([0.5590]), 'bias': tensor([0.3592])})\n",
            "Epoch: 20700 | MAE Train Loss: 0.028311198577284813 | MAE Test Loss: 0.06619425863027573 \n",
            "OrderedDict({'weights': tensor([0.5592]), 'bias': tensor([0.3591])})\n",
            "Epoch: 20710 | MAE Train Loss: 0.02827681601047516 | MAE Test Loss: 0.06611502915620804 \n",
            "OrderedDict({'weights': tensor([0.5593]), 'bias': tensor([0.3591])})\n",
            "Epoch: 20720 | MAE Train Loss: 0.028242507949471474 | MAE Test Loss: 0.06603233516216278 \n",
            "OrderedDict({'weights': tensor([0.5595]), 'bias': tensor([0.3590])})\n",
            "Epoch: 20730 | MAE Train Loss: 0.02820810303092003 | MAE Test Loss: 0.06594966351985931 \n",
            "OrderedDict({'weights': tensor([0.5597]), 'bias': tensor([0.3589])})\n",
            "Epoch: 20740 | MAE Train Loss: 0.02817373350262642 | MAE Test Loss: 0.06587383151054382 \n",
            "OrderedDict({'weights': tensor([0.5598]), 'bias': tensor([0.3589])})\n",
            "Epoch: 20750 | MAE Train Loss: 0.028139367699623108 | MAE Test Loss: 0.06578774750232697 \n",
            "OrderedDict({'weights': tensor([0.5600]), 'bias': tensor([0.3588])})\n",
            "Epoch: 20760 | MAE Train Loss: 0.028105031698942184 | MAE Test Loss: 0.06570851802825928 \n",
            "OrderedDict({'weights': tensor([0.5602]), 'bias': tensor([0.3587])})\n",
            "Epoch: 20770 | MAE Train Loss: 0.028070667758584023 | MAE Test Loss: 0.06563268601894379 \n",
            "OrderedDict({'weights': tensor([0.5604]), 'bias': tensor([0.3586])})\n",
            "Epoch: 20780 | MAE Train Loss: 0.028036344796419144 | MAE Test Loss: 0.06555002927780151 \n",
            "OrderedDict({'weights': tensor([0.5605]), 'bias': tensor([0.3586])})\n",
            "Epoch: 20790 | MAE Train Loss: 0.028001945465803146 | MAE Test Loss: 0.06546735018491745 \n",
            "OrderedDict({'weights': tensor([0.5607]), 'bias': tensor([0.3585])})\n",
            "Epoch: 20800 | MAE Train Loss: 0.027967607602477074 | MAE Test Loss: 0.06538811326026917 \n",
            "OrderedDict({'weights': tensor([0.5609]), 'bias': tensor([0.3584])})\n",
            "Epoch: 20810 | MAE Train Loss: 0.027933210134506226 | MAE Test Loss: 0.06530889123678207 \n",
            "OrderedDict({'weights': tensor([0.5610]), 'bias': tensor([0.3584])})\n",
            "Epoch: 20820 | MAE Train Loss: 0.027898866683244705 | MAE Test Loss: 0.06522620469331741 \n",
            "OrderedDict({'weights': tensor([0.5612]), 'bias': tensor([0.3583])})\n",
            "Epoch: 20830 | MAE Train Loss: 0.02786451205611229 | MAE Test Loss: 0.06515039503574371 \n",
            "OrderedDict({'weights': tensor([0.5614]), 'bias': tensor([0.3582])})\n",
            "Epoch: 20840 | MAE Train Loss: 0.027830183506011963 | MAE Test Loss: 0.06506770104169846 \n",
            "OrderedDict({'weights': tensor([0.5616]), 'bias': tensor([0.3581])})\n",
            "Epoch: 20850 | MAE Train Loss: 0.027795832604169846 | MAE Test Loss: 0.06498847901821136 \n",
            "OrderedDict({'weights': tensor([0.5617]), 'bias': tensor([0.3581])})\n",
            "Epoch: 20860 | MAE Train Loss: 0.027761440724134445 | MAE Test Loss: 0.0649058073759079 \n",
            "OrderedDict({'weights': tensor([0.5619]), 'bias': tensor([0.3580])})\n",
            "Epoch: 20870 | MAE Train Loss: 0.02772711217403412 | MAE Test Loss: 0.06482656300067902 \n",
            "OrderedDict({'weights': tensor([0.5621]), 'bias': tensor([0.3579])})\n",
            "Epoch: 20880 | MAE Train Loss: 0.027692705392837524 | MAE Test Loss: 0.06474386900663376 \n",
            "OrderedDict({'weights': tensor([0.5622]), 'bias': tensor([0.3579])})\n",
            "Epoch: 20890 | MAE Train Loss: 0.027658363804221153 | MAE Test Loss: 0.06466806679964066 \n",
            "OrderedDict({'weights': tensor([0.5624]), 'bias': tensor([0.3578])})\n",
            "Epoch: 20900 | MAE Train Loss: 0.02762402966618538 | MAE Test Loss: 0.0645853579044342 \n",
            "OrderedDict({'weights': tensor([0.5626]), 'bias': tensor([0.3577])})\n",
            "Epoch: 20910 | MAE Train Loss: 0.02758968435227871 | MAE Test Loss: 0.0645061656832695 \n",
            "OrderedDict({'weights': tensor([0.5628]), 'bias': tensor([0.3576])})\n",
            "Epoch: 20920 | MAE Train Loss: 0.02755529247224331 | MAE Test Loss: 0.06442692875862122 \n",
            "OrderedDict({'weights': tensor([0.5629]), 'bias': tensor([0.3576])})\n",
            "Epoch: 20930 | MAE Train Loss: 0.027520954608917236 | MAE Test Loss: 0.06434423476457596 \n",
            "OrderedDict({'weights': tensor([0.5631]), 'bias': tensor([0.3575])})\n",
            "Epoch: 20940 | MAE Train Loss: 0.027486538514494896 | MAE Test Loss: 0.06426157057285309 \n",
            "OrderedDict({'weights': tensor([0.5633]), 'bias': tensor([0.3574])})\n",
            "Epoch: 20950 | MAE Train Loss: 0.02745221182703972 | MAE Test Loss: 0.06418575346469879 \n",
            "OrderedDict({'weights': tensor([0.5634]), 'bias': tensor([0.3574])})\n",
            "Epoch: 20960 | MAE Train Loss: 0.027417832985520363 | MAE Test Loss: 0.0641065165400505 \n",
            "OrderedDict({'weights': tensor([0.5636]), 'bias': tensor([0.3573])})\n",
            "Epoch: 20970 | MAE Train Loss: 0.02738347090780735 | MAE Test Loss: 0.06402041763067245 \n",
            "OrderedDict({'weights': tensor([0.5638]), 'bias': tensor([0.3572])})\n",
            "Epoch: 20980 | MAE Train Loss: 0.02734914794564247 | MAE Test Loss: 0.06394462287425995 \n",
            "OrderedDict({'weights': tensor([0.5640]), 'bias': tensor([0.3571])})\n",
            "Epoch: 20990 | MAE Train Loss: 0.027314787730574608 | MAE Test Loss: 0.0638619214296341 \n",
            "OrderedDict({'weights': tensor([0.5641]), 'bias': tensor([0.3571])})\n",
            "Epoch: 21000 | MAE Train Loss: 0.027280380949378014 | MAE Test Loss: 0.06377924233675003 \n",
            "OrderedDict({'weights': tensor([0.5643]), 'bias': tensor([0.3570])})\n",
            "Epoch: 21010 | MAE Train Loss: 0.02724604308605194 | MAE Test Loss: 0.06370000541210175 \n",
            "OrderedDict({'weights': tensor([0.5645]), 'bias': tensor([0.3569])})\n",
            "Epoch: 21020 | MAE Train Loss: 0.027211686596274376 | MAE Test Loss: 0.06362417340278625 \n",
            "OrderedDict({'weights': tensor([0.5646]), 'bias': tensor([0.3569])})\n",
            "Epoch: 21030 | MAE Train Loss: 0.027177313342690468 | MAE Test Loss: 0.06353811919689178 \n",
            "OrderedDict({'weights': tensor([0.5648]), 'bias': tensor([0.3568])})\n",
            "Epoch: 21040 | MAE Train Loss: 0.027142995968461037 | MAE Test Loss: 0.06346230208873749 \n",
            "OrderedDict({'weights': tensor([0.5650]), 'bias': tensor([0.3567])})\n",
            "Epoch: 21050 | MAE Train Loss: 0.02710862085223198 | MAE Test Loss: 0.06337960064411163 \n",
            "OrderedDict({'weights': tensor([0.5651]), 'bias': tensor([0.3566])})\n",
            "Epoch: 21060 | MAE Train Loss: 0.027074214071035385 | MAE Test Loss: 0.06330038607120514 \n",
            "OrderedDict({'weights': tensor([0.5653]), 'bias': tensor([0.3566])})\n",
            "Epoch: 21070 | MAE Train Loss: 0.02703987993299961 | MAE Test Loss: 0.06321769952774048 \n",
            "OrderedDict({'weights': tensor([0.5655]), 'bias': tensor([0.3565])})\n",
            "Epoch: 21080 | MAE Train Loss: 0.027005547657608986 | MAE Test Loss: 0.0631384626030922 \n",
            "OrderedDict({'weights': tensor([0.5657]), 'bias': tensor([0.3564])})\n",
            "Epoch: 21090 | MAE Train Loss: 0.02697114646434784 | MAE Test Loss: 0.0630626529455185 \n",
            "OrderedDict({'weights': tensor([0.5658]), 'bias': tensor([0.3563])})\n",
            "Epoch: 21100 | MAE Train Loss: 0.0269368477165699 | MAE Test Loss: 0.06297996640205383 \n",
            "OrderedDict({'weights': tensor([0.5660]), 'bias': tensor([0.3563])})\n",
            "Epoch: 21110 | MAE Train Loss: 0.026902463287115097 | MAE Test Loss: 0.06289728730916977 \n",
            "OrderedDict({'weights': tensor([0.5662]), 'bias': tensor([0.3562])})\n",
            "Epoch: 21120 | MAE Train Loss: 0.026868125423789024 | MAE Test Loss: 0.06281805783510208 \n",
            "OrderedDict({'weights': tensor([0.5663]), 'bias': tensor([0.3561])})\n",
            "Epoch: 21130 | MAE Train Loss: 0.026833772659301758 | MAE Test Loss: 0.0627388209104538 \n",
            "OrderedDict({'weights': tensor([0.5665]), 'bias': tensor([0.3561])})\n",
            "Epoch: 21140 | MAE Train Loss: 0.026799391955137253 | MAE Test Loss: 0.06265614926815033 \n",
            "OrderedDict({'weights': tensor([0.5667]), 'bias': tensor([0.3560])})\n",
            "Epoch: 21150 | MAE Train Loss: 0.026764998212456703 | MAE Test Loss: 0.06258033215999603 \n",
            "OrderedDict({'weights': tensor([0.5669]), 'bias': tensor([0.3559])})\n",
            "Epoch: 21160 | MAE Train Loss: 0.026730695739388466 | MAE Test Loss: 0.062497664242982864 \n",
            "OrderedDict({'weights': tensor([0.5670]), 'bias': tensor([0.3558])})\n",
            "Epoch: 21170 | MAE Train Loss: 0.02669631317257881 | MAE Test Loss: 0.06241841986775398 \n",
            "OrderedDict({'weights': tensor([0.5672]), 'bias': tensor([0.3558])})\n",
            "Epoch: 21180 | MAE Train Loss: 0.026661958545446396 | MAE Test Loss: 0.06233571842312813 \n",
            "OrderedDict({'weights': tensor([0.5674]), 'bias': tensor([0.3557])})\n",
            "Epoch: 21190 | MAE Train Loss: 0.026627615094184875 | MAE Test Loss: 0.06225651502609253 \n",
            "OrderedDict({'weights': tensor([0.5675]), 'bias': tensor([0.3556])})\n",
            "Epoch: 21200 | MAE Train Loss: 0.026593226939439774 | MAE Test Loss: 0.06217382475733757 \n",
            "OrderedDict({'weights': tensor([0.5677]), 'bias': tensor([0.3556])})\n",
            "Epoch: 21210 | MAE Train Loss: 0.02655884623527527 | MAE Test Loss: 0.06209801509976387 \n",
            "OrderedDict({'weights': tensor([0.5679]), 'bias': tensor([0.3555])})\n",
            "Epoch: 21220 | MAE Train Loss: 0.026524484157562256 | MAE Test Loss: 0.06201191991567612 \n",
            "OrderedDict({'weights': tensor([0.5681]), 'bias': tensor([0.3554])})\n",
            "Epoch: 21230 | MAE Train Loss: 0.02649015747010708 | MAE Test Loss: 0.06193610280752182 \n",
            "OrderedDict({'weights': tensor([0.5682]), 'bias': tensor([0.3553])})\n",
            "Epoch: 21240 | MAE Train Loss: 0.026455774903297424 | MAE Test Loss: 0.06185687333345413 \n",
            "OrderedDict({'weights': tensor([0.5684]), 'bias': tensor([0.3553])})\n",
            "Epoch: 21250 | MAE Train Loss: 0.02642146870493889 | MAE Test Loss: 0.06177418306469917 \n",
            "OrderedDict({'weights': tensor([0.5686]), 'bias': tensor([0.3552])})\n",
            "Epoch: 21260 | MAE Train Loss: 0.026387061923742294 | MAE Test Loss: 0.06169150397181511 \n",
            "OrderedDict({'weights': tensor([0.5687]), 'bias': tensor([0.3551])})\n",
            "Epoch: 21270 | MAE Train Loss: 0.026352692395448685 | MAE Test Loss: 0.06161567568778992 \n",
            "OrderedDict({'weights': tensor([0.5689]), 'bias': tensor([0.3551])})\n",
            "Epoch: 21280 | MAE Train Loss: 0.0263183806091547 | MAE Test Loss: 0.06153300404548645 \n",
            "OrderedDict({'weights': tensor([0.5691]), 'bias': tensor([0.3550])})\n",
            "Epoch: 21290 | MAE Train Loss: 0.026283975690603256 | MAE Test Loss: 0.061450324952602386 \n",
            "OrderedDict({'weights': tensor([0.5693]), 'bias': tensor([0.3549])})\n",
            "Epoch: 21300 | MAE Train Loss: 0.026249613612890244 | MAE Test Loss: 0.061374515295028687 \n",
            "OrderedDict({'weights': tensor([0.5694]), 'bias': tensor([0.3548])})\n",
            "Epoch: 21310 | MAE Train Loss: 0.026215290650725365 | MAE Test Loss: 0.06129181385040283 \n",
            "OrderedDict({'weights': tensor([0.5696]), 'bias': tensor([0.3548])})\n",
            "Epoch: 21320 | MAE Train Loss: 0.02618088759481907 | MAE Test Loss: 0.061209142208099365 \n",
            "OrderedDict({'weights': tensor([0.5698]), 'bias': tensor([0.3547])})\n",
            "Epoch: 21330 | MAE Train Loss: 0.026146555319428444 | MAE Test Loss: 0.06112990900874138 \n",
            "OrderedDict({'weights': tensor([0.5699]), 'bias': tensor([0.3546])})\n",
            "Epoch: 21340 | MAE Train Loss: 0.02611214481294155 | MAE Test Loss: 0.06105408817529678 \n",
            "OrderedDict({'weights': tensor([0.5701]), 'bias': tensor([0.3546])})\n",
            "Epoch: 21350 | MAE Train Loss: 0.02607785165309906 | MAE Test Loss: 0.06097140908241272 \n",
            "OrderedDict({'weights': tensor([0.5703]), 'bias': tensor([0.3545])})\n",
            "Epoch: 21360 | MAE Train Loss: 0.026043469086289406 | MAE Test Loss: 0.060888707637786865 \n",
            "OrderedDict({'weights': tensor([0.5704]), 'bias': tensor([0.3544])})\n",
            "Epoch: 21370 | MAE Train Loss: 0.026009071618318558 | MAE Test Loss: 0.06081288307905197 \n",
            "OrderedDict({'weights': tensor([0.5706]), 'bias': tensor([0.3543])})\n",
            "Epoch: 21380 | MAE Train Loss: 0.02597476914525032 | MAE Test Loss: 0.060730207711458206 \n",
            "OrderedDict({'weights': tensor([0.5708]), 'bias': tensor([0.3543])})\n",
            "Epoch: 21390 | MAE Train Loss: 0.025940388441085815 | MAE Test Loss: 0.06064753606915474 \n",
            "OrderedDict({'weights': tensor([0.5710]), 'bias': tensor([0.3542])})\n",
            "Epoch: 21400 | MAE Train Loss: 0.025905990973114967 | MAE Test Loss: 0.060571711510419846 \n",
            "OrderedDict({'weights': tensor([0.5711]), 'bias': tensor([0.3541])})\n",
            "Epoch: 21410 | MAE Train Loss: 0.02587169036269188 | MAE Test Loss: 0.060489047318696976 \n",
            "OrderedDict({'weights': tensor([0.5713]), 'bias': tensor([0.3541])})\n",
            "Epoch: 21420 | MAE Train Loss: 0.02583729662001133 | MAE Test Loss: 0.06040634587407112 \n",
            "OrderedDict({'weights': tensor([0.5715]), 'bias': tensor([0.3540])})\n",
            "Epoch: 21430 | MAE Train Loss: 0.025802915915846825 | MAE Test Loss: 0.06033053994178772 \n",
            "OrderedDict({'weights': tensor([0.5716]), 'bias': tensor([0.3539])})\n",
            "Epoch: 21440 | MAE Train Loss: 0.025768613442778587 | MAE Test Loss: 0.06024784594774246 \n",
            "OrderedDict({'weights': tensor([0.5718]), 'bias': tensor([0.3538])})\n",
            "Epoch: 21450 | MAE Train Loss: 0.025734206661581993 | MAE Test Loss: 0.060165148228406906 \n",
            "OrderedDict({'weights': tensor([0.5720]), 'bias': tensor([0.3538])})\n",
            "Epoch: 21460 | MAE Train Loss: 0.025699835270643234 | MAE Test Loss: 0.060089342296123505 \n",
            "OrderedDict({'weights': tensor([0.5722]), 'bias': tensor([0.3537])})\n",
            "Epoch: 21470 | MAE Train Loss: 0.025665471330285072 | MAE Test Loss: 0.06000325828790665 \n",
            "OrderedDict({'weights': tensor([0.5723]), 'bias': tensor([0.3536])})\n",
            "Epoch: 21480 | MAE Train Loss: 0.025631148368120193 | MAE Test Loss: 0.05992742255330086 \n",
            "OrderedDict({'weights': tensor([0.5725]), 'bias': tensor([0.3535])})\n",
            "Epoch: 21490 | MAE Train Loss: 0.02559679187834263 | MAE Test Loss: 0.05984475463628769 \n",
            "OrderedDict({'weights': tensor([0.5727]), 'bias': tensor([0.3535])})\n",
            "Epoch: 21500 | MAE Train Loss: 0.025562386959791183 | MAE Test Loss: 0.05976206809282303 \n",
            "OrderedDict({'weights': tensor([0.5728]), 'bias': tensor([0.3534])})\n",
            "Epoch: 21510 | MAE Train Loss: 0.025528067722916603 | MAE Test Loss: 0.05968623608350754 \n",
            "OrderedDict({'weights': tensor([0.5730]), 'bias': tensor([0.3533])})\n",
            "Epoch: 21520 | MAE Train Loss: 0.02549370564520359 | MAE Test Loss: 0.05960354954004288 \n",
            "OrderedDict({'weights': tensor([0.5732]), 'bias': tensor([0.3533])})\n",
            "Epoch: 21530 | MAE Train Loss: 0.025459300726652145 | MAE Test Loss: 0.059520889073610306 \n",
            "OrderedDict({'weights': tensor([0.5734]), 'bias': tensor([0.3532])})\n",
            "Epoch: 21540 | MAE Train Loss: 0.025424987077713013 | MAE Test Loss: 0.05944506451487541 \n",
            "OrderedDict({'weights': tensor([0.5735]), 'bias': tensor([0.3531])})\n",
            "Epoch: 21550 | MAE Train Loss: 0.025390613824129105 | MAE Test Loss: 0.05936237424612045 \n",
            "OrderedDict({'weights': tensor([0.5737]), 'bias': tensor([0.3530])})\n",
            "Epoch: 21560 | MAE Train Loss: 0.02535620890557766 | MAE Test Loss: 0.0592796616256237 \n",
            "OrderedDict({'weights': tensor([0.5739]), 'bias': tensor([0.3530])})\n",
            "Epoch: 21570 | MAE Train Loss: 0.025321906432509422 | MAE Test Loss: 0.059203874319791794 \n",
            "OrderedDict({'weights': tensor([0.5740]), 'bias': tensor([0.3529])})\n",
            "Epoch: 21580 | MAE Train Loss: 0.025287533178925514 | MAE Test Loss: 0.059121184051036835 \n",
            "OrderedDict({'weights': tensor([0.5742]), 'bias': tensor([0.3528])})\n",
            "Epoch: 21590 | MAE Train Loss: 0.025253131985664368 | MAE Test Loss: 0.059045374393463135 \n",
            "OrderedDict({'weights': tensor([0.5744]), 'bias': tensor([0.3528])})\n",
            "Epoch: 21600 | MAE Train Loss: 0.025218825787305832 | MAE Test Loss: 0.05896268039941788 \n",
            "OrderedDict({'weights': tensor([0.5746]), 'bias': tensor([0.3527])})\n",
            "Epoch: 21610 | MAE Train Loss: 0.025184448808431625 | MAE Test Loss: 0.05887999013066292 \n",
            "OrderedDict({'weights': tensor([0.5747]), 'bias': tensor([0.3526])})\n",
            "Epoch: 21620 | MAE Train Loss: 0.025150101631879807 | MAE Test Loss: 0.058800775557756424 \n",
            "OrderedDict({'weights': tensor([0.5749]), 'bias': tensor([0.3525])})\n",
            "Epoch: 21630 | MAE Train Loss: 0.02511570230126381 | MAE Test Loss: 0.058718085289001465 \n",
            "OrderedDict({'weights': tensor([0.5751]), 'bias': tensor([0.3525])})\n",
            "Epoch: 21640 | MAE Train Loss: 0.025081366300582886 | MAE Test Loss: 0.05864226073026657 \n",
            "OrderedDict({'weights': tensor([0.5752]), 'bias': tensor([0.3524])})\n",
            "Epoch: 21650 | MAE Train Loss: 0.02504701353609562 | MAE Test Loss: 0.0585596077144146 \n",
            "OrderedDict({'weights': tensor([0.5754]), 'bias': tensor([0.3523])})\n",
            "Epoch: 21660 | MAE Train Loss: 0.02501261793076992 | MAE Test Loss: 0.058476902544498444 \n",
            "OrderedDict({'weights': tensor([0.5756]), 'bias': tensor([0.3523])})\n",
            "Epoch: 21670 | MAE Train Loss: 0.024978280067443848 | MAE Test Loss: 0.05840107798576355 \n",
            "OrderedDict({'weights': tensor([0.5757]), 'bias': tensor([0.3522])})\n",
            "Epoch: 21680 | MAE Train Loss: 0.024943942204117775 | MAE Test Loss: 0.05831838771700859 \n",
            "OrderedDict({'weights': tensor([0.5759]), 'bias': tensor([0.3521])})\n",
            "Epoch: 21690 | MAE Train Loss: 0.024909527972340584 | MAE Test Loss: 0.058235716074705124 \n",
            "OrderedDict({'weights': tensor([0.5761]), 'bias': tensor([0.3520])})\n",
            "Epoch: 21700 | MAE Train Loss: 0.024875199422240257 | MAE Test Loss: 0.058159906417131424 \n",
            "OrderedDict({'weights': tensor([0.5763]), 'bias': tensor([0.3520])})\n",
            "Epoch: 21710 | MAE Train Loss: 0.02484085038304329 | MAE Test Loss: 0.05807719752192497 \n",
            "OrderedDict({'weights': tensor([0.5764]), 'bias': tensor([0.3519])})\n",
            "Epoch: 21720 | MAE Train Loss: 0.024806443601846695 | MAE Test Loss: 0.0579945333302021 \n",
            "OrderedDict({'weights': tensor([0.5766]), 'bias': tensor([0.3518])})\n",
            "Epoch: 21730 | MAE Train Loss: 0.024772118777036667 | MAE Test Loss: 0.057918697595596313 \n",
            "OrderedDict({'weights': tensor([0.5768]), 'bias': tensor([0.3518])})\n",
            "Epoch: 21740 | MAE Train Loss: 0.02473776414990425 | MAE Test Loss: 0.05783602595329285 \n",
            "OrderedDict({'weights': tensor([0.5769]), 'bias': tensor([0.3517])})\n",
            "Epoch: 21750 | MAE Train Loss: 0.02470335364341736 | MAE Test Loss: 0.057753343135118484 \n",
            "OrderedDict({'weights': tensor([0.5771]), 'bias': tensor([0.3516])})\n",
            "Epoch: 21760 | MAE Train Loss: 0.024669025093317032 | MAE Test Loss: 0.0576741099357605 \n",
            "OrderedDict({'weights': tensor([0.5773]), 'bias': tensor([0.3515])})\n",
            "Epoch: 21770 | MAE Train Loss: 0.02463466115295887 | MAE Test Loss: 0.05759832262992859 \n",
            "OrderedDict({'weights': tensor([0.5775]), 'bias': tensor([0.3515])})\n",
            "Epoch: 21780 | MAE Train Loss: 0.02460034191608429 | MAE Test Loss: 0.05751560255885124 \n",
            "OrderedDict({'weights': tensor([0.5776]), 'bias': tensor([0.3514])})\n",
            "Epoch: 21790 | MAE Train Loss: 0.024565938860177994 | MAE Test Loss: 0.05743292719125748 \n",
            "OrderedDict({'weights': tensor([0.5778]), 'bias': tensor([0.3513])})\n",
            "Epoch: 21800 | MAE Train Loss: 0.024531584233045578 | MAE Test Loss: 0.05735709145665169 \n",
            "OrderedDict({'weights': tensor([0.5780]), 'bias': tensor([0.3513])})\n",
            "Epoch: 21810 | MAE Train Loss: 0.024497253820300102 | MAE Test Loss: 0.05727441981434822 \n",
            "OrderedDict({'weights': tensor([0.5781]), 'bias': tensor([0.3512])})\n",
            "Epoch: 21820 | MAE Train Loss: 0.024462848901748657 | MAE Test Loss: 0.05719173699617386 \n",
            "OrderedDict({'weights': tensor([0.5783]), 'bias': tensor([0.3511])})\n",
            "Epoch: 21830 | MAE Train Loss: 0.02442849613726139 | MAE Test Loss: 0.05711591988801956 \n",
            "OrderedDict({'weights': tensor([0.5785]), 'bias': tensor([0.3510])})\n",
            "Epoch: 21840 | MAE Train Loss: 0.024394169449806213 | MAE Test Loss: 0.0570332333445549 \n",
            "OrderedDict({'weights': tensor([0.5787]), 'bias': tensor([0.3510])})\n",
            "Epoch: 21850 | MAE Train Loss: 0.024359770119190216 | MAE Test Loss: 0.05695055052638054 \n",
            "OrderedDict({'weights': tensor([0.5788]), 'bias': tensor([0.3509])})\n",
            "Epoch: 21860 | MAE Train Loss: 0.0243254154920578 | MAE Test Loss: 0.05687473341822624 \n",
            "OrderedDict({'weights': tensor([0.5790]), 'bias': tensor([0.3508])})\n",
            "Epoch: 21870 | MAE Train Loss: 0.024291083216667175 | MAE Test Loss: 0.05679205060005188 \n",
            "OrderedDict({'weights': tensor([0.5792]), 'bias': tensor([0.3508])})\n",
            "Epoch: 21880 | MAE Train Loss: 0.02425668016076088 | MAE Test Loss: 0.056709371507167816 \n",
            "OrderedDict({'weights': tensor([0.5793]), 'bias': tensor([0.3507])})\n",
            "Epoch: 21890 | MAE Train Loss: 0.024222342297434807 | MAE Test Loss: 0.05663355067372322 \n",
            "OrderedDict({'weights': tensor([0.5795]), 'bias': tensor([0.3506])})\n",
            "Epoch: 21900 | MAE Train Loss: 0.024187996983528137 | MAE Test Loss: 0.05655089020729065 \n",
            "OrderedDict({'weights': tensor([0.5797]), 'bias': tensor([0.3505])})\n",
            "Epoch: 21910 | MAE Train Loss: 0.024153653532266617 | MAE Test Loss: 0.05647164583206177 \n",
            "OrderedDict({'weights': tensor([0.5798]), 'bias': tensor([0.3505])})\n",
            "Epoch: 21920 | MAE Train Loss: 0.024119259789586067 | MAE Test Loss: 0.05638895556330681 \n",
            "OrderedDict({'weights': tensor([0.5800]), 'bias': tensor([0.3504])})\n",
            "Epoch: 21930 | MAE Train Loss: 0.024084877222776413 | MAE Test Loss: 0.056313127279281616 \n",
            "OrderedDict({'weights': tensor([0.5802]), 'bias': tensor([0.3503])})\n",
            "Epoch: 21940 | MAE Train Loss: 0.024050574749708176 | MAE Test Loss: 0.056230444461107254 \n",
            "OrderedDict({'weights': tensor([0.5804]), 'bias': tensor([0.3502])})\n",
            "Epoch: 21950 | MAE Train Loss: 0.024016166105866432 | MAE Test Loss: 0.05614776164293289 \n",
            "OrderedDict({'weights': tensor([0.5805]), 'bias': tensor([0.3502])})\n",
            "Epoch: 21960 | MAE Train Loss: 0.023981794714927673 | MAE Test Loss: 0.056071944534778595 \n",
            "OrderedDict({'weights': tensor([0.5807]), 'bias': tensor([0.3501])})\n",
            "Epoch: 21970 | MAE Train Loss: 0.023947488516569138 | MAE Test Loss: 0.055989254266023636 \n",
            "OrderedDict({'weights': tensor([0.5809]), 'bias': tensor([0.3500])})\n",
            "Epoch: 21980 | MAE Train Loss: 0.023913081735372543 | MAE Test Loss: 0.05590657517313957 \n",
            "OrderedDict({'weights': tensor([0.5810]), 'bias': tensor([0.3500])})\n",
            "Epoch: 21990 | MAE Train Loss: 0.023878712207078934 | MAE Test Loss: 0.05583074688911438 \n",
            "OrderedDict({'weights': tensor([0.5812]), 'bias': tensor([0.3499])})\n",
            "Epoch: 22000 | MAE Train Loss: 0.02384440042078495 | MAE Test Loss: 0.05574807524681091 \n",
            "OrderedDict({'weights': tensor([0.5814]), 'bias': tensor([0.3498])})\n",
            "Epoch: 22010 | MAE Train Loss: 0.023809995502233505 | MAE Test Loss: 0.05566539615392685 \n",
            "OrderedDict({'weights': tensor([0.5816]), 'bias': tensor([0.3497])})\n",
            "Epoch: 22020 | MAE Train Loss: 0.02377563714981079 | MAE Test Loss: 0.05558958649635315 \n",
            "OrderedDict({'weights': tensor([0.5817]), 'bias': tensor([0.3497])})\n",
            "Epoch: 22030 | MAE Train Loss: 0.023741312325000763 | MAE Test Loss: 0.0555068776011467 \n",
            "OrderedDict({'weights': tensor([0.5819]), 'bias': tensor([0.3496])})\n",
            "Epoch: 22040 | MAE Train Loss: 0.023706911131739616 | MAE Test Loss: 0.05542421340942383 \n",
            "OrderedDict({'weights': tensor([0.5821]), 'bias': tensor([0.3495])})\n",
            "Epoch: 22050 | MAE Train Loss: 0.023672576993703842 | MAE Test Loss: 0.05534497648477554 \n",
            "OrderedDict({'weights': tensor([0.5822]), 'bias': tensor([0.3495])})\n",
            "Epoch: 22060 | MAE Train Loss: 0.02363816648721695 | MAE Test Loss: 0.055269159376621246 \n",
            "OrderedDict({'weights': tensor([0.5824]), 'bias': tensor([0.3494])})\n",
            "Epoch: 22070 | MAE Train Loss: 0.02360387146472931 | MAE Test Loss: 0.05518648028373718 \n",
            "OrderedDict({'weights': tensor([0.5826]), 'bias': tensor([0.3493])})\n",
            "Epoch: 22080 | MAE Train Loss: 0.023569488897919655 | MAE Test Loss: 0.05510377883911133 \n",
            "OrderedDict({'weights': tensor([0.5828]), 'bias': tensor([0.3492])})\n",
            "Epoch: 22090 | MAE Train Loss: 0.023535091429948807 | MAE Test Loss: 0.055027954280376434 \n",
            "OrderedDict({'weights': tensor([0.5829]), 'bias': tensor([0.3492])})\n",
            "Epoch: 22100 | MAE Train Loss: 0.02350078895688057 | MAE Test Loss: 0.05494528263807297 \n",
            "OrderedDict({'weights': tensor([0.5831]), 'bias': tensor([0.3491])})\n",
            "Epoch: 22110 | MAE Train Loss: 0.023466408252716064 | MAE Test Loss: 0.0548626072704792 \n",
            "OrderedDict({'weights': tensor([0.5833]), 'bias': tensor([0.3490])})\n",
            "Epoch: 22120 | MAE Train Loss: 0.023432010784745216 | MAE Test Loss: 0.05478678271174431 \n",
            "OrderedDict({'weights': tensor([0.5834]), 'bias': tensor([0.3490])})\n",
            "Epoch: 22130 | MAE Train Loss: 0.02339770831167698 | MAE Test Loss: 0.05470411106944084 \n",
            "OrderedDict({'weights': tensor([0.5836]), 'bias': tensor([0.3489])})\n",
            "Epoch: 22140 | MAE Train Loss: 0.02336331643164158 | MAE Test Loss: 0.054621417075395584 \n",
            "OrderedDict({'weights': tensor([0.5838]), 'bias': tensor([0.3488])})\n",
            "Epoch: 22150 | MAE Train Loss: 0.023328932002186775 | MAE Test Loss: 0.05454561114311218 \n",
            "OrderedDict({'weights': tensor([0.5840]), 'bias': tensor([0.3487])})\n",
            "Epoch: 22160 | MAE Train Loss: 0.023294635117053986 | MAE Test Loss: 0.054462917149066925 \n",
            "OrderedDict({'weights': tensor([0.5841]), 'bias': tensor([0.3487])})\n",
            "Epoch: 22170 | MAE Train Loss: 0.02326023019850254 | MAE Test Loss: 0.05438021942973137 \n",
            "OrderedDict({'weights': tensor([0.5843]), 'bias': tensor([0.3486])})\n",
            "Epoch: 22180 | MAE Train Loss: 0.023225855082273483 | MAE Test Loss: 0.05430440977215767 \n",
            "OrderedDict({'weights': tensor([0.5845]), 'bias': tensor([0.3485])})\n",
            "Epoch: 22190 | MAE Train Loss: 0.02319149114191532 | MAE Test Loss: 0.05421832948923111 \n",
            "OrderedDict({'weights': tensor([0.5846]), 'bias': tensor([0.3485])})\n",
            "Epoch: 22200 | MAE Train Loss: 0.023157168179750443 | MAE Test Loss: 0.054142486304044724 \n",
            "OrderedDict({'weights': tensor([0.5848]), 'bias': tensor([0.3484])})\n",
            "Epoch: 22210 | MAE Train Loss: 0.023122811689972878 | MAE Test Loss: 0.05405982583761215 \n",
            "OrderedDict({'weights': tensor([0.5850]), 'bias': tensor([0.3483])})\n",
            "Epoch: 22220 | MAE Train Loss: 0.023088406771421432 | MAE Test Loss: 0.05397714301943779 \n",
            "OrderedDict({'weights': tensor([0.5852]), 'bias': tensor([0.3482])})\n",
            "Epoch: 22230 | MAE Train Loss: 0.023054085671901703 | MAE Test Loss: 0.053901307284832 \n",
            "OrderedDict({'weights': tensor([0.5853]), 'bias': tensor([0.3482])})\n",
            "Epoch: 22240 | MAE Train Loss: 0.02301972545683384 | MAE Test Loss: 0.05381862074136734 \n",
            "OrderedDict({'weights': tensor([0.5855]), 'bias': tensor([0.3481])})\n",
            "Epoch: 22250 | MAE Train Loss: 0.022985322400927544 | MAE Test Loss: 0.05373595282435417 \n",
            "OrderedDict({'weights': tensor([0.5857]), 'bias': tensor([0.3480])})\n",
            "Epoch: 22260 | MAE Train Loss: 0.02295100688934326 | MAE Test Loss: 0.053660135716199875 \n",
            "OrderedDict({'weights': tensor([0.5858]), 'bias': tensor([0.3479])})\n",
            "Epoch: 22270 | MAE Train Loss: 0.022916633635759354 | MAE Test Loss: 0.053577445447444916 \n",
            "OrderedDict({'weights': tensor([0.5860]), 'bias': tensor([0.3479])})\n",
            "Epoch: 22280 | MAE Train Loss: 0.02288222871720791 | MAE Test Loss: 0.053494732826948166 \n",
            "OrderedDict({'weights': tensor([0.5862]), 'bias': tensor([0.3478])})\n",
            "Epoch: 22290 | MAE Train Loss: 0.02284792624413967 | MAE Test Loss: 0.05341894552111626 \n",
            "OrderedDict({'weights': tensor([0.5863]), 'bias': tensor([0.3477])})\n",
            "Epoch: 22300 | MAE Train Loss: 0.022813552990555763 | MAE Test Loss: 0.053336262702941895 \n",
            "OrderedDict({'weights': tensor([0.5865]), 'bias': tensor([0.3477])})\n",
            "Epoch: 22310 | MAE Train Loss: 0.022779151797294617 | MAE Test Loss: 0.0532604455947876 \n",
            "OrderedDict({'weights': tensor([0.5867]), 'bias': tensor([0.3476])})\n",
            "Epoch: 22320 | MAE Train Loss: 0.02274484559893608 | MAE Test Loss: 0.05317775160074234 \n",
            "OrderedDict({'weights': tensor([0.5869]), 'bias': tensor([0.3475])})\n",
            "Epoch: 22330 | MAE Train Loss: 0.022710468620061874 | MAE Test Loss: 0.053095053881406784 \n",
            "OrderedDict({'weights': tensor([0.5870]), 'bias': tensor([0.3474])})\n",
            "Epoch: 22340 | MAE Train Loss: 0.022676121443510056 | MAE Test Loss: 0.05301584675908089 \n",
            "OrderedDict({'weights': tensor([0.5872]), 'bias': tensor([0.3474])})\n",
            "Epoch: 22350 | MAE Train Loss: 0.022641722112894058 | MAE Test Loss: 0.05293315649032593 \n",
            "OrderedDict({'weights': tensor([0.5874]), 'bias': tensor([0.3473])})\n",
            "Epoch: 22360 | MAE Train Loss: 0.022607384249567986 | MAE Test Loss: 0.052857331931591034 \n",
            "OrderedDict({'weights': tensor([0.5875]), 'bias': tensor([0.3472])})\n",
            "Epoch: 22370 | MAE Train Loss: 0.022573033347725868 | MAE Test Loss: 0.052774686366319656 \n",
            "OrderedDict({'weights': tensor([0.5877]), 'bias': tensor([0.3472])})\n",
            "Epoch: 22380 | MAE Train Loss: 0.02253863587975502 | MAE Test Loss: 0.052691973745822906 \n",
            "OrderedDict({'weights': tensor([0.5879]), 'bias': tensor([0.3471])})\n",
            "Epoch: 22390 | MAE Train Loss: 0.022504299879074097 | MAE Test Loss: 0.05261614918708801 \n",
            "OrderedDict({'weights': tensor([0.5881]), 'bias': tensor([0.3470])})\n",
            "Epoch: 22400 | MAE Train Loss: 0.022469962015748024 | MAE Test Loss: 0.052533455193042755 \n",
            "OrderedDict({'weights': tensor([0.5882]), 'bias': tensor([0.3469])})\n",
            "Epoch: 22410 | MAE Train Loss: 0.022435547783970833 | MAE Test Loss: 0.05245078727602959 \n",
            "OrderedDict({'weights': tensor([0.5884]), 'bias': tensor([0.3469])})\n",
            "Epoch: 22420 | MAE Train Loss: 0.022401219233870506 | MAE Test Loss: 0.05237497761845589 \n",
            "OrderedDict({'weights': tensor([0.5886]), 'bias': tensor([0.3468])})\n",
            "Epoch: 22430 | MAE Train Loss: 0.022366870194673538 | MAE Test Loss: 0.052292268723249435 \n",
            "OrderedDict({'weights': tensor([0.5887]), 'bias': tensor([0.3467])})\n",
            "Epoch: 22440 | MAE Train Loss: 0.022332463413476944 | MAE Test Loss: 0.052209604531526566 \n",
            "OrderedDict({'weights': tensor([0.5889]), 'bias': tensor([0.3467])})\n",
            "Epoch: 22450 | MAE Train Loss: 0.022298142313957214 | MAE Test Loss: 0.05213377624750137 \n",
            "OrderedDict({'weights': tensor([0.5891]), 'bias': tensor([0.3466])})\n",
            "Epoch: 22460 | MAE Train Loss: 0.0222637839615345 | MAE Test Loss: 0.05205109715461731 \n",
            "OrderedDict({'weights': tensor([0.5893]), 'bias': tensor([0.3465])})\n",
            "Epoch: 22470 | MAE Train Loss: 0.022229373455047607 | MAE Test Loss: 0.05196841433644295 \n",
            "OrderedDict({'weights': tensor([0.5894]), 'bias': tensor([0.3464])})\n",
            "Epoch: 22480 | MAE Train Loss: 0.02219504490494728 | MAE Test Loss: 0.05188918113708496 \n",
            "OrderedDict({'weights': tensor([0.5896]), 'bias': tensor([0.3464])})\n",
            "Epoch: 22490 | MAE Train Loss: 0.02216068096458912 | MAE Test Loss: 0.05181339383125305 \n",
            "OrderedDict({'weights': tensor([0.5898]), 'bias': tensor([0.3463])})\n",
            "Epoch: 22500 | MAE Train Loss: 0.02212636172771454 | MAE Test Loss: 0.051730673760175705 \n",
            "OrderedDict({'weights': tensor([0.5899]), 'bias': tensor([0.3462])})\n",
            "Epoch: 22510 | MAE Train Loss: 0.022091958671808243 | MAE Test Loss: 0.05164799839258194 \n",
            "OrderedDict({'weights': tensor([0.5901]), 'bias': tensor([0.3462])})\n",
            "Epoch: 22520 | MAE Train Loss: 0.022057604044675827 | MAE Test Loss: 0.05157216638326645 \n",
            "OrderedDict({'weights': tensor([0.5903]), 'bias': tensor([0.3461])})\n",
            "Epoch: 22530 | MAE Train Loss: 0.02202327363193035 | MAE Test Loss: 0.051489491015672684 \n",
            "OrderedDict({'weights': tensor([0.5904]), 'bias': tensor([0.3460])})\n",
            "Epoch: 22540 | MAE Train Loss: 0.021988868713378906 | MAE Test Loss: 0.05140680819749832 \n",
            "OrderedDict({'weights': tensor([0.5906]), 'bias': tensor([0.3459])})\n",
            "Epoch: 22550 | MAE Train Loss: 0.02195451594889164 | MAE Test Loss: 0.05133098363876343 \n",
            "OrderedDict({'weights': tensor([0.5908]), 'bias': tensor([0.3459])})\n",
            "Epoch: 22560 | MAE Train Loss: 0.021920189261436462 | MAE Test Loss: 0.051248304545879364 \n",
            "OrderedDict({'weights': tensor([0.5910]), 'bias': tensor([0.3458])})\n",
            "Epoch: 22570 | MAE Train Loss: 0.021885789930820465 | MAE Test Loss: 0.051165621727705 \n",
            "OrderedDict({'weights': tensor([0.5911]), 'bias': tensor([0.3457])})\n",
            "Epoch: 22580 | MAE Train Loss: 0.02185143530368805 | MAE Test Loss: 0.051089804619550705 \n",
            "OrderedDict({'weights': tensor([0.5913]), 'bias': tensor([0.3457])})\n",
            "Epoch: 22590 | MAE Train Loss: 0.021817103028297424 | MAE Test Loss: 0.05100712180137634 \n",
            "OrderedDict({'weights': tensor([0.5915]), 'bias': tensor([0.3456])})\n",
            "Epoch: 22600 | MAE Train Loss: 0.02178269997239113 | MAE Test Loss: 0.05092443898320198 \n",
            "OrderedDict({'weights': tensor([0.5916]), 'bias': tensor([0.3455])})\n",
            "Epoch: 22610 | MAE Train Loss: 0.021748362109065056 | MAE Test Loss: 0.050848621875047684 \n",
            "OrderedDict({'weights': tensor([0.5918]), 'bias': tensor([0.3454])})\n",
            "Epoch: 22620 | MAE Train Loss: 0.021714016795158386 | MAE Test Loss: 0.05076596140861511 \n",
            "OrderedDict({'weights': tensor([0.5920]), 'bias': tensor([0.3454])})\n",
            "Epoch: 22630 | MAE Train Loss: 0.021679673343896866 | MAE Test Loss: 0.050686709582805634 \n",
            "OrderedDict({'weights': tensor([0.5922]), 'bias': tensor([0.3453])})\n",
            "Epoch: 22640 | MAE Train Loss: 0.021645279601216316 | MAE Test Loss: 0.05060402676463127 \n",
            "OrderedDict({'weights': tensor([0.5923]), 'bias': tensor([0.3452])})\n",
            "Epoch: 22650 | MAE Train Loss: 0.021610897034406662 | MAE Test Loss: 0.05052819848060608 \n",
            "OrderedDict({'weights': tensor([0.5925]), 'bias': tensor([0.3451])})\n",
            "Epoch: 22660 | MAE Train Loss: 0.021576594561338425 | MAE Test Loss: 0.05044551566243172 \n",
            "OrderedDict({'weights': tensor([0.5927]), 'bias': tensor([0.3451])})\n",
            "Epoch: 22670 | MAE Train Loss: 0.02154218778014183 | MAE Test Loss: 0.05036283656954765 \n",
            "OrderedDict({'weights': tensor([0.5928]), 'bias': tensor([0.3450])})\n",
            "Epoch: 22680 | MAE Train Loss: 0.02150781638920307 | MAE Test Loss: 0.05028701573610306 \n",
            "OrderedDict({'weights': tensor([0.5930]), 'bias': tensor([0.3449])})\n",
            "Epoch: 22690 | MAE Train Loss: 0.021473506465554237 | MAE Test Loss: 0.0502043254673481 \n",
            "OrderedDict({'weights': tensor([0.5932]), 'bias': tensor([0.3449])})\n",
            "Epoch: 22700 | MAE Train Loss: 0.021439101547002792 | MAE Test Loss: 0.05012164264917374 \n",
            "OrderedDict({'weights': tensor([0.5934]), 'bias': tensor([0.3448])})\n",
            "Epoch: 22710 | MAE Train Loss: 0.021404730156064034 | MAE Test Loss: 0.05004581809043884 \n",
            "OrderedDict({'weights': tensor([0.5935]), 'bias': tensor([0.3447])})\n",
            "Epoch: 22720 | MAE Train Loss: 0.02137042209506035 | MAE Test Loss: 0.049963146448135376 \n",
            "OrderedDict({'weights': tensor([0.5937]), 'bias': tensor([0.3446])})\n",
            "Epoch: 22730 | MAE Train Loss: 0.021336019039154053 | MAE Test Loss: 0.04988046735525131 \n",
            "OrderedDict({'weights': tensor([0.5939]), 'bias': tensor([0.3446])})\n",
            "Epoch: 22740 | MAE Train Loss: 0.02130165696144104 | MAE Test Loss: 0.04980465769767761 \n",
            "OrderedDict({'weights': tensor([0.5940]), 'bias': tensor([0.3445])})\n",
            "Epoch: 22750 | MAE Train Loss: 0.02126733399927616 | MAE Test Loss: 0.04972194880247116 \n",
            "OrderedDict({'weights': tensor([0.5942]), 'bias': tensor([0.3444])})\n",
            "Epoch: 22760 | MAE Train Loss: 0.021232930943369865 | MAE Test Loss: 0.049639277160167694 \n",
            "OrderedDict({'weights': tensor([0.5944]), 'bias': tensor([0.3444])})\n",
            "Epoch: 22770 | MAE Train Loss: 0.02119859680533409 | MAE Test Loss: 0.049560047686100006 \n",
            "OrderedDict({'weights': tensor([0.5946]), 'bias': tensor([0.3443])})\n",
            "Epoch: 22780 | MAE Train Loss: 0.0211641862988472 | MAE Test Loss: 0.04948423057794571 \n",
            "OrderedDict({'weights': tensor([0.5947]), 'bias': tensor([0.3442])})\n",
            "Epoch: 22790 | MAE Train Loss: 0.021129891276359558 | MAE Test Loss: 0.049401551485061646 \n",
            "OrderedDict({'weights': tensor([0.5949]), 'bias': tensor([0.3441])})\n",
            "Epoch: 22800 | MAE Train Loss: 0.021095508709549904 | MAE Test Loss: 0.04931885004043579 \n",
            "OrderedDict({'weights': tensor([0.5951]), 'bias': tensor([0.3441])})\n",
            "Epoch: 22810 | MAE Train Loss: 0.021061111241579056 | MAE Test Loss: 0.0492430254817009 \n",
            "OrderedDict({'weights': tensor([0.5952]), 'bias': tensor([0.3440])})\n",
            "Epoch: 22820 | MAE Train Loss: 0.021026812493801117 | MAE Test Loss: 0.04916035383939743 \n",
            "OrderedDict({'weights': tensor([0.5954]), 'bias': tensor([0.3439])})\n",
            "Epoch: 22830 | MAE Train Loss: 0.020992428064346313 | MAE Test Loss: 0.04907767102122307 \n",
            "OrderedDict({'weights': tensor([0.5956]), 'bias': tensor([0.3439])})\n",
            "Epoch: 22840 | MAE Train Loss: 0.020958030596375465 | MAE Test Loss: 0.04900185018777847 \n",
            "OrderedDict({'weights': tensor([0.5957]), 'bias': tensor([0.3438])})\n",
            "Epoch: 22850 | MAE Train Loss: 0.020923728123307228 | MAE Test Loss: 0.048919182270765305 \n",
            "OrderedDict({'weights': tensor([0.5959]), 'bias': tensor([0.3437])})\n",
            "Epoch: 22860 | MAE Train Loss: 0.020889345556497574 | MAE Test Loss: 0.04883994907140732 \n",
            "OrderedDict({'weights': tensor([0.5961]), 'bias': tensor([0.3436])})\n",
            "Epoch: 22870 | MAE Train Loss: 0.020854994654655457 | MAE Test Loss: 0.04875723645091057 \n",
            "OrderedDict({'weights': tensor([0.5963]), 'bias': tensor([0.3436])})\n",
            "Epoch: 22880 | MAE Train Loss: 0.020820651203393936 | MAE Test Loss: 0.048678040504455566 \n",
            "OrderedDict({'weights': tensor([0.5964]), 'bias': tensor([0.3435])})\n",
            "Epoch: 22890 | MAE Train Loss: 0.020786261186003685 | MAE Test Loss: 0.048595357686281204 \n",
            "OrderedDict({'weights': tensor([0.5966]), 'bias': tensor([0.3434])})\n",
            "Epoch: 22900 | MAE Train Loss: 0.02075188420712948 | MAE Test Loss: 0.04851954057812691 \n",
            "OrderedDict({'weights': tensor([0.5968]), 'bias': tensor([0.3434])})\n",
            "Epoch: 22910 | MAE Train Loss: 0.020717520266771317 | MAE Test Loss: 0.048433441668748856 \n",
            "OrderedDict({'weights': tensor([0.5969]), 'bias': tensor([0.3433])})\n",
            "Epoch: 22920 | MAE Train Loss: 0.02068319357931614 | MAE Test Loss: 0.04835762828588486 \n",
            "OrderedDict({'weights': tensor([0.5971]), 'bias': tensor([0.3432])})\n",
            "Epoch: 22930 | MAE Train Loss: 0.020648811012506485 | MAE Test Loss: 0.04827839881181717 \n",
            "OrderedDict({'weights': tensor([0.5973]), 'bias': tensor([0.3431])})\n",
            "Epoch: 22940 | MAE Train Loss: 0.02061450108885765 | MAE Test Loss: 0.04819570109248161 \n",
            "OrderedDict({'weights': tensor([0.5975]), 'bias': tensor([0.3431])})\n",
            "Epoch: 22950 | MAE Train Loss: 0.020580098032951355 | MAE Test Loss: 0.04811302572488785 \n",
            "OrderedDict({'weights': tensor([0.5976]), 'bias': tensor([0.3430])})\n",
            "Epoch: 22960 | MAE Train Loss: 0.020545724779367447 | MAE Test Loss: 0.048037201166152954 \n",
            "OrderedDict({'weights': tensor([0.5978]), 'bias': tensor([0.3429])})\n",
            "Epoch: 22970 | MAE Train Loss: 0.020511358976364136 | MAE Test Loss: 0.0479511097073555 \n",
            "OrderedDict({'weights': tensor([0.5980]), 'bias': tensor([0.3429])})\n",
            "Epoch: 22980 | MAE Train Loss: 0.02047702483832836 | MAE Test Loss: 0.04787188768386841 \n",
            "OrderedDict({'weights': tensor([0.5981]), 'bias': tensor([0.3428])})\n",
            "Epoch: 22990 | MAE Train Loss: 0.0204426608979702 | MAE Test Loss: 0.04779605194926262 \n",
            "OrderedDict({'weights': tensor([0.5983]), 'bias': tensor([0.3427])})\n",
            "Epoch: 23000 | MAE Train Loss: 0.02040834166109562 | MAE Test Loss: 0.047713398933410645 \n",
            "OrderedDict({'weights': tensor([0.5985]), 'bias': tensor([0.3426])})\n",
            "Epoch: 23010 | MAE Train Loss: 0.020373940467834473 | MAE Test Loss: 0.04763072729110718 \n",
            "OrderedDict({'weights': tensor([0.5987]), 'bias': tensor([0.3426])})\n",
            "Epoch: 23020 | MAE Train Loss: 0.02033960446715355 | MAE Test Loss: 0.047551482915878296 \n",
            "OrderedDict({'weights': tensor([0.5988]), 'bias': tensor([0.3425])})\n",
            "Epoch: 23030 | MAE Train Loss: 0.020305205136537552 | MAE Test Loss: 0.047472257167100906 \n",
            "OrderedDict({'weights': tensor([0.5990]), 'bias': tensor([0.3424])})\n",
            "Epoch: 23040 | MAE Train Loss: 0.020270859822630882 | MAE Test Loss: 0.047389574348926544 \n",
            "OrderedDict({'weights': tensor([0.5992]), 'bias': tensor([0.3424])})\n",
            "Epoch: 23050 | MAE Train Loss: 0.020236507058143616 | MAE Test Loss: 0.04731374233961105 \n",
            "OrderedDict({'weights': tensor([0.5993]), 'bias': tensor([0.3423])})\n",
            "Epoch: 23060 | MAE Train Loss: 0.020202182233333588 | MAE Test Loss: 0.04723107069730759 \n",
            "OrderedDict({'weights': tensor([0.5995]), 'bias': tensor([0.3422])})\n",
            "Epoch: 23070 | MAE Train Loss: 0.020167827606201172 | MAE Test Loss: 0.0471518412232399 \n",
            "OrderedDict({'weights': tensor([0.5997]), 'bias': tensor([0.3421])})\n",
            "Epoch: 23080 | MAE Train Loss: 0.020133433863520622 | MAE Test Loss: 0.04706917330622673 \n",
            "OrderedDict({'weights': tensor([0.5999]), 'bias': tensor([0.3421])})\n",
            "Epoch: 23090 | MAE Train Loss: 0.020099103450775146 | MAE Test Loss: 0.04698992520570755 \n",
            "OrderedDict({'weights': tensor([0.6000]), 'bias': tensor([0.3420])})\n",
            "Epoch: 23100 | MAE Train Loss: 0.02006470039486885 | MAE Test Loss: 0.046907246112823486 \n",
            "OrderedDict({'weights': tensor([0.6002]), 'bias': tensor([0.3419])})\n",
            "Epoch: 23110 | MAE Train Loss: 0.02003035880625248 | MAE Test Loss: 0.046831436455249786 \n",
            "OrderedDict({'weights': tensor([0.6004]), 'bias': tensor([0.3418])})\n",
            "Epoch: 23120 | MAE Train Loss: 0.019996024668216705 | MAE Test Loss: 0.046748727560043335 \n",
            "OrderedDict({'weights': tensor([0.6005]), 'bias': tensor([0.3418])})\n",
            "Epoch: 23130 | MAE Train Loss: 0.019961679354310036 | MAE Test Loss: 0.04666954278945923 \n",
            "OrderedDict({'weights': tensor([0.6007]), 'bias': tensor([0.3417])})\n",
            "Epoch: 23140 | MAE Train Loss: 0.019927287474274635 | MAE Test Loss: 0.04659029841423035 \n",
            "OrderedDict({'weights': tensor([0.6009]), 'bias': tensor([0.3416])})\n",
            "Epoch: 23150 | MAE Train Loss: 0.019892949610948563 | MAE Test Loss: 0.04650759696960449 \n",
            "OrderedDict({'weights': tensor([0.6010]), 'bias': tensor([0.3416])})\n",
            "Epoch: 23160 | MAE Train Loss: 0.01985853537917137 | MAE Test Loss: 0.04642493650317192 \n",
            "OrderedDict({'weights': tensor([0.6012]), 'bias': tensor([0.3415])})\n",
            "Epoch: 23170 | MAE Train Loss: 0.019824206829071045 | MAE Test Loss: 0.04634912684559822 \n",
            "OrderedDict({'weights': tensor([0.6014]), 'bias': tensor([0.3414])})\n",
            "Epoch: 23180 | MAE Train Loss: 0.01978982612490654 | MAE Test Loss: 0.04626988619565964 \n",
            "OrderedDict({'weights': tensor([0.6016]), 'bias': tensor([0.3413])})\n",
            "Epoch: 23190 | MAE Train Loss: 0.019755464047193527 | MAE Test Loss: 0.04618379473686218 \n",
            "OrderedDict({'weights': tensor([0.6017]), 'bias': tensor([0.3413])})\n",
            "Epoch: 23200 | MAE Train Loss: 0.01972114108502865 | MAE Test Loss: 0.04610798880457878 \n",
            "OrderedDict({'weights': tensor([0.6019]), 'bias': tensor([0.3412])})\n",
            "Epoch: 23210 | MAE Train Loss: 0.019686780869960785 | MAE Test Loss: 0.04602530598640442 \n",
            "OrderedDict({'weights': tensor([0.6021]), 'bias': tensor([0.3411])})\n",
            "Epoch: 23220 | MAE Train Loss: 0.01965237781405449 | MAE Test Loss: 0.04594261199235916 \n",
            "OrderedDict({'weights': tensor([0.6022]), 'bias': tensor([0.3411])})\n",
            "Epoch: 23230 | MAE Train Loss: 0.019618038088083267 | MAE Test Loss: 0.04586338251829147 \n",
            "OrderedDict({'weights': tensor([0.6024]), 'bias': tensor([0.3410])})\n",
            "Epoch: 23240 | MAE Train Loss: 0.019583681598305702 | MAE Test Loss: 0.045787543058395386 \n",
            "OrderedDict({'weights': tensor([0.6026]), 'bias': tensor([0.3409])})\n",
            "Epoch: 23250 | MAE Train Loss: 0.019549304619431496 | MAE Test Loss: 0.04570148512721062 \n",
            "OrderedDict({'weights': tensor([0.6028]), 'bias': tensor([0.3408])})\n",
            "Epoch: 23260 | MAE Train Loss: 0.019514989107847214 | MAE Test Loss: 0.04562566429376602 \n",
            "OrderedDict({'weights': tensor([0.6029]), 'bias': tensor([0.3408])})\n",
            "Epoch: 23270 | MAE Train Loss: 0.019480617716908455 | MAE Test Loss: 0.04554297775030136 \n",
            "OrderedDict({'weights': tensor([0.6031]), 'bias': tensor([0.3407])})\n",
            "Epoch: 23280 | MAE Train Loss: 0.01944620907306671 | MAE Test Loss: 0.04546375200152397 \n",
            "OrderedDict({'weights': tensor([0.6033]), 'bias': tensor([0.3406])})\n",
            "Epoch: 23290 | MAE Train Loss: 0.019411873072385788 | MAE Test Loss: 0.04538106918334961 \n",
            "OrderedDict({'weights': tensor([0.6034]), 'bias': tensor([0.3406])})\n",
            "Epoch: 23300 | MAE Train Loss: 0.019377540796995163 | MAE Test Loss: 0.04530183598399162 \n",
            "OrderedDict({'weights': tensor([0.6036]), 'bias': tensor([0.3405])})\n",
            "Epoch: 23310 | MAE Train Loss: 0.019343141466379166 | MAE Test Loss: 0.045226018875837326 \n",
            "OrderedDict({'weights': tensor([0.6038]), 'bias': tensor([0.3404])})\n",
            "Epoch: 23320 | MAE Train Loss: 0.01930883713066578 | MAE Test Loss: 0.04514334350824356 \n",
            "OrderedDict({'weights': tensor([0.6040]), 'bias': tensor([0.3403])})\n",
            "Epoch: 23330 | MAE Train Loss: 0.019274454563856125 | MAE Test Loss: 0.0450606569647789 \n",
            "OrderedDict({'weights': tensor([0.6041]), 'bias': tensor([0.3403])})\n",
            "Epoch: 23340 | MAE Train Loss: 0.0192401222884655 | MAE Test Loss: 0.04498142749071121 \n",
            "OrderedDict({'weights': tensor([0.6043]), 'bias': tensor([0.3402])})\n",
            "Epoch: 23350 | MAE Train Loss: 0.019205771386623383 | MAE Test Loss: 0.044902198016643524 \n",
            "OrderedDict({'weights': tensor([0.6045]), 'bias': tensor([0.3401])})\n",
            "Epoch: 23360 | MAE Train Loss: 0.01917138695716858 | MAE Test Loss: 0.04481951519846916 \n",
            "OrderedDict({'weights': tensor([0.6046]), 'bias': tensor([0.3401])})\n",
            "Epoch: 23370 | MAE Train Loss: 0.01913698948919773 | MAE Test Loss: 0.04474369436502457 \n",
            "OrderedDict({'weights': tensor([0.6048]), 'bias': tensor([0.3400])})\n",
            "Epoch: 23380 | MAE Train Loss: 0.019102687016129494 | MAE Test Loss: 0.0446610264480114 \n",
            "OrderedDict({'weights': tensor([0.6050]), 'bias': tensor([0.3399])})\n",
            "Epoch: 23390 | MAE Train Loss: 0.01906830444931984 | MAE Test Loss: 0.04458179324865341 \n",
            "OrderedDict({'weights': tensor([0.6051]), 'bias': tensor([0.3398])})\n",
            "Epoch: 23400 | MAE Train Loss: 0.019033953547477722 | MAE Test Loss: 0.04449908062815666 \n",
            "OrderedDict({'weights': tensor([0.6053]), 'bias': tensor([0.3398])})\n",
            "Epoch: 23410 | MAE Train Loss: 0.018999610096216202 | MAE Test Loss: 0.04441988468170166 \n",
            "OrderedDict({'weights': tensor([0.6055]), 'bias': tensor([0.3397])})\n",
            "Epoch: 23420 | MAE Train Loss: 0.01896522007882595 | MAE Test Loss: 0.0443372018635273 \n",
            "OrderedDict({'weights': tensor([0.6057]), 'bias': tensor([0.3396])})\n",
            "Epoch: 23430 | MAE Train Loss: 0.018930841237306595 | MAE Test Loss: 0.044261384755373 \n",
            "OrderedDict({'weights': tensor([0.6058]), 'bias': tensor([0.3395])})\n",
            "Epoch: 23440 | MAE Train Loss: 0.018896479159593582 | MAE Test Loss: 0.04417528584599495 \n",
            "OrderedDict({'weights': tensor([0.6060]), 'bias': tensor([0.3395])})\n",
            "Epoch: 23450 | MAE Train Loss: 0.018862152472138405 | MAE Test Loss: 0.04409947246313095 \n",
            "OrderedDict({'weights': tensor([0.6062]), 'bias': tensor([0.3394])})\n",
            "Epoch: 23460 | MAE Train Loss: 0.01882776990532875 | MAE Test Loss: 0.04402024298906326 \n",
            "OrderedDict({'weights': tensor([0.6063]), 'bias': tensor([0.3393])})\n",
            "Epoch: 23470 | MAE Train Loss: 0.018793459981679916 | MAE Test Loss: 0.04393754526972771 \n",
            "OrderedDict({'weights': tensor([0.6065]), 'bias': tensor([0.3393])})\n",
            "Epoch: 23480 | MAE Train Loss: 0.01875906065106392 | MAE Test Loss: 0.04385486990213394 \n",
            "OrderedDict({'weights': tensor([0.6067]), 'bias': tensor([0.3392])})\n",
            "Epoch: 23490 | MAE Train Loss: 0.018724683672189713 | MAE Test Loss: 0.04377904534339905 \n",
            "OrderedDict({'weights': tensor([0.6069]), 'bias': tensor([0.3391])})\n",
            "Epoch: 23500 | MAE Train Loss: 0.0186903178691864 | MAE Test Loss: 0.04369295388460159 \n",
            "OrderedDict({'weights': tensor([0.6070]), 'bias': tensor([0.3390])})\n",
            "Epoch: 23510 | MAE Train Loss: 0.018655983731150627 | MAE Test Loss: 0.0436137318611145 \n",
            "OrderedDict({'weights': tensor([0.6072]), 'bias': tensor([0.3390])})\n",
            "Epoch: 23520 | MAE Train Loss: 0.018621619790792465 | MAE Test Loss: 0.04353789612650871 \n",
            "OrderedDict({'weights': tensor([0.6074]), 'bias': tensor([0.3389])})\n",
            "Epoch: 23530 | MAE Train Loss: 0.018587300553917885 | MAE Test Loss: 0.04345524311065674 \n",
            "OrderedDict({'weights': tensor([0.6075]), 'bias': tensor([0.3388])})\n",
            "Epoch: 23540 | MAE Train Loss: 0.01855289936065674 | MAE Test Loss: 0.04337257146835327 \n",
            "OrderedDict({'weights': tensor([0.6077]), 'bias': tensor([0.3388])})\n",
            "Epoch: 23550 | MAE Train Loss: 0.018518561497330666 | MAE Test Loss: 0.04329332709312439 \n",
            "OrderedDict({'weights': tensor([0.6079]), 'bias': tensor([0.3387])})\n",
            "Epoch: 23560 | MAE Train Loss: 0.018484164029359818 | MAE Test Loss: 0.043214101344347 \n",
            "OrderedDict({'weights': tensor([0.6081]), 'bias': tensor([0.3386])})\n",
            "Epoch: 23570 | MAE Train Loss: 0.018449818715453148 | MAE Test Loss: 0.04313141852617264 \n",
            "OrderedDict({'weights': tensor([0.6082]), 'bias': tensor([0.3385])})\n",
            "Epoch: 23580 | MAE Train Loss: 0.01841546595096588 | MAE Test Loss: 0.04305558651685715 \n",
            "OrderedDict({'weights': tensor([0.6084]), 'bias': tensor([0.3385])})\n",
            "Epoch: 23590 | MAE Train Loss: 0.018381142988801003 | MAE Test Loss: 0.04297291487455368 \n",
            "OrderedDict({'weights': tensor([0.6086]), 'bias': tensor([0.3384])})\n",
            "Epoch: 23600 | MAE Train Loss: 0.018346786499023438 | MAE Test Loss: 0.04289368540048599 \n",
            "OrderedDict({'weights': tensor([0.6087]), 'bias': tensor([0.3383])})\n",
            "Epoch: 23610 | MAE Train Loss: 0.018312392756342888 | MAE Test Loss: 0.042811017483472824 \n",
            "OrderedDict({'weights': tensor([0.6089]), 'bias': tensor([0.3383])})\n",
            "Epoch: 23620 | MAE Train Loss: 0.018278062343597412 | MAE Test Loss: 0.042731769382953644 \n",
            "OrderedDict({'weights': tensor([0.6091]), 'bias': tensor([0.3382])})\n",
            "Epoch: 23630 | MAE Train Loss: 0.018243659287691116 | MAE Test Loss: 0.04264909029006958 \n",
            "OrderedDict({'weights': tensor([0.6093]), 'bias': tensor([0.3381])})\n",
            "Epoch: 23640 | MAE Train Loss: 0.018209317699074745 | MAE Test Loss: 0.04257328063249588 \n",
            "OrderedDict({'weights': tensor([0.6094]), 'bias': tensor([0.3380])})\n",
            "Epoch: 23650 | MAE Train Loss: 0.01817498169839382 | MAE Test Loss: 0.04249057173728943 \n",
            "OrderedDict({'weights': tensor([0.6096]), 'bias': tensor([0.3380])})\n",
            "Epoch: 23660 | MAE Train Loss: 0.0181406382471323 | MAE Test Loss: 0.04241138696670532 \n",
            "OrderedDict({'weights': tensor([0.6098]), 'bias': tensor([0.3379])})\n",
            "Epoch: 23670 | MAE Train Loss: 0.0181062463670969 | MAE Test Loss: 0.042332135140895844 \n",
            "OrderedDict({'weights': tensor([0.6099]), 'bias': tensor([0.3378])})\n",
            "Epoch: 23680 | MAE Train Loss: 0.018071908503770828 | MAE Test Loss: 0.042249441146850586 \n",
            "OrderedDict({'weights': tensor([0.6101]), 'bias': tensor([0.3378])})\n",
            "Epoch: 23690 | MAE Train Loss: 0.018037494271993637 | MAE Test Loss: 0.042166780680418015 \n",
            "OrderedDict({'weights': tensor([0.6103]), 'bias': tensor([0.3377])})\n",
            "Epoch: 23700 | MAE Train Loss: 0.01800316572189331 | MAE Test Loss: 0.04209096357226372 \n",
            "OrderedDict({'weights': tensor([0.6104]), 'bias': tensor([0.3376])})\n",
            "Epoch: 23710 | MAE Train Loss: 0.017968786880373955 | MAE Test Loss: 0.04201173037290573 \n",
            "OrderedDict({'weights': tensor([0.6106]), 'bias': tensor([0.3375])})\n",
            "Epoch: 23720 | MAE Train Loss: 0.017934422940015793 | MAE Test Loss: 0.041925638914108276 \n",
            "OrderedDict({'weights': tensor([0.6108]), 'bias': tensor([0.3375])})\n",
            "Epoch: 23730 | MAE Train Loss: 0.017900103703141212 | MAE Test Loss: 0.041849832981824875 \n",
            "OrderedDict({'weights': tensor([0.6110]), 'bias': tensor([0.3374])})\n",
            "Epoch: 23740 | MAE Train Loss: 0.01786573976278305 | MAE Test Loss: 0.04176715016365051 \n",
            "OrderedDict({'weights': tensor([0.6111]), 'bias': tensor([0.3373])})\n",
            "Epoch: 23750 | MAE Train Loss: 0.017831336706876755 | MAE Test Loss: 0.041684456169605255 \n",
            "OrderedDict({'weights': tensor([0.6113]), 'bias': tensor([0.3373])})\n",
            "Epoch: 23760 | MAE Train Loss: 0.017796996980905533 | MAE Test Loss: 0.04160522669553757 \n",
            "OrderedDict({'weights': tensor([0.6115]), 'bias': tensor([0.3372])})\n",
            "Epoch: 23770 | MAE Train Loss: 0.017762640491127968 | MAE Test Loss: 0.04152938723564148 \n",
            "OrderedDict({'weights': tensor([0.6116]), 'bias': tensor([0.3371])})\n",
            "Epoch: 23780 | MAE Train Loss: 0.01772826351225376 | MAE Test Loss: 0.04144333675503731 \n",
            "OrderedDict({'weights': tensor([0.6118]), 'bias': tensor([0.3370])})\n",
            "Epoch: 23790 | MAE Train Loss: 0.01769394800066948 | MAE Test Loss: 0.041367508471012115 \n",
            "OrderedDict({'weights': tensor([0.6120]), 'bias': tensor([0.3370])})\n",
            "Epoch: 23800 | MAE Train Loss: 0.01765957660973072 | MAE Test Loss: 0.041284821927547455 \n",
            "OrderedDict({'weights': tensor([0.6122]), 'bias': tensor([0.3369])})\n",
            "Epoch: 23810 | MAE Train Loss: 0.017625167965888977 | MAE Test Loss: 0.041205596178770065 \n",
            "OrderedDict({'weights': tensor([0.6123]), 'bias': tensor([0.3368])})\n",
            "Epoch: 23820 | MAE Train Loss: 0.017590831965208054 | MAE Test Loss: 0.0411229133605957 \n",
            "OrderedDict({'weights': tensor([0.6125]), 'bias': tensor([0.3368])})\n",
            "Epoch: 23830 | MAE Train Loss: 0.017556501552462578 | MAE Test Loss: 0.04104368016123772 \n",
            "OrderedDict({'weights': tensor([0.6127]), 'bias': tensor([0.3367])})\n",
            "Epoch: 23840 | MAE Train Loss: 0.01752210035920143 | MAE Test Loss: 0.04096786305308342 \n",
            "OrderedDict({'weights': tensor([0.6128]), 'bias': tensor([0.3366])})\n",
            "Epoch: 23850 | MAE Train Loss: 0.017487796023488045 | MAE Test Loss: 0.04088518023490906 \n",
            "OrderedDict({'weights': tensor([0.6130]), 'bias': tensor([0.3365])})\n",
            "Epoch: 23860 | MAE Train Loss: 0.01745341345667839 | MAE Test Loss: 0.04080250859260559 \n",
            "OrderedDict({'weights': tensor([0.6132]), 'bias': tensor([0.3365])})\n",
            "Epoch: 23870 | MAE Train Loss: 0.017419081181287766 | MAE Test Loss: 0.040723271667957306 \n",
            "OrderedDict({'weights': tensor([0.6134]), 'bias': tensor([0.3364])})\n",
            "Epoch: 23880 | MAE Train Loss: 0.017384730279445648 | MAE Test Loss: 0.04064404219388962 \n",
            "OrderedDict({'weights': tensor([0.6135]), 'bias': tensor([0.3363])})\n",
            "Epoch: 23890 | MAE Train Loss: 0.017350345849990845 | MAE Test Loss: 0.040561359375715256 \n",
            "OrderedDict({'weights': tensor([0.6137]), 'bias': tensor([0.3362])})\n",
            "Epoch: 23900 | MAE Train Loss: 0.017315948382019997 | MAE Test Loss: 0.040485531091690063 \n",
            "OrderedDict({'weights': tensor([0.6139]), 'bias': tensor([0.3362])})\n",
            "Epoch: 23910 | MAE Train Loss: 0.01728164590895176 | MAE Test Loss: 0.04040287062525749 \n",
            "OrderedDict({'weights': tensor([0.6140]), 'bias': tensor([0.3361])})\n",
            "Epoch: 23920 | MAE Train Loss: 0.017247263342142105 | MAE Test Loss: 0.040323637425899506 \n",
            "OrderedDict({'weights': tensor([0.6142]), 'bias': tensor([0.3360])})\n",
            "Epoch: 23930 | MAE Train Loss: 0.017212912440299988 | MAE Test Loss: 0.04024092108011246 \n",
            "OrderedDict({'weights': tensor([0.6144]), 'bias': tensor([0.3360])})\n",
            "Epoch: 23940 | MAE Train Loss: 0.017178568989038467 | MAE Test Loss: 0.040161728858947754 \n",
            "OrderedDict({'weights': tensor([0.6146]), 'bias': tensor([0.3359])})\n",
            "Epoch: 23950 | MAE Train Loss: 0.017144178971648216 | MAE Test Loss: 0.04007904604077339 \n",
            "OrderedDict({'weights': tensor([0.6147]), 'bias': tensor([0.3358])})\n",
            "Epoch: 23960 | MAE Train Loss: 0.01710980013012886 | MAE Test Loss: 0.040003228932619095 \n",
            "OrderedDict({'weights': tensor([0.6149]), 'bias': tensor([0.3357])})\n",
            "Epoch: 23970 | MAE Train Loss: 0.017075438052415848 | MAE Test Loss: 0.03991713002324104 \n",
            "OrderedDict({'weights': tensor([0.6151]), 'bias': tensor([0.3357])})\n",
            "Epoch: 23980 | MAE Train Loss: 0.01704111136496067 | MAE Test Loss: 0.03984132409095764 \n",
            "OrderedDict({'weights': tensor([0.6152]), 'bias': tensor([0.3356])})\n",
            "Epoch: 23990 | MAE Train Loss: 0.017006728798151016 | MAE Test Loss: 0.03976208716630936 \n",
            "OrderedDict({'weights': tensor([0.6154]), 'bias': tensor([0.3355])})\n",
            "Epoch: 24000 | MAE Train Loss: 0.016972418874502182 | MAE Test Loss: 0.0396793894469738 \n",
            "OrderedDict({'weights': tensor([0.6156]), 'bias': tensor([0.3355])})\n",
            "Epoch: 24010 | MAE Train Loss: 0.016938019543886185 | MAE Test Loss: 0.039596717804670334 \n",
            "OrderedDict({'weights': tensor([0.6157]), 'bias': tensor([0.3354])})\n",
            "Epoch: 24020 | MAE Train Loss: 0.016903642565011978 | MAE Test Loss: 0.03952088952064514 \n",
            "OrderedDict({'weights': tensor([0.6159]), 'bias': tensor([0.3353])})\n",
            "Epoch: 24030 | MAE Train Loss: 0.016869276762008667 | MAE Test Loss: 0.03943479806184769 \n",
            "OrderedDict({'weights': tensor([0.6161]), 'bias': tensor([0.3352])})\n",
            "Epoch: 24040 | MAE Train Loss: 0.016834942623972893 | MAE Test Loss: 0.039355576038360596 \n",
            "OrderedDict({'weights': tensor([0.6163]), 'bias': tensor([0.3352])})\n",
            "Epoch: 24050 | MAE Train Loss: 0.01680057868361473 | MAE Test Loss: 0.03927973657846451 \n",
            "OrderedDict({'weights': tensor([0.6164]), 'bias': tensor([0.3351])})\n",
            "Epoch: 24060 | MAE Train Loss: 0.01676625944674015 | MAE Test Loss: 0.03919708728790283 \n",
            "OrderedDict({'weights': tensor([0.6166]), 'bias': tensor([0.3350])})\n",
            "Epoch: 24070 | MAE Train Loss: 0.016731858253479004 | MAE Test Loss: 0.039114415645599365 \n",
            "OrderedDict({'weights': tensor([0.6168]), 'bias': tensor([0.3350])})\n",
            "Epoch: 24080 | MAE Train Loss: 0.01669752039015293 | MAE Test Loss: 0.039035163819789886 \n",
            "OrderedDict({'weights': tensor([0.6169]), 'bias': tensor([0.3349])})\n",
            "Epoch: 24090 | MAE Train Loss: 0.016663122922182083 | MAE Test Loss: 0.038955945521593094 \n",
            "OrderedDict({'weights': tensor([0.6171]), 'bias': tensor([0.3348])})\n",
            "Epoch: 24100 | MAE Train Loss: 0.016628777608275414 | MAE Test Loss: 0.03887326270341873 \n",
            "OrderedDict({'weights': tensor([0.6173]), 'bias': tensor([0.3347])})\n",
            "Epoch: 24110 | MAE Train Loss: 0.016594424843788147 | MAE Test Loss: 0.03879743069410324 \n",
            "OrderedDict({'weights': tensor([0.6175]), 'bias': tensor([0.3347])})\n",
            "Epoch: 24120 | MAE Train Loss: 0.016560101881623268 | MAE Test Loss: 0.038714759051799774 \n",
            "OrderedDict({'weights': tensor([0.6176]), 'bias': tensor([0.3346])})\n",
            "Epoch: 24130 | MAE Train Loss: 0.016525745391845703 | MAE Test Loss: 0.038635533303022385 \n",
            "OrderedDict({'weights': tensor([0.6178]), 'bias': tensor([0.3345])})\n",
            "Epoch: 24140 | MAE Train Loss: 0.016491351649165154 | MAE Test Loss: 0.03855286166071892 \n",
            "OrderedDict({'weights': tensor([0.6180]), 'bias': tensor([0.3345])})\n",
            "Epoch: 24150 | MAE Train Loss: 0.016457021236419678 | MAE Test Loss: 0.03847361356019974 \n",
            "OrderedDict({'weights': tensor([0.6181]), 'bias': tensor([0.3344])})\n",
            "Epoch: 24160 | MAE Train Loss: 0.016422618180513382 | MAE Test Loss: 0.03839094191789627 \n",
            "OrderedDict({'weights': tensor([0.6183]), 'bias': tensor([0.3343])})\n",
            "Epoch: 24170 | MAE Train Loss: 0.01638827659189701 | MAE Test Loss: 0.038315124809741974 \n",
            "OrderedDict({'weights': tensor([0.6185]), 'bias': tensor([0.3342])})\n",
            "Epoch: 24180 | MAE Train Loss: 0.016353940591216087 | MAE Test Loss: 0.03823241591453552 \n",
            "OrderedDict({'weights': tensor([0.6187]), 'bias': tensor([0.3342])})\n",
            "Epoch: 24190 | MAE Train Loss: 0.016319597139954567 | MAE Test Loss: 0.038153231143951416 \n",
            "OrderedDict({'weights': tensor([0.6188]), 'bias': tensor([0.3341])})\n",
            "Epoch: 24200 | MAE Train Loss: 0.016285207122564316 | MAE Test Loss: 0.03807397931814194 \n",
            "OrderedDict({'weights': tensor([0.6190]), 'bias': tensor([0.3340])})\n",
            "Epoch: 24210 | MAE Train Loss: 0.016250867396593094 | MAE Test Loss: 0.03799128532409668 \n",
            "OrderedDict({'weights': tensor([0.6192]), 'bias': tensor([0.3339])})\n",
            "Epoch: 24220 | MAE Train Loss: 0.016216453164815903 | MAE Test Loss: 0.03790862485766411 \n",
            "OrderedDict({'weights': tensor([0.6193]), 'bias': tensor([0.3339])})\n",
            "Epoch: 24230 | MAE Train Loss: 0.016182124614715576 | MAE Test Loss: 0.03783280774950981 \n",
            "OrderedDict({'weights': tensor([0.6195]), 'bias': tensor([0.3338])})\n",
            "Epoch: 24240 | MAE Train Loss: 0.01614774577319622 | MAE Test Loss: 0.037753574550151825 \n",
            "OrderedDict({'weights': tensor([0.6197]), 'bias': tensor([0.3337])})\n",
            "Epoch: 24250 | MAE Train Loss: 0.01611338183283806 | MAE Test Loss: 0.03766748309135437 \n",
            "OrderedDict({'weights': tensor([0.6199]), 'bias': tensor([0.3337])})\n",
            "Epoch: 24260 | MAE Train Loss: 0.016079062595963478 | MAE Test Loss: 0.03759167715907097 \n",
            "OrderedDict({'weights': tensor([0.6200]), 'bias': tensor([0.3336])})\n",
            "Epoch: 24270 | MAE Train Loss: 0.016044698655605316 | MAE Test Loss: 0.037508994340896606 \n",
            "OrderedDict({'weights': tensor([0.6202]), 'bias': tensor([0.3335])})\n",
            "Epoch: 24280 | MAE Train Loss: 0.01601029559969902 | MAE Test Loss: 0.03742630034685135 \n",
            "OrderedDict({'weights': tensor([0.6204]), 'bias': tensor([0.3334])})\n",
            "Epoch: 24290 | MAE Train Loss: 0.0159759558737278 | MAE Test Loss: 0.03734707087278366 \n",
            "OrderedDict({'weights': tensor([0.6205]), 'bias': tensor([0.3334])})\n",
            "Epoch: 24300 | MAE Train Loss: 0.015941599383950233 | MAE Test Loss: 0.03727123141288757 \n",
            "OrderedDict({'weights': tensor([0.6207]), 'bias': tensor([0.3333])})\n",
            "Epoch: 24310 | MAE Train Loss: 0.015907222405076027 | MAE Test Loss: 0.0371851809322834 \n",
            "OrderedDict({'weights': tensor([0.6209]), 'bias': tensor([0.3332])})\n",
            "Epoch: 24320 | MAE Train Loss: 0.015872906893491745 | MAE Test Loss: 0.03710935264825821 \n",
            "OrderedDict({'weights': tensor([0.6210]), 'bias': tensor([0.3332])})\n",
            "Epoch: 24330 | MAE Train Loss: 0.015838537365198135 | MAE Test Loss: 0.03702666610479355 \n",
            "OrderedDict({'weights': tensor([0.6212]), 'bias': tensor([0.3331])})\n",
            "Epoch: 24340 | MAE Train Loss: 0.015804126858711243 | MAE Test Loss: 0.03694744035601616 \n",
            "OrderedDict({'weights': tensor([0.6214]), 'bias': tensor([0.3330])})\n",
            "Epoch: 24350 | MAE Train Loss: 0.01576979085803032 | MAE Test Loss: 0.0368647575378418 \n",
            "OrderedDict({'weights': tensor([0.6216]), 'bias': tensor([0.3329])})\n",
            "Epoch: 24360 | MAE Train Loss: 0.015735460445284843 | MAE Test Loss: 0.03678552433848381 \n",
            "OrderedDict({'weights': tensor([0.6217]), 'bias': tensor([0.3329])})\n",
            "Epoch: 24370 | MAE Train Loss: 0.015701059252023697 | MAE Test Loss: 0.036709707230329514 \n",
            "OrderedDict({'weights': tensor([0.6219]), 'bias': tensor([0.3328])})\n",
            "Epoch: 24380 | MAE Train Loss: 0.01566675677895546 | MAE Test Loss: 0.03662702441215515 \n",
            "OrderedDict({'weights': tensor([0.6221]), 'bias': tensor([0.3327])})\n",
            "Epoch: 24390 | MAE Train Loss: 0.015632372349500656 | MAE Test Loss: 0.036544352769851685 \n",
            "OrderedDict({'weights': tensor([0.6222]), 'bias': tensor([0.3327])})\n",
            "Epoch: 24400 | MAE Train Loss: 0.015598039142787457 | MAE Test Loss: 0.0364651158452034 \n",
            "OrderedDict({'weights': tensor([0.6224]), 'bias': tensor([0.3326])})\n",
            "Epoch: 24410 | MAE Train Loss: 0.015563687309622765 | MAE Test Loss: 0.03638588637113571 \n",
            "OrderedDict({'weights': tensor([0.6226]), 'bias': tensor([0.3325])})\n",
            "Epoch: 24420 | MAE Train Loss: 0.01552930474281311 | MAE Test Loss: 0.03630320355296135 \n",
            "OrderedDict({'weights': tensor([0.6228]), 'bias': tensor([0.3324])})\n",
            "Epoch: 24430 | MAE Train Loss: 0.015494907274842262 | MAE Test Loss: 0.03622737526893616 \n",
            "OrderedDict({'weights': tensor([0.6229]), 'bias': tensor([0.3324])})\n",
            "Epoch: 24440 | MAE Train Loss: 0.015460604801774025 | MAE Test Loss: 0.036144714802503586 \n",
            "OrderedDict({'weights': tensor([0.6231]), 'bias': tensor([0.3323])})\n",
            "Epoch: 24450 | MAE Train Loss: 0.015426223166286945 | MAE Test Loss: 0.0360654816031456 \n",
            "OrderedDict({'weights': tensor([0.6233]), 'bias': tensor([0.3322])})\n",
            "Epoch: 24460 | MAE Train Loss: 0.015391871333122253 | MAE Test Loss: 0.03598276525735855 \n",
            "OrderedDict({'weights': tensor([0.6234]), 'bias': tensor([0.3322])})\n",
            "Epoch: 24470 | MAE Train Loss: 0.015357526950538158 | MAE Test Loss: 0.03590357303619385 \n",
            "OrderedDict({'weights': tensor([0.6236]), 'bias': tensor([0.3321])})\n",
            "Epoch: 24480 | MAE Train Loss: 0.015323137864470482 | MAE Test Loss: 0.035820890218019485 \n",
            "OrderedDict({'weights': tensor([0.6238]), 'bias': tensor([0.3320])})\n",
            "Epoch: 24490 | MAE Train Loss: 0.015288758091628551 | MAE Test Loss: 0.03574507310986519 \n",
            "OrderedDict({'weights': tensor([0.6240]), 'bias': tensor([0.3319])})\n",
            "Epoch: 24500 | MAE Train Loss: 0.015254398807883263 | MAE Test Loss: 0.03565897420048714 \n",
            "OrderedDict({'weights': tensor([0.6241]), 'bias': tensor([0.3319])})\n",
            "Epoch: 24510 | MAE Train Loss: 0.015220070257782936 | MAE Test Loss: 0.035583168268203735 \n",
            "OrderedDict({'weights': tensor([0.6243]), 'bias': tensor([0.3318])})\n",
            "Epoch: 24520 | MAE Train Loss: 0.015185688622295856 | MAE Test Loss: 0.03550393134355545 \n",
            "OrderedDict({'weights': tensor([0.6245]), 'bias': tensor([0.3317])})\n",
            "Epoch: 24530 | MAE Train Loss: 0.015151378698647022 | MAE Test Loss: 0.035421233624219894 \n",
            "OrderedDict({'weights': tensor([0.6246]), 'bias': tensor([0.3317])})\n",
            "Epoch: 24540 | MAE Train Loss: 0.015116977505385876 | MAE Test Loss: 0.03533856198191643 \n",
            "OrderedDict({'weights': tensor([0.6248]), 'bias': tensor([0.3316])})\n",
            "Epoch: 24550 | MAE Train Loss: 0.015082602389156818 | MAE Test Loss: 0.035262733697891235 \n",
            "OrderedDict({'weights': tensor([0.6250]), 'bias': tensor([0.3315])})\n",
            "Epoch: 24560 | MAE Train Loss: 0.015048235654830933 | MAE Test Loss: 0.03517664223909378 \n",
            "OrderedDict({'weights': tensor([0.6252]), 'bias': tensor([0.3314])})\n",
            "Epoch: 24570 | MAE Train Loss: 0.015013901516795158 | MAE Test Loss: 0.03509741276502609 \n",
            "OrderedDict({'weights': tensor([0.6253]), 'bias': tensor([0.3314])})\n",
            "Epoch: 24580 | MAE Train Loss: 0.014979535713791847 | MAE Test Loss: 0.035021573305130005 \n",
            "OrderedDict({'weights': tensor([0.6255]), 'bias': tensor([0.3313])})\n",
            "Epoch: 24590 | MAE Train Loss: 0.01494521927088499 | MAE Test Loss: 0.03493892401456833 \n",
            "OrderedDict({'weights': tensor([0.6257]), 'bias': tensor([0.3312])})\n",
            "Epoch: 24600 | MAE Train Loss: 0.014910812489688396 | MAE Test Loss: 0.03485625237226486 \n",
            "OrderedDict({'weights': tensor([0.6258]), 'bias': tensor([0.3312])})\n",
            "Epoch: 24610 | MAE Train Loss: 0.01487648207694292 | MAE Test Loss: 0.03477701544761658 \n",
            "OrderedDict({'weights': tensor([0.6260]), 'bias': tensor([0.3311])})\n",
            "Epoch: 24620 | MAE Train Loss: 0.014842080883681774 | MAE Test Loss: 0.03469778969883919 \n",
            "OrderedDict({'weights': tensor([0.6262]), 'bias': tensor([0.3310])})\n",
            "Epoch: 24630 | MAE Train Loss: 0.01480773650109768 | MAE Test Loss: 0.034615106880664825 \n",
            "OrderedDict({'weights': tensor([0.6263]), 'bias': tensor([0.3309])})\n",
            "Epoch: 24640 | MAE Train Loss: 0.014773383736610413 | MAE Test Loss: 0.034539274871349335 \n",
            "OrderedDict({'weights': tensor([0.6265]), 'bias': tensor([0.3309])})\n",
            "Epoch: 24650 | MAE Train Loss: 0.014739058911800385 | MAE Test Loss: 0.03445660322904587 \n",
            "OrderedDict({'weights': tensor([0.6267]), 'bias': tensor([0.3308])})\n",
            "Epoch: 24660 | MAE Train Loss: 0.014704704284667969 | MAE Test Loss: 0.03437737748026848 \n",
            "OrderedDict({'weights': tensor([0.6269]), 'bias': tensor([0.3307])})\n",
            "Epoch: 24670 | MAE Train Loss: 0.014670310541987419 | MAE Test Loss: 0.03429470583796501 \n",
            "OrderedDict({'weights': tensor([0.6270]), 'bias': tensor([0.3306])})\n",
            "Epoch: 24680 | MAE Train Loss: 0.014635980129241943 | MAE Test Loss: 0.03421545773744583 \n",
            "OrderedDict({'weights': tensor([0.6272]), 'bias': tensor([0.3306])})\n",
            "Epoch: 24690 | MAE Train Loss: 0.014601576142013073 | MAE Test Loss: 0.034132786095142365 \n",
            "OrderedDict({'weights': tensor([0.6274]), 'bias': tensor([0.3305])})\n",
            "Epoch: 24700 | MAE Train Loss: 0.014567235484719276 | MAE Test Loss: 0.03405696898698807 \n",
            "OrderedDict({'weights': tensor([0.6275]), 'bias': tensor([0.3304])})\n",
            "Epoch: 24710 | MAE Train Loss: 0.014532899484038353 | MAE Test Loss: 0.033974260091781616 \n",
            "OrderedDict({'weights': tensor([0.6277]), 'bias': tensor([0.3304])})\n",
            "Epoch: 24720 | MAE Train Loss: 0.014498556032776833 | MAE Test Loss: 0.03389506787061691 \n",
            "OrderedDict({'weights': tensor([0.6279]), 'bias': tensor([0.3303])})\n",
            "Epoch: 24730 | MAE Train Loss: 0.014464166946709156 | MAE Test Loss: 0.03381583094596863 \n",
            "OrderedDict({'weights': tensor([0.6281]), 'bias': tensor([0.3302])})\n",
            "Epoch: 24740 | MAE Train Loss: 0.014429825358092785 | MAE Test Loss: 0.03373313695192337 \n",
            "OrderedDict({'weights': tensor([0.6282]), 'bias': tensor([0.3301])})\n",
            "Epoch: 24750 | MAE Train Loss: 0.014395412988960743 | MAE Test Loss: 0.0336504764854908 \n",
            "OrderedDict({'weights': tensor([0.6284]), 'bias': tensor([0.3301])})\n",
            "Epoch: 24760 | MAE Train Loss: 0.014361085370182991 | MAE Test Loss: 0.0335746593773365 \n",
            "OrderedDict({'weights': tensor([0.6286]), 'bias': tensor([0.3300])})\n",
            "Epoch: 24770 | MAE Train Loss: 0.014326703734695911 | MAE Test Loss: 0.03349541872739792 \n",
            "OrderedDict({'weights': tensor([0.6287]), 'bias': tensor([0.3299])})\n",
            "Epoch: 24780 | MAE Train Loss: 0.014292341656982899 | MAE Test Loss: 0.033409327268600464 \n",
            "OrderedDict({'weights': tensor([0.6289]), 'bias': tensor([0.3299])})\n",
            "Epoch: 24790 | MAE Train Loss: 0.014258021488785744 | MAE Test Loss: 0.03333352133631706 \n",
            "OrderedDict({'weights': tensor([0.6291]), 'bias': tensor([0.3298])})\n",
            "Epoch: 24800 | MAE Train Loss: 0.014223655685782433 | MAE Test Loss: 0.0332508385181427 \n",
            "OrderedDict({'weights': tensor([0.6293]), 'bias': tensor([0.3297])})\n",
            "Epoch: 24810 | MAE Train Loss: 0.014189252629876137 | MAE Test Loss: 0.03316814452409744 \n",
            "OrderedDict({'weights': tensor([0.6294]), 'bias': tensor([0.3296])})\n",
            "Epoch: 24820 | MAE Train Loss: 0.01415491383522749 | MAE Test Loss: 0.033088915050029755 \n",
            "OrderedDict({'weights': tensor([0.6296]), 'bias': tensor([0.3296])})\n",
            "Epoch: 24830 | MAE Train Loss: 0.014120558276772499 | MAE Test Loss: 0.03301307559013367 \n",
            "OrderedDict({'weights': tensor([0.6298]), 'bias': tensor([0.3295])})\n",
            "Epoch: 24840 | MAE Train Loss: 0.014086181297898293 | MAE Test Loss: 0.0329270176589489 \n",
            "OrderedDict({'weights': tensor([0.6299]), 'bias': tensor([0.3294])})\n",
            "Epoch: 24850 | MAE Train Loss: 0.014051866717636585 | MAE Test Loss: 0.032851189374923706 \n",
            "OrderedDict({'weights': tensor([0.6301]), 'bias': tensor([0.3294])})\n",
            "Epoch: 24860 | MAE Train Loss: 0.014017495326697826 | MAE Test Loss: 0.032768506556749344 \n",
            "OrderedDict({'weights': tensor([0.6303]), 'bias': tensor([0.3293])})\n",
            "Epoch: 24870 | MAE Train Loss: 0.013983083888888359 | MAE Test Loss: 0.03268929198384285 \n",
            "OrderedDict({'weights': tensor([0.6304]), 'bias': tensor([0.3292])})\n",
            "Epoch: 24880 | MAE Train Loss: 0.013948751613497734 | MAE Test Loss: 0.03260660916566849 \n",
            "OrderedDict({'weights': tensor([0.6306]), 'bias': tensor([0.3291])})\n",
            "Epoch: 24890 | MAE Train Loss: 0.013914418406784534 | MAE Test Loss: 0.032527368515729904 \n",
            "OrderedDict({'weights': tensor([0.6308]), 'bias': tensor([0.3291])})\n",
            "Epoch: 24900 | MAE Train Loss: 0.013880017213523388 | MAE Test Loss: 0.03245155140757561 \n",
            "OrderedDict({'weights': tensor([0.6310]), 'bias': tensor([0.3290])})\n",
            "Epoch: 24910 | MAE Train Loss: 0.01384571474045515 | MAE Test Loss: 0.032368868589401245 \n",
            "OrderedDict({'weights': tensor([0.6311]), 'bias': tensor([0.3289])})\n",
            "Epoch: 24920 | MAE Train Loss: 0.013811332173645496 | MAE Test Loss: 0.03228619694709778 \n",
            "OrderedDict({'weights': tensor([0.6313]), 'bias': tensor([0.3289])})\n",
            "Epoch: 24930 | MAE Train Loss: 0.013776997104287148 | MAE Test Loss: 0.03220696002244949 \n",
            "OrderedDict({'weights': tensor([0.6315]), 'bias': tensor([0.3288])})\n",
            "Epoch: 24940 | MAE Train Loss: 0.01374264620244503 | MAE Test Loss: 0.032127730548381805 \n",
            "OrderedDict({'weights': tensor([0.6316]), 'bias': tensor([0.3287])})\n",
            "Epoch: 24950 | MAE Train Loss: 0.013708263635635376 | MAE Test Loss: 0.03204504773020744 \n",
            "OrderedDict({'weights': tensor([0.6318]), 'bias': tensor([0.3286])})\n",
            "Epoch: 24960 | MAE Train Loss: 0.013673866167664528 | MAE Test Loss: 0.03196921944618225 \n",
            "OrderedDict({'weights': tensor([0.6320]), 'bias': tensor([0.3286])})\n",
            "Epoch: 24970 | MAE Train Loss: 0.013639564625918865 | MAE Test Loss: 0.03188655897974968 \n",
            "OrderedDict({'weights': tensor([0.6322]), 'bias': tensor([0.3285])})\n",
            "Epoch: 24980 | MAE Train Loss: 0.013605182059109211 | MAE Test Loss: 0.031807322055101395 \n",
            "OrderedDict({'weights': tensor([0.6323]), 'bias': tensor([0.3284])})\n",
            "Epoch: 24990 | MAE Train Loss: 0.01357082836329937 | MAE Test Loss: 0.03172460198402405 \n",
            "OrderedDict({'weights': tensor([0.6325]), 'bias': tensor([0.3283])})\n",
            "Epoch: 25000 | MAE Train Loss: 0.013536485843360424 | MAE Test Loss: 0.03164542466402054 \n",
            "OrderedDict({'weights': tensor([0.6327]), 'bias': tensor([0.3283])})\n",
            "Epoch: 25010 | MAE Train Loss: 0.013502096757292747 | MAE Test Loss: 0.03156273812055588 \n",
            "OrderedDict({'weights': tensor([0.6328]), 'bias': tensor([0.3282])})\n",
            "Epoch: 25020 | MAE Train Loss: 0.013467718847095966 | MAE Test Loss: 0.03148692101240158 \n",
            "OrderedDict({'weights': tensor([0.6330]), 'bias': tensor([0.3281])})\n",
            "Epoch: 25030 | MAE Train Loss: 0.013433357700705528 | MAE Test Loss: 0.03140081837773323 \n",
            "OrderedDict({'weights': tensor([0.6332]), 'bias': tensor([0.3281])})\n",
            "Epoch: 25040 | MAE Train Loss: 0.013399029150605202 | MAE Test Loss: 0.03132501244544983 \n",
            "OrderedDict({'weights': tensor([0.6334]), 'bias': tensor([0.3280])})\n",
            "Epoch: 25050 | MAE Train Loss: 0.013364645652472973 | MAE Test Loss: 0.031245773658156395 \n",
            "OrderedDict({'weights': tensor([0.6335]), 'bias': tensor([0.3279])})\n",
            "Epoch: 25060 | MAE Train Loss: 0.013330337591469288 | MAE Test Loss: 0.031163077801465988 \n",
            "OrderedDict({'weights': tensor([0.6337]), 'bias': tensor([0.3278])})\n",
            "Epoch: 25070 | MAE Train Loss: 0.013295936398208141 | MAE Test Loss: 0.03108040615916252 \n",
            "OrderedDict({'weights': tensor([0.6339]), 'bias': tensor([0.3278])})\n",
            "Epoch: 25080 | MAE Train Loss: 0.013261561281979084 | MAE Test Loss: 0.03100457787513733 \n",
            "OrderedDict({'weights': tensor([0.6340]), 'bias': tensor([0.3277])})\n",
            "Epoch: 25090 | MAE Train Loss: 0.013227196410298347 | MAE Test Loss: 0.030918484553694725 \n",
            "OrderedDict({'weights': tensor([0.6342]), 'bias': tensor([0.3276])})\n",
            "Epoch: 25100 | MAE Train Loss: 0.013192860409617424 | MAE Test Loss: 0.030839258804917336 \n",
            "OrderedDict({'weights': tensor([0.6344]), 'bias': tensor([0.3276])})\n",
            "Epoch: 25110 | MAE Train Loss: 0.013158494606614113 | MAE Test Loss: 0.0307634174823761 \n",
            "OrderedDict({'weights': tensor([0.6346]), 'bias': tensor([0.3275])})\n",
            "Epoch: 25120 | MAE Train Loss: 0.013124177232384682 | MAE Test Loss: 0.030680770054459572 \n",
            "OrderedDict({'weights': tensor([0.6347]), 'bias': tensor([0.3274])})\n",
            "Epoch: 25130 | MAE Train Loss: 0.013089773245155811 | MAE Test Loss: 0.030598098412156105 \n",
            "OrderedDict({'weights': tensor([0.6349]), 'bias': tensor([0.3273])})\n",
            "Epoch: 25140 | MAE Train Loss: 0.013055439107120037 | MAE Test Loss: 0.03051885962486267 \n",
            "OrderedDict({'weights': tensor([0.6351]), 'bias': tensor([0.3273])})\n",
            "Epoch: 25150 | MAE Train Loss: 0.01302103977650404 | MAE Test Loss: 0.03043963387608528 \n",
            "OrderedDict({'weights': tensor([0.6352]), 'bias': tensor([0.3272])})\n",
            "Epoch: 25160 | MAE Train Loss: 0.012986699119210243 | MAE Test Loss: 0.03035694919526577 \n",
            "OrderedDict({'weights': tensor([0.6354]), 'bias': tensor([0.3271])})\n",
            "Epoch: 25170 | MAE Train Loss: 0.012952342629432678 | MAE Test Loss: 0.030281120911240578 \n",
            "OrderedDict({'weights': tensor([0.6356]), 'bias': tensor([0.3271])})\n",
            "Epoch: 25180 | MAE Train Loss: 0.01291801780462265 | MAE Test Loss: 0.03019844926893711 \n",
            "OrderedDict({'weights': tensor([0.6357]), 'bias': tensor([0.3270])})\n",
            "Epoch: 25190 | MAE Train Loss: 0.012883663177490234 | MAE Test Loss: 0.030119221657514572 \n",
            "OrderedDict({'weights': tensor([0.6359]), 'bias': tensor([0.3269])})\n",
            "Epoch: 25200 | MAE Train Loss: 0.012849269434809685 | MAE Test Loss: 0.030036550015211105 \n",
            "OrderedDict({'weights': tensor([0.6361]), 'bias': tensor([0.3268])})\n",
            "Epoch: 25210 | MAE Train Loss: 0.012814940884709358 | MAE Test Loss: 0.029957300052046776 \n",
            "OrderedDict({'weights': tensor([0.6363]), 'bias': tensor([0.3268])})\n",
            "Epoch: 25220 | MAE Train Loss: 0.012780535034835339 | MAE Test Loss: 0.02987462840974331 \n",
            "OrderedDict({'weights': tensor([0.6364]), 'bias': tensor([0.3267])})\n",
            "Epoch: 25230 | MAE Train Loss: 0.012746194377541542 | MAE Test Loss: 0.029798811301589012 \n",
            "OrderedDict({'weights': tensor([0.6366]), 'bias': tensor([0.3266])})\n",
            "Epoch: 25240 | MAE Train Loss: 0.012711858376860619 | MAE Test Loss: 0.02971610426902771 \n",
            "OrderedDict({'weights': tensor([0.6368]), 'bias': tensor([0.3266])})\n",
            "Epoch: 25250 | MAE Train Loss: 0.012677514925599098 | MAE Test Loss: 0.029636913910508156 \n",
            "OrderedDict({'weights': tensor([0.6369]), 'bias': tensor([0.3265])})\n",
            "Epoch: 25260 | MAE Train Loss: 0.012643125839531422 | MAE Test Loss: 0.02955767512321472 \n",
            "OrderedDict({'weights': tensor([0.6371]), 'bias': tensor([0.3264])})\n",
            "Epoch: 25270 | MAE Train Loss: 0.01260878425091505 | MAE Test Loss: 0.029474979266524315 \n",
            "OrderedDict({'weights': tensor([0.6373]), 'bias': tensor([0.3263])})\n",
            "Epoch: 25280 | MAE Train Loss: 0.012574371881783009 | MAE Test Loss: 0.029392320662736893 \n",
            "OrderedDict({'weights': tensor([0.6375]), 'bias': tensor([0.3263])})\n",
            "Epoch: 25290 | MAE Train Loss: 0.012540044263005257 | MAE Test Loss: 0.029316503554582596 \n",
            "OrderedDict({'weights': tensor([0.6376]), 'bias': tensor([0.3262])})\n",
            "Epoch: 25300 | MAE Train Loss: 0.012505662627518177 | MAE Test Loss: 0.02923726476728916 \n",
            "OrderedDict({'weights': tensor([0.6378]), 'bias': tensor([0.3261])})\n",
            "Epoch: 25310 | MAE Train Loss: 0.01247129961848259 | MAE Test Loss: 0.029151171445846558 \n",
            "OrderedDict({'weights': tensor([0.6380]), 'bias': tensor([0.3261])})\n",
            "Epoch: 25320 | MAE Train Loss: 0.01243698038160801 | MAE Test Loss: 0.029075365513563156 \n",
            "OrderedDict({'weights': tensor([0.6381]), 'bias': tensor([0.3260])})\n",
            "Epoch: 25330 | MAE Train Loss: 0.012402615509927273 | MAE Test Loss: 0.028992682695388794 \n",
            "OrderedDict({'weights': tensor([0.6383]), 'bias': tensor([0.3259])})\n",
            "Epoch: 25340 | MAE Train Loss: 0.012368211522698402 | MAE Test Loss: 0.028909986838698387 \n",
            "OrderedDict({'weights': tensor([0.6385]), 'bias': tensor([0.3258])})\n",
            "Epoch: 25350 | MAE Train Loss: 0.012333872728049755 | MAE Test Loss: 0.028830761089920998 \n",
            "OrderedDict({'weights': tensor([0.6387]), 'bias': tensor([0.3258])})\n",
            "Epoch: 25360 | MAE Train Loss: 0.012299517169594765 | MAE Test Loss: 0.02875491976737976 \n",
            "OrderedDict({'weights': tensor([0.6388]), 'bias': tensor([0.3257])})\n",
            "Epoch: 25370 | MAE Train Loss: 0.012265139259397984 | MAE Test Loss: 0.028668861836194992 \n",
            "OrderedDict({'weights': tensor([0.6390]), 'bias': tensor([0.3256])})\n",
            "Epoch: 25380 | MAE Train Loss: 0.012230826541781425 | MAE Test Loss: 0.0285930335521698 \n",
            "OrderedDict({'weights': tensor([0.6392]), 'bias': tensor([0.3255])})\n",
            "Epoch: 25390 | MAE Train Loss: 0.012196453288197517 | MAE Test Loss: 0.028510350733995438 \n",
            "OrderedDict({'weights': tensor([0.6393]), 'bias': tensor([0.3255])})\n",
            "Epoch: 25400 | MAE Train Loss: 0.012162042781710625 | MAE Test Loss: 0.028431136161088943 \n",
            "OrderedDict({'weights': tensor([0.6395]), 'bias': tensor([0.3254])})\n",
            "Epoch: 25410 | MAE Train Loss: 0.01212771050632 | MAE Test Loss: 0.028348451480269432 \n",
            "OrderedDict({'weights': tensor([0.6397]), 'bias': tensor([0.3253])})\n",
            "Epoch: 25420 | MAE Train Loss: 0.0120933772996068 | MAE Test Loss: 0.028269212692975998 \n",
            "OrderedDict({'weights': tensor([0.6399]), 'bias': tensor([0.3253])})\n",
            "Epoch: 25430 | MAE Train Loss: 0.012058975175023079 | MAE Test Loss: 0.0281933955848217 \n",
            "OrderedDict({'weights': tensor([0.6400]), 'bias': tensor([0.3252])})\n",
            "Epoch: 25440 | MAE Train Loss: 0.012024672701954842 | MAE Test Loss: 0.02811071276664734 \n",
            "OrderedDict({'weights': tensor([0.6402]), 'bias': tensor([0.3251])})\n",
            "Epoch: 25450 | MAE Train Loss: 0.011990291066467762 | MAE Test Loss: 0.028028041124343872 \n",
            "OrderedDict({'weights': tensor([0.6404]), 'bias': tensor([0.3250])})\n",
            "Epoch: 25460 | MAE Train Loss: 0.011955955997109413 | MAE Test Loss: 0.027948802337050438 \n",
            "OrderedDict({'weights': tensor([0.6405]), 'bias': tensor([0.3250])})\n",
            "Epoch: 25470 | MAE Train Loss: 0.01192160602658987 | MAE Test Loss: 0.02786957658827305 \n",
            "OrderedDict({'weights': tensor([0.6407]), 'bias': tensor([0.3249])})\n",
            "Epoch: 25480 | MAE Train Loss: 0.011887222528457642 | MAE Test Loss: 0.027786891907453537 \n",
            "OrderedDict({'weights': tensor([0.6409]), 'bias': tensor([0.3248])})\n",
            "Epoch: 25490 | MAE Train Loss: 0.011852826923131943 | MAE Test Loss: 0.027711063623428345 \n",
            "OrderedDict({'weights': tensor([0.6410]), 'bias': tensor([0.3248])})\n",
            "Epoch: 25500 | MAE Train Loss: 0.01181852351874113 | MAE Test Loss: 0.027628403156995773 \n",
            "OrderedDict({'weights': tensor([0.6412]), 'bias': tensor([0.3247])})\n",
            "Epoch: 25510 | MAE Train Loss: 0.011784140951931477 | MAE Test Loss: 0.02754916623234749 \n",
            "OrderedDict({'weights': tensor([0.6414]), 'bias': tensor([0.3246])})\n",
            "Epoch: 25520 | MAE Train Loss: 0.01174978632479906 | MAE Test Loss: 0.02746644616127014 \n",
            "OrderedDict({'weights': tensor([0.6416]), 'bias': tensor([0.3245])})\n",
            "Epoch: 25530 | MAE Train Loss: 0.011715445667505264 | MAE Test Loss: 0.027387266978621483 \n",
            "OrderedDict({'weights': tensor([0.6417]), 'bias': tensor([0.3245])})\n",
            "Epoch: 25540 | MAE Train Loss: 0.011681055650115013 | MAE Test Loss: 0.02730458416044712 \n",
            "OrderedDict({'weights': tensor([0.6419]), 'bias': tensor([0.3244])})\n",
            "Epoch: 25550 | MAE Train Loss: 0.011646677739918232 | MAE Test Loss: 0.027228767052292824 \n",
            "OrderedDict({'weights': tensor([0.6421]), 'bias': tensor([0.3243])})\n",
            "Epoch: 25560 | MAE Train Loss: 0.011612316593527794 | MAE Test Loss: 0.027142662554979324 \n",
            "OrderedDict({'weights': tensor([0.6422]), 'bias': tensor([0.3243])})\n",
            "Epoch: 25570 | MAE Train Loss: 0.011577988043427467 | MAE Test Loss: 0.027066856622695923 \n",
            "OrderedDict({'weights': tensor([0.6424]), 'bias': tensor([0.3242])})\n",
            "Epoch: 25580 | MAE Train Loss: 0.011543605476617813 | MAE Test Loss: 0.02698761783540249 \n",
            "OrderedDict({'weights': tensor([0.6426]), 'bias': tensor([0.3241])})\n",
            "Epoch: 25590 | MAE Train Loss: 0.011509297415614128 | MAE Test Loss: 0.026904921978712082 \n",
            "OrderedDict({'weights': tensor([0.6428]), 'bias': tensor([0.3240])})\n",
            "Epoch: 25600 | MAE Train Loss: 0.011474897153675556 | MAE Test Loss: 0.026822250336408615 \n",
            "OrderedDict({'weights': tensor([0.6429]), 'bias': tensor([0.3240])})\n",
            "Epoch: 25610 | MAE Train Loss: 0.01144052017480135 | MAE Test Loss: 0.026746422052383423 \n",
            "OrderedDict({'weights': tensor([0.6431]), 'bias': tensor([0.3239])})\n",
            "Epoch: 25620 | MAE Train Loss: 0.011406155303120613 | MAE Test Loss: 0.02666032873094082 \n",
            "OrderedDict({'weights': tensor([0.6433]), 'bias': tensor([0.3238])})\n",
            "Epoch: 25630 | MAE Train Loss: 0.01137181930243969 | MAE Test Loss: 0.02658110298216343 \n",
            "OrderedDict({'weights': tensor([0.6434]), 'bias': tensor([0.3238])})\n",
            "Epoch: 25640 | MAE Train Loss: 0.011337453499436378 | MAE Test Loss: 0.026505261659622192 \n",
            "OrderedDict({'weights': tensor([0.6436]), 'bias': tensor([0.3237])})\n",
            "Epoch: 25650 | MAE Train Loss: 0.011303136125206947 | MAE Test Loss: 0.026422614231705666 \n",
            "OrderedDict({'weights': tensor([0.6438]), 'bias': tensor([0.3236])})\n",
            "Epoch: 25660 | MAE Train Loss: 0.011268731206655502 | MAE Test Loss: 0.0263399425894022 \n",
            "OrderedDict({'weights': tensor([0.6440]), 'bias': tensor([0.3235])})\n",
            "Epoch: 25670 | MAE Train Loss: 0.011234397999942303 | MAE Test Loss: 0.026260703802108765 \n",
            "OrderedDict({'weights': tensor([0.6441]), 'bias': tensor([0.3235])})\n",
            "Epoch: 25680 | MAE Train Loss: 0.01120000146329403 | MAE Test Loss: 0.026181478053331375 \n",
            "OrderedDict({'weights': tensor([0.6443]), 'bias': tensor([0.3234])})\n",
            "Epoch: 25690 | MAE Train Loss: 0.011165655218064785 | MAE Test Loss: 0.026098793372511864 \n",
            "OrderedDict({'weights': tensor([0.6445]), 'bias': tensor([0.3233])})\n",
            "Epoch: 25700 | MAE Train Loss: 0.01113130059093237 | MAE Test Loss: 0.02602296508848667 \n",
            "OrderedDict({'weights': tensor([0.6446]), 'bias': tensor([0.3233])})\n",
            "Epoch: 25710 | MAE Train Loss: 0.011096976697444916 | MAE Test Loss: 0.025940293446183205 \n",
            "OrderedDict({'weights': tensor([0.6448]), 'bias': tensor([0.3232])})\n",
            "Epoch: 25720 | MAE Train Loss: 0.011062621138989925 | MAE Test Loss: 0.025861065834760666 \n",
            "OrderedDict({'weights': tensor([0.6450]), 'bias': tensor([0.3231])})\n",
            "Epoch: 25730 | MAE Train Loss: 0.01102822832763195 | MAE Test Loss: 0.0257783941924572 \n",
            "OrderedDict({'weights': tensor([0.6452]), 'bias': tensor([0.3230])})\n",
            "Epoch: 25740 | MAE Train Loss: 0.010993899777531624 | MAE Test Loss: 0.02569914422929287 \n",
            "OrderedDict({'weights': tensor([0.6453]), 'bias': tensor([0.3230])})\n",
            "Epoch: 25750 | MAE Train Loss: 0.010959493927657604 | MAE Test Loss: 0.025616472586989403 \n",
            "OrderedDict({'weights': tensor([0.6455]), 'bias': tensor([0.3229])})\n",
            "Epoch: 25760 | MAE Train Loss: 0.010925153270363808 | MAE Test Loss: 0.025540655478835106 \n",
            "OrderedDict({'weights': tensor([0.6457]), 'bias': tensor([0.3228])})\n",
            "Epoch: 25770 | MAE Train Loss: 0.010890817269682884 | MAE Test Loss: 0.025457948446273804 \n",
            "OrderedDict({'weights': tensor([0.6458]), 'bias': tensor([0.3227])})\n",
            "Epoch: 25780 | MAE Train Loss: 0.01085647288709879 | MAE Test Loss: 0.02537875808775425 \n",
            "OrderedDict({'weights': tensor([0.6460]), 'bias': tensor([0.3227])})\n",
            "Epoch: 25790 | MAE Train Loss: 0.010822083801031113 | MAE Test Loss: 0.025299519300460815 \n",
            "OrderedDict({'weights': tensor([0.6462]), 'bias': tensor([0.3226])})\n",
            "Epoch: 25800 | MAE Train Loss: 0.01078774593770504 | MAE Test Loss: 0.02521682344377041 \n",
            "OrderedDict({'weights': tensor([0.6463]), 'bias': tensor([0.3225])})\n",
            "Epoch: 25810 | MAE Train Loss: 0.010753328911960125 | MAE Test Loss: 0.025134164839982986 \n",
            "OrderedDict({'weights': tensor([0.6465]), 'bias': tensor([0.3225])})\n",
            "Epoch: 25820 | MAE Train Loss: 0.010719003155827522 | MAE Test Loss: 0.02505834773182869 \n",
            "OrderedDict({'weights': tensor([0.6467]), 'bias': tensor([0.3224])})\n",
            "Epoch: 25830 | MAE Train Loss: 0.010684621520340443 | MAE Test Loss: 0.024979108944535255 \n",
            "OrderedDict({'weights': tensor([0.6469]), 'bias': tensor([0.3223])})\n",
            "Epoch: 25840 | MAE Train Loss: 0.010650258511304855 | MAE Test Loss: 0.02489301562309265 \n",
            "OrderedDict({'weights': tensor([0.6470]), 'bias': tensor([0.3222])})\n",
            "Epoch: 25850 | MAE Train Loss: 0.010615939274430275 | MAE Test Loss: 0.02481720969080925 \n",
            "OrderedDict({'weights': tensor([0.6472]), 'bias': tensor([0.3222])})\n",
            "Epoch: 25860 | MAE Train Loss: 0.010581574402749538 | MAE Test Loss: 0.024734526872634888 \n",
            "OrderedDict({'weights': tensor([0.6474]), 'bias': tensor([0.3221])})\n",
            "Epoch: 25870 | MAE Train Loss: 0.010547170415520668 | MAE Test Loss: 0.02465183101594448 \n",
            "OrderedDict({'weights': tensor([0.6475]), 'bias': tensor([0.3220])})\n",
            "Epoch: 25880 | MAE Train Loss: 0.01051283162087202 | MAE Test Loss: 0.02457260526716709 \n",
            "OrderedDict({'weights': tensor([0.6477]), 'bias': tensor([0.3220])})\n",
            "Epoch: 25890 | MAE Train Loss: 0.010478476993739605 | MAE Test Loss: 0.024496763944625854 \n",
            "OrderedDict({'weights': tensor([0.6479]), 'bias': tensor([0.3219])})\n",
            "Epoch: 25900 | MAE Train Loss: 0.01044409815222025 | MAE Test Loss: 0.024410706013441086 \n",
            "OrderedDict({'weights': tensor([0.6481]), 'bias': tensor([0.3218])})\n",
            "Epoch: 25910 | MAE Train Loss: 0.010409785434603691 | MAE Test Loss: 0.024334877729415894 \n",
            "OrderedDict({'weights': tensor([0.6482]), 'bias': tensor([0.3217])})\n",
            "Epoch: 25920 | MAE Train Loss: 0.010375414043664932 | MAE Test Loss: 0.02425219491124153 \n",
            "OrderedDict({'weights': tensor([0.6484]), 'bias': tensor([0.3217])})\n",
            "Epoch: 25930 | MAE Train Loss: 0.010341000743210316 | MAE Test Loss: 0.024172980338335037 \n",
            "OrderedDict({'weights': tensor([0.6486]), 'bias': tensor([0.3216])})\n",
            "Epoch: 25940 | MAE Train Loss: 0.010306669399142265 | MAE Test Loss: 0.024090295657515526 \n",
            "OrderedDict({'weights': tensor([0.6487]), 'bias': tensor([0.3215])})\n",
            "Epoch: 25950 | MAE Train Loss: 0.010272336192429066 | MAE Test Loss: 0.02401105687022209 \n",
            "OrderedDict({'weights': tensor([0.6489]), 'bias': tensor([0.3215])})\n",
            "Epoch: 25960 | MAE Train Loss: 0.010237935930490494 | MAE Test Loss: 0.0239352285861969 \n",
            "OrderedDict({'weights': tensor([0.6491]), 'bias': tensor([0.3214])})\n",
            "Epoch: 25970 | MAE Train Loss: 0.010203631594777107 | MAE Test Loss: 0.023852556943893433 \n",
            "OrderedDict({'weights': tensor([0.6493]), 'bias': tensor([0.3213])})\n",
            "Epoch: 25980 | MAE Train Loss: 0.010169250890612602 | MAE Test Loss: 0.023769885301589966 \n",
            "OrderedDict({'weights': tensor([0.6494]), 'bias': tensor([0.3212])})\n",
            "Epoch: 25990 | MAE Train Loss: 0.010134914889931679 | MAE Test Loss: 0.02369064651429653 \n",
            "OrderedDict({'weights': tensor([0.6496]), 'bias': tensor([0.3212])})\n",
            "Epoch: 26000 | MAE Train Loss: 0.010100564919412136 | MAE Test Loss: 0.023611420765519142 \n",
            "OrderedDict({'weights': tensor([0.6498]), 'bias': tensor([0.3211])})\n",
            "Epoch: 26010 | MAE Train Loss: 0.010066183283925056 | MAE Test Loss: 0.02352873608469963 \n",
            "OrderedDict({'weights': tensor([0.6499]), 'bias': tensor([0.3210])})\n",
            "Epoch: 26020 | MAE Train Loss: 0.010031785815954208 | MAE Test Loss: 0.02345290780067444 \n",
            "OrderedDict({'weights': tensor([0.6501]), 'bias': tensor([0.3210])})\n",
            "Epoch: 26030 | MAE Train Loss: 0.009997482411563396 | MAE Test Loss: 0.023370247334241867 \n",
            "OrderedDict({'weights': tensor([0.6503]), 'bias': tensor([0.3209])})\n",
            "Epoch: 26040 | MAE Train Loss: 0.009963099844753742 | MAE Test Loss: 0.023291010409593582 \n",
            "OrderedDict({'weights': tensor([0.6504]), 'bias': tensor([0.3208])})\n",
            "Epoch: 26050 | MAE Train Loss: 0.009928745217621326 | MAE Test Loss: 0.023208290338516235 \n",
            "OrderedDict({'weights': tensor([0.6506]), 'bias': tensor([0.3207])})\n",
            "Epoch: 26060 | MAE Train Loss: 0.00989440456032753 | MAE Test Loss: 0.023129111155867577 \n",
            "OrderedDict({'weights': tensor([0.6508]), 'bias': tensor([0.3207])})\n",
            "Epoch: 26070 | MAE Train Loss: 0.009860014542937279 | MAE Test Loss: 0.023046428337693214 \n",
            "OrderedDict({'weights': tensor([0.6510]), 'bias': tensor([0.3206])})\n",
            "Epoch: 26080 | MAE Train Loss: 0.009825636632740498 | MAE Test Loss: 0.022970611229538918 \n",
            "OrderedDict({'weights': tensor([0.6511]), 'bias': tensor([0.3205])})\n",
            "Epoch: 26090 | MAE Train Loss: 0.00979127548635006 | MAE Test Loss: 0.022884506732225418 \n",
            "OrderedDict({'weights': tensor([0.6513]), 'bias': tensor([0.3205])})\n",
            "Epoch: 26100 | MAE Train Loss: 0.009756946936249733 | MAE Test Loss: 0.022808700799942017 \n",
            "OrderedDict({'weights': tensor([0.6515]), 'bias': tensor([0.3204])})\n",
            "Epoch: 26110 | MAE Train Loss: 0.009722564369440079 | MAE Test Loss: 0.022729462012648582 \n",
            "OrderedDict({'weights': tensor([0.6516]), 'bias': tensor([0.3203])})\n",
            "Epoch: 26120 | MAE Train Loss: 0.009688256308436394 | MAE Test Loss: 0.022646766155958176 \n",
            "OrderedDict({'weights': tensor([0.6518]), 'bias': tensor([0.3202])})\n",
            "Epoch: 26130 | MAE Train Loss: 0.009653856046497822 | MAE Test Loss: 0.02256409451365471 \n",
            "OrderedDict({'weights': tensor([0.6520]), 'bias': tensor([0.3202])})\n",
            "Epoch: 26140 | MAE Train Loss: 0.009619479067623615 | MAE Test Loss: 0.022488266229629517 \n",
            "OrderedDict({'weights': tensor([0.6522]), 'bias': tensor([0.3201])})\n",
            "Epoch: 26150 | MAE Train Loss: 0.009585114195942879 | MAE Test Loss: 0.022402172908186913 \n",
            "OrderedDict({'weights': tensor([0.6523]), 'bias': tensor([0.3200])})\n",
            "Epoch: 26160 | MAE Train Loss: 0.009550778195261955 | MAE Test Loss: 0.022322947159409523 \n",
            "OrderedDict({'weights': tensor([0.6525]), 'bias': tensor([0.3200])})\n",
            "Epoch: 26170 | MAE Train Loss: 0.009516412392258644 | MAE Test Loss: 0.022247105836868286 \n",
            "OrderedDict({'weights': tensor([0.6527]), 'bias': tensor([0.3199])})\n",
            "Epoch: 26180 | MAE Train Loss: 0.009482095018029213 | MAE Test Loss: 0.02216445840895176 \n",
            "OrderedDict({'weights': tensor([0.6528]), 'bias': tensor([0.3198])})\n",
            "Epoch: 26190 | MAE Train Loss: 0.009447690099477768 | MAE Test Loss: 0.022081786766648293 \n",
            "OrderedDict({'weights': tensor([0.6530]), 'bias': tensor([0.3197])})\n",
            "Epoch: 26200 | MAE Train Loss: 0.009413356892764568 | MAE Test Loss: 0.02200254797935486 \n",
            "OrderedDict({'weights': tensor([0.6532]), 'bias': tensor([0.3197])})\n",
            "Epoch: 26210 | MAE Train Loss: 0.009378960356116295 | MAE Test Loss: 0.02192332223057747 \n",
            "OrderedDict({'weights': tensor([0.6534]), 'bias': tensor([0.3196])})\n",
            "Epoch: 26220 | MAE Train Loss: 0.00934461411088705 | MAE Test Loss: 0.021840637549757957 \n",
            "OrderedDict({'weights': tensor([0.6535]), 'bias': tensor([0.3195])})\n",
            "Epoch: 26230 | MAE Train Loss: 0.009310259483754635 | MAE Test Loss: 0.021764809265732765 \n",
            "OrderedDict({'weights': tensor([0.6537]), 'bias': tensor([0.3194])})\n",
            "Epoch: 26240 | MAE Train Loss: 0.009275935590267181 | MAE Test Loss: 0.0216821376234293 \n",
            "OrderedDict({'weights': tensor([0.6539]), 'bias': tensor([0.3194])})\n",
            "Epoch: 26250 | MAE Train Loss: 0.009241580031812191 | MAE Test Loss: 0.02160291001200676 \n",
            "OrderedDict({'weights': tensor([0.6540]), 'bias': tensor([0.3193])})\n",
            "Epoch: 26260 | MAE Train Loss: 0.009207187220454216 | MAE Test Loss: 0.021520238369703293 \n",
            "OrderedDict({'weights': tensor([0.6542]), 'bias': tensor([0.3192])})\n",
            "Epoch: 26270 | MAE Train Loss: 0.00917285867035389 | MAE Test Loss: 0.021440988406538963 \n",
            "OrderedDict({'weights': tensor([0.6544]), 'bias': tensor([0.3192])})\n",
            "Epoch: 26280 | MAE Train Loss: 0.00913845282047987 | MAE Test Loss: 0.021358316764235497 \n",
            "OrderedDict({'weights': tensor([0.6546]), 'bias': tensor([0.3191])})\n",
            "Epoch: 26290 | MAE Train Loss: 0.009104112163186073 | MAE Test Loss: 0.0212824996560812 \n",
            "OrderedDict({'weights': tensor([0.6547]), 'bias': tensor([0.3190])})\n",
            "Epoch: 26300 | MAE Train Loss: 0.00906977616250515 | MAE Test Loss: 0.021199792623519897 \n",
            "OrderedDict({'weights': tensor([0.6549]), 'bias': tensor([0.3189])})\n",
            "Epoch: 26310 | MAE Train Loss: 0.009035431779921055 | MAE Test Loss: 0.021120602265000343 \n",
            "OrderedDict({'weights': tensor([0.6551]), 'bias': tensor([0.3189])})\n",
            "Epoch: 26320 | MAE Train Loss: 0.009001042693853378 | MAE Test Loss: 0.02104136347770691 \n",
            "OrderedDict({'weights': tensor([0.6552]), 'bias': tensor([0.3188])})\n",
            "Epoch: 26330 | MAE Train Loss: 0.008966704830527306 | MAE Test Loss: 0.020958667621016502 \n",
            "OrderedDict({'weights': tensor([0.6554]), 'bias': tensor([0.3187])})\n",
            "Epoch: 26340 | MAE Train Loss: 0.00893228780478239 | MAE Test Loss: 0.02087600901722908 \n",
            "OrderedDict({'weights': tensor([0.6556]), 'bias': tensor([0.3187])})\n",
            "Epoch: 26350 | MAE Train Loss: 0.008897962048649788 | MAE Test Loss: 0.020800191909074783 \n",
            "OrderedDict({'weights': tensor([0.6557]), 'bias': tensor([0.3186])})\n",
            "Epoch: 26360 | MAE Train Loss: 0.008863580413162708 | MAE Test Loss: 0.02072095312178135 \n",
            "OrderedDict({'weights': tensor([0.6559]), 'bias': tensor([0.3185])})\n",
            "Epoch: 26370 | MAE Train Loss: 0.008829217404127121 | MAE Test Loss: 0.020634859800338745 \n",
            "OrderedDict({'weights': tensor([0.6561]), 'bias': tensor([0.3184])})\n",
            "Epoch: 26380 | MAE Train Loss: 0.00879489816725254 | MAE Test Loss: 0.020559053868055344 \n",
            "OrderedDict({'weights': tensor([0.6563]), 'bias': tensor([0.3184])})\n",
            "Epoch: 26390 | MAE Train Loss: 0.008760533295571804 | MAE Test Loss: 0.02047637104988098 \n",
            "OrderedDict({'weights': tensor([0.6564]), 'bias': tensor([0.3183])})\n",
            "Epoch: 26400 | MAE Train Loss: 0.008726129308342934 | MAE Test Loss: 0.020393675193190575 \n",
            "OrderedDict({'weights': tensor([0.6566]), 'bias': tensor([0.3182])})\n",
            "Epoch: 26410 | MAE Train Loss: 0.008691790513694286 | MAE Test Loss: 0.020314449444413185 \n",
            "OrderedDict({'weights': tensor([0.6568]), 'bias': tensor([0.3182])})\n",
            "Epoch: 26420 | MAE Train Loss: 0.00865743588656187 | MAE Test Loss: 0.020238608121871948 \n",
            "OrderedDict({'weights': tensor([0.6569]), 'bias': tensor([0.3181])})\n",
            "Epoch: 26430 | MAE Train Loss: 0.008623057045042515 | MAE Test Loss: 0.02015255019068718 \n",
            "OrderedDict({'weights': tensor([0.6571]), 'bias': tensor([0.3180])})\n",
            "Epoch: 26440 | MAE Train Loss: 0.008588744327425957 | MAE Test Loss: 0.020076721906661987 \n",
            "OrderedDict({'weights': tensor([0.6573]), 'bias': tensor([0.3179])})\n",
            "Epoch: 26450 | MAE Train Loss: 0.008554372936487198 | MAE Test Loss: 0.019994039088487625 \n",
            "OrderedDict({'weights': tensor([0.6575]), 'bias': tensor([0.3179])})\n",
            "Epoch: 26460 | MAE Train Loss: 0.008519959636032581 | MAE Test Loss: 0.01991482451558113 \n",
            "OrderedDict({'weights': tensor([0.6576]), 'bias': tensor([0.3178])})\n",
            "Epoch: 26470 | MAE Train Loss: 0.008485628291964531 | MAE Test Loss: 0.01983213983476162 \n",
            "OrderedDict({'weights': tensor([0.6578]), 'bias': tensor([0.3177])})\n",
            "Epoch: 26480 | MAE Train Loss: 0.008451295085251331 | MAE Test Loss: 0.019752901047468185 \n",
            "OrderedDict({'weights': tensor([0.6580]), 'bias': tensor([0.3177])})\n",
            "Epoch: 26490 | MAE Train Loss: 0.00841689482331276 | MAE Test Loss: 0.019677072763442993 \n",
            "OrderedDict({'weights': tensor([0.6581]), 'bias': tensor([0.3176])})\n",
            "Epoch: 26500 | MAE Train Loss: 0.008382590487599373 | MAE Test Loss: 0.019594401121139526 \n",
            "OrderedDict({'weights': tensor([0.6583]), 'bias': tensor([0.3175])})\n",
            "Epoch: 26510 | MAE Train Loss: 0.008348209783434868 | MAE Test Loss: 0.01951172947883606 \n",
            "OrderedDict({'weights': tensor([0.6585]), 'bias': tensor([0.3174])})\n",
            "Epoch: 26520 | MAE Train Loss: 0.008313873782753944 | MAE Test Loss: 0.019432490691542625 \n",
            "OrderedDict({'weights': tensor([0.6587]), 'bias': tensor([0.3174])})\n",
            "Epoch: 26530 | MAE Train Loss: 0.008279523812234402 | MAE Test Loss: 0.019353264942765236 \n",
            "OrderedDict({'weights': tensor([0.6588]), 'bias': tensor([0.3173])})\n",
            "Epoch: 26540 | MAE Train Loss: 0.008245142176747322 | MAE Test Loss: 0.019270580261945724 \n",
            "OrderedDict({'weights': tensor([0.6590]), 'bias': tensor([0.3172])})\n",
            "Epoch: 26550 | MAE Train Loss: 0.008210744708776474 | MAE Test Loss: 0.019194751977920532 \n",
            "OrderedDict({'weights': tensor([0.6592]), 'bias': tensor([0.3171])})\n",
            "Epoch: 26560 | MAE Train Loss: 0.008176441304385662 | MAE Test Loss: 0.01911209151148796 \n",
            "OrderedDict({'weights': tensor([0.6593]), 'bias': tensor([0.3171])})\n",
            "Epoch: 26570 | MAE Train Loss: 0.008142056874930859 | MAE Test Loss: 0.019032854586839676 \n",
            "OrderedDict({'weights': tensor([0.6595]), 'bias': tensor([0.3170])})\n",
            "Epoch: 26580 | MAE Train Loss: 0.008107704110443592 | MAE Test Loss: 0.01895013451576233 \n",
            "OrderedDict({'weights': tensor([0.6597]), 'bias': tensor([0.3169])})\n",
            "Epoch: 26590 | MAE Train Loss: 0.008073361590504646 | MAE Test Loss: 0.01887095533311367 \n",
            "OrderedDict({'weights': tensor([0.6599]), 'bias': tensor([0.3169])})\n",
            "Epoch: 26600 | MAE Train Loss: 0.008038973435759544 | MAE Test Loss: 0.018788272514939308 \n",
            "OrderedDict({'weights': tensor([0.6600]), 'bias': tensor([0.3168])})\n",
            "Epoch: 26610 | MAE Train Loss: 0.008004595525562763 | MAE Test Loss: 0.01871245540678501 \n",
            "OrderedDict({'weights': tensor([0.6602]), 'bias': tensor([0.3167])})\n",
            "Epoch: 26620 | MAE Train Loss: 0.007970234379172325 | MAE Test Loss: 0.018626350909471512 \n",
            "OrderedDict({'weights': tensor([0.6604]), 'bias': tensor([0.3166])})\n",
            "Epoch: 26630 | MAE Train Loss: 0.007935905829071999 | MAE Test Loss: 0.01855054497718811 \n",
            "OrderedDict({'weights': tensor([0.6605]), 'bias': tensor([0.3166])})\n",
            "Epoch: 26640 | MAE Train Loss: 0.007901523262262344 | MAE Test Loss: 0.018471306189894676 \n",
            "OrderedDict({'weights': tensor([0.6607]), 'bias': tensor([0.3165])})\n",
            "Epoch: 26650 | MAE Train Loss: 0.00786721520125866 | MAE Test Loss: 0.01838861033320427 \n",
            "OrderedDict({'weights': tensor([0.6609]), 'bias': tensor([0.3164])})\n",
            "Epoch: 26660 | MAE Train Loss: 0.007832814939320087 | MAE Test Loss: 0.018305938690900803 \n",
            "OrderedDict({'weights': tensor([0.6610]), 'bias': tensor([0.3164])})\n",
            "Epoch: 26670 | MAE Train Loss: 0.007798439357429743 | MAE Test Loss: 0.01823011040687561 \n",
            "OrderedDict({'weights': tensor([0.6612]), 'bias': tensor([0.3163])})\n",
            "Epoch: 26680 | MAE Train Loss: 0.007764072623103857 | MAE Test Loss: 0.018144017085433006 \n",
            "OrderedDict({'weights': tensor([0.6614]), 'bias': tensor([0.3162])})\n",
            "Epoch: 26690 | MAE Train Loss: 0.007729736156761646 | MAE Test Loss: 0.018064791336655617 \n",
            "OrderedDict({'weights': tensor([0.6616]), 'bias': tensor([0.3161])})\n",
            "Epoch: 26700 | MAE Train Loss: 0.0076953694224357605 | MAE Test Loss: 0.01798895001411438 \n",
            "OrderedDict({'weights': tensor([0.6617]), 'bias': tensor([0.3161])})\n",
            "Epoch: 26710 | MAE Train Loss: 0.007661054376512766 | MAE Test Loss: 0.017906302586197853 \n",
            "OrderedDict({'weights': tensor([0.6619]), 'bias': tensor([0.3160])})\n",
            "Epoch: 26720 | MAE Train Loss: 0.0076266503892838955 | MAE Test Loss: 0.017823630943894386 \n",
            "OrderedDict({'weights': tensor([0.6621]), 'bias': tensor([0.3159])})\n",
            "Epoch: 26730 | MAE Train Loss: 0.007592315785586834 | MAE Test Loss: 0.017744392156600952 \n",
            "OrderedDict({'weights': tensor([0.6622]), 'bias': tensor([0.3159])})\n",
            "Epoch: 26740 | MAE Train Loss: 0.007557920180261135 | MAE Test Loss: 0.017665166407823563 \n",
            "OrderedDict({'weights': tensor([0.6624]), 'bias': tensor([0.3158])})\n",
            "Epoch: 26750 | MAE Train Loss: 0.007523573003709316 | MAE Test Loss: 0.01758248172700405 \n",
            "OrderedDict({'weights': tensor([0.6626]), 'bias': tensor([0.3157])})\n",
            "Epoch: 26760 | MAE Train Loss: 0.00748922023922205 | MAE Test Loss: 0.01750665344297886 \n",
            "OrderedDict({'weights': tensor([0.6628]), 'bias': tensor([0.3156])})\n",
            "Epoch: 26770 | MAE Train Loss: 0.007454894483089447 | MAE Test Loss: 0.017423981800675392 \n",
            "OrderedDict({'weights': tensor([0.6629]), 'bias': tensor([0.3156])})\n",
            "Epoch: 26780 | MAE Train Loss: 0.007420540787279606 | MAE Test Loss: 0.017344754189252853 \n",
            "OrderedDict({'weights': tensor([0.6631]), 'bias': tensor([0.3155])})\n",
            "Epoch: 26790 | MAE Train Loss: 0.007386147975921631 | MAE Test Loss: 0.017262082546949387 \n",
            "OrderedDict({'weights': tensor([0.6633]), 'bias': tensor([0.3154])})\n",
            "Epoch: 26800 | MAE Train Loss: 0.007351817097514868 | MAE Test Loss: 0.017182832583785057 \n",
            "OrderedDict({'weights': tensor([0.6634]), 'bias': tensor([0.3154])})\n",
            "Epoch: 26810 | MAE Train Loss: 0.007317414041608572 | MAE Test Loss: 0.01710016094148159 \n",
            "OrderedDict({'weights': tensor([0.6636]), 'bias': tensor([0.3153])})\n",
            "Epoch: 26820 | MAE Train Loss: 0.007283070590347052 | MAE Test Loss: 0.017024343833327293 \n",
            "OrderedDict({'weights': tensor([0.6638]), 'bias': tensor([0.3152])})\n",
            "Epoch: 26830 | MAE Train Loss: 0.007248734124004841 | MAE Test Loss: 0.01694163680076599 \n",
            "OrderedDict({'weights': tensor([0.6640]), 'bias': tensor([0.3151])})\n",
            "Epoch: 26840 | MAE Train Loss: 0.0072143906727433205 | MAE Test Loss: 0.016862446442246437 \n",
            "OrderedDict({'weights': tensor([0.6641]), 'bias': tensor([0.3151])})\n",
            "Epoch: 26850 | MAE Train Loss: 0.007180002983659506 | MAE Test Loss: 0.016783207654953003 \n",
            "OrderedDict({'weights': tensor([0.6643]), 'bias': tensor([0.3150])})\n",
            "Epoch: 26860 | MAE Train Loss: 0.007145664654672146 | MAE Test Loss: 0.016700511798262596 \n",
            "OrderedDict({'weights': tensor([0.6645]), 'bias': tensor([0.3149])})\n",
            "Epoch: 26870 | MAE Train Loss: 0.0071112485602498055 | MAE Test Loss: 0.016617853194475174 \n",
            "OrderedDict({'weights': tensor([0.6646]), 'bias': tensor([0.3149])})\n",
            "Epoch: 26880 | MAE Train Loss: 0.007076920475810766 | MAE Test Loss: 0.016542036086320877 \n",
            "OrderedDict({'weights': tensor([0.6648]), 'bias': tensor([0.3148])})\n",
            "Epoch: 26890 | MAE Train Loss: 0.007042539305984974 | MAE Test Loss: 0.016462797299027443 \n",
            "OrderedDict({'weights': tensor([0.6650]), 'bias': tensor([0.3147])})\n",
            "Epoch: 26900 | MAE Train Loss: 0.0070081776939332485 | MAE Test Loss: 0.01637670397758484 \n",
            "OrderedDict({'weights': tensor([0.6652]), 'bias': tensor([0.3146])})\n",
            "Epoch: 26910 | MAE Train Loss: 0.006973856594413519 | MAE Test Loss: 0.016300898045301437 \n",
            "OrderedDict({'weights': tensor([0.6653]), 'bias': tensor([0.3146])})\n",
            "Epoch: 26920 | MAE Train Loss: 0.00693949218839407 | MAE Test Loss: 0.016218215227127075 \n",
            "OrderedDict({'weights': tensor([0.6655]), 'bias': tensor([0.3145])})\n",
            "Epoch: 26930 | MAE Train Loss: 0.006905088666826487 | MAE Test Loss: 0.01613551937043667 \n",
            "OrderedDict({'weights': tensor([0.6657]), 'bias': tensor([0.3144])})\n",
            "Epoch: 26940 | MAE Train Loss: 0.006870749406516552 | MAE Test Loss: 0.01605629362165928 \n",
            "OrderedDict({'weights': tensor([0.6658]), 'bias': tensor([0.3144])})\n",
            "Epoch: 26950 | MAE Train Loss: 0.006836394779384136 | MAE Test Loss: 0.015980452299118042 \n",
            "OrderedDict({'weights': tensor([0.6660]), 'bias': tensor([0.3143])})\n",
            "Epoch: 26960 | MAE Train Loss: 0.00680201593786478 | MAE Test Loss: 0.015894394367933273 \n",
            "OrderedDict({'weights': tensor([0.6662]), 'bias': tensor([0.3142])})\n",
            "Epoch: 26970 | MAE Train Loss: 0.006767702754586935 | MAE Test Loss: 0.01581856608390808 \n",
            "OrderedDict({'weights': tensor([0.6663]), 'bias': tensor([0.3141])})\n",
            "Epoch: 26980 | MAE Train Loss: 0.0067333318293094635 | MAE Test Loss: 0.01573588326573372 \n",
            "OrderedDict({'weights': tensor([0.6665]), 'bias': tensor([0.3141])})\n",
            "Epoch: 26990 | MAE Train Loss: 0.006698918528854847 | MAE Test Loss: 0.015656668692827225 \n",
            "OrderedDict({'weights': tensor([0.6667]), 'bias': tensor([0.3140])})\n",
            "Epoch: 27000 | MAE Train Loss: 0.006664587650448084 | MAE Test Loss: 0.015573984012007713 \n",
            "OrderedDict({'weights': tensor([0.6669]), 'bias': tensor([0.3139])})\n",
            "Epoch: 27010 | MAE Train Loss: 0.006630253978073597 | MAE Test Loss: 0.015494746156036854 \n",
            "OrderedDict({'weights': tensor([0.6670]), 'bias': tensor([0.3138])})\n",
            "Epoch: 27020 | MAE Train Loss: 0.006595853716135025 | MAE Test Loss: 0.015418916940689087 \n",
            "OrderedDict({'weights': tensor([0.6672]), 'bias': tensor([0.3138])})\n",
            "Epoch: 27030 | MAE Train Loss: 0.006561549846082926 | MAE Test Loss: 0.01533624529838562 \n",
            "OrderedDict({'weights': tensor([0.6674]), 'bias': tensor([0.3137])})\n",
            "Epoch: 27040 | MAE Train Loss: 0.006527169141918421 | MAE Test Loss: 0.015253573656082153 \n",
            "OrderedDict({'weights': tensor([0.6675]), 'bias': tensor([0.3136])})\n",
            "Epoch: 27050 | MAE Train Loss: 0.006492833141237497 | MAE Test Loss: 0.01517433486878872 \n",
            "OrderedDict({'weights': tensor([0.6677]), 'bias': tensor([0.3136])})\n",
            "Epoch: 27060 | MAE Train Loss: 0.006458482705056667 | MAE Test Loss: 0.01509510912001133 \n",
            "OrderedDict({'weights': tensor([0.6679]), 'bias': tensor([0.3135])})\n",
            "Epoch: 27070 | MAE Train Loss: 0.0064241006039083 | MAE Test Loss: 0.015012425370514393 \n",
            "OrderedDict({'weights': tensor([0.6681]), 'bias': tensor([0.3134])})\n",
            "Epoch: 27080 | MAE Train Loss: 0.00638970360159874 | MAE Test Loss: 0.014936596155166626 \n",
            "OrderedDict({'weights': tensor([0.6682]), 'bias': tensor([0.3133])})\n",
            "Epoch: 27090 | MAE Train Loss: 0.006355400197207928 | MAE Test Loss: 0.01485393662005663 \n",
            "OrderedDict({'weights': tensor([0.6684]), 'bias': tensor([0.3133])})\n",
            "Epoch: 27100 | MAE Train Loss: 0.006321015767753124 | MAE Test Loss: 0.014774697832763195 \n",
            "OrderedDict({'weights': tensor([0.6686]), 'bias': tensor([0.3132])})\n",
            "Epoch: 27110 | MAE Train Loss: 0.006286663003265858 | MAE Test Loss: 0.014691978693008423 \n",
            "OrderedDict({'weights': tensor([0.6687]), 'bias': tensor([0.3131])})\n",
            "Epoch: 27120 | MAE Train Loss: 0.006252320948988199 | MAE Test Loss: 0.014612799510359764 \n",
            "OrderedDict({'weights': tensor([0.6689]), 'bias': tensor([0.3131])})\n",
            "Epoch: 27130 | MAE Train Loss: 0.006217931862920523 | MAE Test Loss: 0.014530116692185402 \n",
            "OrderedDict({'weights': tensor([0.6691]), 'bias': tensor([0.3130])})\n",
            "Epoch: 27140 | MAE Train Loss: 0.006183554418385029 | MAE Test Loss: 0.014454299584031105 \n",
            "OrderedDict({'weights': tensor([0.6693]), 'bias': tensor([0.3129])})\n",
            "Epoch: 27150 | MAE Train Loss: 0.0061491928063333035 | MAE Test Loss: 0.014368194155395031 \n",
            "OrderedDict({'weights': tensor([0.6694]), 'bias': tensor([0.3128])})\n",
            "Epoch: 27160 | MAE Train Loss: 0.0061148651875555515 | MAE Test Loss: 0.014292389154434204 \n",
            "OrderedDict({'weights': tensor([0.6696]), 'bias': tensor([0.3128])})\n",
            "Epoch: 27170 | MAE Train Loss: 0.00608048215508461 | MAE Test Loss: 0.01421315036714077 \n",
            "OrderedDict({'weights': tensor([0.6698]), 'bias': tensor([0.3127])})\n",
            "Epoch: 27180 | MAE Train Loss: 0.006046173628419638 | MAE Test Loss: 0.014130455441772938 \n",
            "OrderedDict({'weights': tensor([0.6699]), 'bias': tensor([0.3126])})\n",
            "Epoch: 27190 | MAE Train Loss: 0.006011773832142353 | MAE Test Loss: 0.014047783799469471 \n",
            "OrderedDict({'weights': tensor([0.6701]), 'bias': tensor([0.3126])})\n",
            "Epoch: 27200 | MAE Train Loss: 0.0059773982502520084 | MAE Test Loss: 0.013971954584121704 \n",
            "OrderedDict({'weights': tensor([0.6703]), 'bias': tensor([0.3125])})\n",
            "Epoch: 27210 | MAE Train Loss: 0.005943031515926123 | MAE Test Loss: 0.0138858612626791 \n",
            "OrderedDict({'weights': tensor([0.6705]), 'bias': tensor([0.3124])})\n",
            "Epoch: 27220 | MAE Train Loss: 0.005908695049583912 | MAE Test Loss: 0.01380663551390171 \n",
            "OrderedDict({'weights': tensor([0.6706]), 'bias': tensor([0.3123])})\n",
            "Epoch: 27230 | MAE Train Loss: 0.005874328315258026 | MAE Test Loss: 0.013730794191360474 \n",
            "OrderedDict({'weights': tensor([0.6708]), 'bias': tensor([0.3123])})\n",
            "Epoch: 27240 | MAE Train Loss: 0.0058400132693350315 | MAE Test Loss: 0.013648146763443947 \n",
            "OrderedDict({'weights': tensor([0.6710]), 'bias': tensor([0.3122])})\n",
            "Epoch: 27250 | MAE Train Loss: 0.005805609282106161 | MAE Test Loss: 0.01356547512114048 \n",
            "OrderedDict({'weights': tensor([0.6711]), 'bias': tensor([0.3121])})\n",
            "Epoch: 27260 | MAE Train Loss: 0.0057712746784091 | MAE Test Loss: 0.013486236333847046 \n",
            "OrderedDict({'weights': tensor([0.6713]), 'bias': tensor([0.3121])})\n",
            "Epoch: 27270 | MAE Train Loss: 0.005736879073083401 | MAE Test Loss: 0.013407009653747082 \n",
            "OrderedDict({'weights': tensor([0.6715]), 'bias': tensor([0.3120])})\n",
            "Epoch: 27280 | MAE Train Loss: 0.005702531430870295 | MAE Test Loss: 0.013324325904250145 \n",
            "OrderedDict({'weights': tensor([0.6716]), 'bias': tensor([0.3119])})\n",
            "Epoch: 27290 | MAE Train Loss: 0.005668179132044315 | MAE Test Loss: 0.013248497620224953 \n",
            "OrderedDict({'weights': tensor([0.6718]), 'bias': tensor([0.3118])})\n",
            "Epoch: 27300 | MAE Train Loss: 0.005633854307234287 | MAE Test Loss: 0.013165825977921486 \n",
            "OrderedDict({'weights': tensor([0.6720]), 'bias': tensor([0.3118])})\n",
            "Epoch: 27310 | MAE Train Loss: 0.005599498748779297 | MAE Test Loss: 0.013086599297821522 \n",
            "OrderedDict({'weights': tensor([0.6722]), 'bias': tensor([0.3117])})\n",
            "Epoch: 27320 | MAE Train Loss: 0.0055651068687438965 | MAE Test Loss: 0.013003927655518055 \n",
            "OrderedDict({'weights': tensor([0.6723]), 'bias': tensor([0.3116])})\n",
            "Epoch: 27330 | MAE Train Loss: 0.005530775524675846 | MAE Test Loss: 0.01292467676103115 \n",
            "OrderedDict({'weights': tensor([0.6725]), 'bias': tensor([0.3115])})\n",
            "Epoch: 27340 | MAE Train Loss: 0.005496372934430838 | MAE Test Loss: 0.012842005118727684 \n",
            "OrderedDict({'weights': tensor([0.6727]), 'bias': tensor([0.3115])})\n",
            "Epoch: 27350 | MAE Train Loss: 0.005462029483169317 | MAE Test Loss: 0.012766188010573387 \n",
            "OrderedDict({'weights': tensor([0.6728]), 'bias': tensor([0.3114])})\n",
            "Epoch: 27360 | MAE Train Loss: 0.0054276930168271065 | MAE Test Loss: 0.012683480978012085 \n",
            "OrderedDict({'weights': tensor([0.6730]), 'bias': tensor([0.3113])})\n",
            "Epoch: 27370 | MAE Train Loss: 0.005393349565565586 | MAE Test Loss: 0.01260429061949253 \n",
            "OrderedDict({'weights': tensor([0.6732]), 'bias': tensor([0.3113])})\n",
            "Epoch: 27380 | MAE Train Loss: 0.005358961410820484 | MAE Test Loss: 0.012525051832199097 \n",
            "OrderedDict({'weights': tensor([0.6734]), 'bias': tensor([0.3112])})\n",
            "Epoch: 27390 | MAE Train Loss: 0.0053246235474944115 | MAE Test Loss: 0.01244235597550869 \n",
            "OrderedDict({'weights': tensor([0.6735]), 'bias': tensor([0.3111])})\n",
            "Epoch: 27400 | MAE Train Loss: 0.005290207918733358 | MAE Test Loss: 0.012359696440398693 \n",
            "OrderedDict({'weights': tensor([0.6737]), 'bias': tensor([0.3110])})\n",
            "Epoch: 27410 | MAE Train Loss: 0.005255879368633032 | MAE Test Loss: 0.012283879332244396 \n",
            "OrderedDict({'weights': tensor([0.6739]), 'bias': tensor([0.3110])})\n",
            "Epoch: 27420 | MAE Train Loss: 0.0052214981988072395 | MAE Test Loss: 0.012204641476273537 \n",
            "OrderedDict({'weights': tensor([0.6740]), 'bias': tensor([0.3109])})\n",
            "Epoch: 27430 | MAE Train Loss: 0.005187136121094227 | MAE Test Loss: 0.012118548154830933 \n",
            "OrderedDict({'weights': tensor([0.6742]), 'bias': tensor([0.3108])})\n",
            "Epoch: 27440 | MAE Train Loss: 0.0051528154872357845 | MAE Test Loss: 0.012042743153870106 \n",
            "OrderedDict({'weights': tensor([0.6744]), 'bias': tensor([0.3108])})\n",
            "Epoch: 27450 | MAE Train Loss: 0.00511845201253891 | MAE Test Loss: 0.011960059404373169 \n",
            "OrderedDict({'weights': tensor([0.6746]), 'bias': tensor([0.3107])})\n",
            "Epoch: 27460 | MAE Train Loss: 0.005084047559648752 | MAE Test Loss: 0.011877363547682762 \n",
            "OrderedDict({'weights': tensor([0.6747]), 'bias': tensor([0.3106])})\n",
            "Epoch: 27470 | MAE Train Loss: 0.005049708299338818 | MAE Test Loss: 0.011798137798905373 \n",
            "OrderedDict({'weights': tensor([0.6749]), 'bias': tensor([0.3105])})\n",
            "Epoch: 27480 | MAE Train Loss: 0.005015353672206402 | MAE Test Loss: 0.011722296476364136 \n",
            "OrderedDict({'weights': tensor([0.6751]), 'bias': tensor([0.3105])})\n",
            "Epoch: 27490 | MAE Train Loss: 0.004980974830687046 | MAE Test Loss: 0.011636239476501942 \n",
            "OrderedDict({'weights': tensor([0.6752]), 'bias': tensor([0.3104])})\n",
            "Epoch: 27500 | MAE Train Loss: 0.004946662578731775 | MAE Test Loss: 0.011560410261154175 \n",
            "OrderedDict({'weights': tensor([0.6754]), 'bias': tensor([0.3103])})\n",
            "Epoch: 27510 | MAE Train Loss: 0.004912290722131729 | MAE Test Loss: 0.011477726511657238 \n",
            "OrderedDict({'weights': tensor([0.6756]), 'bias': tensor([0.3103])})\n",
            "Epoch: 27520 | MAE Train Loss: 0.004877876490354538 | MAE Test Loss: 0.011398511938750744 \n",
            "OrderedDict({'weights': tensor([0.6757]), 'bias': tensor([0.3102])})\n",
            "Epoch: 27530 | MAE Train Loss: 0.0048435465432703495 | MAE Test Loss: 0.011315828189253807 \n",
            "OrderedDict({'weights': tensor([0.6759]), 'bias': tensor([0.3101])})\n",
            "Epoch: 27540 | MAE Train Loss: 0.004809212870895863 | MAE Test Loss: 0.011236590333282948 \n",
            "OrderedDict({'weights': tensor([0.6761]), 'bias': tensor([0.3100])})\n",
            "Epoch: 27550 | MAE Train Loss: 0.004774812608957291 | MAE Test Loss: 0.01116076111793518 \n",
            "OrderedDict({'weights': tensor([0.6763]), 'bias': tensor([0.3100])})\n",
            "Epoch: 27560 | MAE Train Loss: 0.004740508738905191 | MAE Test Loss: 0.011078089475631714 \n",
            "OrderedDict({'weights': tensor([0.6764]), 'bias': tensor([0.3099])})\n",
            "Epoch: 27570 | MAE Train Loss: 0.0047061266377568245 | MAE Test Loss: 0.010995417833328247 \n",
            "OrderedDict({'weights': tensor([0.6766]), 'bias': tensor([0.3098])})\n",
            "Epoch: 27580 | MAE Train Loss: 0.004671793431043625 | MAE Test Loss: 0.010916179046034813 \n",
            "OrderedDict({'weights': tensor([0.6768]), 'bias': tensor([0.3098])})\n",
            "Epoch: 27590 | MAE Train Loss: 0.004637441597878933 | MAE Test Loss: 0.010836953297257423 \n",
            "OrderedDict({'weights': tensor([0.6769]), 'bias': tensor([0.3097])})\n",
            "Epoch: 27600 | MAE Train Loss: 0.004603059496730566 | MAE Test Loss: 0.010754269547760487 \n",
            "OrderedDict({'weights': tensor([0.6771]), 'bias': tensor([0.3096])})\n",
            "Epoch: 27610 | MAE Train Loss: 0.004568661097437143 | MAE Test Loss: 0.01067844033241272 \n",
            "OrderedDict({'weights': tensor([0.6773]), 'bias': tensor([0.3095])})\n",
            "Epoch: 27620 | MAE Train Loss: 0.004534358624368906 | MAE Test Loss: 0.010595780797302723 \n",
            "OrderedDict({'weights': tensor([0.6775]), 'bias': tensor([0.3095])})\n",
            "Epoch: 27630 | MAE Train Loss: 0.0044999755918979645 | MAE Test Loss: 0.010516542010009289 \n",
            "OrderedDict({'weights': tensor([0.6776]), 'bias': tensor([0.3094])})\n",
            "Epoch: 27640 | MAE Train Loss: 0.004465620964765549 | MAE Test Loss: 0.010433822870254517 \n",
            "OrderedDict({'weights': tensor([0.6778]), 'bias': tensor([0.3093])})\n",
            "Epoch: 27650 | MAE Train Loss: 0.004431279841810465 | MAE Test Loss: 0.010354643687605858 \n",
            "OrderedDict({'weights': tensor([0.6780]), 'bias': tensor([0.3093])})\n",
            "Epoch: 27660 | MAE Train Loss: 0.004396890755742788 | MAE Test Loss: 0.010271960869431496 \n",
            "OrderedDict({'weights': tensor([0.6781]), 'bias': tensor([0.3092])})\n",
            "Epoch: 27670 | MAE Train Loss: 0.0043625133112072945 | MAE Test Loss: 0.010196143761277199 \n",
            "OrderedDict({'weights': tensor([0.6783]), 'bias': tensor([0.3091])})\n",
            "Epoch: 27680 | MAE Train Loss: 0.004328151699155569 | MAE Test Loss: 0.010110038332641125 \n",
            "OrderedDict({'weights': tensor([0.6785]), 'bias': tensor([0.3090])})\n",
            "Epoch: 27690 | MAE Train Loss: 0.0042938245460391045 | MAE Test Loss: 0.010034233331680298 \n",
            "OrderedDict({'weights': tensor([0.6787]), 'bias': tensor([0.3090])})\n",
            "Epoch: 27700 | MAE Train Loss: 0.0042594424448907375 | MAE Test Loss: 0.009954994544386864 \n",
            "OrderedDict({'weights': tensor([0.6788]), 'bias': tensor([0.3089])})\n",
            "Epoch: 27710 | MAE Train Loss: 0.004225132055580616 | MAE Test Loss: 0.009872299619019032 \n",
            "OrderedDict({'weights': tensor([0.6790]), 'bias': tensor([0.3088])})\n",
            "Epoch: 27720 | MAE Train Loss: 0.004190732724964619 | MAE Test Loss: 0.009789627976715565 \n",
            "OrderedDict({'weights': tensor([0.6792]), 'bias': tensor([0.3088])})\n",
            "Epoch: 27730 | MAE Train Loss: 0.004156357143074274 | MAE Test Loss: 0.009713798761367798 \n",
            "OrderedDict({'weights': tensor([0.6793]), 'bias': tensor([0.3087])})\n",
            "Epoch: 27740 | MAE Train Loss: 0.004121991340070963 | MAE Test Loss: 0.009627705439925194 \n",
            "OrderedDict({'weights': tensor([0.6795]), 'bias': tensor([0.3086])})\n",
            "Epoch: 27750 | MAE Train Loss: 0.004087654408067465 | MAE Test Loss: 0.009548479691147804 \n",
            "OrderedDict({'weights': tensor([0.6797]), 'bias': tensor([0.3085])})\n",
            "Epoch: 27760 | MAE Train Loss: 0.004053287208080292 | MAE Test Loss: 0.009472638368606567 \n",
            "OrderedDict({'weights': tensor([0.6799]), 'bias': tensor([0.3085])})\n",
            "Epoch: 27770 | MAE Train Loss: 0.004018974956125021 | MAE Test Loss: 0.00938999094069004 \n",
            "OrderedDict({'weights': tensor([0.6800]), 'bias': tensor([0.3084])})\n",
            "Epoch: 27780 | MAE Train Loss: 0.003984568174928427 | MAE Test Loss: 0.009307319298386574 \n",
            "OrderedDict({'weights': tensor([0.6802]), 'bias': tensor([0.3083])})\n",
            "Epoch: 27790 | MAE Train Loss: 0.003950233571231365 | MAE Test Loss: 0.00922808051109314 \n",
            "OrderedDict({'weights': tensor([0.6804]), 'bias': tensor([0.3082])})\n",
            "Epoch: 27800 | MAE Train Loss: 0.003915836568921804 | MAE Test Loss: 0.009148853830993176 \n",
            "OrderedDict({'weights': tensor([0.6805]), 'bias': tensor([0.3082])})\n",
            "Epoch: 27810 | MAE Train Loss: 0.003881491720676422 | MAE Test Loss: 0.009066170081496239 \n",
            "OrderedDict({'weights': tensor([0.6807]), 'bias': tensor([0.3081])})\n",
            "Epoch: 27820 | MAE Train Loss: 0.0038471377920359373 | MAE Test Loss: 0.008990341797471046 \n",
            "OrderedDict({'weights': tensor([0.6809]), 'bias': tensor([0.3080])})\n",
            "Epoch: 27830 | MAE Train Loss: 0.0038128129672259092 | MAE Test Loss: 0.00890767015516758 \n",
            "OrderedDict({'weights': tensor([0.6810]), 'bias': tensor([0.3080])})\n",
            "Epoch: 27840 | MAE Train Loss: 0.0037784562446177006 | MAE Test Loss: 0.008828443475067616 \n",
            "OrderedDict({'weights': tensor([0.6812]), 'bias': tensor([0.3079])})\n",
            "Epoch: 27850 | MAE Train Loss: 0.003744065761566162 | MAE Test Loss: 0.008745771832764149 \n",
            "OrderedDict({'weights': tensor([0.6814]), 'bias': tensor([0.3078])})\n",
            "Epoch: 27860 | MAE Train Loss: 0.0037097358144819736 | MAE Test Loss: 0.008666520938277245 \n",
            "OrderedDict({'weights': tensor([0.6816]), 'bias': tensor([0.3077])})\n",
            "Epoch: 27870 | MAE Train Loss: 0.0036753318272531033 | MAE Test Loss: 0.008583849295973778 \n",
            "OrderedDict({'weights': tensor([0.6817]), 'bias': tensor([0.3077])})\n",
            "Epoch: 27880 | MAE Train Loss: 0.0036409900058060884 | MAE Test Loss: 0.008508032187819481 \n",
            "OrderedDict({'weights': tensor([0.6819]), 'bias': tensor([0.3076])})\n",
            "Epoch: 27890 | MAE Train Loss: 0.0036066516768187284 | MAE Test Loss: 0.008425325155258179 \n",
            "OrderedDict({'weights': tensor([0.6821]), 'bias': tensor([0.3075])})\n",
            "Epoch: 27900 | MAE Train Loss: 0.003572306828573346 | MAE Test Loss: 0.008346134796738625 \n",
            "OrderedDict({'weights': tensor([0.6822]), 'bias': tensor([0.3075])})\n",
            "Epoch: 27910 | MAE Train Loss: 0.003537920070812106 | MAE Test Loss: 0.00826689600944519 \n",
            "OrderedDict({'weights': tensor([0.6824]), 'bias': tensor([0.3074])})\n",
            "Epoch: 27920 | MAE Train Loss: 0.003503581043332815 | MAE Test Loss: 0.008184200152754784 \n",
            "OrderedDict({'weights': tensor([0.6826]), 'bias': tensor([0.3073])})\n",
            "Epoch: 27930 | MAE Train Loss: 0.003469166811555624 | MAE Test Loss: 0.008101540617644787 \n",
            "OrderedDict({'weights': tensor([0.6828]), 'bias': tensor([0.3072])})\n",
            "Epoch: 27940 | MAE Train Loss: 0.0034348382614552975 | MAE Test Loss: 0.00802572350949049 \n",
            "OrderedDict({'weights': tensor([0.6829]), 'bias': tensor([0.3072])})\n",
            "Epoch: 27950 | MAE Train Loss: 0.0034004568587988615 | MAE Test Loss: 0.00794648565351963 \n",
            "OrderedDict({'weights': tensor([0.6831]), 'bias': tensor([0.3071])})\n",
            "Epoch: 27960 | MAE Train Loss: 0.003366093384101987 | MAE Test Loss: 0.007860392332077026 \n",
            "OrderedDict({'weights': tensor([0.6833]), 'bias': tensor([0.3070])})\n",
            "Epoch: 27970 | MAE Train Loss: 0.00333177438005805 | MAE Test Loss: 0.0077845873311161995 \n",
            "OrderedDict({'weights': tensor([0.6834]), 'bias': tensor([0.3070])})\n",
            "Epoch: 27980 | MAE Train Loss: 0.0032974109053611755 | MAE Test Loss: 0.007701903581619263 \n",
            "OrderedDict({'weights': tensor([0.6836]), 'bias': tensor([0.3069])})\n",
            "Epoch: 27990 | MAE Train Loss: 0.0032630078494548798 | MAE Test Loss: 0.007619208190590143 \n",
            "OrderedDict({'weights': tensor([0.6838]), 'bias': tensor([0.3068])})\n",
            "Epoch: 28000 | MAE Train Loss: 0.003228668821975589 | MAE Test Loss: 0.007539981510490179 \n",
            "OrderedDict({'weights': tensor([0.6840]), 'bias': tensor([0.3067])})\n",
            "Epoch: 28010 | MAE Train Loss: 0.003194312797859311 | MAE Test Loss: 0.0074641406536102295 \n",
            "OrderedDict({'weights': tensor([0.6841]), 'bias': tensor([0.3067])})\n",
            "Epoch: 28020 | MAE Train Loss: 0.0031599351204931736 | MAE Test Loss: 0.007378083653748035 \n",
            "OrderedDict({'weights': tensor([0.6843]), 'bias': tensor([0.3066])})\n",
            "Epoch: 28030 | MAE Train Loss: 0.0031256198417395353 | MAE Test Loss: 0.0073022544384002686 \n",
            "OrderedDict({'weights': tensor([0.6845]), 'bias': tensor([0.3065])})\n",
            "Epoch: 28040 | MAE Train Loss: 0.0030912496149539948 | MAE Test Loss: 0.007219570688903332 \n",
            "OrderedDict({'weights': tensor([0.6846]), 'bias': tensor([0.3065])})\n",
            "Epoch: 28050 | MAE Train Loss: 0.0030568353831768036 | MAE Test Loss: 0.007140356115996838 \n",
            "OrderedDict({'weights': tensor([0.6848]), 'bias': tensor([0.3064])})\n",
            "Epoch: 28060 | MAE Train Loss: 0.003022505436092615 | MAE Test Loss: 0.007057672832161188 \n",
            "OrderedDict({'weights': tensor([0.6850]), 'bias': tensor([0.3063])})\n",
            "Epoch: 28070 | MAE Train Loss: 0.0029881715308874846 | MAE Test Loss: 0.006978434510529041 \n",
            "OrderedDict({'weights': tensor([0.6852]), 'bias': tensor([0.3062])})\n",
            "Epoch: 28080 | MAE Train Loss: 0.0029537715017795563 | MAE Test Loss: 0.006902605295181274 \n",
            "OrderedDict({'weights': tensor([0.6853]), 'bias': tensor([0.3062])})\n",
            "Epoch: 28090 | MAE Train Loss: 0.002919467631727457 | MAE Test Loss: 0.006819933652877808 \n",
            "OrderedDict({'weights': tensor([0.6855]), 'bias': tensor([0.3061])})\n",
            "Epoch: 28100 | MAE Train Loss: 0.0028850852977484465 | MAE Test Loss: 0.006737262010574341 \n",
            "OrderedDict({'weights': tensor([0.6857]), 'bias': tensor([0.3060])})\n",
            "Epoch: 28110 | MAE Train Loss: 0.0028507523238658905 | MAE Test Loss: 0.006658023688942194 \n",
            "OrderedDict({'weights': tensor([0.6858]), 'bias': tensor([0.3059])})\n",
            "Epoch: 28120 | MAE Train Loss: 0.0028164007235318422 | MAE Test Loss: 0.00657879700884223 \n",
            "OrderedDict({'weights': tensor([0.6860]), 'bias': tensor([0.3059])})\n",
            "Epoch: 28130 | MAE Train Loss: 0.0027820183895528316 | MAE Test Loss: 0.00649611372500658 \n",
            "OrderedDict({'weights': tensor([0.6862]), 'bias': tensor([0.3058])})\n",
            "Epoch: 28140 | MAE Train Loss: 0.002747619990259409 | MAE Test Loss: 0.0064202845096588135 \n",
            "OrderedDict({'weights': tensor([0.6863]), 'bias': tensor([0.3057])})\n",
            "Epoch: 28150 | MAE Train Loss: 0.0027133189141750336 | MAE Test Loss: 0.006337624974548817 \n",
            "OrderedDict({'weights': tensor([0.6865]), 'bias': tensor([0.3057])})\n",
            "Epoch: 28160 | MAE Train Loss: 0.00267893448472023 | MAE Test Loss: 0.0062583861872553825 \n",
            "OrderedDict({'weights': tensor([0.6867]), 'bias': tensor([0.3056])})\n",
            "Epoch: 28170 | MAE Train Loss: 0.0026445798575878143 | MAE Test Loss: 0.00617566704750061 \n",
            "OrderedDict({'weights': tensor([0.6869]), 'bias': tensor([0.3055])})\n",
            "Epoch: 28180 | MAE Train Loss: 0.0026102387346327305 | MAE Test Loss: 0.006096488330513239 \n",
            "OrderedDict({'weights': tensor([0.6870]), 'bias': tensor([0.3054])})\n",
            "Epoch: 28190 | MAE Train Loss: 0.002575849648565054 | MAE Test Loss: 0.006013804581016302 \n",
            "OrderedDict({'weights': tensor([0.6872]), 'bias': tensor([0.3054])})\n",
            "Epoch: 28200 | MAE Train Loss: 0.0025414719711989164 | MAE Test Loss: 0.005937987472862005 \n",
            "OrderedDict({'weights': tensor([0.6874]), 'bias': tensor([0.3053])})\n",
            "Epoch: 28210 | MAE Train Loss: 0.0025071105919778347 | MAE Test Loss: 0.0058518825098872185 \n",
            "OrderedDict({'weights': tensor([0.6875]), 'bias': tensor([0.3052])})\n",
            "Epoch: 28220 | MAE Train Loss: 0.0024727836716920137 | MAE Test Loss: 0.005776077508926392 \n",
            "OrderedDict({'weights': tensor([0.6877]), 'bias': tensor([0.3052])})\n",
            "Epoch: 28230 | MAE Train Loss: 0.002438401337713003 | MAE Test Loss: 0.005696839187294245 \n",
            "OrderedDict({'weights': tensor([0.6879]), 'bias': tensor([0.3051])})\n",
            "Epoch: 28240 | MAE Train Loss: 0.002404090715572238 | MAE Test Loss: 0.005614143796265125 \n",
            "OrderedDict({'weights': tensor([0.6881]), 'bias': tensor([0.3050])})\n",
            "Epoch: 28250 | MAE Train Loss: 0.0023696913849562407 | MAE Test Loss: 0.0055314721539616585 \n",
            "OrderedDict({'weights': tensor([0.6882]), 'bias': tensor([0.3049])})\n",
            "Epoch: 28260 | MAE Train Loss: 0.0023353160358965397 | MAE Test Loss: 0.005455642938613892 \n",
            "OrderedDict({'weights': tensor([0.6884]), 'bias': tensor([0.3049])})\n",
            "Epoch: 28270 | MAE Train Loss: 0.0023009502328932285 | MAE Test Loss: 0.005369550082832575 \n",
            "OrderedDict({'weights': tensor([0.6886]), 'bias': tensor([0.3048])})\n",
            "Epoch: 28280 | MAE Train Loss: 0.0022666133008897305 | MAE Test Loss: 0.005290323402732611 \n",
            "OrderedDict({'weights': tensor([0.6887]), 'bias': tensor([0.3047])})\n",
            "Epoch: 28290 | MAE Train Loss: 0.0022322461009025574 | MAE Test Loss: 0.005214482545852661 \n",
            "OrderedDict({'weights': tensor([0.6889]), 'bias': tensor([0.3047])})\n",
            "Epoch: 28300 | MAE Train Loss: 0.0021979338489472866 | MAE Test Loss: 0.005131834652274847 \n",
            "OrderedDict({'weights': tensor([0.6891]), 'bias': tensor([0.3046])})\n",
            "Epoch: 28310 | MAE Train Loss: 0.0021635270677506924 | MAE Test Loss: 0.00504916300997138 \n",
            "OrderedDict({'weights': tensor([0.6893]), 'bias': tensor([0.3045])})\n",
            "Epoch: 28320 | MAE Train Loss: 0.0021291926968842745 | MAE Test Loss: 0.004969924688339233 \n",
            "OrderedDict({'weights': tensor([0.6894]), 'bias': tensor([0.3044])})\n",
            "Epoch: 28330 | MAE Train Loss: 0.00209479546174407 | MAE Test Loss: 0.004890698008239269 \n",
            "OrderedDict({'weights': tensor([0.6896]), 'bias': tensor([0.3044])})\n",
            "Epoch: 28340 | MAE Train Loss: 0.0020604506134986877 | MAE Test Loss: 0.00480801472440362 \n",
            "OrderedDict({'weights': tensor([0.6898]), 'bias': tensor([0.3043])})\n",
            "Epoch: 28350 | MAE Train Loss: 0.002026096684858203 | MAE Test Loss: 0.004732185509055853 \n",
            "OrderedDict({'weights': tensor([0.6899]), 'bias': tensor([0.3042])})\n",
            "Epoch: 28360 | MAE Train Loss: 0.001991771860048175 | MAE Test Loss: 0.004649513866752386 \n",
            "OrderedDict({'weights': tensor([0.6901]), 'bias': tensor([0.3042])})\n",
            "Epoch: 28370 | MAE Train Loss: 0.001957415137439966 | MAE Test Loss: 0.004570287652313709 \n",
            "OrderedDict({'weights': tensor([0.6903]), 'bias': tensor([0.3041])})\n",
            "Epoch: 28380 | MAE Train Loss: 0.0019230246543884277 | MAE Test Loss: 0.0044876160100102425 \n",
            "OrderedDict({'weights': tensor([0.6905]), 'bias': tensor([0.3040])})\n",
            "Epoch: 28390 | MAE Train Loss: 0.0018886945908889174 | MAE Test Loss: 0.004408365581184626 \n",
            "OrderedDict({'weights': tensor([0.6906]), 'bias': tensor([0.3039])})\n",
            "Epoch: 28400 | MAE Train Loss: 0.0018542908364906907 | MAE Test Loss: 0.004325693938881159 \n",
            "OrderedDict({'weights': tensor([0.6908]), 'bias': tensor([0.3039])})\n",
            "Epoch: 28410 | MAE Train Loss: 0.001819948898628354 | MAE Test Loss: 0.004249876830726862 \n",
            "OrderedDict({'weights': tensor([0.6910]), 'bias': tensor([0.3038])})\n",
            "Epoch: 28420 | MAE Train Loss: 0.001785610569640994 | MAE Test Loss: 0.0041671693325042725 \n",
            "OrderedDict({'weights': tensor([0.6911]), 'bias': tensor([0.3037])})\n",
            "Epoch: 28430 | MAE Train Loss: 0.0017512657213956118 | MAE Test Loss: 0.004087978508323431 \n",
            "OrderedDict({'weights': tensor([0.6913]), 'bias': tensor([0.3037])})\n",
            "Epoch: 28440 | MAE Train Loss: 0.0017168789636343718 | MAE Test Loss: 0.004008740186691284 \n",
            "OrderedDict({'weights': tensor([0.6915]), 'bias': tensor([0.3036])})\n",
            "Epoch: 28450 | MAE Train Loss: 0.0016825400525704026 | MAE Test Loss: 0.003926044795662165 \n",
            "OrderedDict({'weights': tensor([0.6916]), 'bias': tensor([0.3035])})\n",
            "Epoch: 28460 | MAE Train Loss: 0.0016481258207932115 | MAE Test Loss: 0.0038433850277215242 \n",
            "OrderedDict({'weights': tensor([0.6918]), 'bias': tensor([0.3034])})\n",
            "Epoch: 28470 | MAE Train Loss: 0.001613797270692885 | MAE Test Loss: 0.0037675679195672274 \n",
            "OrderedDict({'weights': tensor([0.6920]), 'bias': tensor([0.3034])})\n",
            "Epoch: 28480 | MAE Train Loss: 0.0015794157516211271 | MAE Test Loss: 0.003688329365104437 \n",
            "OrderedDict({'weights': tensor([0.6922]), 'bias': tensor([0.3033])})\n",
            "Epoch: 28490 | MAE Train Loss: 0.0015450522769242525 | MAE Test Loss: 0.00360223650932312 \n",
            "OrderedDict({'weights': tensor([0.6923]), 'bias': tensor([0.3032])})\n",
            "Epoch: 28500 | MAE Train Loss: 0.0015107333892956376 | MAE Test Loss: 0.0035264312755316496 \n",
            "OrderedDict({'weights': tensor([0.6925]), 'bias': tensor([0.3031])})\n",
            "Epoch: 28510 | MAE Train Loss: 0.0014763697981834412 | MAE Test Loss: 0.0034437477588653564 \n",
            "OrderedDict({'weights': tensor([0.6927]), 'bias': tensor([0.3031])})\n",
            "Epoch: 28520 | MAE Train Loss: 0.0014419667422771454 | MAE Test Loss: 0.003361052367836237 \n",
            "OrderedDict({'weights': tensor([0.6928]), 'bias': tensor([0.3030])})\n",
            "Epoch: 28530 | MAE Train Loss: 0.0014076277147978544 | MAE Test Loss: 0.003281825687736273 \n",
            "OrderedDict({'weights': tensor([0.6930]), 'bias': tensor([0.3029])})\n",
            "Epoch: 28540 | MAE Train Loss: 0.0013732716906815767 | MAE Test Loss: 0.0032059848308563232 \n",
            "OrderedDict({'weights': tensor([0.6932]), 'bias': tensor([0.3029])})\n",
            "Epoch: 28550 | MAE Train Loss: 0.0013388938969001174 | MAE Test Loss: 0.0031199275981634855 \n",
            "OrderedDict({'weights': tensor([0.6934]), 'bias': tensor([0.3028])})\n",
            "Epoch: 28560 | MAE Train Loss: 0.001304578734561801 | MAE Test Loss: 0.0030440986156463623 \n",
            "OrderedDict({'weights': tensor([0.6935]), 'bias': tensor([0.3027])})\n",
            "Epoch: 28570 | MAE Train Loss: 0.0012702085077762604 | MAE Test Loss: 0.002961415098980069 \n",
            "OrderedDict({'weights': tensor([0.6937]), 'bias': tensor([0.3026])})\n",
            "Epoch: 28580 | MAE Train Loss: 0.0012357942759990692 | MAE Test Loss: 0.002882200526073575 \n",
            "OrderedDict({'weights': tensor([0.6939]), 'bias': tensor([0.3026])})\n",
            "Epoch: 28590 | MAE Train Loss: 0.001201464212499559 | MAE Test Loss: 0.002799517009407282 \n",
            "OrderedDict({'weights': tensor([0.6940]), 'bias': tensor([0.3025])})\n",
            "Epoch: 28600 | MAE Train Loss: 0.0011671304237097502 | MAE Test Loss: 0.0027202784549444914 \n",
            "OrderedDict({'weights': tensor([0.6942]), 'bias': tensor([0.3024])})\n",
            "Epoch: 28610 | MAE Train Loss: 0.001132730394601822 | MAE Test Loss: 0.002644449472427368 \n",
            "OrderedDict({'weights': tensor([0.6944]), 'bias': tensor([0.3024])})\n",
            "Epoch: 28620 | MAE Train Loss: 0.0010984264081344008 | MAE Test Loss: 0.0025617778301239014 \n",
            "OrderedDict({'weights': tensor([0.6946]), 'bias': tensor([0.3023])})\n",
            "Epoch: 28630 | MAE Train Loss: 0.0010640450054779649 | MAE Test Loss: 0.0024791061878204346 \n",
            "OrderedDict({'weights': tensor([0.6947]), 'bias': tensor([0.3022])})\n",
            "Epoch: 28640 | MAE Train Loss: 0.0010297112166881561 | MAE Test Loss: 0.0023998678661882877 \n",
            "OrderedDict({'weights': tensor([0.6949]), 'bias': tensor([0.3021])})\n",
            "Epoch: 28650 | MAE Train Loss: 0.0009953596163541079 | MAE Test Loss: 0.0023206411860883236 \n",
            "OrderedDict({'weights': tensor([0.6951]), 'bias': tensor([0.3021])})\n",
            "Epoch: 28660 | MAE Train Loss: 0.0009609780972823501 | MAE Test Loss: 0.0022379576694220304 \n",
            "OrderedDict({'weights': tensor([0.6952]), 'bias': tensor([0.3020])})\n",
            "Epoch: 28670 | MAE Train Loss: 0.0009265787666663527 | MAE Test Loss: 0.0021621286869049072 \n",
            "OrderedDict({'weights': tensor([0.6954]), 'bias': tensor([0.3019])})\n",
            "Epoch: 28680 | MAE Train Loss: 0.0008922778069972992 | MAE Test Loss: 0.0020794689189642668 \n",
            "OrderedDict({'weights': tensor([0.6956]), 'bias': tensor([0.3019])})\n",
            "Epoch: 28690 | MAE Train Loss: 0.0008578933775424957 | MAE Test Loss: 0.00200023059733212 \n",
            "OrderedDict({'weights': tensor([0.6957]), 'bias': tensor([0.3018])})\n",
            "Epoch: 28700 | MAE Train Loss: 0.0008235402638092637 | MAE Test Loss: 0.001917511224746704 \n",
            "OrderedDict({'weights': tensor([0.6959]), 'bias': tensor([0.3017])})\n",
            "Epoch: 28710 | MAE Train Loss: 0.000789199024438858 | MAE Test Loss: 0.0018383323913440108 \n",
            "OrderedDict({'weights': tensor([0.6961]), 'bias': tensor([0.3016])})\n",
            "Epoch: 28720 | MAE Train Loss: 0.0007548086578026414 | MAE Test Loss: 0.0017556488746777177 \n",
            "OrderedDict({'weights': tensor([0.6963]), 'bias': tensor([0.3016])})\n",
            "Epoch: 28730 | MAE Train Loss: 0.0007204316789284348 | MAE Test Loss: 0.0016798317665234208 \n",
            "OrderedDict({'weights': tensor([0.6964]), 'bias': tensor([0.3015])})\n",
            "Epoch: 28740 | MAE Train Loss: 0.0006860696012154222 | MAE Test Loss: 0.0015937269199639559 \n",
            "OrderedDict({'weights': tensor([0.6966]), 'bias': tensor([0.3014])})\n",
            "Epoch: 28750 | MAE Train Loss: 0.0006517410511150956 | MAE Test Loss: 0.0015179216861724854 \n",
            "OrderedDict({'weights': tensor([0.6968]), 'bias': tensor([0.3014])})\n",
            "Epoch: 28760 | MAE Train Loss: 0.0006173588335514069 | MAE Test Loss: 0.0014386832481250167 \n",
            "OrderedDict({'weights': tensor([0.6969]), 'bias': tensor([0.3013])})\n",
            "Epoch: 28770 | MAE Train Loss: 0.0005830496666021645 | MAE Test Loss: 0.0013559877406805754 \n",
            "OrderedDict({'weights': tensor([0.6971]), 'bias': tensor([0.3012])})\n",
            "Epoch: 28780 | MAE Train Loss: 0.0005486503359861672 | MAE Test Loss: 0.0012733160983771086 \n",
            "OrderedDict({'weights': tensor([0.6973]), 'bias': tensor([0.3011])})\n",
            "Epoch: 28790 | MAE Train Loss: 0.0005142748123034835 | MAE Test Loss: 0.0011974871158599854 \n",
            "OrderedDict({'weights': tensor([0.6975]), 'bias': tensor([0.3011])})\n",
            "Epoch: 28800 | MAE Train Loss: 0.0004799090384040028 | MAE Test Loss: 0.0011113941436633468 \n",
            "OrderedDict({'weights': tensor([0.6976]), 'bias': tensor([0.3010])})\n",
            "Epoch: 28810 | MAE Train Loss: 0.00044557228102348745 | MAE Test Loss: 0.0010321676963940263 \n",
            "OrderedDict({'weights': tensor([0.6978]), 'bias': tensor([0.3009])})\n",
            "Epoch: 28820 | MAE Train Loss: 0.000411204993724823 | MAE Test Loss: 0.0009563267230987549 \n",
            "OrderedDict({'weights': tensor([0.6980]), 'bias': tensor([0.3008])})\n",
            "Epoch: 28830 | MAE Train Loss: 0.0003768928290810436 | MAE Test Loss: 0.0008736789459362626 \n",
            "OrderedDict({'weights': tensor([0.6981]), 'bias': tensor([0.3008])})\n",
            "Epoch: 28840 | MAE Train Loss: 0.00034248604788444936 | MAE Test Loss: 0.0007910073036327958 \n",
            "OrderedDict({'weights': tensor([0.6983]), 'bias': tensor([0.3007])})\n",
            "Epoch: 28850 | MAE Train Loss: 0.00030815228819847107 | MAE Test Loss: 0.0007117688655853271 \n",
            "OrderedDict({'weights': tensor([0.6985]), 'bias': tensor([0.3006])})\n",
            "Epoch: 28860 | MAE Train Loss: 0.00027375444187782705 | MAE Test Loss: 0.0006325423601083457 \n",
            "OrderedDict({'weights': tensor([0.6987]), 'bias': tensor([0.3006])})\n",
            "Epoch: 28870 | MAE Train Loss: 0.00023940802202560008 | MAE Test Loss: 0.0005498587852343917 \n",
            "OrderedDict({'weights': tensor([0.6988]), 'bias': tensor([0.3005])})\n",
            "Epoch: 28880 | MAE Train Loss: 0.0002050563634838909 | MAE Test Loss: 0.000474029773613438 \n",
            "OrderedDict({'weights': tensor([0.6990]), 'bias': tensor([0.3004])})\n",
            "Epoch: 28890 | MAE Train Loss: 0.00017073079652618617 | MAE Test Loss: 0.0003913581313099712 \n",
            "OrderedDict({'weights': tensor([0.6992]), 'bias': tensor([0.3003])})\n",
            "Epoch: 28900 | MAE Train Loss: 0.00013637244410347193 | MAE Test Loss: 0.00031213165493682027 \n",
            "OrderedDict({'weights': tensor([0.6993]), 'bias': tensor([0.3003])})\n",
            "Epoch: 28910 | MAE Train Loss: 0.00010198354721069336 | MAE Test Loss: 0.00022945999808143824 \n",
            "OrderedDict({'weights': tensor([0.6995]), 'bias': tensor([0.3002])})\n",
            "Epoch: 28920 | MAE Train Loss: 6.765350553905591e-05 | MAE Test Loss: 0.000150209671119228 \n",
            "OrderedDict({'weights': tensor([0.6997]), 'bias': tensor([0.3001])})\n",
            "Epoch: 28930 | MAE Train Loss: 3.324970748508349e-05 | MAE Test Loss: 6.75380215398036e-05 \n",
            "OrderedDict({'weights': tensor([0.6999]), 'bias': tensor([0.3001])})\n",
            "Epoch: 28940 | MAE Train Loss: 7.015168375801295e-05 | MAE Test Loss: 2.7412175768404268e-05 \n",
            "OrderedDict({'weights': tensor([0.7000]), 'bias': tensor([0.3001])})\n",
            "Epoch: 28950 | MAE Train Loss: 7.015168375801295e-05 | MAE Test Loss: 2.7412175768404268e-05 \n",
            "OrderedDict({'weights': tensor([0.7000]), 'bias': tensor([0.3001])})\n",
            "Epoch: 28960 | MAE Train Loss: 7.015168375801295e-05 | MAE Test Loss: 2.7412175768404268e-05 \n",
            "OrderedDict({'weights': tensor([0.7000]), 'bias': tensor([0.3001])})\n",
            "Epoch: 28970 | MAE Train Loss: 7.015168375801295e-05 | MAE Test Loss: 2.7412175768404268e-05 \n",
            "OrderedDict({'weights': tensor([0.7000]), 'bias': tensor([0.3001])})\n",
            "Epoch: 28980 | MAE Train Loss: 7.015168375801295e-05 | MAE Test Loss: 2.7412175768404268e-05 \n",
            "OrderedDict({'weights': tensor([0.7000]), 'bias': tensor([0.3001])})\n",
            "Epoch: 28990 | MAE Train Loss: 7.015168375801295e-05 | MAE Test Loss: 2.7412175768404268e-05 \n",
            "OrderedDict({'weights': tensor([0.7000]), 'bias': tensor([0.3001])})\n",
            "Epoch: 29000 | MAE Train Loss: 7.015168375801295e-05 | MAE Test Loss: 2.7412175768404268e-05 \n",
            "OrderedDict({'weights': tensor([0.7000]), 'bias': tensor([0.3001])})\n",
            "Epoch: 29010 | MAE Train Loss: 7.015168375801295e-05 | MAE Test Loss: 2.7412175768404268e-05 \n",
            "OrderedDict({'weights': tensor([0.7000]), 'bias': tensor([0.3001])})\n",
            "Epoch: 29020 | MAE Train Loss: 7.015168375801295e-05 | MAE Test Loss: 2.7412175768404268e-05 \n",
            "OrderedDict({'weights': tensor([0.7000]), 'bias': tensor([0.3001])})\n",
            "Epoch: 29030 | MAE Train Loss: 7.015168375801295e-05 | MAE Test Loss: 2.7412175768404268e-05 \n",
            "OrderedDict({'weights': tensor([0.7000]), 'bias': tensor([0.3001])})\n",
            "Epoch: 29040 | MAE Train Loss: 7.015168375801295e-05 | MAE Test Loss: 2.7412175768404268e-05 \n",
            "OrderedDict({'weights': tensor([0.7000]), 'bias': tensor([0.3001])})\n",
            "Epoch: 29050 | MAE Train Loss: 7.015168375801295e-05 | MAE Test Loss: 2.7412175768404268e-05 \n",
            "OrderedDict({'weights': tensor([0.7000]), 'bias': tensor([0.3001])})\n",
            "Epoch: 29060 | MAE Train Loss: 7.015168375801295e-05 | MAE Test Loss: 2.7412175768404268e-05 \n",
            "OrderedDict({'weights': tensor([0.7000]), 'bias': tensor([0.3001])})\n",
            "Epoch: 29070 | MAE Train Loss: 7.015168375801295e-05 | MAE Test Loss: 2.7412175768404268e-05 \n",
            "OrderedDict({'weights': tensor([0.7000]), 'bias': tensor([0.3001])})\n",
            "Epoch: 29080 | MAE Train Loss: 7.015168375801295e-05 | MAE Test Loss: 2.7412175768404268e-05 \n",
            "OrderedDict({'weights': tensor([0.7000]), 'bias': tensor([0.3001])})\n",
            "Epoch: 29090 | MAE Train Loss: 7.015168375801295e-05 | MAE Test Loss: 2.7412175768404268e-05 \n",
            "OrderedDict({'weights': tensor([0.7000]), 'bias': tensor([0.3001])})\n",
            "Epoch: 29100 | MAE Train Loss: 7.015168375801295e-05 | MAE Test Loss: 2.7412175768404268e-05 \n",
            "OrderedDict({'weights': tensor([0.7000]), 'bias': tensor([0.3001])})\n",
            "Epoch: 29110 | MAE Train Loss: 7.015168375801295e-05 | MAE Test Loss: 2.7412175768404268e-05 \n",
            "OrderedDict({'weights': tensor([0.7000]), 'bias': tensor([0.3001])})\n",
            "Epoch: 29120 | MAE Train Loss: 7.015168375801295e-05 | MAE Test Loss: 2.7412175768404268e-05 \n",
            "OrderedDict({'weights': tensor([0.7000]), 'bias': tensor([0.3001])})\n",
            "Epoch: 29130 | MAE Train Loss: 7.015168375801295e-05 | MAE Test Loss: 2.7412175768404268e-05 \n",
            "OrderedDict({'weights': tensor([0.7000]), 'bias': tensor([0.3001])})\n",
            "Epoch: 29140 | MAE Train Loss: 7.015168375801295e-05 | MAE Test Loss: 2.7412175768404268e-05 \n",
            "OrderedDict({'weights': tensor([0.7000]), 'bias': tensor([0.3001])})\n",
            "Epoch: 29150 | MAE Train Loss: 7.015168375801295e-05 | MAE Test Loss: 2.7412175768404268e-05 \n",
            "OrderedDict({'weights': tensor([0.7000]), 'bias': tensor([0.3001])})\n",
            "Epoch: 29160 | MAE Train Loss: 7.015168375801295e-05 | MAE Test Loss: 2.7412175768404268e-05 \n",
            "OrderedDict({'weights': tensor([0.7000]), 'bias': tensor([0.3001])})\n",
            "Epoch: 29170 | MAE Train Loss: 7.015168375801295e-05 | MAE Test Loss: 2.7412175768404268e-05 \n",
            "OrderedDict({'weights': tensor([0.7000]), 'bias': tensor([0.3001])})\n",
            "Epoch: 29180 | MAE Train Loss: 7.015168375801295e-05 | MAE Test Loss: 2.7412175768404268e-05 \n",
            "OrderedDict({'weights': tensor([0.7000]), 'bias': tensor([0.3001])})\n",
            "Epoch: 29190 | MAE Train Loss: 7.015168375801295e-05 | MAE Test Loss: 2.7412175768404268e-05 \n",
            "OrderedDict({'weights': tensor([0.7000]), 'bias': tensor([0.3001])})\n",
            "Epoch: 29200 | MAE Train Loss: 7.015168375801295e-05 | MAE Test Loss: 2.7412175768404268e-05 \n",
            "OrderedDict({'weights': tensor([0.7000]), 'bias': tensor([0.3001])})\n",
            "Epoch: 29210 | MAE Train Loss: 7.015168375801295e-05 | MAE Test Loss: 2.7412175768404268e-05 \n",
            "OrderedDict({'weights': tensor([0.7000]), 'bias': tensor([0.3001])})\n",
            "Epoch: 29220 | MAE Train Loss: 7.015168375801295e-05 | MAE Test Loss: 2.7412175768404268e-05 \n",
            "OrderedDict({'weights': tensor([0.7000]), 'bias': tensor([0.3001])})\n",
            "Epoch: 29230 | MAE Train Loss: 7.015168375801295e-05 | MAE Test Loss: 2.7412175768404268e-05 \n",
            "OrderedDict({'weights': tensor([0.7000]), 'bias': tensor([0.3001])})\n",
            "Epoch: 29240 | MAE Train Loss: 7.015168375801295e-05 | MAE Test Loss: 2.7412175768404268e-05 \n",
            "OrderedDict({'weights': tensor([0.7000]), 'bias': tensor([0.3001])})\n",
            "Epoch: 29250 | MAE Train Loss: 7.015168375801295e-05 | MAE Test Loss: 2.7412175768404268e-05 \n",
            "OrderedDict({'weights': tensor([0.7000]), 'bias': tensor([0.3001])})\n",
            "Epoch: 29260 | MAE Train Loss: 7.015168375801295e-05 | MAE Test Loss: 2.7412175768404268e-05 \n",
            "OrderedDict({'weights': tensor([0.7000]), 'bias': tensor([0.3001])})\n",
            "Epoch: 29270 | MAE Train Loss: 7.015168375801295e-05 | MAE Test Loss: 2.7412175768404268e-05 \n",
            "OrderedDict({'weights': tensor([0.7000]), 'bias': tensor([0.3001])})\n",
            "Epoch: 29280 | MAE Train Loss: 7.015168375801295e-05 | MAE Test Loss: 2.7412175768404268e-05 \n",
            "OrderedDict({'weights': tensor([0.7000]), 'bias': tensor([0.3001])})\n",
            "Epoch: 29290 | MAE Train Loss: 7.015168375801295e-05 | MAE Test Loss: 2.7412175768404268e-05 \n",
            "OrderedDict({'weights': tensor([0.7000]), 'bias': tensor([0.3001])})\n",
            "Epoch: 29300 | MAE Train Loss: 7.015168375801295e-05 | MAE Test Loss: 2.7412175768404268e-05 \n",
            "OrderedDict({'weights': tensor([0.7000]), 'bias': tensor([0.3001])})\n",
            "Epoch: 29310 | MAE Train Loss: 7.015168375801295e-05 | MAE Test Loss: 2.7412175768404268e-05 \n",
            "OrderedDict({'weights': tensor([0.7000]), 'bias': tensor([0.3001])})\n",
            "Epoch: 29320 | MAE Train Loss: 7.015168375801295e-05 | MAE Test Loss: 2.7412175768404268e-05 \n",
            "OrderedDict({'weights': tensor([0.7000]), 'bias': tensor([0.3001])})\n",
            "Epoch: 29330 | MAE Train Loss: 7.015168375801295e-05 | MAE Test Loss: 2.7412175768404268e-05 \n",
            "OrderedDict({'weights': tensor([0.7000]), 'bias': tensor([0.3001])})\n",
            "Epoch: 29340 | MAE Train Loss: 7.015168375801295e-05 | MAE Test Loss: 2.7412175768404268e-05 \n",
            "OrderedDict({'weights': tensor([0.7000]), 'bias': tensor([0.3001])})\n",
            "Epoch: 29350 | MAE Train Loss: 7.015168375801295e-05 | MAE Test Loss: 2.7412175768404268e-05 \n",
            "OrderedDict({'weights': tensor([0.7000]), 'bias': tensor([0.3001])})\n",
            "Epoch: 29360 | MAE Train Loss: 7.015168375801295e-05 | MAE Test Loss: 2.7412175768404268e-05 \n",
            "OrderedDict({'weights': tensor([0.7000]), 'bias': tensor([0.3001])})\n",
            "Epoch: 29370 | MAE Train Loss: 7.015168375801295e-05 | MAE Test Loss: 2.7412175768404268e-05 \n",
            "OrderedDict({'weights': tensor([0.7000]), 'bias': tensor([0.3001])})\n",
            "Epoch: 29380 | MAE Train Loss: 7.015168375801295e-05 | MAE Test Loss: 2.7412175768404268e-05 \n",
            "OrderedDict({'weights': tensor([0.7000]), 'bias': tensor([0.3001])})\n",
            "Epoch: 29390 | MAE Train Loss: 7.015168375801295e-05 | MAE Test Loss: 2.7412175768404268e-05 \n",
            "OrderedDict({'weights': tensor([0.7000]), 'bias': tensor([0.3001])})\n",
            "Epoch: 29400 | MAE Train Loss: 7.015168375801295e-05 | MAE Test Loss: 2.7412175768404268e-05 \n",
            "OrderedDict({'weights': tensor([0.7000]), 'bias': tensor([0.3001])})\n",
            "Epoch: 29410 | MAE Train Loss: 7.015168375801295e-05 | MAE Test Loss: 2.7412175768404268e-05 \n",
            "OrderedDict({'weights': tensor([0.7000]), 'bias': tensor([0.3001])})\n",
            "Epoch: 29420 | MAE Train Loss: 7.015168375801295e-05 | MAE Test Loss: 2.7412175768404268e-05 \n",
            "OrderedDict({'weights': tensor([0.7000]), 'bias': tensor([0.3001])})\n",
            "Epoch: 29430 | MAE Train Loss: 7.015168375801295e-05 | MAE Test Loss: 2.7412175768404268e-05 \n",
            "OrderedDict({'weights': tensor([0.7000]), 'bias': tensor([0.3001])})\n",
            "Epoch: 29440 | MAE Train Loss: 7.015168375801295e-05 | MAE Test Loss: 2.7412175768404268e-05 \n",
            "OrderedDict({'weights': tensor([0.7000]), 'bias': tensor([0.3001])})\n",
            "Epoch: 29450 | MAE Train Loss: 7.015168375801295e-05 | MAE Test Loss: 2.7412175768404268e-05 \n",
            "OrderedDict({'weights': tensor([0.7000]), 'bias': tensor([0.3001])})\n",
            "Epoch: 29460 | MAE Train Loss: 7.015168375801295e-05 | MAE Test Loss: 2.7412175768404268e-05 \n",
            "OrderedDict({'weights': tensor([0.7000]), 'bias': tensor([0.3001])})\n",
            "Epoch: 29470 | MAE Train Loss: 7.015168375801295e-05 | MAE Test Loss: 2.7412175768404268e-05 \n",
            "OrderedDict({'weights': tensor([0.7000]), 'bias': tensor([0.3001])})\n",
            "Epoch: 29480 | MAE Train Loss: 7.015168375801295e-05 | MAE Test Loss: 2.7412175768404268e-05 \n",
            "OrderedDict({'weights': tensor([0.7000]), 'bias': tensor([0.3001])})\n",
            "Epoch: 29490 | MAE Train Loss: 7.015168375801295e-05 | MAE Test Loss: 2.7412175768404268e-05 \n",
            "OrderedDict({'weights': tensor([0.7000]), 'bias': tensor([0.3001])})\n",
            "Epoch: 29500 | MAE Train Loss: 7.015168375801295e-05 | MAE Test Loss: 2.7412175768404268e-05 \n",
            "OrderedDict({'weights': tensor([0.7000]), 'bias': tensor([0.3001])})\n",
            "Epoch: 29510 | MAE Train Loss: 7.015168375801295e-05 | MAE Test Loss: 2.7412175768404268e-05 \n",
            "OrderedDict({'weights': tensor([0.7000]), 'bias': tensor([0.3001])})\n",
            "Epoch: 29520 | MAE Train Loss: 7.015168375801295e-05 | MAE Test Loss: 2.7412175768404268e-05 \n",
            "OrderedDict({'weights': tensor([0.7000]), 'bias': tensor([0.3001])})\n",
            "Epoch: 29530 | MAE Train Loss: 7.015168375801295e-05 | MAE Test Loss: 2.7412175768404268e-05 \n",
            "OrderedDict({'weights': tensor([0.7000]), 'bias': tensor([0.3001])})\n",
            "Epoch: 29540 | MAE Train Loss: 7.015168375801295e-05 | MAE Test Loss: 2.7412175768404268e-05 \n",
            "OrderedDict({'weights': tensor([0.7000]), 'bias': tensor([0.3001])})\n",
            "Epoch: 29550 | MAE Train Loss: 7.015168375801295e-05 | MAE Test Loss: 2.7412175768404268e-05 \n",
            "OrderedDict({'weights': tensor([0.7000]), 'bias': tensor([0.3001])})\n",
            "Epoch: 29560 | MAE Train Loss: 7.015168375801295e-05 | MAE Test Loss: 2.7412175768404268e-05 \n",
            "OrderedDict({'weights': tensor([0.7000]), 'bias': tensor([0.3001])})\n",
            "Epoch: 29570 | MAE Train Loss: 7.015168375801295e-05 | MAE Test Loss: 2.7412175768404268e-05 \n",
            "OrderedDict({'weights': tensor([0.7000]), 'bias': tensor([0.3001])})\n",
            "Epoch: 29580 | MAE Train Loss: 7.015168375801295e-05 | MAE Test Loss: 2.7412175768404268e-05 \n",
            "OrderedDict({'weights': tensor([0.7000]), 'bias': tensor([0.3001])})\n",
            "Epoch: 29590 | MAE Train Loss: 7.015168375801295e-05 | MAE Test Loss: 2.7412175768404268e-05 \n",
            "OrderedDict({'weights': tensor([0.7000]), 'bias': tensor([0.3001])})\n",
            "Epoch: 29600 | MAE Train Loss: 7.015168375801295e-05 | MAE Test Loss: 2.7412175768404268e-05 \n",
            "OrderedDict({'weights': tensor([0.7000]), 'bias': tensor([0.3001])})\n",
            "Epoch: 29610 | MAE Train Loss: 7.015168375801295e-05 | MAE Test Loss: 2.7412175768404268e-05 \n",
            "OrderedDict({'weights': tensor([0.7000]), 'bias': tensor([0.3001])})\n",
            "Epoch: 29620 | MAE Train Loss: 7.015168375801295e-05 | MAE Test Loss: 2.7412175768404268e-05 \n",
            "OrderedDict({'weights': tensor([0.7000]), 'bias': tensor([0.3001])})\n",
            "Epoch: 29630 | MAE Train Loss: 7.015168375801295e-05 | MAE Test Loss: 2.7412175768404268e-05 \n",
            "OrderedDict({'weights': tensor([0.7000]), 'bias': tensor([0.3001])})\n",
            "Epoch: 29640 | MAE Train Loss: 7.015168375801295e-05 | MAE Test Loss: 2.7412175768404268e-05 \n",
            "OrderedDict({'weights': tensor([0.7000]), 'bias': tensor([0.3001])})\n",
            "Epoch: 29650 | MAE Train Loss: 7.015168375801295e-05 | MAE Test Loss: 2.7412175768404268e-05 \n",
            "OrderedDict({'weights': tensor([0.7000]), 'bias': tensor([0.3001])})\n",
            "Epoch: 29660 | MAE Train Loss: 7.015168375801295e-05 | MAE Test Loss: 2.7412175768404268e-05 \n",
            "OrderedDict({'weights': tensor([0.7000]), 'bias': tensor([0.3001])})\n",
            "Epoch: 29670 | MAE Train Loss: 7.015168375801295e-05 | MAE Test Loss: 2.7412175768404268e-05 \n",
            "OrderedDict({'weights': tensor([0.7000]), 'bias': tensor([0.3001])})\n",
            "Epoch: 29680 | MAE Train Loss: 7.015168375801295e-05 | MAE Test Loss: 2.7412175768404268e-05 \n",
            "OrderedDict({'weights': tensor([0.7000]), 'bias': tensor([0.3001])})\n",
            "Epoch: 29690 | MAE Train Loss: 7.015168375801295e-05 | MAE Test Loss: 2.7412175768404268e-05 \n",
            "OrderedDict({'weights': tensor([0.7000]), 'bias': tensor([0.3001])})\n",
            "Epoch: 29700 | MAE Train Loss: 7.015168375801295e-05 | MAE Test Loss: 2.7412175768404268e-05 \n",
            "OrderedDict({'weights': tensor([0.7000]), 'bias': tensor([0.3001])})\n",
            "Epoch: 29710 | MAE Train Loss: 7.015168375801295e-05 | MAE Test Loss: 2.7412175768404268e-05 \n",
            "OrderedDict({'weights': tensor([0.7000]), 'bias': tensor([0.3001])})\n",
            "Epoch: 29720 | MAE Train Loss: 7.015168375801295e-05 | MAE Test Loss: 2.7412175768404268e-05 \n",
            "OrderedDict({'weights': tensor([0.7000]), 'bias': tensor([0.3001])})\n",
            "Epoch: 29730 | MAE Train Loss: 7.015168375801295e-05 | MAE Test Loss: 2.7412175768404268e-05 \n",
            "OrderedDict({'weights': tensor([0.7000]), 'bias': tensor([0.3001])})\n",
            "Epoch: 29740 | MAE Train Loss: 7.015168375801295e-05 | MAE Test Loss: 2.7412175768404268e-05 \n",
            "OrderedDict({'weights': tensor([0.7000]), 'bias': tensor([0.3001])})\n",
            "Epoch: 29750 | MAE Train Loss: 7.015168375801295e-05 | MAE Test Loss: 2.7412175768404268e-05 \n",
            "OrderedDict({'weights': tensor([0.7000]), 'bias': tensor([0.3001])})\n",
            "Epoch: 29760 | MAE Train Loss: 7.015168375801295e-05 | MAE Test Loss: 2.7412175768404268e-05 \n",
            "OrderedDict({'weights': tensor([0.7000]), 'bias': tensor([0.3001])})\n",
            "Epoch: 29770 | MAE Train Loss: 7.015168375801295e-05 | MAE Test Loss: 2.7412175768404268e-05 \n",
            "OrderedDict({'weights': tensor([0.7000]), 'bias': tensor([0.3001])})\n",
            "Epoch: 29780 | MAE Train Loss: 7.015168375801295e-05 | MAE Test Loss: 2.7412175768404268e-05 \n",
            "OrderedDict({'weights': tensor([0.7000]), 'bias': tensor([0.3001])})\n",
            "Epoch: 29790 | MAE Train Loss: 7.015168375801295e-05 | MAE Test Loss: 2.7412175768404268e-05 \n",
            "OrderedDict({'weights': tensor([0.7000]), 'bias': tensor([0.3001])})\n",
            "Epoch: 29800 | MAE Train Loss: 7.015168375801295e-05 | MAE Test Loss: 2.7412175768404268e-05 \n",
            "OrderedDict({'weights': tensor([0.7000]), 'bias': tensor([0.3001])})\n",
            "Epoch: 29810 | MAE Train Loss: 7.015168375801295e-05 | MAE Test Loss: 2.7412175768404268e-05 \n",
            "OrderedDict({'weights': tensor([0.7000]), 'bias': tensor([0.3001])})\n",
            "Epoch: 29820 | MAE Train Loss: 7.015168375801295e-05 | MAE Test Loss: 2.7412175768404268e-05 \n",
            "OrderedDict({'weights': tensor([0.7000]), 'bias': tensor([0.3001])})\n",
            "Epoch: 29830 | MAE Train Loss: 7.015168375801295e-05 | MAE Test Loss: 2.7412175768404268e-05 \n",
            "OrderedDict({'weights': tensor([0.7000]), 'bias': tensor([0.3001])})\n",
            "Epoch: 29840 | MAE Train Loss: 7.015168375801295e-05 | MAE Test Loss: 2.7412175768404268e-05 \n",
            "OrderedDict({'weights': tensor([0.7000]), 'bias': tensor([0.3001])})\n",
            "Epoch: 29850 | MAE Train Loss: 7.015168375801295e-05 | MAE Test Loss: 2.7412175768404268e-05 \n",
            "OrderedDict({'weights': tensor([0.7000]), 'bias': tensor([0.3001])})\n",
            "Epoch: 29860 | MAE Train Loss: 7.015168375801295e-05 | MAE Test Loss: 2.7412175768404268e-05 \n",
            "OrderedDict({'weights': tensor([0.7000]), 'bias': tensor([0.3001])})\n",
            "Epoch: 29870 | MAE Train Loss: 7.015168375801295e-05 | MAE Test Loss: 2.7412175768404268e-05 \n",
            "OrderedDict({'weights': tensor([0.7000]), 'bias': tensor([0.3001])})\n",
            "Epoch: 29880 | MAE Train Loss: 7.015168375801295e-05 | MAE Test Loss: 2.7412175768404268e-05 \n",
            "OrderedDict({'weights': tensor([0.7000]), 'bias': tensor([0.3001])})\n",
            "Epoch: 29890 | MAE Train Loss: 7.015168375801295e-05 | MAE Test Loss: 2.7412175768404268e-05 \n",
            "OrderedDict({'weights': tensor([0.7000]), 'bias': tensor([0.3001])})\n",
            "Epoch: 29900 | MAE Train Loss: 7.015168375801295e-05 | MAE Test Loss: 2.7412175768404268e-05 \n",
            "OrderedDict({'weights': tensor([0.7000]), 'bias': tensor([0.3001])})\n",
            "Epoch: 29910 | MAE Train Loss: 7.015168375801295e-05 | MAE Test Loss: 2.7412175768404268e-05 \n",
            "OrderedDict({'weights': tensor([0.7000]), 'bias': tensor([0.3001])})\n",
            "Epoch: 29920 | MAE Train Loss: 7.015168375801295e-05 | MAE Test Loss: 2.7412175768404268e-05 \n",
            "OrderedDict({'weights': tensor([0.7000]), 'bias': tensor([0.3001])})\n",
            "Epoch: 29930 | MAE Train Loss: 7.015168375801295e-05 | MAE Test Loss: 2.7412175768404268e-05 \n",
            "OrderedDict({'weights': tensor([0.7000]), 'bias': tensor([0.3001])})\n",
            "Epoch: 29940 | MAE Train Loss: 7.015168375801295e-05 | MAE Test Loss: 2.7412175768404268e-05 \n",
            "OrderedDict({'weights': tensor([0.7000]), 'bias': tensor([0.3001])})\n",
            "Epoch: 29950 | MAE Train Loss: 7.015168375801295e-05 | MAE Test Loss: 2.7412175768404268e-05 \n",
            "OrderedDict({'weights': tensor([0.7000]), 'bias': tensor([0.3001])})\n",
            "Epoch: 29960 | MAE Train Loss: 7.015168375801295e-05 | MAE Test Loss: 2.7412175768404268e-05 \n",
            "OrderedDict({'weights': tensor([0.7000]), 'bias': tensor([0.3001])})\n",
            "Epoch: 29970 | MAE Train Loss: 7.015168375801295e-05 | MAE Test Loss: 2.7412175768404268e-05 \n",
            "OrderedDict({'weights': tensor([0.7000]), 'bias': tensor([0.3001])})\n",
            "Epoch: 29980 | MAE Train Loss: 7.015168375801295e-05 | MAE Test Loss: 2.7412175768404268e-05 \n",
            "OrderedDict({'weights': tensor([0.7000]), 'bias': tensor([0.3001])})\n",
            "Epoch: 29990 | MAE Train Loss: 7.015168375801295e-05 | MAE Test Loss: 2.7412175768404268e-05 \n",
            "OrderedDict({'weights': tensor([0.7000]), 'bias': tensor([0.3001])})\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# import numpy as np\n",
        "# np.array(torch.tensor(loss_values).numpy()), test_loss_values"
      ],
      "metadata": {
        "collapsed": true,
        "id": "F-tEwq0Pxw_Y"
      },
      "execution_count": 119,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot the loss curves\n",
        "plt.plot(epoch_count, loss_values, label=\"Train loss\")\n",
        "plt.plot(epoch_count, test_loss_values, label=\"Test loss\")\n",
        "plt.title(\"Training and test loss curves\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.xlabel(\"Epochs\")\n",
        "plt.legend();"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 472
        },
        "id": "lPgptlCLsV34",
        "outputId": "4a08a6a6-9e30-45d1-ca78-76c1d5d0f2d6"
      },
      "execution_count": 120,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjcAAAHHCAYAAABDUnkqAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjAsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvlHJYcgAAAAlwSFlzAAAPYQAAD2EBqD+naQAAadxJREFUeJzt3Xd4VHXaxvHvpE0aaaQCgdBD70SkKlGaKKgrKitlV1wR26KuYqGtK/ZlFQXF17oW1BVQKYIRLIgivYdOIpBQQhJIIAmZ8/4xZMJICCEkOZnJ/bmuuZKcMvPMSUJufuc552cxDMNARERExE14mF2AiIiISEVSuBERERG3onAjIiIibkXhRkRERNyKwo2IiIi4FYUbERERcSsKNyIiIuJWFG5ERETErSjciIiIiFtRuBGpZKNGjSIuLq5c+06ePBmLxVKxBVUz+/btw2Kx8O6775pdSrlYLBYmT55sdhkicg6FG6mxLBZLmR7Lly83u1QBtm7dyuTJk9m3b1+lvs7rr7/uskFLROy8zC5AxCwffPCB09fvv/8+S5cuPW95ixYtLut1Zs+ejc1mK9e+Tz75JI899thlvb672Lp1K1OmTKFPnz7lHgkri9dff53w8HBGjRpVaa8hIpVL4UZqrD//+c9OX//yyy8sXbr0vOV/lJubi7+/f5lfx9vbu1z1AXh5eeHlpV9TqV5sNhv5+fn4+vqaXYpIiXRaSqQUffr0oXXr1qxZs4ZevXrh7+/P448/DsD8+fMZNGgQderUwWq10rhxY/75z39SWFjo9Bx/7Lkp6jF58cUXefPNN2ncuDFWq5UuXbrw22+/Oe1bUs+NxWLh3nvvZd68ebRu3Rqr1UqrVq1YvHjxefUvX76czp074+vrS+PGjXnjjTfK3Mfz448/8qc//Yn69etjtVqJjY3l73//O6dOnTrv/QUGBnLgwAGGDBlCYGAgERERPPzww+cdi8zMTEaNGkVwcDAhISGMHDmSzMzMi9by7rvv8qc//QmAq666qsRThosWLaJnz54EBARQq1YtBg0axJYtW5yeJy0tjdGjR1OvXj2sVisxMTHccMMNjlNdcXFxbNmyhe+//97xGn369LlofX+0bt06BgwYQFBQEIGBgfTt25dffvnFaZuCggKmTJlC06ZN8fX1pXbt2vTo0YOlS5eWud7SbN++nVtuuYWIiAj8/Pxo3rw5TzzxhGP9hXrBSvuZ+/DDD2nVqhVWq5WvvvqKsLAwRo8efd5zZGdn4+vry8MPP+xYlpeXx6RJk2jSpInj5+kf//gHeXl5TvsuXbqUHj16EBISQmBgIM2bN3f8zomUlf5LKHIRx44dY8CAAdx66638+c9/JioqCrD/wQ0MDGT8+PEEBgby3XffMXHiRLKzs3nhhRcu+rwfffQRJ06c4G9/+xsWi4Xnn3+eG2+8kT179lx0tOenn37iiy++4J577qFWrVq88sor3HTTTaSkpFC7dm3A/ge2f//+xMTEMGXKFAoLC5k6dSoRERFlet+fffYZubm5jB07ltq1a7Nq1SpeffVVfv/9dz777DOnbQsLC+nXrx8JCQm8+OKLfPvtt7z00ks0btyYsWPHAmAYBjfccAM//fQTd999Ny1atGDu3LmMHDnyorX06tWL+++/n1deeYXHH3/ccaqw6OMHH3zAyJEj6devH8899xy5ubnMnDmTHj16sG7dOscf8ZtuuoktW7Zw3333ERcXx+HDh1m6dCkpKSnExcUxffp07rvvPgIDAx1BoOj7XVZbtmyhZ8+eBAUF8Y9//ANvb2/eeOMN+vTpw/fff09CQgJgDxHTpk3jzjvvpGvXrmRnZ7N69WrWrl3LNddcU6Z6L2Tjxo307NkTb29v7rrrLuLi4ti9ezdfffUV//rXvy7p/RT57rvv+PTTT7n33nsJDw+nadOmDB06lC+++II33ngDHx8fx7bz5s0jLy+PW2+9FbCP9Fx//fX89NNP3HXXXbRo0YJNmzbx73//mx07djBv3jzHsbvuuuto27YtU6dOxWq1smvXLlasWFGumqUGM0TEMAzDGDdunPHHX4nevXsbgDFr1qzzts/NzT1v2d/+9jfD39/fOH36tGPZyJEjjQYNGji+3rt3rwEYtWvXNjIyMhzL58+fbwDGV1995Vg2adKk82oCDB8fH2PXrl2OZRs2bDAA49VXX3UsGzx4sOHv728cOHDAsWznzp2Gl5fXec9ZkpLe37Rp0wyLxWLs37/f6f0BxtSpU5227dChg9GpUyfH1/PmzTMA4/nnn3csO3PmjNGzZ08DMN55551S6/nss88MwFi2bJnT8hMnThghISHGmDFjnJanpaUZwcHBjuXHjx83AOOFF14o9XVatWpl9O7du9RtzgUYkyZNcnw9ZMgQw8fHx9i9e7dj2cGDB41atWoZvXr1cixr166dMWjQoAs+b1nrLUmvXr2MWrVqOX2fDMMwbDab4/M//lwWudDPnIeHh7Flyxan5d988815P7OGYRgDBw40GjVq5Pj6gw8+MDw8PIwff/zRabtZs2YZgLFixQrDMAzj3//+twEYR44cKfubFSmBTkuJXITVai1x6N3Pz8/x+YkTJzh69Cg9e/YkNzeX7du3X/R5hw0bRmhoqOPrnj17ArBnz56L7puYmEjjxo0dX7dt25agoCDHvoWFhXz77bcMGTKEOnXqOLZr0qQJAwYMuOjzg/P7y8nJ4ejRo1x55ZUYhsG6devO2/7uu+92+rpnz55O72XhwoV4eXk5RnIAPD09ue+++8pUz4UsXbqUzMxMbrvtNo4ePep4eHp6kpCQwLJlyxzvx8fHh+XLl3P8+PHLes0LKSwsZMmSJQwZMoRGjRo5lsfExHD77bfz008/kZ2dDUBISAhbtmxh586dJT5Xees9cuQIP/zwA3/5y1+oX7++07rLua1A7969admypdOyq6++mvDwcObMmeNYdvz4cZYuXcqwYcMcyz777DNatGhBfHy80/fo6quvBnB8j0JCQgD7Kd/yNuGLgHpuRC6qbt26TkPuRbZs2cLQoUMJDg4mKCiIiIgIRzNyVlbWRZ/3j394ioJOWf6Q/XHfov2L9j18+DCnTp2iSZMm521X0rKSpKSkMGrUKMLCwhx9NL179wbOf3++vr7nne46tx6A/fv3ExMTQ2BgoNN2zZs3L1M9F1IUDq6++moiIiKcHkuWLOHw4cOAPaQ+99xzLFq0iKioKHr16sXzzz9PWlraZb3+uY4cOUJubm6J76lFixbYbDZSU1MBmDp1KpmZmTRr1ow2bdrwyCOPsHHjRsf25a23KFC2bt26wt4XQMOGDc9b5uXlxU033cT8+fMdvTNffPEFBQUFTuFm586dbNmy5bzvT7NmzQAc36Nhw4bRvXt37rzzTqKiorj11lv59NNPFXTkkqnnRuQizh3BKJKZmUnv3r0JCgpi6tSpNG7cGF9fX9auXcujjz5apn+MPT09S1xuGEal7lsWhYWFXHPNNWRkZPDoo48SHx9PQEAABw4cYNSoUee9vwvVUxWKavnggw+Ijo4+b/25V5s9+OCDDB48mHnz5vHNN9/w1FNPMW3aNL777js6dOhQZTWDvY9o9+7dzJ8/nyVLlvDWW2/x73//m1mzZnHnnXdWer0XGsX5YxN4kZJ+DwBuvfVW3njjDRYtWsSQIUP49NNPiY+Pp127do5tbDYbbdq04eWXXy7xOWJjYx2v8cMPP7Bs2TIWLFjA4sWLmTNnDldffTVLliwx9edMXIvCjUg5LF++nGPHjvHFF1/Qq1cvx/K9e/eaWFWxyMhIfH192bVr13nrSlr2R5s2bWLHjh289957jBgxwrH83Ct5LlWDBg1ISkri5MmTTqM3ycnJZdr/Qn+Mi07PRUZGkpiYeNHnady4MQ899BAPPfQQO3fupH379rz00kv897//LfV1yiIiIgJ/f/8S39P27dvx8PBw/CEHHFcbjR49mpMnT9KrVy8mT57sCDdlqfePik6Hbd68udRaQ0NDS7xSbf/+/WV5qw69evUiJiaGOXPm0KNHD7777junq7KK3sOGDRvo27fvRY+vh4cHffv2pW/fvrz88ss888wzPPHEEyxbtqxM318R0GkpkXIp+h/kuSMl+fn5vP7662aV5MTT05PExETmzZvHwYMHHct37drFokWLyrQ/OL8/wzD4z3/+U+6aBg4cyJkzZ5g5c6ZjWWFhIa+++mqZ9g8ICAA47w9yv379CAoK4plnnqGgoOC8/Y4cOQLY7090+vRpp3WNGzemVq1aTpcjBwQElOny9JJ4enpy7bXXMn/+fKfLtdPT0/noo4/o0aMHQUFBgP0qvHMFBgbSpEkTRy1lrfePIiIi6NWrF2+//TYpKSlO6879fjZu3JisrCynU2GHDh1i7ty5l/SePTw8uPnmm/nqq6/44IMPOHPmjNMpKYBbbrmFAwcOMHv27PP2P3XqFDk5OQBkZGSct759+/YApb5nkT/SyI1IOVx55ZWEhoYycuRI7r//fiwWCx988EGFnRaqCJMnT2bJkiV0796dsWPHUlhYyIwZM2jdujXr168vdd/4+HgaN27Mww8/zIEDBwgKCuJ///vfZTXiDh48mO7du/PYY4+xb98+WrZsyRdffFGm/iSw/5Hz9PTkueeeIysrC6vVytVXX01kZCQzZ87kjjvuoGPHjtx6661ERESQkpLCggUL6N69OzNmzGDHjh307duXW265hZYtW+Ll5cXcuXNJT093XLIM0KlTJ2bOnMnTTz9NkyZNiIyMdDS+lsXTTz/tuFfLPffcg5eXF2+88QZ5eXk8//zzju1atmxJnz596NSpE2FhYaxevZrPP/+ce++9F6DM9ZbklVdeoUePHnTs2JG77rqLhg0bsm/fPhYsWOD43t966608+uijDB06lPvvv99x+XyzZs1Yu3Ztmd8v2HtlXn31VSZNmkSbNm3Ou6v3HXfcwaeffsrdd9/NsmXL6N69O4WFhWzfvp1PP/2Ub775hs6dOzN16lR++OEHBg0aRIMGDTh8+DCvv/469erVo0ePHpdUk9Rw5l2oJVK9XOhS8FatWpW4/YoVK4wrrrjC8PPzM+rUqWP84x//cFwae+7lyhe6FLykS3z5w2XFF7osd9y4ceft26BBA2PkyJFOy5KSkowOHToYPj4+RuPGjY233nrLeOihhwxfX98LHIViW7duNRITE43AwEAjPDzcGDNmjOOS83Mv2x45cqQREBBw3v4l1X7s2DHjjjvuMIKCgozg4GDjjjvuMNatW1emS8ENwzBmz55tNGrUyPD09DzvOC9btszo16+fERwcbPj6+hqNGzc2Ro0aZaxevdowDMM4evSoMW7cOCM+Pt4ICAgwgoODjYSEBOPTTz91eo20tDRj0KBBRq1atQzgopeF//F7ZhiGsXbtWqNfv35GYGCg4e/vb1x11VXGzz//7LTN008/bXTt2tUICQkx/Pz8jPj4eONf//qXkZ+ff0n1XsjmzZuNoUOHGiEhIYavr6/RvHlz46mnnnLaZsmSJUbr1q0NHx8fo3nz5sZ///vfS/qZK2Kz2YzY2FgDMJ5++ukSt8nPzzeee+45o1WrVobVajVCQ0ONTp06GVOmTDGysrIMw7D/vN5www1GnTp1DB8fH6NOnTrGbbfdZuzYsaNM71mkiMUwqtF/NUWk0g0ZMqTUS5BFRFydem5E3Ngfp0rYuXMnCxcuLNeUAiIirkIjNyJuLCYmhlGjRtGoUSP279/PzJkzycvLY926dTRt2tTs8kREKoUaikXcWP/+/fn4449JS0vDarXSrVs3nnnmGQUbEXFrGrkRERERt2J6z81rr71GXFwcvr6+JCQksGrVqlK3z8zMZNy4ccTExGC1WmnWrBkLFy6sompFRESkujP1tNScOXMYP348s2bNIiEhgenTp9OvXz+Sk5OJjIw8b/v8/HyuueYaIiMj+fzzz6lbty779+93TLYmIiIiYuppqYSEBLp06cKMGTMA+/wjsbGx3HfffTz22GPnbT9r1ixeeOEFtm/fjre3d7le02azcfDgQWrVqnVZt1kXERGRqmMYBidOnKBOnTp4eJR+4sm0cJOfn4+/vz+ff/45Q4YMcSwfOXIkmZmZzJ8//7x9Bg4cSFhYGP7+/syfP5+IiAhuv/12Hn300TJPqPb77787ze0iIiIiriM1NZV69eqVuo1pp6WOHj1KYWEhUVFRTsujoqLYvn17ifvs2bOH7777juHDh7Nw4UJ27drFPffcQ0FBAZMmTSpxn7y8PKc5SYqyXGpqqmOOFxEREanesrOziY2NpVatWhfd1qUuBbfZbERGRvLmm2/i6elJp06dOHDgAC+88MIFw820adOYMmXKecuDgoIUbkRERFxMWVpKTLtaKjw8HE9PT9LT052Wp6enEx0dXeI+MTExNGvWzOkUVIsWLUhLSyM/P7/EfSZMmEBWVpbjkZqaWnFvQkRERKod08KNj48PnTp1IikpybHMZrORlJREt27dStyne/fu7Nq1C5vN5li2Y8cOYmJi8PHxKXEfq9XqGKXRaI2IiIj7M/U+N+PHj2f27Nm89957bNu2jbFjx5KTk8Po0aMBGDFiBBMmTHBsP3bsWDIyMnjggQfYsWMHCxYs4JlnnmHcuHFmvQURERGpZkztuRk2bBhHjhxh4sSJpKWl0b59exYvXuxoMk5JSXG63Cs2NpZvvvmGv//977Rt25a6devywAMP8Oijj5r1FkREpJopLCykoKDA7DKkHHx8fC56mXdZ1LjpF7KzswkODiYrK0unqERE3IhhGKSlpZGZmWl2KVJOHh4eNGzYsMRWk0v5++1SV0uJiIhcSFGwiYyMxN/fXzdqdTFFN9k9dOgQ9evXv6zvn8KNiIi4vMLCQkewqV27ttnlSDlFRERw8OBBzpw5U+6ZCKAaTJwpIiJyuYp6bPz9/U2uRC5H0emowsLCy3oehRsREXEbOhXl2irq+6dwIyIiIm5F4UZERMSNxMXFMX36dNOfw0wKNyIiIiawWCylPiZPnlyu5/3tt9+46667KrZYF6OrpSpSzjHIPQoRzc2uREREqrlDhw45Pp8zZw4TJ04kOTnZsSwwMNDxuWEYFBYW4uV18T/bERERFVuoC9LITUVJXgwvNIIvxphdiYiIuIDo6GjHIzg4GIvF4vh6+/bt1KpVi0WLFtGpUyesVis//fQTu3fv5oYbbiAqKorAwEC6dOnCt99+6/S8fzylZLFYeOuttxg6dCj+/v40bdqUL7/88pJqTUlJ4YYbbiAwMJCgoCBuueUWp4mvN2zYwFVXXUWtWrUICgqiU6dOrF69GoD9+/czePBgQkNDCQgIoFWrVixcuLD8B64MNHJTUSLj7R8Pb4Mz+eBV8kSeIiJS+QzD4FTB5V1OXF5+3p4VdtXPY489xosvvkijRo0IDQ0lNTWVgQMH8q9//Qur1cr777/P4MGDSU5Opn79+hd8nilTpvD888/zwgsv8OqrrzJ8+HD2799PWFjYRWuw2WyOYPP9999z5swZxo0bx7Bhw1i+fDkAw4cPp0OHDsycORNPT0/Wr1/vuE/NuHHjyM/P54cffiAgIICtW7c6jUpVBoWbihLSAHyD4XQWHNkOMW3NrkhEpMY6VVBIy4nfmPLaW6f2w9+nYv68Tp06lWuuucbxdVhYGO3atXN8/c9//pO5c+fy5Zdfcu+9917weUaNGsVtt90GwDPPPMMrr7zCqlWr6N+//0VrSEpKYtOmTezdu5fY2FgA3n//fVq1asVvv/1Gly5dSElJ4ZFHHiE+3v4f/aZNmzr2T0lJ4aabbqJNmzYANGrU6BKOQPnotFRFsVgg+mygSdtobi0iIuIWOnfu7PT1yZMnefjhh2nRogUhISEEBgaybds2UlJSSn2etm2L/8MdEBBAUFAQhw8fLlMN27ZtIzY21hFsAFq2bElISAjbtm0DYPz48dx5550kJiby7LPPsnv3bse2999/P08//TTdu3dn0qRJbNxY+X8jNXJTkWLawb4f4dBG6GB2MSIiNZeftydbp/Yz7bUrSkBAgNPXDz/8MEuXLuXFF1+kSZMm+Pn5cfPNN5Ofn1/q8/xxKgOLxYLNZquwOidPnsztt9/OggULWLRoEZMmTeKTTz5h6NCh3HnnnfTr148FCxawZMkSpk2bxksvvcR9991XYa//Rwo3FUkjNyIi1YLFYqmwU0PVyYoVKxg1ahRDhw4F7CM5+/btq9TXbNGiBampqaSmpjpGb7Zu3UpmZiYtW7Z0bNesWTOaNWvG3//+d2677TbeeecdR52xsbHcfffd3H333UyYMIHZs2dXarjRaamKVNRnk7YJKjARi4iIgL2X5YsvvmD9+vVs2LCB22+/vUJHYEqSmJhImzZtGD58OGvXrmXVqlWMGDGC3r1707lzZ06dOsW9997L8uXL2b9/PytWrOC3336jRYsWADz44IN888037N27l7Vr17Js2TLHusqicFORajcFLz/IPwkZe8yuRkRE3MzLL79MaGgoV155JYMHD6Zfv3507NixUl/TYrEwf/58QkND6dWrF4mJiTRq1Ig5c+YA4OnpybFjxxgxYgTNmjXjlltuYcCAAUyZMgWwT4I5btw4WrRoQf/+/WnWrBmvv/565dZsGIZRqa9QzWRnZxMcHExWVhZBQUEV/wKz+8KB1XDz29D6pop/fhEROc/p06fZu3cvDRs2xNfX1+xypJxK+z5eyt9vjdxUtKJTU4fUdyMiImIGhZuKVtRUfGiDuXWIiIjUUAo3FS3mnCumatYZPxERkWpB4aaiRbYCiyfkHoPsg2ZXIyIiUuMo3FQ0b1+IODvPlO53IyIiUuUUbipDjPpuREREzKJwUxmidcWUiIiIWRRuKkPM2RlbdVpKRESkyincVIZo+7TuZKVCboa5tYiIiNQwCjeVwTcIQhvaP1ffjYiIVEP79u3DYrGwfv16s0upcAo3lSVGM4SLiMiFWSyWUh+TJ0++rOeeN29ehdXqatxvPvjqIqYdbJ2vpmIRESnRoUOHHJ/PmTOHiRMnkpyc7FgWGBhoRlluQSM3lSVaTcUiInJh0dHRjkdwcDAWi8Vp2SeffEKLFi3w9fUlPj7eaSbt/Px87r33XmJiYvD19aVBgwZMmzYNgLi4OACGDh2KxWJxfF0W33//PV27dsVqtRITE8Njjz3GmTNnHOs///xz2rRpg5+fH7Vr1yYxMZGcnBwAli9fTteuXQkICCAkJITu3buzf//+yz9Q5aCRm8pSdFrq6E7IzwGfAHPrERGpSQwDCnLNeW1vf7BYLuspPvzwQyZOnMiMGTPo0KED69atY8yYMQQEBDBy5EheeeUVvvzySz799FPq169PamoqqampAPz2229ERkbyzjvv0L9/fzw9Pcv0mgcOHGDgwIGMGjWK999/n+3btzNmzBh8fX2ZPHkyhw4d4rbbbuP5559n6NChnDhxgh9//BHDMDhz5gxDhgxhzJgxfPzxx+Tn57Nq1Sosl3kcykvhprIERkJgNJxMg7TNUD/B7IpERGqOglx4po45r/34wcv+D+2kSZN46aWXuPHGGwFo2LAhW7du5Y033mDkyJGkpKTQtGlTevTogcVioUGDBo59IyIiAAgJCSE6OrrMr/n6668TGxvLjBkzsFgsxMfHc/DgQR599FEmTpzIoUOHOHPmDDfeeKPj9dq0sV8dnJGRQVZWFtdddx2NGzcGoEWLFpd1DC6HTktVJjUVi4jIJcrJyWH37t389a9/JTAw0PF4+umn2b17NwCjRo1i/fr1NG/enPvvv58lS5Zc9utu27aNbt26OY22dO/enZMnT/L777/Trl07+vbtS5s2bfjTn/7E7NmzOX78OABhYWGMGjWKfv36MXjwYP7zn/849RRVNY3cVKaYdrBziS4HFxGpat7+9hEUs177Mpw8eRKA2bNnk5DgPOpfdIqpY8eO7N27l0WLFvHtt99yyy23kJiYyOeff35Zr10aT09Pli5dys8//8ySJUt49dVXeeKJJ/j1119p2LAh77zzDvfffz+LFy9mzpw5PPnkkyxdupQrrrii0mq6EIWbyhStkRsREVNYLC7b6xgVFUWdOnXYs2cPw4cPv+B2QUFBDBs2jGHDhnHzzTfTv39/MjIyCAsLw9vbm8LCwkt63RYtWvC///0PwzAcozcrVqygVq1a1KtXD7BfYt69e3e6d+/OxIkTadCgAXPnzmX8+PEAdOjQgQ4dOjBhwgS6devGRx99pHDjdopOS6VvhTP54OVjbj0iIuISpkyZwv33309wcDD9+/cnLy+P1atXc/z4ccaPH8/LL79MTEwMHTp0wMPDg88++4zo6GhCQkIA+xVTSUlJdO/eHavVSmho6EVf85577mH69Oncd9993HvvvSQnJzNp0iTGjx+Ph4cHv/76K0lJSVx77bVERkby66+/cuTIEVq0aMHevXt58803uf7666lTpw7Jycns3LmTESNGVPKRKpnCTWUKaQC+wXA6C45sLw47IiIipbjzzjvx9/fnhRde4JFHHiEgIIA2bdrw4IMPAlCrVi2ef/55du7ciaenJ126dGHhwoV4eNhbaV966SXGjx/P7NmzqVu3Lvv27bvoa9atW5eFCxfyyCOP0K5dO8LCwvjrX//Kk08+CdhHin744QemT59OdnY2DRo04KWXXmLAgAGkp6ezfft23nvvPY4dO0ZMTAzjxo3jb3/7W2UdolJZDMMwTHllk2RnZxMcHExWVhZBQUGV/4LvXgf7foQbXoMOf6781xMRqYFOnz7N3r17adiwIb6+vmaXI+VU2vfxUv5+62qpylY0Q7juVCwiIlIlFG4qW1FTsa6YEhERqRIKN5XN0VS8GWw2c2sRERGpARRuKlvtpuDlC/knIWOP2dWIiIi4PYWbyubpBVGt7Z+n6dSUiEhlqmHXyLidivr+KdxUhRj13YiIVCZvb28AcnNNmixTKkR+fj5AmSf7vBDd56YqOJqKdcWUiEhl8PT0JCQkhMOHDwPg7+9v2ozUUj42m40jR47g7++Pl9flxROFm6pw7gSahmG/LbiIiFSoohmwiwKOuB4PDw/q169/2cFU4aYqRLYCiyfkHoPsgxBc1+yKRETcjsViISYmhsjISAoKCswuR8rBx8fHcZfly6FwUxW8fSEiHg5vsffdKNyIiFQaT0/Py+7ZENdWLRqKX3vtNeLi4vD19SUhIYFVq1ZdcNt3330Xi8Xi9HCJW23HaIZwERGRqmB6uJkzZw7jx49n0qRJrF27lnbt2tGvX79Sz5kGBQVx6NAhx2P//v1VWHE5qalYRESkSpgebl5++WXGjBnD6NGjadmyJbNmzcLf35+33377gvtYLBaio6Mdj6ioqCqsuJyK5pjSyI2IiEilMjXc5Ofns2bNGhITEx3LPDw8SExMZOXKlRfc7+TJkzRo0IDY2FhuuOEGtmzZcsFt8/LyyM7OdnqYIrqN/WNWKuRmmFODiIhIDWBquDl69CiFhYXnjbxERUWRlpZW4j7Nmzfn7bffZv78+fz3v//FZrNx5ZVX8vvvv5e4/bRp0wgODnY8YmNjK/x9lIlvEIQ2tH+um/mJiIhUGtNPS12qbt26MWLECNq3b0/v3r354osviIiI4I033ihx+wkTJpCVleV4pKamVnHF51BTsYiISKUz9VLw8PBwPD09SU9Pd1qenp7uuBnTxXh7e9OhQwd27dpV4nqr1YrVar3sWitEdFvYOl9NxSIiIpXI1JEbHx8fOnXqRFJSkmOZzWYjKSmJbt26lek5CgsL2bRpEzExMZVVZsWJaW//qNNSIiIilcb0m/iNHz+ekSNH0rlzZ7p27cr06dPJyclh9OjRAIwYMYK6desybdo0AKZOncoVV1xBkyZNyMzM5IUXXmD//v3ceeedZr6Nsik6LXVsF+SdBGugufWIiIi4IdPDzbBhwzhy5AgTJ04kLS2N9u3bs3jxYkeTcUpKitOtmI8fP86YMWNIS0sjNDSUTp068fPPP9OyZUuz3kLZBUZCYDScTIP0LVA/weyKRERE3I7FMAzD7CKqUnZ2NsHBwWRlZREUFFT1BXz4J9i5BAa+CF3HVP3ri4iIuKBL+fvtcldLubyim/kdWm9qGSIiIu5K4aaqaRoGERGRSqVwU9WKmooPb4Mz+ebWIiIi4oYUbqpaSAPwDQZbARzZbnY1IiIibkfhpqpZLOecmtL9bkRERCqawo0ZNEO4iIhIpVG4MYOaikVERCqNwo0ZHBNobgKbzdxaRERE3IzCjRlqNwUvXyjIgYzdZlcjIiLiVhRuzODpBVGt7Z+rqVhERKRCKdyYxXFqSn03IiIiFUnhxixqKhYREakUCjdmiTnnXjc1a+5SERGRSqVwY5bIVuDhBacyIDPF7GpERETchsKNWbx9IaqV/fODa82tRURExI0o3Jipbmf7x99Xm1uHiIiIG1G4MVPdTvaPBzRyIyIiUlEUbsxU7+zIzaH1UHjG1FJERETchcKNmWo3BWsQFOTCkW1mVyMiIuIWFG7M5OEBdTrYP1ffjYiISIVQuDGbo+9mjbl1iIiIuAmFG7OpqVhERKRCKdyYraip+Mg2yDtpbi0iIiJuQOHGbLWiIaguGDb7VVMiIiJyWRRuqoOiU1NqKhYREblsCjfVgZqKRUREKozCTXVQ1HejcCMiInLZFG6qg5j2YPGA7AOQfcjsakRERFyawk11YA2EiHj75xq9ERERuSwKN9VFvS72j6m/mluHiIiIi1O4qS7qX2H/mPKLuXWIiIi4OIWb6iI2wf7x0HooOG1qKSIiIq5M4aa6CGsEARFQmA8H15ldjYiIiMtSuKkuLJbiU1OpOjUlIiJSXgo31Ums+m5EREQul8JNdeIYufkVbDZzaxEREXFRCjfVSXRb8PKFU8fh2E6zqxEREXFJCjfViZdP8TxTOjUlIiJSLgo31Y3udyMiInJZFG6qm1hdMSUiInI5FG6qm9iz0zBk7IGTh82tRURExAUp3FQ3fqEQ0cL+ueaZEhERuWQKN9WR+m5ERETKTeGmOlK4ERERKTeFm+rIMYnmBsjPNbcWERERF6NwUx2FxkGtGLAVwO+/mV2NiIiIS1G4qY4sFojraf987w/m1iIiIuJiqkW4ee2114iLi8PX15eEhARWrVpVpv0++eQTLBYLQ4YMqdwCzdDwbLjZ96O5dYiIiLgY08PNnDlzGD9+PJMmTWLt2rW0a9eOfv36cfhw6fd42bdvHw8//DA9e/asokqrWMNe9o8H1kDeSXNrERERcSGmh5uXX36ZMWPGMHr0aFq2bMmsWbPw9/fn7bffvuA+hYWFDB8+nClTptCoUaMqrLYKhcZBcH2wndFVUyIiIpfA1HCTn5/PmjVrSExMdCzz8PAgMTGRlStXXnC/qVOnEhkZyV//+teqKNM8jlNT6rsREREpKy8zX/zo0aMUFhYSFRXltDwqKort27eXuM9PP/3E//3f/7F+/foyvUZeXh55eXmOr7Ozs8tdb5Vr2AvWfwh71XcjIiJSVqaflroUJ06c4I477mD27NmEh4eXaZ9p06YRHBzseMTGxlZylRWo6IqpQ+vhdJappYiIiLgKU0duwsPD8fT0JD093Wl5eno60dHR522/e/du9u3bx+DBgx3LbDYbAF5eXiQnJ9O4cWOnfSZMmMD48eMdX2dnZ7tOwAmuC2GNIWM37P8Zmg8wuyIREZFqz9SRGx8fHzp16kRSUpJjmc1mIykpiW7dup23fXx8PJs2bWL9+vWOx/XXX89VV13F+vXrSwwtVquVoKAgp4dLKeq70akpERGRMjF15AZg/PjxjBw5ks6dO9O1a1emT59OTk4Oo0ePBmDEiBHUrVuXadOm4evrS+vWrZ32DwkJAThvuduI6wlr3lVTsYiISBmZHm6GDRvGkSNHmDhxImlpabRv357Fixc7moxTUlLw8HCp1qCKVXS/m7RNkJsB/mHm1iMiIlLNWQzDMMwuoiplZ2cTHBxMVlaW65yiei0BjmyHWz6AltebXY2IiEiVu5S/3zV4SMSFxGkqBhERkbJSuHEFRaemNImmiIjIRSncuIK4HoDFfmrqRPpFNxcREanJFG5cgX8YRLexf75nuamliIiIVHcKN66iSV/7x91JpW8nIiJSwyncuIrGZ8PNriQ4e1dmEREROZ/CjauITQCfQMg9Cmkbza5GRESk2lK4cRVePsWXhOvUlIiIyAUp3LiSor6bXd+ZW4eIiEg1pnDjSorCTeovkHfC3FpERESqKYUbVxLWCEIbgu2MZgkXERG5AIUbV9Mk0f5x5xJz6xAREammFG5cTbN+9o87l0DNmvNURESkTBRuXE1cD/Dyg+wDkL7Z7GpERESqHYUbV+PtB4362D/f8Y2ppYiIiFRHCjeuqNm19o8KNyIiIudRuHFFTc+Gm99/g5xj5tYiIiJSzSjcuKLgehDVBjB01ZSIiMgfKNy4qub97R+TF5pbh4iISDWjcOOq4gfZP+5KgoJT5tYiIiJSjSjcuKqY9hBUFwpyYM/3ZlcjIiJSbSjcuCqLpXj0JnmBubWIiIhUIwo3rqz5QPvH5EVgKzS3FhERkWpC4caVxfUAazDkHLFfFi4iIiIKNy7N07t4rqntOjUlIiICCjeur6jvZtuXmkhTREQEhRvX1/Qa+0Sax/fBoQ1mVyMiImI6hRtX5xNQPNfU1nmmliIiIlIdKNy4g5ZD7B+3zNOpKRERqfEUbtxBs35nT03t1akpERGp8RRu3IFOTYmIiDgo3LgLnZoSEREBFG7ch9OpqfVmVyMiImIahRt34RNQfEO/TZ+bW4uIiIiJFG7cSdtb7B83/09zTYmISI2lcONOmlwDfqFw4hDs+9HsakREREyhcONOvHyKG4s3fmpqKSIiImZRuHE3bYfZP279EgpOmVuLiIiICRRu3E1sAoTUh/wTkLzI7GpERESqnMKNu/HwgDZnG4t1akpERGoghRt3VHTV1K6lcPKIubWIiIhUMYUbdxTRHOp2AtsZ2PiJ2dWIiIhUKYUbd9XhDvvHte9rOgYREalRFG7cVeubwNsfju6A1FVmVyMiIlJlFG7clW8QtBpq/3zd++bWIiIiUoUUbtxZ0ampzXMh74S5tYiIiFQRhRt3Vv8KqN0UCnJg8xdmVyMiIlIlFG7cmcUCHc9pLBYREakByhVuUlNT+f333x1fr1q1igcffJA333yzXEW89tprxMXF4evrS0JCAqtWXbgB9osvvqBz586EhIQQEBBA+/bt+eCDD8r1ujVCu9vAwxsOrIaD68yuRkREpNKVK9zcfvvtLFu2DIC0tDSuueYaVq1axRNPPMHUqVMv6bnmzJnD+PHjmTRpEmvXrqVdu3b069ePw4cPl7h9WFgYTzzxBCtXrmTjxo2MHj2a0aNH880335Tnrbi/wMjixuJVs82tRUREpApYDOPSb4ISGhrKL7/8QvPmzXnllVeYM2cOK1asYMmSJdx9993s2bOnzM+VkJBAly5dmDFjBgA2m43Y2Fjuu+8+HnvssTI9R8eOHRk0aBD//Oc/L7ptdnY2wcHBZGVlERQUVOY6XVrqb/B/ieBphfFbISDc7IpEREQuyaX8/S7XyE1BQQFWqxWAb7/9luuvvx6A+Ph4Dh06VObnyc/PZ82aNSQmJhYX5OFBYmIiK1euvOj+hmGQlJREcnIyvXr1KnGbvLw8srOznR41Tr3OUKcDFOap90ZERNxeucJNq1atmDVrFj/++CNLly6lf//+ABw8eJDatWuX+XmOHj1KYWEhUVFRTsujoqJIS0u74H5ZWVkEBgbi4+PDoEGDePXVV7nmmmtK3HbatGkEBwc7HrGxsWWuz21YLND1Lvvnv/0fFJ4xtx4REZFKVK5w89xzz/HGG2/Qp08fbrvtNtq1awfAl19+SdeuXSu0wJLUqlWL9evX89tvv/Gvf/2L8ePHs3z58hK3nTBhAllZWY5HampqpddXLbW6EfxrQ/bvkLzQ7GpEREQqjVd5durTpw9Hjx4lOzub0NBQx/K77roLf3//Mj9PeHg4np6epKenOy1PT08nOjr6gvt5eHjQpEkTANq3b8+2bduYNm0affr0OW9bq9XqOIVWo3n7QseR8NPLsOpNaHm92RWJiIhUinKN3Jw6dYq8vDxHsNm/fz/Tp08nOTmZyMjIMj+Pj48PnTp1IikpybHMZrORlJREt27dyvw8NpuNvLy8sr+BmqrLX8HiAft+hLTNZlcjIiJSKcoVbm644Qbef9/emJqZmUlCQgIvvfQSQ4YMYebMmZf0XOPHj2f27Nm89957bNu2jbFjx5KTk8Po0aMBGDFiBBMmTHBsP23aNJYuXcqePXvYtm0bL730Eh988AF//vOfy/NWapbgetDyBvvnK/5jbi0iIiKVpFzhZu3atfTs2ROAzz//nKioKPbv38/777/PK6+8cknPNWzYMF588UUmTpxI+/btWb9+PYsXL3Y0GaekpDhdgZWTk8M999xDq1at6N69O//73//473//y5133lmet1KhDMPgxOkCs8soXfcH7R83/w+O7zOzEhERkUpRrvvc+Pv7s337durXr88tt9xCq1atmDRpEqmpqTRv3pzc3NzKqLVCVNZ9blbsOsrf56wnLjyAT/9W9lNqpvhgKOz+DrqMgUEvml2NiIjIRVX6fW6aNGnCvHnzSE1N5ZtvvuHaa68F4PDhwzXnxnh/EBXky+ETeWz8PZOCQpvZ5ZSux9/tH9d9ACePmFuLiIhIBStXuJk4cSIPP/wwcXFxdO3a1dH8u2TJEjp06FChBbqKRuEBBPt5c7rAxrZD1fxGgXE9oW4nOHMafp1ldjUiIiIVqlzh5uabbyYlJYXVq1c7zenUt29f/v3vf1dYca7Ew8NCx/ohAKzZf9zcYi7GYikevfltNpyu5mFMRETkEpQr3ABER0fToUMHDh486JghvGvXrsTHx1dYca6mUwP7pfFrUzLNLaQsmg+C8GZwOgvWvGt2NSIiIhWmXOHGZrMxdepUgoODadCgAQ0aNCAkJIR//vOf2GzVvN+kEnWsfzbcVPeRGwAPj+Irp35+BfJzTC1HRESkopQr3DzxxBPMmDGDZ599lnXr1rFu3TqeeeYZXn31VZ566qmKrtFltIsNwcMCBzJPkZZ12uxyLq7tLRDaEHKOqPdGRETcRrnCzXvvvcdbb73F2LFjadu2LW3btuWee+5h9uzZvPvuuxVcousIsHoRH22/WmxtiguM3nh6w1VP2D9f8R845QI1i4iIXES5wk1GRkaJvTXx8fFkZGRcdlGurKjvpto3FRdpfRNEtrL33uiuxSIi4gbKFW7atWvHjBkzzls+Y8YM2rZte9lFuTKXCzceHtD37KnEX2bBifTStxcREanmyjUr+PPPP8+gQYP49ttvHfe4WblyJampqSxcuLBCC3Q1RU3FWw5mcbqgEF9vT5MrKoNm/aFeV/h9Ffzwgu5aLCIiLq1cIze9e/dmx44dDB06lMzMTDIzM7nxxhvZsmULH3zwQUXX6FJiw/wID7RSUGiw+UCW2eWUjcUCfSfaP1/zruacEhERl1auuaUuZMOGDXTs2JHCwsKKesoKV1lzS53rrvdXs2RrOo8PjOeuXo0r5TUqxftDYM8yaHsr3PiG2dWIiIg4VPrcUlI6l+u7KVI0erPxE0j9zdxaREREyknhphIUh5tMKnBgrPLV7Qjth9s/X/gQ2KrvCJyIiMiFKNxUgtZ1g/H2tHD0ZB6/Hz9ldjmXJnEKWIPh0AZY847Z1YiIiFyyS7pa6sYbbyx1fWZm5uXU4jZ8vT1pVSeY9amZrNl/nNgwf7NLKrvACLj6SVj0CCT9E1oOhYDaZlclIiJSZpc0chMcHFzqo0GDBowYMaKyanUpjnmmXOFOxX/U+S8Q1QZOZ0LSZLOrERERuSSXNHLzzjs6TVFWnRqE8vaKva7XVAzg6WW/183b/WDtB9BxJNTrbHZVIiIiZaKem0rSsUEIANsOZZOTd8bcYsqj/hXQ7jbAgAVqLhYREdehcFNJYoL9qBPsi82ADb9nml1O+VwzFaxBcGg9rH7b7GpERETKROGmEnU8e0n4Wlc8NQUQGAlXn513aulEOLrL3HpERETKQOGmEhXd72ZtSqa5hVyOLndCw95QkAtfjIHCArMrEhERKZXCTSU694opm82FbuZ3Lg8PGDITfIPh4Fr4QZNqiohI9aZwU4la1gnC19uDzNwC9hzNMbuc8guuC4Netn/+wwvw+2pz6xERESmFwk0l8vb0oG3dEMBF73dzrjY3Q+ubwSi0n57Kd+GwJiIibk3hppK5fFPxuQa9CEF1IWMPfPOE2dWIiIiUSOGmkhU3FbtBuPELhSGv2z9f8w7s+MbcekREREqgcFPJOtQPAWBH+kmyTrnBlUaN+sAV4+yfzx8HWQdMLUdEROSPFG4qWXiglbja9okz17nD6A1A34kQ1RpyjsDHwyDvpNkViYiIOCjcVIHiS8IzzS2konj7wq0fgX84pG2CuX8Dm83sqkRERACFmyrhVk3FRUIb2AOOpw9s/xqSpphdkYiICKBwUyWKmorXp2ZS6Ko38ytJ/QS44TX75yumw7oPTS1HREQEFG6qRLOoWgRavTiZd4Yd6SfMLqditb0Fej1i//yrB2D/z+bWIyIiNZ7CTRXw9LDQPjYEgDXudGqqSJ/HoeUNYCuAT4bb74MjIiJiEoWbKtLx7CXhbnG/mz/y8IAhs6BOBziVAR/dCqezzK5KRERqKIWbKuKWTcXn8vGHWz+GWnXgaDJ8NgrO5JldlYiI1EAKN1Wkw9nLwfcdy+XoSTf9ox8UA7d9DN7+sPs7+PhWzUElIiJVTuGmigT7edM0MhCAde5yv5uS1Glvv0S8KOB8cCOcyjS7KhERqUEUbqpQ0SXhbtlUfK7GV8GI+eAbDKm/wHvXwckjZlclIiI1hMJNFeroTpNoXkxsVxi1AAIi7HcxfmcAZP1udlUiIlIDKNxUoaJpGDakZlJQWAOmK4huA6MXQ1A9OLYT3u4Px3abXZWIiLg5hZsq1Cg8gBB/b/LO2Nh6MNvscqpGeBP4y2Ko3QSyUu0BJ22z2VWJiIgbU7ipQh4eFjqcvZlfjTg1VSQkFkYvgqg2kHMY3h0Iqb+ZXZWIiLgphZsqVmOaiv8oMBJGfQX1utpv8Pf+DbBnudlViYiIG1K4qWJFTcVufTn4hfiFwoh50OgqKMiBD/8Em/9ndlUiIuJmFG6qWLt6IXhY4EDmKQ5lnTK7nKrnEwC3z4H466AwHz7/C8y9W/fCERGRCqNwU8UCrF60iAkCYO3+THOLMYuXFf70HvT4O1g8YMPHMPNK2L3M7MpERMQNKNyYoOiS8BrVVPxHnl6QONl+qXhoQ8g+AB8MgYWPQH6u2dWJiIgLqxbh5rXXXiMuLg5fX18SEhJYtWrVBbedPXs2PXv2JDQ0lNDQUBITE0vdvjqqsU3FJamfAGNXQJc77V+vehPe6Am/rza3LhERcVmmh5s5c+Ywfvx4Jk2axNq1a2nXrh39+vXj8OHDJW6/fPlybrvtNpYtW8bKlSuJjY3l2muv5cCBA1VcefkVhZstB7M4lV9ocjXVgE8ADHoJ/vyFfVbxY7vg/66BpH/CmXyzqxMRERdjMQzDMLOAhIQEunTpwowZMwCw2WzExsZy33338dhjj110/8LCQkJDQ5kxYwYjRoy46PbZ2dkEBweTlZVFUFDQZddfHoZh0OO5ZRzIPMX7f+lKr2YRptRRLZ06Dgv/AZs+tX8d3QaGvgFRrcytS0RETHUpf79NHbnJz89nzZo1JCYmOpZ5eHiQmJjIypUry/Qcubm5FBQUEBYWVuL6vLw8srOznR5ms1gsdGtcG4AVu4+aXE014xcKN822Nxz7hdnnpXqzD6z4D9g0yiUiIhdnarg5evQohYWFREVFOS2PiooiLS2tTM/x6KOPUqdOHaeAdK5p06YRHBzseMTGxl523RWhexN7uPl51zGTK6mmWg2Be36BZgPsl4wvnQjvDoKMPWZXJiIi1ZzpPTeX49lnn+WTTz5h7ty5+Pr6lrjNhAkTyMrKcjxSU1OruMqSXdk4HIDNB7PIyi0wuZpqqlYU3PYxXD8DfGpBykqY2QNWvw3mnk0VEZFqzNRwEx4ejqenJ+np6U7L09PTiY6OLnXfF198kWeffZYlS5bQtm3bC25ntVoJCgpyelQHUUG+NI4IwDBg5R6N3lyQxQId77BfUdWgh/3Oxl//HT68GbIPmV2diIhUQ6aGGx8fHzp16kRSUpJjmc1mIykpiW7dul1wv+eff55//vOfLF68mM6dO1dFqZWiaPRmxS713VxUaAMY+RX0mwZevrDrW3gtAZY8Ccf3m12diIhUI6aflho/fjyzZ8/mvffeY9u2bYwdO5acnBxGjx4NwIgRI5gwYYJj++eee46nnnqKt99+m7i4ONLS0khLS+PkyZNmvYVy69HUHm5+2HnE5EpchIcHdLsH/vYD1OkAeVnw86vwSnv4+Hb7RJw6XSUiUuN5mV3AsGHDOHLkCBMnTiQtLY327duzePFiR5NxSkoKHh7FGWzmzJnk5+dz8803Oz3PpEmTmDx5clWWftm6NwnH29PC/mO57D2aQ8PwALNLcg0RzeHOJNi5FH6dBXuWQfIC+yMiHrqOgba3gjXQ7EpFRMQEpt/npqpVh/vcnOu2N39h5Z5jTBrcktHdG5pdjms6ssN+Z+P1H9l7cgCswdDhz9D1TghrZG59IiJy2VzmPjcCfZrbb+C3PFmnpsotohkMehEe2gb9n7WHmbws+OU1eKUjfDQMdiXplJWISA2hcGOyPs0jAfhlzzFOF+gmdZfFNxiuGAv3roHhn0OTRMCAHYvhvzfCjC7w65uQd8LsSkVEpBIp3JisWVQgMcG+5J2x6ZLwiuLhAU2vgT//zx50Eu623yfn2E5Y9Ai81AIWPQrHdptdqYiIVAKFG5NZLBbH6E3StvSLbC2XLLwJDHjOfspqwAtQuynkn7A3Ir/aEf57s70x2WYzu1IREakgCjfVwLWt7FeGLd2ajs2mvpBKYa0FCXfBuFX22ceb9gMssGup/YaAMzrDLzPhdJbZlYqIyGVSuKkGrmxcmwAfT9Kz89h4QH9cK5WHBzTpC8M/hfvXwhXjwBoEGbth8WPwcktY8LD9CiwREXFJCjfVgNXLkz7x9lNTS7aUbcJQqQBhjaD/MzB+Gwx6CcKbQ/5J+G02vNYF3h8CyYs1G7mIiItRuKkmrm1pPzX1jcJN1bMGQpc7YdyvMGI+NB8IWOw3B/x4mL035+cZcCrT7EpFRKQMFG6qiaviI/H2tLD7SA470nWpsiksFmjUxz4T+QPr4cr77JeXH98HS56Al1vYJ+08vN3kQkVEpDQKN9VEkK83vZrab+j39YaDJlcjhMbBtU/bT1ldNx0iW0JBLqx+G15PgPcGw/YFOmUlIlINKdxUI9e3rwPAlxsOUsNmxai+fAKg82gY+zOM/BrirwOLB+z9AT653T5p54r/QG6G2ZWKiMhZCjfVSGKLKHy9Pdh3LJfNB7LNLkfOZbFAw55w64fwwAbo/iD4hUJmCiydaL/K6sv7IX2L2ZWKiNR4CjfVSIDVi74t7I3FX244YHI1ckEh9eGaKfZTVte/ClFt4MwpWPsezLwS3hkEW7+EwjNmVyoiUiMp3FQzg9vaT019vfGQbuhX3Xn7QccRcPePMHoRtLwBLJ6w/yf49A74Tzv48WXI0bQaIiJVSeGmmunTPIJavl4cyjqtuaZchcUCDa6EW96HBzdCz4fAvzZk/w5JU+DfLWH+ODi00exKRURqBIWbasbX25MbzjYWz/kt1eRq5JIF14O+E+HvW+GG1yGmHZw5Dev+C2/0hLf7w5a5UFhgdqUiIm5L4aYauqVzLACLt6SRlas/gi7J2xc6DIe7voe/LIFWN4KHF6SshM9GwUvxMP9e+x2QC06bXa2IiFvxMrsAOV+busHER9die9oJ5m84wIhucWaXJOVlsUD9BPsj+5D9Pjlr3oGcI7DuA/vDOwCaJtovM296jf0qLBERKTeLUcNuqJKdnU1wcDBZWVkEBQWZXc4Fvf3TXqZ+vZVWdYJYcH9Ps8uRilRYAPtX2G8CuH0BZJ9zZZyHF8T1sAed5gMhuK55dYqIVCOX8vdb4aaaysjJ54pnksgvtDH3nivpUF//m3dLhgEH1xUHnSPbnNfX6Qjxg+xhJ6K5fSRIRKQGUrgphauEG4CHPt3A/9b+zg3t6/CfWzuYXY5UhWO7zwadryF1FXDOr2dYY3vQaTEY6nYGD7XMiUjNoXBTClcKN5sPZHHdqz/h5WFhxWNXExXka3ZJUpVOpMOORfaws2c5FOYXrwuIhOYD7CM6DXvZG5hFRNyYwk0pXCncAPxp1s/8tu8491/dhPHXNje7HDFL3gnY9a096OxYAnlZxet8AqFJon1Ep+k19pnMRUTcjMJNKVwt3CzYeIhxH62ldoAPKx67Gl9vT7NLErOdybffBbmoT+fEoeJ1Ht72ObDiB9kbkoPqmFeniEgFUrgphauFmzOFNnq/sJwDmaf45w2tuEOXhcu5bDZ7Q3LyAtj2NRxNdl5ft5P91FX8dRDRzJwaRUQqgMJNKVwt3AC8v3IfE+dvoW6IH8se7oOPlxpJ5QKO7ixuSP79N+d1tZsWX3lVt5MakkXEpSjclMIVw83pgkJ6Pr+MIyfyeP6mttzSJdbsksQVnEiD5IVnG5K/B9s5d7sOjLKftipqSPbyMa9OEZEyULgphSuGG4DZP+zhXwu30aC2P0nje+Plqf91yyU4nQ27ltpPXe1cCvknitdZg+yNyPGDoMk14Os6vxciUnMo3JTCVcNNTt4Zejz3HcdzC3jupjYM61Lf7JLEVZ3Jg30/nj19tRBOphWv8/CGRr2LG5JrRZtXp4jIORRuSuGq4QbgrR/38PSCbUQFWVn2cB/8fTQ1mFwmmw0OrLH36Gz/Go7tcl5fr8vZPp3BEN7EnBpFRFC4KZUrh5u8M4Ukvvw9qRmnePjaZtx7dVOzSxJ3c2TH2aCzAA6sdl4X3ry4IblOBzUki0iVUrgphSuHG4AvNxzk/o/XEWj1YvkjfQgPtJpdkrir7ENnG5K/hr0/Ojck14o525A8COJ6qiFZRCqdwk0pXD3c2GwGQ15fwcbfs7i5Uz1e/FM7s0uSmuBU5tk7JBc1JJ8sXmcNhmbXnm1ITgRrLdPKFBH3pXBTClcPNwBr9h/n5lk/Yxjw0Z0JXNkk3OySpCY5kwd7fzh7+moh5BwuXufpA436FDckB0aaVqaIuBeFm1K4Q7gBeGreZj74ZT8NwwNY9EBPTcsg5rDZ7L0527+2X2aesfuclRaI7Vrcp1O7sWlliojrU7gphbuEm+zTBSS+9D2HT+Rx39VNeEiTaorZDAOOJBc3JB9c67w+osXZoDPI3pBssZhTp4i4JIWbUrhLuAFYtOkQYz9ci5eHhc/u7kaH+qFmlyRSLOtA8R2S9/0ItjPF64LqntOQ3AM8vc2rU0RcgsJNKdwp3BiGwb0fr2PBxkPEhvmx4P6eBPnqj4RUQ6eO2xuRt38NO7+Fgpzidb7B0LQftLgOGvcFa6B5dYpItaVwUwp3CjcAWacKGPifHzmQeYrB7erwyq3tsWi4X6qzgtOw9/vihuTco8XrPK3Q+Cr7iE6zARAYYV6dIlKtKNyUwt3CDdivnrrljZUU2gz+NbQ1wxMamF2SSNnYCu2zlxc1JB/fe85KC9S/orhPJ6yRaWWKiPkUbkrhjuEG4PXlu3h+cTJeHhbe+0tXuuvycHE1hgGHt52d8+prOLTeeX1kS/tVV/GDIKadGpJFahiFm1K4a7gxDIMH56xn/vqD1PL14ouxV9I0SjdTExeWmQrJi+xBZ99PYBQWrwuqVzyi0+BKNSSL1AAKN6Vw13ADcLqgkD+/9Sur9x+nXqgfX9xzJZG1fM0uS+Ty5WbAziX2oLMrCQpyi9f5hkCz/mfvkNwXfAJMK1NEKo/CTSncOdwAZOTkM/T1Few/lkuTyEA+GpOggCPupeAU7FluDzrJiyD3WPE6L19ofPXZhuT+EKDTsyLuQuGmFO4ebgD2Hc3httm/cCjrNI0iAvh4zBVEBSngiBuyFULqr/Y+nW1fQeb+4nUWD6jfrfj0VWicaWWKyOVTuClFTQg3APuP5XDbm79wMOs0DcMD+OCvXakX6m92WSKVxzAgfUtxQ3LaRuf1Ua2Lp4KIbqOGZBEXo3BTipoSbgBSM3K59c1fOJB5itoBPsz8cye6NgwzuyyRqpGZYr+PzvavYf/Pzg3JwfWLR3TqdwNPL/PqFJEyuZS/3x5VVNMFvfbaa8TFxeHr60tCQgKrVq264LZbtmzhpptuIi4uDovFwvTp06uuUBcUG+bPZ3d3o1WdII7l5DP8rV/46NcUs8sSqRoh9eGKu2HU1/DILhgyyz5q4+UHWSnw60x47zp4sQnMHWu/z05+7sWfV0SqPVPDzZw5cxg/fjyTJk1i7dq1tGvXjn79+nH48OESt8/NzaVRo0Y8++yzREdHV3G1rqlOiB+f330l17WNoaDQ4PG5m5jwxUZy8s5cfGcRd+EfBu1vg1s/hH/sgVs/gvbDwS/MPjXEho9gznB4vhF8MhzWf2S/QktEXJKpp6USEhLo0qULM2bMAMBmsxEbG8t9993HY489Vuq+cXFxPPjggzz44IOX9Jo16bTUuQzD4PXlu3lxSTKGAfVC/Xjupra62Z/UbIVnIPWXsw3JX9tHdIpYPO330IkfZJ/kM1R3/hYxk0uclsrPz2fNmjUkJiYWF+PhQWJiIitXrqyw18nLyyM7O9vpURNZLBbGXdWED/+aQN0QP34/forhb/3K43M3kX26wOzyRMzh6WWflbz/NHhwI/ztR+gzAaLa2Ht09v0Iix+D/7SFWT1g+bOQttnevCwi1ZZp4ebo0aMUFhYSFRXltDwqKoq0tLQKe51p06YRHBzseMTGxlbYc7uiK5uE883fe3HHFfb/hX70awq9n1/GWz/u4XRB4UX2FnFjFgvEtIU+j8HYn+CBDdBvGjToYb+sPG0TLJ8Gs7rDf9rB4sdh3wr75egiUq2Y3lBc2SZMmEBWVpbjkZqaanZJpgu0evHPIa35aEwCjSICOJ5bwNMLttH3pe/5bHUqhTb9r1SE0Djodg+MXgAP74IbXofmg+w3CszcD7+8Bu8OhBebwrxx9iuzCk6ZXbWIAKZd/xgeHo6npyfp6elOy9PT0yu0WdhqtWK1Wivs+dzJlY3DWfJgLz5f8zvTv93JgcxTPPL5Rl79bhd/vqI+f+oUS2iAj9llipgvoDZ0GG5/5OfA7u/sfTpFd0he/1/7w9vfPgVE/HXQ9Fp7I7OIVDnTRm58fHzo1KkTSUlJjmU2m42kpCS6detmVlk1jpenB7d2rc/yR/rw+MB4Qvy9ScnI5ZmF27liWhIPf7aBjb9nml2mSPXhEwAtBsPQWfDIbhj5FSTcDcGx9jmvtn0Fc/8GLzSB9wbDr2/YJwEVkSpj6tVSc+bMYeTIkbzxxht07dqV6dOn8+mnn7J9+3aioqIYMWIEdevWZdq0aYC9CXnr1q0ADBw4kOHDhzN8+HACAwNp0qRJmV6zpl4tVVan8guZv/4A76/cz9ZDxc3X8dG16Ncqmv6to4mProVFd3cVcWYY9rsiF115dXiL8/qYdvYRnfhBENlSd0gWuUQudYfiGTNm8MILL5CWlkb79u155ZVXSEhIAKBPnz7ExcXx7rvvArBv3z4aNmx43nP07t2b5cuXl+n1FG7KxjAM1qZk8sHKfSzclEZ+oc2xrkFtf/q3iqZf62ja1wvBw0P/SIucJ2PP2TskL7Bfbm4U/w4RGlccdGITwMPTtDJFXIVLhZuqpnBz6TJz80nadpjFW9L4YccR8s4U/yMd4u9Nl7gwEhqG0bVhGC1jgvDydPs+dZFLc/II7FhsDzq7v4PCvOJ1/uHQvL897DTqA95+ppUpUp0p3JRC4eby5OSd4fsdR1i8OY3vth/m5B/udBxo9aJTg1C6nhN2Aqyat0fEIe9kcUPyjsVwOrN4nXdAcUNys2vBL9S0MkWqG4WbUijcVJyCQhubD2Sxam8Gv+7N4Ld9GZw47Rx2LBZoEOZPyzpBtIwJomWdIFrEBBEd5Ku+HZHCAvukntsX2B/Zvxevs3jabzAYfx3ED4TgeubVKVINKNyUQuGm8hTaDLanZbNqbwar9mawZv9xDp/IK3HbUH9ve9CJtgeeZlG1aBgeoFEeqbkMAw6tLw46h7c6r49pf05Dcgs1JEuNo3BTCoWbqnX0ZB7bDmWz7VA2Ww9ms/VQNruP5FzwRoFRQVYahQfSMCKARuEBNIoIoGF4IPVC/fBWL4/UJMd2Q/LZhuSUX4BzfmfCGtlDTvx1UK+LGpKlRlC4KYXCjflOFxSyM/0kWw9lse3QCbYezGb3kZMcy8m/4D5eHhbq1/anUXgADcMDaBQRaP8YHkBELatOcYl7O3n4nIbkZc4NyQER0HyAPeg07A3evubVKVKJFG5KoXBTfWXlFrDn6En2Hs1h79Ec9hzJYc/RHPYePcnpAtsF9wu0etHwbOhpGB5Ag9r+1A/zp35tfyICFXzEzeSdgF1JZxuSv4G8rOJ1PoHQJPHsHZKvAb8Q08oUqWgKN6VQuHE9NptBWvZpe+A5msOeI8UBKDUjl9KmwvLz9qR+mD+xYf5Ooad+mD/1Qv2wemk4X1xYYQHs+6m4T+fEweJ1Hl4Q1/Ps6atBEFTHvDpFKoDCTSkUbtxL3plCUjNyHaM8+47msP9YLikZuRzKOlVq8LFYICbI1xF2GtQOsIegMPvXIf7eGvUR12EYcHAdbP/aHnSObHdeX6djcZ9ORHM1JIvLUbgphcJNzZF/xsaBzFPsP2Yf4SkKPUWP3PzCUvev5et1NvScHfkJC3B8HRPsq5sVSvV2dBcknx3RSV2FU0Ny7SbFQaduZ/DQz7JUfwo3pVC4EbBPL3H0ZP7ZoJNDyrFT7M8oDkEXuoS9iJeHhbqhfvbTXGH+ziGodgCBuqRdqpMT6bBjkT3o7FkOhec07wdE2u+jE38dNOwFXlbTyhQpjcJNKRRupCxO5ReSejyXlGO57M/IPRt6ckjJyCX1+Cnyz1y4wRkgLMDn/NBztt8nqpav5uMS8+SdgF3fntOQXDxBLj61oOk5Dcm+webVKfIHCjelULiRy2WzGaSfOF18muvsx6IQlFHKJe0APl4exIb60aB2QIkjP77eanKWKnImH/b9aA86yQvhxKHidR7e9pGc+EHQfCAExZhXpwgKN6VSuJHKduJ0QYmhZ/+xXA5knrrgDQyLRAVZzwaegD+c7vKndoCPmpylcthsZxuSv7LPZn402Xl93c7nNCQ3M6dGqdEUbkqhcCNmOlNo42Dm6bOhJ8cpBKUcy+XEHyYi/aMAH09izxnpsV/abg9BdUP88PFSY6hUkKM7z15i/jX8/pvzutpNocV19qBTp6MakqVKKNyUQuFGqivDMMjMLWB/0RVdZ3t89h+zj/wcyj5Nab+tHhaICfY7734+RVd5Bft7V92bEfdyIq14Kog934OtoHhdYPTZhuRBENcLvHzMq1PcmsJNKRRuxFWdLijkQOap4tNdjkvb7SGotLs4AwT7ef8h9BSHoJhgPzzV5CxlcToLdi61B52dSyH/RPE6a5C9ETn+Ovudkn31b6xUHIWbUijciDsyDIMjJ/L+EHqKQ9DRk6Vf2u7taaFeqL/TTQyLQlD9MH/N1i4lO5MHe38obkg+mV68ztPHPtdVUUNyrSjz6hS3oHBTCoUbqYly88849/ecc7or9XguBYWl/zMQHlh8aXtRj0/R6a9ITVwqYG9IPrDm7B2Sv4Zju85ZabHPXh4/CFoMhtqNTStTXJfCTSkUbkScFZ6du+tCd3LOzC0odX9fbw9iQ88f7Sma00uXttdQR3YUTwVxYLXzuoj44jmvYjqoIVnKROGmFAo3Ipcm61TBH0JPcaPzwczS5+8CiKxlLTH41A/zJ0KjPjVD9sHihuS9P4DtnKsCa9Upbkhu0EMNyXJBCjelULgRqTgFhTYOHD/lGOVJPWfEpyyXtmvUpwY6lXn2Dslfn21IPlm8zhoMza4925DcF6y1TCtTqh+Fm1Io3IhUjaJL2889xZV6Tr/PxWZtB436uD1HQ/LX9hsH5hwuXudphUZ9zjYkD4DASNPKlOpB4aYUCjci1UP+GRsHM88f9SlqdNaoTw1js9l7c7Z9ZQ87GXvOWWmB2ITiPh01JNdICjelULgRqf4qatSnaOoKjfq4GMOAI8nFDckH1zqvj2x5TkNye9D3skZQuCmFwo2I66uoUZ+Swo9GfaqhrANnG5K/hn0/OTckB9U7pyG5O3jqTtzuSuGmFAo3Iu5Noz5u7tRxeyPytq9gVxIU5BSv8w2BZv3tQadJX/AJMK1MqXgKN6VQuBGp2TTq40YKTsGe5WfvkLwIco8Wr/PyhUZXFTckB4SbVqZUDIWbUijciMiFaNTHhdkKIfXX4pnMj+8rXmfxgNgrivt0whqaVqaUn8JNKRRuRKS8NOrjIgwD0rcU9+kc2uC8Pqp1cdCJbquGZBehcFMKhRsRqQwa9anGMlPsp622fQX7fwajsHhdcGxx0Kl/JXhqktjqSuGmFAo3ImIGjfpUE7kZsOMb+4jOriQ4c6p4nV9ocUNy46vVkFzNKNyUQuFGRKqbihj1iQqyOoKORn3KKD/3nIbkhXAqo3idl5894MQPsgeegNqmlSl2CjelULgREVdTEaM+547yaNSnBIVnIPUX+zQQ27+yn8oqYvGA+t2KT1+FxplWZk2mcFMKhRsRcSca9akERQ3JRVdepW10Xh/V5pyG5DZqSK4iCjelULgRkZpEoz4VIDPlbNBZcH5Dckh9+yzm8YPsl5urIbnSKNyUQuFGRMROoz7lkJsBOxbbg855Dclh9hsGxl8Hja8Cbz/z6nRDCjelULgRESkbjfpcRH4u7P7OHnR2LLJPDVHE2/9sQ/J10Kwf+IeZV6ebULgphcKNiMjl06jPHxSegZSVxX06WanF6yye0ODKs6evBtpPZcklU7gphcKNiEjlq9GjPoZhvyty8kJ72Enf7Lw+um1xn05UKzUkl5HCTSkUbkREzFXjRn0y9hYHnZSVYNiK14U0KA469a8Aj2oc2kymcFMKhRsRkerNrUd9co4WNyTv/g7OnC5e518bmg04e4dkNST/kcJNKRRuRERcl1uN+uTnFDckJy+C05nF67z9oUlf+6hO02vVkIzCTakUbkRE3JfLjvoUFpzTkLzg/IbkuO72oNN8IITEVk4N1ZzCTSkUbkREaiaXGfUpakguCjqHtzivj2kH8YPtp68iW9SYhmSFm1Io3IiISEmq7ahPxp6zQWehfXSHc/5shzY8OxXEdRDb1a0bkhVuSqFwIyIil6rajPqcPOLckFyYV7zOP7z4DsmN+oC372W95+pG4aYUCjciIlLRTBn1yTt5tiH5a3vgOZ1VvM47AJomnm1Ivgb8Qiv4HVc9hZtSKNyIiEhVqtRRn9r+RARasdjOwP4VxX062QeKd/bwgrgexQ3JwXUr9w1XEpcLN6+99hovvPACaWlptGvXjldffZWuXbtecPvPPvuMp556in379tG0aVOee+45Bg4cWKbXUrgREZHqpMJHfUL9aGXZS5OM7wlJWYLHkW3OO9TpcLZPZzBENHeZhmSXCjdz5sxhxIgRzJo1i4SEBKZPn85nn31GcnIykZGR523/888/06tXL6ZNm8Z1113HRx99xHPPPcfatWtp3br1RV9P4UZERFxFRYz6dKqVwfW+6+l55lcantqM5ZyGZCOsMZaihuR6XcDDo5LfUfm5VLhJSEigS5cuzJgxAwCbzUZsbCz33Xcfjz322HnbDxs2jJycHL7++mvHsiuuuIL27dsza9asi76ewo2IiLiLSx31CSeLvp5rudZjNT08NmO1FDjWnfQK42Bkb041upbA+u3x8Sr/lVfeVl+i6zYo9/4luZS/314V+sqXKD8/nzVr1jBhwgTHMg8PDxITE1m5cmWJ+6xcuZLx48c7LevXrx/z5s0rcfu8vDzy8oq7ybOzsy+/cBERkWrAx8uDuPAA4sIDzlt34VGfRkw8NpDsrAx6WDZyredq+nqsI+hMBs0OzoWDcy+7ru1eLYh+8pfLfp7yMjXcHD16lMLCQqKiopyWR0VFsX379hL3SUtLK3H7tLS0ErefNm0aU6ZMqZiCRUREXITFYiE0wIfQAB/axYact94+6jOAlIxcvjqahcf+FUSnLSP+xM+E2jIu67UNT+/L2v9ymRpuqsKECROcRnqys7OJja2Zt64WEREp4jTq0ywCrmwCjKyQ525RIc9SfqaGm/DwcDw9PUlPT3danp6eTnR0dIn7REdHX9L2VqsVq9VaMQWLiIhItWdqW7SPjw+dOnUiKSnJscxms5GUlES3bt1K3Kdbt25O2wMsXbr0gtuLiIhIzWL6aanx48czcuRIOnfuTNeuXZk+fTo5OTmMHj0agBEjRlC3bl2mTZsGwAMPPEDv3r156aWXGDRoEJ988gmrV6/mzTffNPNtiIiISDVhergZNmwYR44cYeLEiaSlpdG+fXsWL17saBpOSUnB45zr7q+88ko++ugjnnzySR5//HGaNm3KvHnzynSPGxEREXF/pt/npqrpPjciIiKu51L+flffWxGKiIiIlIPCjYiIiLgVhRsRERFxKwo3IiIi4lYUbkRERMStKNyIiIiIW1G4EREREbeicCMiIiJuReFGRERE3Irp0y9UtaIbMmdnZ5tciYiIiJRV0d/tskysUOPCzYkTJwCIjY01uRIRERG5VCdOnCA4OLjUbWrc3FI2m42DBw9Sq1YtLBZLhT53dnY2sbGxpKamat6qi9CxKjsdq7LTsbo0Ol5lp2NVdpV1rAzD4MSJE9SpU8dpQu2S1LiRGw8PD+rVq1eprxEUFKQf/jLSsSo7Hauy07G6NDpeZadjVXaVcawuNmJTRA3FIiIi4lYUbkRERMStKNxUIKvVyqRJk7BarWaXUu3pWJWdjlXZ6VhdGh2vstOxKrvqcKxqXEOxiIiIuDeN3IiIiIhbUbgRERERt6JwIyIiIm5F4UZERETcisJNBXnttdeIi4vD19eXhIQEVq1aZXZJlW7y5MlYLBanR3x8vGP96dOnGTduHLVr1yYwMJCbbrqJ9PR0p+dISUlh0KBB+Pv7ExkZySOPPMKZM2ectlm+fDkdO3bEarXSpEkT3n333ap4e5flhx9+YPDgwdSpUweLxcK8efOc1huGwcSJE4mJicHPz4/ExER27tzptE1GRgbDhw8nKCiIkJAQ/vrXv3Ly5EmnbTZu3EjPnj3x9fUlNjaW559//rxaPvvsM+Lj4/H19aVNmzYsXLiwwt/v5bjYsRo1atR5P2f9+/d32qamHKtp06bRpUsXatWqRWRkJEOGDCE5Odlpm6r8vavO/+6V5Vj16dPnvJ+tu+++22mbmnCsZs6cSdu2bR033evWrRuLFi1yrHfJnylDLtsnn3xi+Pj4GG+//baxZcsWY8yYMUZISIiRnp5udmmVatKkSUarVq2MQ4cOOR5HjhxxrL/77ruN2NhYIykpyVi9erVxxRVXGFdeeaVj/ZkzZ4zWrVsbiYmJxrp164yFCxca4eHhxoQJExzb7Nmzx/D39zfGjx9vbN261Xj11VcNT09PY/HixVX6Xi/VwoULjSeeeML44osvDMCYO3eu0/pnn33WCA4ONubNm2ds2LDBuP76642GDRsap06dcmzTv39/o127dsYvv/xi/Pjjj0aTJk2M2267zbE+KyvLiIqKMoYPH25s3rzZ+Pjjjw0/Pz/jjTfecGyzYsUKw9PT03j++eeNrVu3Gk8++aTh7e1tbNq0qdKPQVld7FiNHDnS6N+/v9PPWUZGhtM2NeVY9evXz3jnnXeMzZs3G+vXrzcGDhxo1K9f3zh58qRjm6r6vavu/+6V5Vj17t3bGDNmjNPPVlZWlmN9TTlWX375pbFgwQJjx44dRnJysvH4448b3t7exubNmw3DcM2fKYWbCtC1a1dj3Lhxjq8LCwuNOnXqGNOmTTOxqso3adIko127diWuy8zMNLy9vY3PPvvMsWzbtm0GYKxcudIwDPsfNQ8PDyMtLc2xzcyZM42goCAjLy/PMAzD+Mc//mG0atXK6bmHDRtm9OvXr4LfTeX54x9sm81mREdHGy+88IJjWWZmpmG1Wo2PP/7YMAzD2Lp1qwEYv/32m2ObRYsWGRaLxThw4IBhGIbx+uuvG6GhoY5jZRiG8eijjxrNmzd3fH3LLbcYgwYNcqonISHB+Nvf/lah77GiXCjc3HDDDRfcp6YeK8MwjMOHDxuA8f333xuGUbW/d672794fj5Vh2MPNAw88cMF9auqxMgzDCA0NNd566y2X/ZnSaanLlJ+fz5o1a0hMTHQs8/DwIDExkZUrV5pYWdXYuXMnderUoVGjRgwfPpyUlBQA1qxZQ0FBgdNxiY+Pp379+o7jsnLlStq0aUNUVJRjm379+pGdnc2WLVsc25z7HEXbuPKx3bt3L2lpaU7vKzg4mISEBKdjExISQufOnR3bJCYm4uHhwa+//urYplevXvj4+Di26devH8nJyRw/ftyxjTscv+XLlxMZGUnz5s0ZO3Ysx44dc6yryccqKysLgLCwMKDqfu9c8d+9Px6rIh9++CHh4eG0bt2aCRMmkJub61hXE49VYWEhn3zyCTk5OXTr1s1lf6Zq3MSZFe3o0aMUFhY6fVMBoqKi2L59u0lVVY2EhATeffddmjdvzqFDh5gyZQo9e/Zk8+bNpKWl4ePjQ0hIiNM+UVFRpKWlAZCWllbicStaV9o22dnZnDp1Cj8/v0p6d5Wn6L2V9L7Ofd+RkZFO6728vAgLC3PapmHDhuc9R9G60NDQCx6/oudwBf379+fGG2+kYcOG7N69m8cff5wBAwawcuVKPD09a+yxstlsPPjgg3Tv3p3WrVsDVNnv3fHjx13q372SjhXA7bffToMGDahTpw4bN27k0UcfJTk5mS+++AKoWcdq06ZNdOvWjdOnTxMYGMjcuXNp2bIl69evd8mfKYUbKbcBAwY4Pm/bti0JCQk0aNCATz/91CVDh1RPt956q+PzNm3a0LZtWxo3bszy5cvp27eviZWZa9y4cWzevJmffvrJ7FKqvQsdq7vuusvxeZs2bYiJiaFv377s3r2bxo0bV3WZpmrevDnr168nKyuLzz//nJEjR/L999+bXVa56bTUZQoPD8fT0/O8zvH09HSio6NNqsocISEhNGvWjF27dhEdHU1+fj6ZmZlO25x7XKKjo0s8bkXrStsmKCjIZQNU0Xsr7WcmOjqaw4cPO60/c+YMGRkZFXL8XPlns1GjRoSHh7Nr1y6gZh6re++9l6+//pply5ZRr149x/Kq+r1zpX/3LnSsSpKQkADg9LNVU46Vj48PTZo0oVOnTkybNo127drxn//8x2V/phRuLpOPjw+dOnUiKSnJscxms5GUlES3bt1MrKzqnTx5kt27dxMTE0OnTp3w9vZ2Oi7JycmkpKQ4jku3bt3YtGmT0x+mpUuXEhQURMuWLR3bnPscRdu48rFt2LAh0dHRTu8rOzubX3/91enYZGZmsmbNGsc23333HTabzfEPcLdu3fjhhx8oKChwbLN06VKaN29OaGioYxt3O36///47x44dIyYmBqhZx8owDO69917mzp3Ld999d96ptqr6vXOFf/cudqxKsn79egCnn62acKxKYrPZyMvLc92fqUtuQZbzfPLJJ4bVajXeffddY+vWrcZdd91lhISEOHWOu6OHHnrIWL58ubF3715jxYoVRmJiohEeHm4cPnzYMAz75YP169c3vvvuO2P16tVGt27djG7dujn2L7p88NprrzXWr19vLF682IiIiCjx8sFHHnnE2LZtm/Haa6+5xKXgJ06cMNatW2esW7fOAIyXX37ZWLdunbF//37DMOyXgoeEhBjz5883Nm7caNxwww0lXgreoUMH49dffzV++ukno2nTpk6XN2dmZhpRUVHGHXfcYWzevNn45JNPDH9///Mub/by8jJefPFFY9u2bcakSZOq3eXNpR2rEydOGA8//LCxcuVKY+/evca3335rdOzY0WjatKlx+vRpx3PUlGM1duxYIzg42Fi+fLnT5cu5ubmObarq9666/7t3sWO1a9cuY+rUqcbq1auNvXv3GvPnzzcaNWpk9OrVy/EcNeVYPfbYY8b3339v7N2719i4caPx2GOPGRaLxViyZIlhGK75M6VwU0FeffVVo379+oaPj4/RtWtX45dffjG7pEo3bNgwIyYmxvDx8THq1q1rDBs2zNi1a5dj/alTp4x77rnHCA0NNfz9/Y2hQ4cahw4dcnqOffv2GQMGDDD8/PyM8PBw46GHHjIKCgqctlm2bJnRvn17w8fHx2jUqJHxzjvvVMXbuyzLli0zgPMeI0eONAzDfjn4U089ZURFRRlWq9Xo27evkZyc7PQcx44dM2677TYjMDDQCAoKMkaPHm2cOHHCaZsNGzYYPXr0MKxWq1G3bl3j2WefPa+WTz/91GjWrJnh4+NjtGrVyliwYEGlve/yKO1Y5ebmGtdee60RERFheHt7Gw0aNDDGjBlz3j92NeVYlXScAKffiar8vavO/+5d7FilpKQYvXr1MsLCwgyr1Wo0adLEeOSRR5zuc2MYNeNY/eUvfzEaNGhg+Pj4GBEREUbfvn0dwcYwXPNnymIYhnHp4z0iIiIi1ZN6bkRERMStKNyIiIiIW1G4EREREbeicCMiIiJuReFGRERE3IrCjYiIiLgVhRsRERFxKwo3IlIjWSwW5s2bZ3YZIlIJFG5EpMqNGjUKi8Vy3qN///5mlyYibsDL7AJEpGbq378/77zzjtMyq9VqUjUi4k40ciMiprBarURHRzs9imbotlgszJw5kwEDBuDn50ejRo34/PPPnfbftGkTV199NX5+ftSuXZu77rqLkydPOm3z9ttv06pVK6xWKzExMdx7771O648ePcrQoUPx9/enadOmfPnll451x48fZ/jw4URERODn50fTpk3PC2MiUj0p3IhItfTUU09x0003sWHDBoYPH86tt97Ktm3bAMjJyaFfv36Ehoby22+/8dlnn/Htt986hZeZM2cybtw47rrrLjZt2sSXX35JkyZNnF5jypQp3HLLLWzcuJGBAwcyfPhwMjIyHK+/detWFi1axLZt25g5cybh4eFVdwBEpPzKNd2miMhlGDlypOHp6WkEBAQ4Pf71r38ZhmGf0fnuu+922ichIcEYO3asYRiG8eabbxqhoaHGyZMnHesXLFhgeHh4OGYMr1OnjvHEE09csAbAePLJJx1fnzx50gCMRYsWGYZhGIMHDzZGjx5dMW9YRKqUem5ExBRXXXUVM2fOdFoWFhbm+Lxbt25O67p168b69esB2LZtG+3atSMgIMCxvnv37thsNpKTk7FYLBw8eJC+ffuWWkPbtm0dnwcEBBAUFMThw4cBGDt2LDfddBNr167l2muvZciQIVx55ZXleq8iUrUUbkTEFAEBAeedJqoofn5+ZdrO29vb6WuLxYLNZgNgwIAB7N+/n4ULF7J06VL69u3LuHHjePHFFyu8XhGpWOq5EZFq6Zdffjnv6xYtWgDQokULNmzYQE5OjmP9ihUr8PDwoHnz5tSqVYu4uDiSkpIuq4aIiAhGjhzJf//7X6ZPn86bb755Wc8nIlVDIzciYoq8vDzS0tKclnl5eTmadj/77DM6d+5Mjx49+PDDD1m1ahX/93//B8Dw4cOZNGkSI0eOZPLkyRw5coT77ruPO+64g6ioKAAmT57M3XffTWRkJAMGDODEiROsWLGC++67r0z1TZw4kU6dOtGqVSvy8vL4+uuvHeFKRKo3hRsRMcXixYuJiYlxWta8eXO2b98O2K9k+uSTT7jnnnuIiYnh448/pmXLlgD4+/vzzTff8MADD9ClSxf8/f256aabePnllx3PNXLkSE6fPs2///1vHn74YcLDw7n55pvLXJ+Pjw8TJkxg3759+Pn50bNnTz755JMKeOciUtkshmEYZhchInIui8XC3LlzGTJkiNmliIgLUs+NiIiIuBWFGxEREXEr6rkRkWpHZ8tF5HJo5EZERETcisKNiIiIuBWFGxEREXErCjciIiLiVhRuRERExK0o3IiIiIhbUbgRERERt6JwIyIiIm5F4UZERETcyv8Dlhv8gm3QoIUAAAAASUVORK5CYII=\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with torch.inference_mode():\n",
        "  y_preds_new = model_0(X_test)\n",
        "\n",
        "y_preds"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oR0Pk993sQdQ",
        "outputId": "67d9e9cd-417f-4d74-e82b-2d8388d650d6"
      },
      "execution_count": 121,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.3375],\n",
              "        [0.3401],\n",
              "        [0.3427],\n",
              "        [0.3452],\n",
              "        [0.3478],\n",
              "        [0.3504],\n",
              "        [0.3530],\n",
              "        [0.3555],\n",
              "        [0.3581],\n",
              "        [0.3607]])"
            ]
          },
          "metadata": {},
          "execution_count": 121
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_0.state_dict()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d1gEyyRRwR4C",
        "outputId": "4624c4ff-45f2-427f-9a5b-72193bfdf99c"
      },
      "execution_count": 122,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "OrderedDict([('weights', tensor([0.6999])), ('bias', tensor([0.3000]))])"
            ]
          },
          "metadata": {},
          "execution_count": 122
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "weight,bias"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fx_HnM4RwcHN",
        "outputId": "8d05058c-5bf9-4949-e831-d9e56082957d"
      },
      "execution_count": 123,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.7, 0.3)"
            ]
          },
          "metadata": {},
          "execution_count": 123
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plot_predictions(predictions=y_preds)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 430
        },
        "id": "LL4Y_hCJviqs",
        "outputId": "f431ad81-51b7-4cc1-f083-7583ff1f368e"
      },
      "execution_count": 124,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plot_predictions(predictions=y_preds_new)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 430
        },
        "id": "ubCA0qntkZtq",
        "outputId": "ac9585ff-0d39-4036-9244-1781831651b2"
      },
      "execution_count": 125,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Saving a model in Pytorch\n",
        "\n",
        "There are three main method you should for saving and loading models in Pytorch.\n",
        "\n",
        "1. `torch.save()` - allows you save a Pytorch object in Python's pickle format\n",
        "\n",
        "2. `torch.load()` - allows you load a saved Pytorch object\n",
        "\n",
        "3. `torch.nn.module.load_state_dict()` - this allows to load a model's saved state dictionary"
      ],
      "metadata": {
        "id": "DIUBdHgj69iY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# saving our Pytorch model\n",
        "from pathlib import Path\n",
        "\n",
        "# Create a model directory\n",
        "MODEL_PATH = Path(\"models\")\n",
        "MODEL_PATH.mkdir(parents=True , exist_ok=True)\n",
        "\n",
        "# 2 Create model save\n",
        "MODEL_NAME  = \"01_pytorch_workflow_model_0.pth\"\n",
        "MODEL_SAVE_PATH = MODEL_PATH / MODEL_NAME\n",
        "\n",
        "#3.save the model state dict\n",
        "print(f\"saving model to: {MODEL_SAVE_PATH}\")\n",
        "torch.save(obj=model_0.state_dict(),\n",
        "           f=MODEL_SAVE_PATH)"
      ],
      "metadata": {
        "id": "NOFZ6k6cqap9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "76028a75-4673-4152-f182-6cc243e588a2"
      },
      "execution_count": 126,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "saving model to: models/01_pytorch_workflow_model_0.pth\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! ls -l models"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TPdtrv4tCIfl",
        "outputId": "ad7b8efd-0f66-4369-a31e-12293a17cf7d"
      },
      "execution_count": 127,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total 4\n",
            "-rw-r--r-- 1 root root 2117 Aug 27 19:28 01_pytorch_workflow_model_0.pth\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Loading a Pytorch model\n",
        "\n",
        "Since we saved our models `state_dict()` rather the entire model we'll create a new instance of our model and load the saved `state_dict()` into that\n"
      ],
      "metadata": {
        "id": "vLqi24QJhgaK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_0.state_dict()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G6O6QS6gf4a5",
        "outputId": "68c2166d-b661-4878-9dae-f386cf826b60"
      },
      "execution_count": 128,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "OrderedDict([('weights', tensor([0.6999])), ('bias', tensor([0.3000]))])"
            ]
          },
          "metadata": {},
          "execution_count": 128
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# To load in a saved state_dict we have to instantiate a new instance of our model class\n",
        "loaded_model_0 = LinearRegressionModel()\n",
        "\n",
        "# Load the saved state_dict of model_0 (this will update the new instance with updated parameters)\n",
        "loaded_model_0.load_state_dict(torch.load(f=MODEL_SAVE_PATH))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HweRHxCuiJ7q",
        "outputId": "389ea925-e48b-4e50-8909-99f44f1d8d08"
      },
      "execution_count": 129,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 129
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loaded_model_0.state_dict()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tgDhIBGmlIjs",
        "outputId": "24df2254-eb9e-4d4d-8dd1-0db7143f954d"
      },
      "execution_count": 130,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "OrderedDict([('weights', tensor([0.6999])), ('bias', tensor([0.3000]))])"
            ]
          },
          "metadata": {},
          "execution_count": 130
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Make some prediction with our loaded model\n",
        "loaded_model_0.eval()\n",
        "with torch.inference_mode():\n",
        "  loaded_model_preds = loaded_model_0(X_test)\n",
        "\n",
        "loaded_model_preds"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0mbgXOEFlSY-",
        "outputId": "8cb4f34a-bab4-4667-c073-03a96400ab0b"
      },
      "execution_count": 131,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.8599],\n",
              "        [0.8739],\n",
              "        [0.8879],\n",
              "        [0.9019],\n",
              "        [0.9159],\n",
              "        [0.9299],\n",
              "        [0.9439],\n",
              "        [0.9579],\n",
              "        [0.9719],\n",
              "        [0.9859]])"
            ]
          },
          "metadata": {},
          "execution_count": 131
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Make some models preds\n",
        "model_0.eval()\n",
        "with torch.inference_mode():\n",
        "  y_preds = model_0(X_test)\n",
        "\n",
        "\n",
        "  y_preds"
      ],
      "metadata": {
        "id": "jy6e4g3Zm4St"
      },
      "execution_count": 132,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# compare loaded model preds with original model preds\n",
        "y_preds == loaded_model_preds"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Sl1sudkgmudf",
        "outputId": "83fa2d6d-0334-4a64-922b-c4a07f4a7e9b"
      },
      "execution_count": 133,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[True],\n",
              "        [True],\n",
              "        [True],\n",
              "        [True],\n",
              "        [True],\n",
              "        [True],\n",
              "        [True],\n",
              "        [True],\n",
              "        [True],\n",
              "        [True]])"
            ]
          },
          "metadata": {},
          "execution_count": 133
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "learn saving and loading model"
      ],
      "metadata": {
        "id": "XK9qhPYYrKiI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 6.Putting it all together\n",
        "\n",
        "Lets go back through the steps above and see it all in one place"
      ],
      "metadata": {
        "id": "ZYhRHMoTrivM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import Pytorch and matplotlib\n",
        "import torch\n",
        "from torch import nn\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "#Check Pytorch version\n",
        "torch.__version__"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "Qc_CKYmam71-",
        "outputId": "8877a387-3ec9-450a-d999-b81960174eb3"
      },
      "execution_count": 134,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'2.8.0+cu126'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 134
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Create device_agnostic code.\n",
        "\n",
        "This means if we've got acesss to a GPU , our code (for potentially faster computing).\n",
        "\n",
        "If no GPU is available ,the code will default to using CPU"
      ],
      "metadata": {
        "id": "4q-Tb8Dssbza"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Setup device agnostic code\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(f\"Using device: {device}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QdKa1lr7s3X-",
        "outputId": "ec656cdb-b2ed-4444-8c7d-97a610ae16b2"
      },
      "execution_count": 135,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cpu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hPLjwNlxtQZ9",
        "outputId": "bab0ba11-ca94-4a27-b683-a0a5cd361a83"
      },
      "execution_count": 136,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/bin/bash: line 1: nvidia-smi: command not found\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 6.1 Data"
      ],
      "metadata": {
        "id": "-oHbXJhKrwBS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        " # Create some data using the linear regression formula of y = weight * X + bias\n",
        " weight = 0.7\n",
        " bias =0.3\n",
        "\n",
        " # Create range values\n",
        " start =0\n",
        " end = 1\n",
        " step =0.02\n",
        "\n",
        " # Create X and y (features  and labels)\n",
        "\n",
        "X = torch.arange(start,end,step).unsqueeze(dim=1)#without unsqueeze, error will pop up\n",
        "y = weight * X + bias\n",
        "X[:10], y[:10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-OEZWiw_sEoR",
        "outputId": "5501393f-f247-4abd-fddb-f35084edc5d8"
      },
      "execution_count": 137,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([[0.0000],\n",
              "         [0.0200],\n",
              "         [0.0400],\n",
              "         [0.0600],\n",
              "         [0.0800],\n",
              "         [0.1000],\n",
              "         [0.1200],\n",
              "         [0.1400],\n",
              "         [0.1600],\n",
              "         [0.1800]]),\n",
              " tensor([[0.3000],\n",
              "         [0.3140],\n",
              "         [0.3280],\n",
              "         [0.3420],\n",
              "         [0.3560],\n",
              "         [0.3700],\n",
              "         [0.3840],\n",
              "         [0.3980],\n",
              "         [0.4120],\n",
              "         [0.4260]]))"
            ]
          },
          "metadata": {},
          "execution_count": 137
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Split data\n",
        "train_split = int(0.8 * len(X))\n",
        "X_train, y_train = X[:train_split], y[:train_split]\n",
        "X_test, y_test = X[train_split:], y[train_split:]\n",
        "len(X_train), len(y_train), len(X_test), len(y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qzzw1LbOy_hq",
        "outputId": "f9d490f4-d960-439a-cea9-20aff703aa8c"
      },
      "execution_count": 138,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(40, 40, 10, 10)"
            ]
          },
          "metadata": {},
          "execution_count": 138
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Plot the data\n",
        "# Note: if you dont have the plot_prediction() function loaded,this will error\n",
        "plot_predictions(X_train,y_train,X_test,y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 430
        },
        "id": "0hd8v1tozrhP",
        "outputId": "a3def473-21b2-471a-e81a-1aa841bfd46b"
      },
      "execution_count": 139,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#6.2 Building a Pytorch linear model"
      ],
      "metadata": {
        "id": "PLY77gnt0lHS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a linear model by subclassing nn.Module\n",
        "class LinearRegressionModelV2(nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    # Use nn.Linear() for creating thre model parameters / also called : linear transform\n",
        "    self.linear_layer = nn.Linear(in_features=1,\n",
        "                                  out_features=1)\n",
        "\n",
        "  # Correctly define the forward method outside of __init__\n",
        "  def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
        "    return self.linear_layer(x)\n",
        "\n",
        "#Set the manual seed\n",
        "torch.manual_seed(42)\n",
        "model_1 = LinearRegressionModelV2()\n",
        "model_1, model_1.state_dict()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8ZAn8ckF0S3Y",
        "outputId": "d18e2e33-013c-4617-80be-90d6ad3a3a93"
      },
      "execution_count": 140,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(LinearRegressionModelV2(\n",
              "   (linear_layer): Linear(in_features=1, out_features=1, bias=True)\n",
              " ),\n",
              " OrderedDict([('linear_layer.weight', tensor([[0.7645]])),\n",
              "              ('linear_layer.bias', tensor([0.8300]))]))"
            ]
          },
          "metadata": {},
          "execution_count": 140
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train[:5], y_train[:5]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tHMerqco1-nz",
        "outputId": "1b78dcce-34c7-406f-9a32-da78cd3b7d22"
      },
      "execution_count": 141,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([[0.0000],\n",
              "         [0.0200],\n",
              "         [0.0400],\n",
              "         [0.0600],\n",
              "         [0.0800]]),\n",
              " tensor([[0.3000],\n",
              "         [0.3140],\n",
              "         [0.3280],\n",
              "         [0.3420],\n",
              "         [0.3560]]))"
            ]
          },
          "metadata": {},
          "execution_count": 141
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_1.state_dict()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3EUMolDO2rtO",
        "outputId": "48f15401-64b4-42c2-ac15-a85007273dfc"
      },
      "execution_count": 142,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "OrderedDict([('linear_layer.weight', tensor([[0.7645]])),\n",
              "             ('linear_layer.bias', tensor([0.8300]))])"
            ]
          },
          "metadata": {},
          "execution_count": 142
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Setthe model to use the target device\n",
        "next(model_1.parameters()).device"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wa3W3HtG4fcK",
        "outputId": "f9f89038-37b8-435a-c76c-d4a4e6c81599"
      },
      "execution_count": 143,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cpu')"
            ]
          },
          "metadata": {},
          "execution_count": 143
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Set the model to use the target device\n",
        "model_1.to(device)\n",
        "next(model_1.parameters()).device"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B6cN9yIu68B2",
        "outputId": "711d462b-d9a7-450f-ffba-21080b488008"
      },
      "execution_count": 144,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cpu')"
            ]
          },
          "metadata": {},
          "execution_count": 144
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 6.3 Training\n",
        "\n",
        "For trainig we needd:\n",
        "* Loss function\n",
        "* Optimizer\n",
        "* Training loop\n",
        "* Testing loop"
      ],
      "metadata": {
        "id": "FigU5oKc7RE2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Setup loss function\n",
        "loss_fn = nn.L1Loss() # same as MAE\n",
        "\n",
        "#Setup our optimizer\n",
        "optimizer = torch.optim.SGD(params=model_1.parameters(),\n",
        "                            lr=0.01)"
      ],
      "metadata": {
        "id": "Nd-PGPjh7My9"
      },
      "execution_count": 145,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(42)\n",
        "\n",
        "# Set the number of epochs\n",
        "epochs = 1000\n",
        "\n",
        "# Put data on the available device\n",
        "# Without this, error will happen (not all model/data on device)\n",
        "X_train = X_train.to(device)\n",
        "X_test = X_test.to(device)\n",
        "y_train = y_train.to(device)\n",
        "y_test = y_test.to(device)\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    ### Training\n",
        "    model_1.train() # train mode is on by default after construction\n",
        "\n",
        "    # 1. Forward pass\n",
        "    y_pred = model_1(X_train)\n",
        "\n",
        "    # 2. Calculate loss\n",
        "    loss = loss_fn(y_pred, y_train)\n",
        "\n",
        "    # 3. Zero grad optimizer\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    # 4. Loss backward\n",
        "    loss.backward()\n",
        "\n",
        "    # 5. Step the optimizer\n",
        "    optimizer.step()\n",
        "\n",
        "    ### Testing\n",
        "    model_1.eval() # put the model in evaluation mode for testing (inference)\n",
        "    # 1. Forward pass\n",
        "    with torch.inference_mode():\n",
        "        test_pred = model_1(X_test)\n",
        "\n",
        "        # 2. Calculate the loss\n",
        "        test_loss = loss_fn(test_pred, y_test)\n",
        "\n",
        "    if epoch % 100 == 0:\n",
        "        print(f\"Epoch: {epoch} | Train loss: {loss} | Test loss: {test_loss}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nwBGCw6z8BoT",
        "outputId": "53d9752a-b5ed-437f-fe2a-b02b286d0261"
      },
      "execution_count": 146,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 0 | Train loss: 0.5551779866218567 | Test loss: 0.5739762187004089\n",
            "Epoch: 100 | Train loss: 0.006215679459273815 | Test loss: 0.014086711220443249\n",
            "Epoch: 200 | Train loss: 0.0012645035749301314 | Test loss: 0.013801807537674904\n",
            "Epoch: 300 | Train loss: 0.0012645035749301314 | Test loss: 0.013801807537674904\n",
            "Epoch: 400 | Train loss: 0.0012645035749301314 | Test loss: 0.013801807537674904\n",
            "Epoch: 500 | Train loss: 0.0012645035749301314 | Test loss: 0.013801807537674904\n",
            "Epoch: 600 | Train loss: 0.0012645035749301314 | Test loss: 0.013801807537674904\n",
            "Epoch: 700 | Train loss: 0.0012645035749301314 | Test loss: 0.013801807537674904\n",
            "Epoch: 800 | Train loss: 0.0012645035749301314 | Test loss: 0.013801807537674904\n",
            "Epoch: 900 | Train loss: 0.0012645035749301314 | Test loss: 0.013801807537674904\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_1.state_dict()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pzTTkDgu-nOC",
        "outputId": "ce820290-85fe-46bd-e220-c3e2df08749c"
      },
      "execution_count": 147,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "OrderedDict([('linear_layer.weight', tensor([[0.6968]])),\n",
              "             ('linear_layer.bias', tensor([0.3025]))])"
            ]
          },
          "metadata": {},
          "execution_count": 147
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "weight,bias"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CxFFb75OATJ7",
        "outputId": "46d590fd-76fc-4b1d-dfc5-150313dbdc96"
      },
      "execution_count": 148,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.7, 0.3)"
            ]
          },
          "metadata": {},
          "execution_count": 148
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 6.4 Making and evaluating predictions"
      ],
      "metadata": {
        "id": "mZLaoTizBTiW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Turn model into evaluation mode\n",
        "model_1.eval()\n",
        "\n",
        "#Make prediction on the test data\n",
        "with torch.inference_mode():\n",
        "  y_preds = model_1(X_test)\n",
        "\n",
        "y_preds"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E0-TB6DEAWVR",
        "outputId": "a3e01b7b-c2a4-446e-c302-fe438a771a41"
      },
      "execution_count": 149,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.8600],\n",
              "        [0.8739],\n",
              "        [0.8878],\n",
              "        [0.9018],\n",
              "        [0.9157],\n",
              "        [0.9296],\n",
              "        [0.9436],\n",
              "        [0.9575],\n",
              "        [0.9714],\n",
              "        [0.9854]])"
            ]
          },
          "metadata": {},
          "execution_count": 149
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Check our model prediction visually\n",
        "\n",
        "plot_predictions(predictions=y_preds.cpu())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 430
        },
        "id": "bUYW0HNGBvEE",
        "outputId": "42a4fe4b-d66b-4914-b846-1fc12e511af1"
      },
      "execution_count": 152,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "p5IMxqk7CR_P"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}